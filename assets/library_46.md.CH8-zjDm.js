import{_ as h,o as a,c as n,a as t,m as c,t as d,C as f,M as g,U as y,F as b,p as w,e as v,f as x,q as T}from"./chunks/framework.B1z0IdBH.js";const k={name:"PoemCard",props:{poem:{type:Object,required:!0}}},A={class:"poem-container"},C={class:"review"},I={class:"review-title"},S={class:"review-content"};function P(i,e,l,u,o,s){return a(),n("div",A,[t("div",C,[t("div",I,[e[0]||(e[0]=t("span",{class:"icon"},"question:",-1)),c(d(l.poem.question),1)]),e[2]||(e[2]=t("div",{class:"divider"},null,-1)),t("p",S,[e[1]||(e[1]=t("span",{class:"icon"},"answer:",-1)),c(d(l.poem.answer),1)])])])}const R=h(k,[["render",P],["__scopeId","data-v-66c4de5a"]]),O=JSON.parse(`[{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: Now a days, due to staying indoors, it is possible that you will develop the deficiency of vitamin D.Abstract:Importance: Vitamin D treatment has been found to decrease incidence of viral respiratory tract infection, especially in vitamin D deficiency.It is unknown whether COVID-19 incidence is associated with vitamin D deficiency and treatment.Objective: To examine whether vitamin D deficiency and treatment are associated with testing positive for COVID-19.Design: Retrospective cohort study Setting: University of Chicago Medicine Participants: Patients tested for COVID-19 from 3/3/2020-4/10/2020.Vitamin D deficiency was defined by the most recent 25-hydroxycholecalciferol <20ng/ml or 1,25-dihydroxycholecalciferol <18pg/ml within 1 year before COVID-19 testing.Treatment was defined by the most recent vitamin D type and dose, and treatment changes between the time of the most recent vitamin D level and time of COVID-19 testing.Vitamin D deficiency and treatment changes were combined to categorize vitamin D status at the time of COVID-19 testing as likely deficient(last-level-deficient/treatment-not-increased), likely sufficient(last-level-not-deficient/treatment-not-decreased), or uncertain deficiency(last-level-deficient/treatment-increased or last-level-not-deficient/treatment-decreased).Main Outcomes and Measures: The main outcome was testing positive for COVID-19.Multivariable analysis tested whether the most recent vitamin D level and treatment changes after that level were associated with testing positive for COVID-19 controlling for demographic and comorbidity indicators.Bivariate analyses of associations of treatment with vitamin D deficiency and COVID-19 were performed.Results: Among 4,314 patients tested for COVID-19, 499 had a vitamin D level in the year before testing.Vitamin D status at the time of COVID-19 testing was categorized as likely deficient for 127(25%) patients, likely sufficient for 291(58%) patients, and uncertain for 81(16%) patients.In multivariate analysis, testing positive for COVID-19 was associated with increasing age(RR(age<50)=1.05,p<0.021;RR(age[≥]50)=1.02,p<0.064)), non-white race(RR=2.54,p<0.01) and being likely vitamin D deficient (deficient/treatment-not-increased:RR=1.77,p<0.02) as compared to likely vitamin D sufficient(not-deficient/treatment-not-decreased), with predicted COVID-19 rates in the vitamin D deficient group of 21.6%(95%CI[14.0%-29.2%] ) versus 12.2%(95%CI[8.9%-15.4%]) in the vitamin D sufficient group.Vitamin D deficiency declined with increasing vitamin D dose, especially of vitamin D3.Vitamin D dose was not significantly associated with testing positive for COVID-19.Conclusions and Relevance: Vitamin D deficiency that is not sufficiently treated is associated with COVID-19 risk.Testing and treatment for vitamin D deficiency to address COVID-19 warrant aggressive pursuit and study.","answer":"{\\"verdict\\": \\"NEI\\", \\"evidence\\": []}"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the properties of the @xmath7 boson have been measured to very high precision at lep@xcite .naturally one wants to match this precision for the charged carriers of the electroweak interaction . over the next few yearsthe tevatron is the only accelerator which can produce @xmath2 bosons .measuring the properties of the @xmath2 boson to a very high precision is an important test of the standard model . from the measured @xmath2 cross section, one can infer an indirect measurement of the @xmath2 width and lepton universality . since at the tevatronthe @xmath2 bosons are produced through quark anti - quark annihilation , a significant uncertainty for all direct electroweak measurements comes from the knowledge of the parton distributions inside the proton .the probability of finding a parton carrying a momentum fraction @xmath8 within the incoming proton is expressed in the parton distribution function ( pdf ) .the measurement of the @xmath2 charge asymmetry provides important input on the ratio of the @xmath9 and @xmath10 quark components of the pdf and will help to further constrain parton distribution functions .the @xmath2 boson mass serves as a test of the standard model , but through radiative corrections is also sensitive to hypothetical new particles .together with a precise measurement of the top quark mass@xcite , the @xmath2 boson mass constrains the mass of the higgs boson , which has not yet been observed experimentally .both cdf and d are multi - purpose detectors .they consist of tracking systems surrounded by calorimeter and muon identification systems .cdf s tracking system consists of a wire drift chamber ( the central outer tracker ) and a 7-layer silicon microstrip vertex detector ( svxii ) immersed in a 1.4 t magnetic field . a lead ( iron ) scintillator sampling calorimeteris used for measuring electromagnetic ( hadronic ) showers .d employs a silicon microstrip tracker ( smt ) and a central fiber tracker ( cft ) , both located in a 2 t magnetic field .the sampling calorimeter consists of liquid argon and uranium .since the hadronic decay of the @xmath2 boson has an extremely large background originating from strongly interacting processes , cdf and d use the clean leptonic decays to study the @xmath2 boson .the signature is a high energy lepton with large missing transverse momentum originating from the neutrino , which does not interact with the detector .the momentum balance in the direction of the beam is unconstrained and as a result , the @xmath2 events are studied in the plane transverse to the beam .a typically used quantity is the transverse mass : @xmath11 which is similar to the invariant mass , just in the two transverse dimensions . if not otherwise stated , we restrict the lepton identification to the well instrumented central region of @xmath12 .@xmath7 boson events are identified by two high energy leptons .these events have very low background .@xmath2 and @xmath7 bosons are identified by their leptonic decays to electrons , muons and taus , from which the total rates @xmath14br(@xmath15 ) and @xmath14br(@xmath16 ) are obtained .the cross section times branching ratio is calculated as follows : @xmath17 the @xmath2 and @xmath7 boson cross sections have been measured by cdf@xcite with different datasets in different sub - detectors .figure [ wzx ]    shows a summary of the cdf and d cross section measurements in all leptonic decay modes .all measurements show good agreement with nnlo calculations@xcite , represented by the vertical band .lepton universality in @xmath2 decays can be tested by extracting the ratio of the electroweak couplings @xmath18 and @xmath19 from the measured ratio of @xmath15 cross sections .the @xmath15 couplings are related to the measured production cross section ratio @xmath20 as follows : @xmath21 in this ratio , important systematic uncertainties cancel .the results obtained are@xcite : @xmath22 @xmath23 where the largest systematic uncertainty comes from event selection efficiencies .since these efficiencies are measured using the @xmath16 sample , the uncertainty will decrease as more @xmath7 bosons are collected .the ratio @xmath24 of the cross section measurements for @xmath2 and @xmath7 bosons can be used to extract the total width of the @xmath2 boson .@xmath24 can be expressed as : @xmath25 using the very precise measurement of @xmath26/@xmath27 from lep and nnlo calculations of @xmath28 , together with the standard model prediction of @xmath29 one can extract @xmath30 from equation [ indwidth ] .    0.1 in    ._ summary of indirect @xmath2 width measurements . _ [ cols=\\"<,^,^\\",options=\\"header \\" , ]     [ syst ]    for comparison the uncertainties from the previous collider run@xcite ( run 1b ) are also included .the overall uncertainty is 76 mev .the @xmath2 boson mass fit results are currently blinded with a constant offset .the offset will be removed when further cross checks have been completed .the @xmath2 boson physics program at the tevatron is very successful .cdf and d have measured the inclusive @xmath2 and @xmath7 cross sections in all three leptonic decay channels , which show good agreement with nnlo calculations . from the cross section measurements , cdf has extracted competitive measurements on lepton universality and an indirect measurement of the @xmath2 boson width .d has measured the @xmath2 boson width directly in the electron channel with an uncertainty smaller than the run 1 value .the new cdf @xmath2 charge asymmetry will help to further constrain the uncertainties of parton distribution functions , which affect all the aforementioned measurements . with the addition of 600 pb@xmath1 of data on tape, these measurements will further constrain the standard model .cdf has determined the uncertainty on the @xmath2 boson mass with the first @xmath0200 pb@xmath1 of run 2 data to be 76 mev , which is lower than its run 1 uncertainty of 79 mev . with the additional data to come ,run 2 promises the world s highest precision measurement of the @xmath2 boson mass , with an anticipated uncertainty of 30 mev for 2 fb@xmath1 .i would like to thank my colleagues from the cdf and d electroweak groups for their hard work and input to this talk .    99 particle data group , phys .b * 592 * , 343 ( 2004 ) .george velev , these proceedings .d.  acosta _ et al .lett . * 94 * , 091803 ( 2005 ) . c.  anastasiou_ et al . _ ,d. * 69 * , 094008 ( 2004 ) .the d collaboration , d note 4563-conf ( 2004 ) . http://www-d0.fnal.gov/run2physics/www/results/prelim/ew/e08/e08.pdf v. m. abazov _et al . _ ,d. * 66 * , 032008 ( 2002 ) .the cdf collaboration and the d collaboration , phys .d. * 70 * , 092008 ( 2004 ) .d.  acosta _ et al .d. * 71 * , 051104 ( 2005 ) .g.  arnison _ et al .b. * 122 * , 103 ( 1983 ) .m.  banner _et al . _ ,b. * 122 * , 476 ( 1983 ) .the lep electroweak working group , 2003 - 01 ( 2003 ) http://lepewwg.web.cern.ch/lepewwg/lepww/mw/winter03/mwgw_w03.ps.gz j.  pumplin _ et al ._ , jhep * 07 * , 012 ( 2002 ) .a. d.  martin _ et al ._ , hep - ph/0307262 ( 2003 ). t.  affolder _ et al .d. * 64 * , 052001 ( 2001 ) .","answer":"the cdf and d collaborations have analyzed up to @xmath0200 pb@xmath1 of run 2 physics data to measure @xmath2 production properties such as the @xmath2 cross section , the @xmath2 width , lepton universality and the @xmath2 charge asymmetry . from the cross section measurements , cdf obtains a lepton universality of @xmath3 and @xmath4 and an indirect @xmath2 width of @xmath5=2079@xmath641 mev .  d measured the @xmath2 width directly and finds @xmath5=2011@xmath6142 mev .  cdf has estimated the uncertainties on the @xmath2 boson mass measurements in the electron and muon decay channels and obtains an overall uncertainty of 76 mev .     = 11.6pt"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: Which protein mediates gene loop formation in the yeast S. cerevisiae?Context: A transcription-independent role for TFIIB in gene looping.Moreover, looping is dependent upon the general transcription factor TFIIB: the E62K (glutamic acid 62 -->lysine) form of TFIIB adversely affects looping at every gene tested, including BLM10, SAC3, GAL10, SEN1, and HEM3TFIIB crosslinks to both the promoter and terminator regions of the PMA1 and BLM10 genes, and its association with the terminator, but not the promoter, is adversely affected by E62K and by depletion of the Ssu72 component of the CPF 3' end processing complex, and is independent of TBPWe present a high-resolution genome-wide map of TFIIB locations that implicates 3' NFRs in gene looping.Instead, activators physically interacted with the general transcription factor TFIIB when the genes were activated and in a looped configuration. TFIIB cross-linked to both the promoter and the terminator regions during the transcriptionally activated state of a gene.We propose that the activators facilitate gene looping through their interaction with TFIIB during transcriptional activation of genes.Gene looping, defined as the interaction of the promoter and the terminator regions of a gene during transcription, requires transcription factor IIB (TFIIB).We have earlier demonstrated association of TFIIB with the distal ends of a gene in an activator-dependent mannerFurthermore, TFIIB interaction with the CF1 complex and Pap1 is crucial for gene looping and transcriptional regulation.TFIIB also cross-links to terminator regions and is required for gene loops that juxtapose promoter-terminator elements in a transcription-dependent manner.These results define a novel, functional interaction between TFIIB and Ssl2 that affects start site selection and gene looping.Gene-loop formation is dependent on regulatory proteins localized at the 5' and 3' ends of genes, such as TFIIB.Gene-loop formation is dependent on regulatory proteins localized at the 5' and 3' ends of genes, such as TFIIB.","answer":"TFIIB"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Synergistic cytotoxic effect of genistein and doxorubicin on drug-resistant human breast cancer MCF-7/Adr cells. The molecular mechanisms underlying genistein-mediated reversal of chemoresistance remains unknown. In the present study, we investigated the molecular mechanisms by which genistein overcomes chemoresistance and its effect on doxorubicin-induced cytotoxicity. Consistent with previous reports , genistein combined with doxorubicin had a synergistic effect on MCF-7/Adr cells , and genistein reduced the chemoresistance of these cells . genistein treatment increased the intracellular accumulation of doxorubicin but did not influence P-gp function. The combination of genistein and doxorubicin significantly induced cell cycle arrest and apoptosis. genistein treatment strongly inhibited HER2/neu but not MDR-1 expression at both the mRNA and protein levels. Therefore, our results demonstrated that genistein combined with doxorubicin had a synergistic effect on MCF-7/Adr cells, and the mechanisms likely involve an increase in the intracellular accumulation of doxorubicin and suppression of HER2/neu expression.sentence: Consistent with previous reports , genistein combined with doxorubicin had a synergistic effect on MCF-7/Adr cells , and genistein reduced the chemoresistance of these cells .","answer":"[[\\"genistein\\", \\"doxorubicin\\", \\"POS\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Drug Interaction During Pregnancy: Cromolyn sodium and isoproterenol were studied following subcutaneous injections in pregnant mice. Cromolyn sodium alone in doses up to 540 mg/kg/day (approximately 340 times the maximum recommended daily inhalation dose in adults on a mg/m2 basis) did not cause significant increases in resorptions or major malformations. Isoproterenol alone at a dose of 2.7 mg/kg/day (approximately 7 times the maximum recommended daily inhalation dose in adults on a mg/m2 basis) increased both resorptions and malformations. The addition of 540 mg/kg/day of cromolyn sodium (approximately 340 times the maximum recommended daily inhalation dose in adults on a mg/m2 basis) to 2.7 mg/kg/day of isoproterenol (approximately 7 times the maximum recommended daily inhalation dose in adults on a mg/m2 basis) appears to have increased the incidence of both resorptions and malformations.","answer":"{\\"Brand\\": [], \\"Drug\\": [\\"Cromolyn sodium\\", \\"isoproterenol\\", \\"Isoproterenol\\", \\"cromolyn sodium\\"], \\"DrugGroup\\": [], \\"UnapprovedDrug\\": []}"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:a thorough knowledge of the external and internal anatomy of teeth is a very important factor in root canal treatment . in many cases , dentists have to deal with various morphological variations .if the dentist fails to detect the morphological variations , it would be a major cause of failure .when a preoperative radiograph shows an atypical tooth shape , further radiographic examinations should be considered in order to detect unusual anatomical differences . in maxillaryfirst molars , morphological variations , such as abnormal numbers of roots , canals , fusion and germination and the existence of c - shaped root canals have been widely known .a few cases of c - shaped root canals in maxillary molars have been reported , though c - shaped canals are most frequently found in mandibular second molars .some authors have reported that c - shaped canals result from the fusion of mesiobuccal ( mb ) and palatal ( p ) roots of maxillary molars , while others have reported that the distobuccal ( db ) and p roots of maxillary molars were fused , and even a case of fusion of the mb and db roots of maxillary molars was reported . the incidence of c - shaped canals in maxillary firstmolar has been reported to be as low as 0.091% based on radiographic examination . in case of anatomical abnormalities , periapical surgery , intentional replantation and even extractionintentional replantation has been performed for more than a thousand years and this technique consists of intentional tooth extraction , cleaning of the apical part of the tooth and reinsertion of the extracted tooth into its own socket immediately .many authors agree that this technique should be the  last option ' after all the other procedures have failed or when endodontic periradicular surgery can not be performed .the purpose of this report is to present a morphological variation of c - shaped canal in a maxillary first molar in which the mb , db and p roots were fused to mimic the letter  o ' .a 39-year - old male was referred by a private practitioner to the department of conservative dentistry at yonsei university dental hospital .the reason for referral was high possibility of fracture of the maxillary left first molar while trying to remove a pre - existing old post in the palatal canal ( figure 1 ) .the tooth had been treated endodontically and restored with a post and core 10 years ago .however , he had no symptoms at that point in time . on the clinical examinations , percussion and mobility tests were within normal limits and probing depth was also normal .based on clinical and radiographic findings , the diagnosis of chronic apical periodontitis was established .the possibility of root perforation by the post and sinus involvement by the roots could not be ignored as the cause of the symptom . for further examination cone - beam computed tomography ( cbct , rayscan symphony ; ray co. , ltd , seoul ,cbct examination revealed a single - rooted maxillary first molar , and all the roots seemed to be fused together into one o - shaped root .the sinus wall seemed to be intact ( figure 3 ) , but the possibility of perforation by the post or root fracture could not be excluded because it was presumed that the existence of an o - shaped root was unlikely at that time and the overlapping of root images were persistent . it was concluded that the conventional root canal retreatment was not possible because of difficulty in negotiating all canals and the possibility of root fracture during removal of the post .hence , intentional replantation was planned . on the day of surgery , patient received a preoperative regimen of antibiotics and anti - inflammatory drugs . with delicate luxation using a root elevator , the tooth was extracted without fracture .the inflamed granulation tissue in the center of the fused roots was removed meticulously , and one root with an o - shape was observed . on a side view , the root was rectangular in shape , and on an apical view all roots were fully connected and no perforation by the post was observed ( figure 4 ) . when the tooth was examined with a surgical operating microscope ( carl zeiss opmi pico ; carl zeiss , oberkochen , germany ) , more than five or six small foramina were observed .it was decided to resect the apical end of the root for removing the unnoticed small foramina .the apical 3  mm of the root were trimmed . on the prepared apical o - shaped root surfacethere were 56 root canals with connecting fins , and hence , a 360 circular root end cavity was made with an ultrasonic tip and it was checked by methylene blue ( figure 5 ) . during intentional replantation , the tooth was kept under wet gauze for maintaining the pdl cells of the root surface vital .the root canal was re - cleaned and filled with retrograde root filling material ( resin - modified glass ionomer ; fuji ii ; gc , tokyo , japan ) to cover the long root end cavity .and the tooth was re - implanted into its own socket . at the 9 months recall visit ,the tooth was asymptomatic and a progressive healing of the lesion was evident ( figure 6 ) .we herein present the case of a patient with unusual root morphology of the maxillary first molar which has not been reported up to now .we named this morphological variation as an o - shaped root following the concept of c - shaped roots . at first, we suspected that this tooth had a c - shaped root because a blunt apex and an unclear root shape were seen on the periapical radiographs .the axial and cross - sectional view of the maxillary arch showed the symmetric morphology of the maxillary first molars with an o - shaped root , but we could not exclude the possibility of intimate proximity of roots or simple fusion between the c - shaped root and the other root . at first , periapical microsurgery was considered for establishing the diagnosis and management of the unusual root morphology .however , the tooth also had difficulties with surgical approaches and the possibility of maxillary sinus perforation during microsurgery .as a result , intentional replantation was planned carefully because the possibility of tooth fracture could not be excluded .the extraction and replantation procedure was also expected to be difficult because of the rectangular shape of the root .extraction of the tooth from its socket was done successfully without causing root fracture or alveolar bone fracture , while trying to preserve the periodontal ligament and not exerting too much pressure on the tooth and socket walls .after removal of the granulation tissue that covered the root from the apical concave area up to the normal furcation area , an o - shaped root was observed .no visible perforation by the post was detected on the root surface , and also no sinus involvement was detected .because of this inner granulation tissue , the possibility of perforation by the post could not be excluded . in this case , the extraoral time needed was almost 17  min for meticulous extraction and management of the unusual root morphology .reported that the initial ankylosis did not show when experimental group tooth was treated with the extraoral ( complete dry ) time of 15  min ., mineral trioxide aggregate has been accepted as the material of choice for root - end filling in endodontic surgery , but mineral trioxide aggregate is a technique sensitive material of root end filling for handling in comparison with other materials . in this case ,resin - modified glass ionomer was selected as a retrograde filling material because it had marginal sealing ability in narrow root end cavity , though it was less tissue - tolerant .unusual root anatomy of the maxillary molars that has been reported previously includes the fusion of buccal roots , the fusion of mb and p roots , and the fusion of db and p roots , but to the best of our knowledge this is the first case report of all roots being fused together forming an o - shape with a normal furcation . in this case ,cbct was useful for diagnosing the unusual root morphology because of its ability to display the serial sections of the tooth .meticulous examination and recognition of an o - shaped root morphology using periapical radiographs and cbct could be helpful to diagnose the rare  o - shaped root ' .the value of this case report was to present maxillary first molar with a very unusual o - shaped root canal system , as such case is seldom mentioned in textbooks . during endodontic therapy , even though the incidence of an o - shaped root is very rare , the recognition with periapical radiographs and cbct should not be underestimated .","answer":"this case report is to present a maxillary first molar with one o - shaped root , which is an extended c - shaped canal system .  patient with chronic apical periodontitis in maxillary left first molar underwent replantation because of difficulty in negotiating all canals .  periapical radiographs and cone - beam computed tomography ( cbct ) were taken .  all roots were connected and fused to one root , and all canals seemed to be connected to form an o - shape .  the apical 3  mm of the root were resected and retrograde filled with resin - modified glass ionomer .  intentional replantation as an alternative treatment could be considered in a maxillary first molar having an unusual o - shaped root ."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Ambulation in simulated fractional gravity using lower body positive pressure: cardiovascular safety and gait analyses.Abstract 1:The purpose of this study is to assess cardiovascular responses to  lower body positive pressure ( LBPP )  and to examine the effects of LBPP unloading on gait mechanics during treadmill ambulation . We hypothesized that LBPP allows comfortable unloading of the body with minimal impact on the cardiovascular system and gait parameters . Fifteen healthy male and female subjects ( 22 - 55 yr ) volunteered for the study . Nine underwent noninvasive cardiovascular studies while st and ing and ambulating upright in LBPP , and six completed a gait analysis protocol . During stance , heart rate decreased significantly from 83 + /- 3 beats/min in ambient pressure to 73 + /- 3 beats/min at 50 mmHg LBPP ( P < 0.05 ) . During ambulation in LBPP at 3 mph ( 1.34 m/s ) , heart rate decreased significantly from 99 + /- 4 beats/min in ambient pressure to 84 + /- 2 beats/min at 50 mmHg LBPP ( P < 0.009 ) . Blood pressure , brain oxygenation , blood flow velocity through the middle cerebral artery , and head skin microvascular blood flow did not change significantly with LBPP . As allowed by LBPP , ambulating at 60 and 20 % body weight decreased ground reaction force ( P < 0.05 ) , whereas knee and ankle sagittal ranges of motion remained unaffected . In conclusion , ambulating in LBPP has no adverse impact on the systemic and head cardiovascular parameters while producing significant unweighting and minimal alterations in gait kinematics . Therefore , ambulating within LBPP is potentially a new and safe rehabilitation tool for patients to reduce loads on lower body musculoskeletal structures while preserving gait mechanicsTitle 2:Walking in simulated reduced gravity: mechanical energy fluctuations and exchange.Abstract 2:Walking humans conserve mechanical and , presumably , metabolic energy with an inverted pendulum-like exchange of gravitational potential energy and horizontal kinetic energy . Walking in simulated reduced gravity involves a relatively high metabolic cost , suggesting that the inverted-pendulum mechanism is disrupted because of a mismatch of potential and kinetic energy . We tested this hypothesis by measuring the fluctuations and exchange of mechanical energy of the center of mass at different combinations of velocity and simulated reduced gravity .  Subjects walked with smaller fluctuations in horizontal velocity in lower gravity , such that the ratio of horizontal kinetic to gravitational potential energy fluctuations remained constant over a fourfold change in gravity . The amount of exchange , or percent recovery , at 1.00 m/s was not significantly different at 1.00 , 0.75 , and 0.50 G ( average 64.4 % ) , although it decreased to 48 % at 0.25 G. As a result , the amount of work performed on the center of mass does not explain the relatively high metabolic cost of walking in simulated reduced gravityTitle 3:Soleus H-reflex gain in humans walking and running under simulated reduced gravity.Abstract 3:The Hoffmann ( H- ) reflex is an electrical analogue of the monosynaptic stretch reflex , elicited by bypassing the muscle spindle and directly stimulating the afferent nerve . Study ing H-reflex modulation provides insight into how the nervous system central ly modulates stretch reflex responses . A common measure of H-reflex gain is the slope of the relationship between H-reflex amplitude and EMG amplitude . To examine soleus H-reflex gain across a range of EMG levels during human locomotion , we used  simulated reduced gravity  to reduce muscle activity . We hypothesised that H-reflex gain would be independent of gravity level . We recorded  EMG from  eight subjects walking ( 1.25 m s-1 ) and running ( 3.0 m s-1 ) at four gravity levels ( 1.0 , 0.75 , 0.5 and 0.25 G ( Earth gravity ) ) . We normalised the stimulus M-wave and result ing H-reflex to the maximal M-wave amplitude ( Mmax ) elicited throughout the stride to correct for movement of stimulus and recording electrodes relative to nerve and muscle fibres . Peak soleus EMG amplitude decreased by ~30 % for walking and for running over the fourfold change in gravity . As hypothesised , slopes of linear regressions fitted to H-reflex versus EMG data were independent of gravity for walking and running ( ANOVA , P > 0.8 ) . The slopes were also independent of gait ( P > 0.6 ) , contrary to previous studies . Walking had a greater y-intercept ( 19.9 % Mmax ) than running ( -2.5 % Mmax ; P < 0.001 ) . At all levels of EMG , walking H-reflex amplitudes were higher than running H-reflex amplitudes by a constant amount . We conclude that the nervous system adjusts H-reflex threshold but not H-reflex gain between walking and running . These findings provide insight into potential neural mechanisms responsible for spinal modulation of the stretch reflex during human locomotion","answer":"Studies investigating the immediate effects of partial gravity exposure reveal that cardiopulmonary parameters such as heart rate , oxygen consumption , metabolic rate , and cost of transport are reduced compared to 1 g , whereas stroke volume seems to increase with decreasing gravity levels .Biomechanical studies reveal that ground reaction forces , mechanical work , stance phase duration , stride frequency , duty factor and preferred walk-to-run transition speed are reduced compared to 1 g. Partial gravity exposure below 0.4 g seems to be insufficient to maintain musculoskeletal and cardiopulmonary properties in the long-term .To compensate for the anticipated lack of mechanical and metabolic stimuli some form of exercise countermeasure appears to be necessary in order to maintain reasonable astronauts ' health , and thus ensure both sufficient work performance and mission safety"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: [Antibody treatment in colorectal cancer--what the surgeon needs to know]. Advances in the medical treatment of colorectal cancer patients have resulted in considerable improvements through the introduction of new cytotoxic drugs. The significant progress in molecular and tumour biology has produced a great number of targeted, tumour-specific, monoclonal antibodies that are now in various stages of clinical development. Two of these antibodies , cetuximab ( Erbitux ) und bevacizumab ( Avastin ) , directed against the epidermal growth factor receptor ( EGFR ) and the vascular epithelial growth factor ( VEGF ) , respectively , have recently been approved for use in metastatic colorectal cancer . The combination of well-known and newly developed cytotoxic agents with monoclonal antibodies makes the medical treatment of colorectal cancer patients considerably more complex, but also provides additional therapeutic strategies for patients in advanced stages of disease.sentence: Two of these antibodies , cetuximab ( Erbitux ) und bevacizumab ( Avastin ) , directed against the epidermal growth factor receptor ( EGFR ) and the vascular epithelial growth factor ( VEGF ) , respectively , have recently been approved for use in metastatic colorectal cancer .","answer":"[]"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:TheevolutionaryrelationshipsamongthoseproteinsareillustratedbyaphylogenetictreeconstructedbasedontheAAhomologyofproteins(Fig.4).","answer":"[\\"proteins\\", \\"AA\\", \\"proteins\\"]"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: Ants Systems, A State Of The Art Overview: Applications To Industrial Plants Problems. Chapter Title:  Flow Shop 1. Abstract of Cited Paper (BIB001):  Ant Colony Optimization is an evolutionary method that has recently been applied to scheduling problems. We propose an ACO algorithm for the Single Machine Total Weighted Tardiness Problem. Compared to an existing ACO algorithm for the unweighted Total Tardiness Problem our algorithm has several improvements. The main novelty is that in our algorithm the ants are guided on their way to good solutions by sums of pheromone values. This allows the ants to take into account pheromone values that have already been used for making earlier decisions. 2. Abstract of Cited Paper (BIB002):  Abstract The problem of scheduling in permutation flowshops with the objective of minimizing the completion-time variance of jobs is considered and solved by making use of ant-colony optimization (ACO) algorithms. ACO is an algorithmic approach, inspired by the foraging behavior of real ants, which can be applied to solve combinatorial optimization problems. A new ant-colony algorithm (NACO) has been developed in this paper to solve the flowshop scheduling problem. The objective is to minimize the completion-time variance of jobs. Two existing ant-colony algorithms and the proposed ant-colony algorithm have been compared with an existing heuristic for scheduling with the objective of minimizing the completion-time variance of jobs. It is found that the proposed ant-colony algorithm gives promising and better results, on an average, as compared to those solutions given by the existing ant-colony algorithms and the existing heuristic for the permutation flowshop scheduling problem under study.Literature Review:","answer":"The simplest case of Flow Shop is the 2-machine flowshop scheduling problem with n jobs to schedule on 2 machines. Every jobs have a specific processing time on the two machines (i.e. job i has processing time a i on first machine and b i on second machine). C i is the completion time of job i on machine 2, where i=1,…n. For these types of problems two criterions can be defined: (i) the makespan criterion, called Cmax, defined as the maximum completion time of jobs on machine 2; (ii) the total completion time criterion, called ∑Ci, defined as the sum of completion time of jobs on machine 2. It is supposed that the total completion time criterion has to be minimized subject to the condition that the makespan computed is minimum. It is supposed to minimize the makespan (maximum completion time) as the primary objective and minimize total flow-time (sum of the completion times of all jobs) as the secondary objective. In practice this problem is a multiple criteria scheduling problem and it is a strongly NP-hard. The 2-machine flowshop scheduling problem has been extensively studied in literature and both exact and heuristic algorithms have been proposed. An ACO algorithm was also proposed to solve this problem. The ACO heuristic proposed for this problem is known as SACO (T'kindt et al. 2001) . In SACO each ant builds a feasible schedule by using a constructive procedure. This procedure uses a particular structure called \\"pheromone matrix\\" that, based on memory shared by ants, contains the information about the ways to build a good feasible schedule. Every element that composes the pheromone matrix represents a probability (i.e. τ ij is the probability of having job i at position j in a good schedule for the ∑Ci criterion). Starting from position 1 to position n, the most suitable job for position j is chosen according to either the intensification mode (the ant chooses the job with the highest value of τ ij ) or the diversification mode (the ant uses a wheel process to select the most suitable job). When an ant has built a complete schedule, a local search is applied, that among various schedules keeps the schedule that has an optimal value of the makespan and the lowest value for the total completion time. Several computational experiments have suggested that SACO yields better results than existing heuristics. Another variant of 2-machine flowshop scheduling problem involve the machine setup time. In this case the objective function is to find a schedule of jobs such that the total completion time, the sum of completion times of all jobs, is minimized. To solve this problem was proposed a particular variant of ACO (Shyu et al. 2004) . First of all the original problem is transformed into a graph-based-model in which every edge has an associated weight w. Also, unlike the strategy used by Dorigo in classical ACO, where every edge has a constant quantity of initial pheromone, this method initializes the pheromone on edges on the basis of results obtained by a greedy heuristic algorithm. To obtain a better initialization of pheromone intensity, the greedy heuristic is applied n times by letting every node be the starting node. Obtained the initial solution the algorithm starts choosing the next node to visit and updating pheromone trail. The algorithm ends after a given number of iterative cycles. The flow shop problem becomes more complicate in case of n machines. BIB001 propose two algorithms to solve this problem. The first algorithm, called M-MMAS, extends the ant-colony algorithm called MMAS, by incorporating the summation rule developed by BIB002 for the single-machine total weighted-tardiness problem, and modifying the procedure for job selection to be appended to the partial ant-sequence. In addition, the M-MMAS makes use of a new local search technique, called job-index-based local search. The second algorithm developed by BIB001 is called PACO. The first sequence of the antcolony algorithm is obtained in a way similar to M-MMAS with the objective function value set to best value. There is a specific procedure to select an unscheduled job i for position k. The resulting sequence is subjected to the job index-based local search scheme three times to improve the solution. Moreover the algorithm has a procedure to update pheromone trail based, not only on the resultant sequence obtained after the three-time application of the job index-based local search procedure, but also on the relative distance between a given position and the position of job i in the resultant sequence. PACO algorithm generates 40 antsequences and among them it is obtained the best heuristic sequence. Another important contribution is the application of ACS to solve flow shop problem, in which n jobs should be processed on m machines, with the objective to find a permutation of jobs that minimizes the makespan. The problem can be represented in ACS by a disjunctive graph, where the set O contains all operations of each job on machine, C contains the precedence relationships between the processing operations of a single job, and D represents the machine constraints of operations belonging to different jobs. Also, there are two additional nodes: a nest node N and a source food node F. After the construction of the graph, since the jobs have all the same ordering sequence, it is simple to find the first sequence. The next node an ant chooses to move to is calculated by applying a specific state transition rule. The chosen node is then added to the tabu list and the process is iterated. At the end, the node permutation given by the tabu list can determine the job sequence. Another algorithm to solve the flow shop scheduling problem was proposed by BIB003 , called NACO. This time the aim is to minimize the variance of jobs completion times (called the completion-timevariance problem, CTV). In the NACO algorithm the initial solution is obtained by NEH (Nawaz, Enscore and Ham) heuristic considering the jobs CTV minimization. To improve the initial sequence is used a random-job-insertion local search procedure and for every ant-sequence generated and for final solution is executed the local search procedure three times. As in every ACO algorithm, there is a step to update the pheromone trail or trail intensity."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:STATISTICAL METHODS FOR ASSESSING AGREEMENT BETWEEN TWO METHODS OF CLINICAL MEASUREMENTAbstract 1:In clinical measurement comparison of a new measurement technique with an established one is often needed to see whether they agree sufficiently for the new to replace the old . Such investigations are often analysed inappropriately , notably by using correlation coefficients . The use of correlation is misleading . An alternative approach , based on graphical techniques and simple calculations , is described , together with the relation between this analysis and the assessment of repeatabilityTitle 2:The smartphone inclinometer: A new tool to determine elbow range of motion?Abstract 2:Background There are easily accessible tools on smartphones ( APP ) for measuring elbow range of motion ( ROM ) . The purpose of this study is to evaluate the validity of a particular APP in determining elbow ROM in comparison with the commonly used goniometer ( GON ) , surgeon estimation of range ( EST ) and measurement on X-ray ( XR ) . Methods The study included 20 patients ( 40 elbows ) .  Flexion , extension , pronation and supination were measured using three different methods : EST , GON and APP . Radiographic measurements were taken using the average humeral diaphysis axis and dorsal midthird of ulna in flexion and extension . Results The accuracy of the three different methods has been compared to GON using statistical analysis ( ANOVA and paired sample s test ) . There was no statistically significant difference for XR flexion measurement ( mean of 2.8 ° ± 1.5 ° ) . The APP overestimated flexion ( mean of 6.4 ° ± 1.0 ° ) , and EST underestimated it ( mean of − 7.9 ° ± 1.1 ° ) . For extension , the mean difference was 2.8 ° ± 0.7 ° for EST and − 26.8 ° ± 3.1 ° for XR . The APP method did not significantly differ from GON . Supination accuracy was greater with EST ( 2.7 ° ± 1.7 ° ) than with APP ( 5.9 ° ± 1.9 ° ) . There was no difference for pronation measurement with both EST and APP . Conclusions This study is the first comparing four measurement techniques of elbow ROM . Our results showed that EST was only accurate for forearm rotation . The XR scored the best for flexion but is less reliable for extension . Surprisingly , compared to GON , APP did not correlate as we expected for flexion and supination , but the other methods were also inaccurate . We found APP to be very useful to measure complete arc of motion ( difference between maximal flexion and maximal extension).Level of Evidence III , Retrospective review of a prospect i ve cohort of elbow fracture patients : Diagnostic StudyTitle 3:Use of the smartphone for end vertebra selection in scoliosisAbstract 3:Objectives The aim of our study was to develop a smartphone-aided end vertebra selection method and to investigate its effectiveness in Cobb angle measurement . Methods Twenty-nine adolescent idiopathic scoliosis patients ' pre-operative posteroanterior scoliosis radiographs were used for end vertebra selection and Cobb angle measurement by st and ard method and smartphone-aided method . Measurements were performed by 7 examiners . The intraclass correlation coefficient was used to analyze selection and measurement reliability . Summary statistics of variance calculations were used to provide 95 % prediction limits for the error in Cobb angle measurements . A paired 2-tailed t test was used to analyze end vertebra selection differences . Results Mean absolute Cobb angle difference was 3.6 ° for the manual method and 1.9 ° for the smartphone-aided method . Both intraobserver and interobserver reliability were found excellent in manual and smartphone set for Cobb angle measurement . Both intraobserver and interobserver reliability were found excellent in manual and smartphone set for end vertebra selection . But reliability values of manual set were lower than smartphone . Two observers selected significantly different end vertebra in their repeated selection s for manual method . Conclusion Smartphone-aided method for end vertebra selection and Cobb angle measurement showed excellent reliability . We can expect a reduction in measurement error rates with the widespread use of this method in clinical practice . Level of evidence Level III , DiagnosticTitle 4:Video Movement Analysis Using Smartphones (ViMAS): A Pilot Study.Abstract 4:The use of smartphones in clinical practice is steadily increasing with the availability of low cost/freely available \\" apps \\" that could be used to assess human gait . The primary aim of this manuscript is to test the concurrent validity of kinematic measures recorded by a smartphone application in comparison to a 3D motion capture system in the sagittal plane . The secondary aim was to develop a protocol for clinicians on the set up of the smartphone camera for video movement analysis . The sagittal plane knee angle was measured during heel strike and toe off events using the smart phone app and a 3D motion-capture system in 32 healthy subjects . Three trials were performed at near ( 2-m ) and far ( 4-m ) smartphone camera distances . The order of the distances was r and omized . Regression analysis was performed to estimate the height of the camera based on either the subject 's height or leg length . Absolute measurement errors were least during toe off ( 3.12 ± 5.44 degrees ) compared to heel strike ( 5.81 ± 5.26 degrees ) . There were significant ( p < 0.05 ) but moderate agreements between the application and 3D motion capture measures of knee angles . There were also no significant ( p > 0.05 ) differences between the absolute measurement errors between the two camera positions . The measurement errors averaged between 3 - 5 degrees during toe off and heel strike events of the gait cycle . The use of smartphone apps can be a useful tool in the clinic for performing gait or human movement analysis . Further studies are needed to establish the accuracy in measuring movements of the upper extremity and trunkTitle 5:The TiltMeter app is a novel and accurate measurement tool for the weight bearing lunge test.Abstract 5:OBJECTIVES The weight bearing lunge test is increasing being used by health care clinicians who treat lower limb and foot pathology . This measure is commonly established accurately and reliably with the use of expensive equipment . This study aims to compare the digital inclinometer with a free app , TiltMeter on an Apple iPhone . DESIGN This was an intra-rater and inter-rater reliability study . Two raters ( novice and experienced ) conducted the measurements in both a bent knee and straight leg position to determine the intra-rater and inter-rater reliability . Concurrent validity was also established . METHODS Allied health practitioners were recruited as participants from the workplace . A preconditioning stretch was conducted and the ankle range of motion was established with the weight bearing lunge test position with firstly the leg straight and secondly with the knee bent . The measurement device and each participant were r and omised during measurement . RESULTS The intra-rater reliability and inter-rater reliability for the devices and in both positions were all over ICC 0.8 except for one intra-rater measure ( Digital inclinometer , novice , ICC 0.65 ) . The inter-rater reliability between the digital inclinometer and the tilmeter was near perfect , ICC 0.96 ( CI : 0.898 - 0.983 ) ; Concurrent validity ICC between the two devices was 0.83 ( CI : -0.740 to 0.445 ) . CONCLUSIONS The use of the Tiltmeter app on the iPhone is a reliable and inexpensive tool to measure the available ankle range of motion . Health practitioners should use caution in applying these findings to other smart phone equipment if surface areas are not comparableTitle 6:Validation of an innovative method of shoulder range-of-motion measurement using a smartphone clinometer application.Abstract 6:BACKGROUND An accurate and reliable measurement of shoulder range of motion ( ROM ) is important in the evaluation of the shoulder . A smartphone digital clinometer application is a potentially simpler method for measuring shoulder ROM . The goal of this study was to establish the reliability and validity of shoulder ROM measurements among varying health care providers using a smartphone clinometer application in healthy and symptomatic adults . METHODS An attending surgeon , fellow , resident , physician assistant , and student served as examiners . Bilateral shoulders of 24 healthy subjects were included . Fifteen postoperative patients served as the symptomatic cohort . Examiners measured ROM of each shoulder , first using visual estimation and then using a goniometer and smartphone clinometer in a r and omized fashion . RESULTS The interobserver reliability among examiners showed significant correlation , with average intraclass correlation coefficient [ ICC(2,1 ) ] values of 0.61 ( estimation ) , 0.69 ( goniometer ) , and 0.80 ( smartphone ) . All 5 examiners had substantial agreement with the gold st and ard in healthy subjects , with average ICC(2,1 ) values ranging from 0.62 to 0.79 . The interobserver reliability in symptomatic patients showed significant correlation , with average ICC(2,1 ) values of 0.72 ( estimation ) , 0.79 ( goniometer ) , and 0.89 ( smartphone ) . Examiners had excellent agreement with the gold st and ard in symptomatic patients , with an average ICC(2,1 ) value of 0.98 . CONCLUSION The smartphone clinometer has excellent agreement with a goniometer-based gold st and ard for measurement of shoulder ROM in both healthy and symptomatic subjects . There is good correlation among different skill levels of providers for measurements obtained using the smartphone . A smartphone-based clinometer is a good re source for shoulder ROM measurement in both healthy subjects and symptomatic patientsTitle 7:Reliability assessment of measuring active wrist pronation and supination range of motion with a smartphone.Abstract 7:This study aim ed to improve clinical examination techniques by determining the reliability of different methods to evaluate forearm movements . Two methods using the iPhone ™ 5 and its gyroscope application ( alone [ I5 ] or attached to a selfie stick [ ISS ] ) were compared with two conventional measurement devices ( a plastic goniometer with a h and -held pencil [ HHP ] and a bubble goniometer [ BG ] ) to evaluate the active range of movement ( AROM ) of the wrist during pronation and supination . Two independent groups of subjects took part in this prospect i ve single-center diagnostic study : 20 healthy subjects and 20 patients . The four evaluation methods had high intra-observer consistency after three measurements ( intra-class correlation coefficient [ ICC ] [ 3 , 1 ] of 0.916 for the HHP ; 0.944 for ISS ; 0.925 for BG ; 0.933 for I5 ) and excellent inter-observer reliability ( ICC [ 2 , k ] of 0.926 for HHP ; 0.934 for ISS ; 0.899 for BG ; 0.894 for I5 ) , with an agreement of plus or minus 2 ° . When these devices are used with rigorous methodology , they are reliable for the goniometric evaluation of AROM of wrist pronation and supinationTitle 8:Reliability and validity of goniometric iPhone applications for the assessment of active shoulder external rotationAbstract 8:ABSTRACT Purpose /hypothesis : The purpose of this study was to determine the reliability and validity of two smartphone applications : ( 1 ) GetMyROM – inclinometery-based and ( 2 ) DrGoniometry – photo-based in the measurement of active shoulder external rotation ( ER ) as compared to st and ard goniometry ( SG ) . Participants : Ninety-four Texas Woman 's University Doctor of Physical Therapy students from the School of Physical Therapy – Houston campus , were recruited to participate in this study . Material s/ methods : Two iPhone applications were compared to SG using both novice and experienced raters . Active shoulder ER range of motion was measured over two time periods in r and om order by blinded novice and experienced raters . Results : Intra-rater reliability using novice raters for the two applications ranged from an intraclass correlation coefficient ( ICC ) of 0.79 to 0.81 with SG at 0.82 . Inter-rater reliability ( novice/expert ) for the two applications ranged from an ICC of 0.92 to 0.94 with SG at 0.91 . Concurrent validity ( when compared to SG ) ranged from 0.93 to 0.94 . There were no significant differences between the novice and experienced raters . Conclusion : Both applications were found to be reliable and comparable to SG . A photo-based application potentially offers a superior method of measurement as visualizing the l and marks may be simplified in this format and it provides a record of measurement . Clinical relevance : Further study using patient population s may find the two studied applications are useful as an adjunct for clinical practice","answer":"Psychometric characteristics of the selected apps were robust , but heterogeneity of the studies did not enable comparisons between apps to identify the most valid one ."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Treatment of Niemann-Pick disease type C in two children with miglustat: initial responses and maintenance of effects over 1 year. Niemann-Pick disease type C (NP-C) is a lipid storage disorder characterized by the accumulation of unesterified cholesterol and glycolipids in the lysosomal/late endosomal system of certain cells in the central nervous system (CNS) and visceral organs. Clinical symptoms include progressive neurological deterioration and visceral organomegaly. Miglustat, a small iminosugar molecule approved for the treatment of Gaucher disease, reversibly inhibits glucosylceramide synthase, which catalyses the first committed step in glycosphingolipid synthesis. The physicochemical properties of miglustat allow it to cross the blood-brain barrier and suggest possible benefits in lysosomal storage diseases affecting the CNS. Here, we present findings in two children with NP-C, aged 14 years (patient 1) and 9 years (patient 2), treated with miglustat for 1 year. Before treatment, patient 1 presented with severe difficulties in swallowing and walking, and patient 2 with problems mostly affecting communication and social interaction. Videofluoroscopic studies in patient 1 demonstrated a substantial improvement in swallowing by month 6 of treatment, and ambulation index measurements indicated improved walking. Mini Mental-State Examination (MMSE) assessments in patient 2 showed cognitive improvement by month 6, which was sustained up to month 12. Liver/spleen volume and plasma chitotriosidase activities were stabilized in both cases. There was no weight loss during treatment. Patient 1 experienced severe but self-limiting paresthesia, which was not associated with peripheral neuropathy. We conclude that miglustat can provide therapeutic benefits in CNS symptoms and allows stabilization of systemic disease in childhood-onset NP-C. Further follow-up is crucial to determine the long-term maintenance of these effects.","answer":"[[\\"Miglustat\\", \\"INHIBITOR\\", \\"glucosylceramide synthase\\"]]"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:in july 2011 , a bat was found in the city of lleida and taken to the wildlife care center of vallcalent ( lleida , catalonia ) .the bat arrived lethargic and dehydrated , died soon after admission , and its carcass was frozen at 20c . on march 12 , 2012 , as part of the rabies surveillance program in spain , the bat carcass was received by the national center of microbiology , where rabies testing was conducted by 2 generic reverse transcription pcr ( rt - pcr ) methods for lyssavirus detection ( 9,10 ) and 2 commercial rabies antiserum assays ( bio - rad laboratories , marnes la coquette , france ; and fujirebio , inc . ,brain smears were positive for lyssavirus by rt - pcr and fluorescent antibody testing , and an oropharyngeal swab sample was positive by rt - pcr .further attempts to isolate the virus by tissue cultures were unsuccessful after 2 blind passages in bhk-21 and murine neuroblastoma cells .the negative results could be explained by the fact that the sample had been stored at 20c for 8 months and had been frozen and thawed twice before cell culture testing ; however , the possibility of the cell lines not being permissive for the virus can not be excluded .  the bat was morphologically identified as a bent - winged bat ( m. schreibersii ) and genetically identified by cytochrome b sequencing ( 11 ) .the genomic sequence of the corresponding fragment of the diagnostic rt - pcr on the conserved region of the nucleoprotein gene , determined by blast ( http://blast.ncbi.nlm.nih.gov/ ) , showed no substantial sequence similarity to previously known lyssaviruses .to determine the identity of the lyssavirus , we sequenced a larger fragment ( 565 bp ) , including the variable codifying region of the nucleoprotein gene ( genbank accession number submitted ) .we reconstructed an overall phylogeny of lyssaviruses by using a bayesian inference with the first 405 nt of the n - gene and mrbayes version 3.1.2 ( http://mrbayes.csit.fsu.edu/ ) .two simultaneous runs of 10 generations were conducted , each with 4 markov chains , and trees were sampled every 100 generations . the best - fit nucleotide model , gtr + i +the phylogenetic reconstruction was based on a dataset representative of all known lyssaviruses , including the recently described ikov .the topology obtained showed that this sequence is more closely related to ikov and wcbv than to the lyssaviruses in phylogroups i and ii ( figure ) .these results suggest that this sequence tentatively belongs to a new lyssavirus species named after the location of collection , lleida bat lyssavirus ( llebv ) .phylogenetic reconstruction based on the first 405 nt of the nucleoprotein gene , including all representative lyssaviruses .the tree was obtained by bayesian inference , and the first 25% of trees were excluded from the analysis as burn - in .arav , aravan virus ; ablv , australian bat lyssavirus ; bblv , bokeloh bat lyssavirus ; duvv , duvenhage virus ; eblv-1 and eblv-2 , european bat lyssavirus types 1 and 2 ; irkv , irkut virus ; khuv , khujand virus ; lbv , lagos bat virus ( lineages a , b , c , and d ) ; mokv , mokola virus ; rabv , rabies virus ; shibv , shimoni bat virus ; wcbv , west caucasian bat virus ; ikov , ikoma lyssavirus ; llebv , lleida bat lyssavirus ( proposed ) .the highest nucleotide identity was with ikov ( 71.6% ) , followed by shibv ( 68.6% ) , irkv ( 68.1% ) , khuv ( 67.6% ) , eblv-2 ( 67%68.2% ) , arav ( 67.3% ) , wcbv ( 67.4% ) , ablv ( 66.6%67.7% ) , bblv ( 66.1% ) , lbv ( 65.7%68.6% ) , mokv ( 65.7%67.2% ) , duvv ( 65.5%65.8% ) , rabv ( 64.766.4% ) , and eblv-1 ( 63.7%64% ) .the lowest nucleotide identity was with the only lyssavirus found in bats of the iberian peninsula , eblv-1 .the nucleotide identity among the previously known lyssaviruses was 63.5%80.0% in this particular fragment , and the lowest identities among strains belonging to the same lyssavirus were 80.4% for ablv and 79.9% for lbv ( the most distant lbv strain has been suggested to be a different lyssavirus ) ( technical appendix ) .the lyssavirus - specific antigen reactivity and association with a genomic sequence found in a bent - winged bat in northeastern spain could be derived from the tentative new virus llebv . according to our phylogenetic reconstruction, the virus does not seem to belong to phylogroup i , which comprises most bat lyssaviruses , or to the african phylogroup ii .the evolutionary relationships between the llebv sequence with wcbv and ikov sequences need to be clarified before it can be determined whether they form > 1 different phylogroups .   of note , the new llebv was detected in m. schreibersii bats , as was wcbv , the other european lyssavirus outside phylogroup i. the genus miniopterus has traditionally been considered to belong to the family vespertilionidae as do other bat genera linked to lyssaviruses in eurasia ( eptesicus , myotis , and murina ) .however , recent molecular analyses have confirmed that the genus miniopterus belongs to the family miniopteridae ( 12 ) .large numbers ( thousands ) of these bats overwinter in caves and move in the spring to different and sometimes distant summer roosts for reproduction ( 13 ) .these ecologic features make it relatively easy for an infectious agent to quickly spread out within and among the populations .consequently , it is difficult to imagine that wcbv or llebv are locally restricted ; both could be located far from where they were found .the cumulative description of new bat lyssaviruses in recent years shows the convenience of always using generic amplification primers for rabies diagnosis based on rt - pcr to complement antigen detection .no human exposure to the new virus has been reported . however , because of the divergence exhibited by llebv and ikov , and the growing evidence of inadequate protection / cross - neutralization against viruses outside phylogroup i , the effectiveness of current rabies vaccines remains for these viruses a concern ( 15 ) .analysis was performed with the 405-nt fragment of the n - gene of all the known lyssavirus species .","answer":"a new tentative lyssavirus , lleida bat lyssavirus , was found in a bent - winged bat ( miniopterus schreibersii ) in spain . it does not belong to phylogroups i or ii , and  it seems to be more closely related to the west causasian bat virus , and especially to the ikoma lyssavirus ."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Can Trials of Physical Treatments Be Blinded?: The Example of Transcutaneous Electrical Nerve Stimulation for Chronic PainAbstract 1:Therapeutic trials often attempt to “ blind ” patient and investigator to the true nature of treatments received , reducing the influences of conscious or subconscious prejudices . In drug trials , this is accomplished with placebo tablets , but blinding in trials of physical treatments is more problematic . This issue arose in a clinical trial of transcutaneous electrical nerve stimulation ( TENS ) for patients with chronic low back pain . Several study design features were incorporated to promote blinding : use of sham TENS units visually identical with real units , exclusion of potential subjects with previous TENS experience , avoidance of a crossover design and use of identical visit frequency , instructions and modifications in electrode placement . Subjects were asked not to discuss treatments with the clinicians who performed outcome assessment s. Both patients and clinicians were asked to guess actual treatment assignments at the trial 's end . Every patient in the true TENS group believed the unit was functioning properly , but the degree of certainty varied . In the sham TENS group , 84 % also believed they had functioning units , but their certainty was significantly less than in the active treatment group . Differences in patient perceptions did not affect compliance , as the two groups had similar dropout rates , appointment compliance , days of TENS use and daily duration of TENS use . Clinicians guessed treatments correctly 61 % of the time ( as opposed to 50 % expected by chance ) , again suggesting partial success in blinding . These efforts at blinding may partly explain the negative trial results for TENS efficacy . We conclude that complete blinding is difficult to achieve because of sensory difference in treatment and unintended communication between patient and examiner . Nonetheless , trials of physical treatments can achieve partial blinding with the techniques described here , and the success of blinding can be assessed with simple questions at study completionTitle 2:Effect of active hand exercise and wax bath treatment in rheumatoid arthritis patients.Abstract 2:The effect of active h and exercise and warm wax treatment was evaluated in 52 rheumatoid arthritis patients r and omized into four groups : ( 1 ) both exercise and wax bath , ( 2 ) exercise only , ( 3 ) wax bath only , and ( 4 ) controls .  Treatment was given three times a week for 4 weeks . Deficits in flexion and extension in digits II-V bilaterally , grip function , grip strength , pain , and stiffness were measured before and after the treatment period . The control group was measured at corresponding times . Wax bath treatment followed by active h and exercise result ed in significant improvements of range of motion ( ROM ) and grip function . Active h and exercise alone reduced stiffness and pain with nonresisted motion and increased ROM .  Wax bath alone had no significant effectTitle 3:The effect of local heat and cold therapy on the intraarticular and skin surface temperature of the knee.Abstract 3:OBJECTIVE To evaluate the effects of local application of ice chips , ligno-paraffin , short-wave diathermy , and nitrogen-cold air on skin and intraarticular temperature . METHODS Forty-two healthy subjects were divided into 4 treatment groups . A temperature probe was inserted into the knee joint cavity and another placed on the overlying skin , and changes in temperature over 3 hours , by treatment group , were recorded . RESULTS The mean skin surface temperature dropped from 27.9 degrees C to 11.5 degrees C after application of ice chips , and from 28.8 degrees C to 13.8 degrees C after application of cold air . The mean intraarticular temperature decreased from 31.9 degrees C to 22.5 degrees C and from 32.9 degrees C to 28.8 degrees C , respectively , after these 2 treatments . Shortwave diathermy  increased skin temperature by 2.4 degrees C ; intraarticular temperature was increased only 1.4 degrees C by short-wave diathermy . Treatment with ligno-paraffin increased the skin surface temperature 8.9 degrees C ; the temperature in the joint cavity was increased 3.5 degrees C. CONCLUSION The use of short-wave diathermy and superficial heat packs in the treatment of patients with arthritis may potentially cause harm by increasing intraarticular temperature . This may have major implication s regarding treatment policy for patients with arthritisTitle 4:Effects of local heat and cold treatment on surface and articular temperature of arthritic knees.Abstract 4:OBJECTIVE To evaluate and compare the effects of locally applied heat and cold treatments on skin and intraarticular temperature in patients with arthritis . METHODS Thirty-nine patients with arthritis of the knee were divided at r and om into 4 treatment groups ( ice chips , nitrogen cold air , ligno-paraffin , and placebo short wave ) . A temperature probe was inserted into the knee joint cavity and another placed on the overlying skin , and changes in temperature over 3 hours were recorded for each treatment group . RESULTS The mean temperature of the surface of the skin dropped from 32.2 degrees C to 16.0 degrees C after application of ice chips and from 32.6 degrees C to 9.8 degrees C after application of nitrogen cold air ; the mean intraarticular temperature decreased from 35.5 degrees C to 29.1 degrees C and from 35.8 degrees C to 32.5 degrees C , respectively , after these treatments . Treatment with ligno-paraffin increased the surface temperature by 7.5 degrees C and the temperature in the joint cavity by 1.7 degrees C. No significant changes were observed with placebo short wave diathermy . CONCLUSION The traditional model , that intraarticular temperature is decreased by superficial heat and increased by superficial cold , must be discarded . In arthritis patients , intraarticular temperature is increased by superficial heat and decreased by superficial cold . This has clear consequences for treatment policyTitle 5:Cryotherapy for postoperative pain relief following knee arthroplasty.Abstract 5:Ninety consecutive patients undergoing primary knee arthroplasty received local cryotherapy 72 hours after surgery for pain relief . Thermal-pad circulating temperatures were r and omly assigned to 50 degrees , 60 degrees , or 70 degrees F ( room temperature ) . Pain relief was monitored using patient-controlled analgesia machines . The amount of morphine received and number of attempts per hour were statistically analyzed with relation to temperature group , age , sex , weight , side , and diagnosis . The amount of morphine injected was positively correlated to the number of attempts per hour and moderately correlated to body weight . There was no correlation between thermal-pad temperature or any other parameter and the amount of morphine injected after surgeryTitle 6:The influence of heat and cold on the pain threshold in rheumatoid arthritis.Abstract 6:Superficial heat and cold are commonly used therapeutic methods in patients with rheumatoid arthritis . Both procedures have analgesic effect . In 30 in patients with rheumatoid arthritis the pain threshold was measured before and after warm bath and ice massage .  Rheumatoid patients had significantly lower pain threshold compared to the healthy subjects in normal circumstances . Heat and cold remarkably raise the pain threshold right after the application . The pain threshold is also raised 10 and 30 min after cryotherapy , but not after the warm bath . Between investigated groups there were no statistically significant differences in the pain threshold values in any observed time . We consider that both methods have a reasonable place in the therapy of rheumatoid arthritis","answer":"There was no effect on objective measures of disease activity ( including inflammation , pain and x-ray measured joint destruction ) of either ice versus control or heat versus control .There was no difference in patient preference for heat  or ice .No harmful effects of ice or heat  were reported .REVIEW ER 'S CONCLUSIONS Since patients enjoy thermotherapy , and there are no harmful effects , thermotherapy should be recommended as a therapy which can be applied at home as needed to relieve pain .There is no need for further research on the effects of heat or cold for RA"},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: The coronavirus can be dramatically slowed or stopped completely with the immediate widespread doses of vitamin CAbstract:BACKGROUND The coronavirus disease 2019 (COVID-19) is a pandemic caused by coronavirus with mild to severe respiratory symptoms.This paper aimed to investigate the effect of nutrients on the immune system and their possible roles in the prevention, treatment, and management of COVID-19 in adults.METHODS This Systematic review was designed based on the guideline of the Preferred Reporting for Systematic Reviews (PRISMA).The articles that focussed on nutrition, immune system, viral infection, and coronaviruses were collected by searching databases for both published papers and accepted manuscripts from 1990 to 2020.Irrelevant papers and articles without English abstract were excluded from the review process.RESULTS Some nutrients are actively involved in the proper functioning and strengthening of the human immune system against viral infections including dietary protein, omega-3 fatty acids, vitamin A, vitamin D, vitamin E, vitamin B1, vitamin B6, vitamin B12, vitamin C, iron, zinc, and selenium.Few studies were done on the effect of dietary components on prevention of COVID-19, but supplementation with these nutrients may be effective in improving the health status of patients with viral infections.CONCLUSION Following a balanced diet and supplementation with proper nutrients may play a vital role in prevention, treatment, and management of COVID-19.However, further clinical trials are needed to confirm these findings and presenting the strong recommendations against this pandemic.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"RESULTS Some nutrients are actively involved in the proper functioning and strengthening of the human immune system against viral infections including dietary protein, omega-3 fatty acids, vitamin A, vitamin D, vitamin E, vitamin B1, vitamin B6, vitamin B12, vitamin C, iron, zinc, and selenium.\\", \\"Few studies were done on the effect of dietary components on prevention of COVID-19, but supplementation with these nutrients may be effective in improving the health status of patients with viral infections.\\"]}"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:In this preliminary report, we present a simple but very effective technique to stabilize the training of CNN based GANs. Motivated by recently published methods using frequency decomposition of convolutions (e.g. Octave Convolutions), we propose a novel convolution scheme to stabilize the training and reduce the likelihood of a mode collapse. The basic idea of our approach is to split convolutional filters into additive high and low frequency parts, while shifting weight updates from low to high during the training. Intuitively, this method forces GANs to learn low frequency coarse image structures before descending into fine (high frequency) details. Our approach is orthogonal and complementary to existing stabilization methods and can simply plugged into any CNN based GAN architecture. First experiments on the CelebA dataset show the effectiveness of the proposed method.Cited Abstract(s):[1]: In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.","answer":"Deep Convolutional GAN (DCGAN) , [1] is one of the popular and successful network topology design for GAN that in a certain way achieves a consistently stability during training. It is a direct extension of the GAN described above, except that it is mainly composed of convolutional and convolutional-transpose layers without max pooling or fully connected layers in both discriminator and generator."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Effect of blood-retinal barrier development on formation of selenite nuclear cataract in rat. Selenite cataract, as an experimental animal model of nuclear cataract to mimic human senile cataract, is produced only when overdose selenite is injected to neonatal rats before eyelid opening. To clarify the cause of age differences on selenite cataract formation in rats, mRNA expression of GPx1, MsrA and MsrB1, as well as GPx activity in Wistar rat lens at different ages were assayed, level of lipid peroxidation, extent of lens damage induced by sodium selenite and barricade function of blood-retinal barrier (BRB) were investigated. The results showed that mRNA expressions and activity of antioxidant enzymes in neonatal rat lens before eyelid opening were the highest and then decreased with age, and revealed by transmission electron microscopy (TEM) using lanthanum hydroxide as tracer that higher selenite content entering eyes injured lens and resulted in cataract formation for immature BRB before eyelid opening, moreover, a little selenite content entering eyes was not enough to induce cataract formation after eyelid opening because of mature BRB.","answer":"[[\\"sodium selenite\\", \\"REGULATOR\\", \\"GPx\\"], [\\"sodium selenite\\", \\"INDIRECT-REGULATOR\\", \\"MsrB1\\"], [\\"sodium selenite\\", \\"INDIRECT-REGULATOR\\", \\"GPx1\\"], [\\"sodium selenite\\", \\"INDIRECT-REGULATOR\\", \\"MsrA\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Isolation, genomic organization, and expression analysis of the mouse and rat homologs of MEFV, the gene for familial mediterranean fever. Familial Mediterranean fever (FMF) is a recessive disorder characterized by episodes of fever with serositis or synovitis. Recently the FMF gene (MEFV) was cloned; the protein product, pyrin/marenostrin, is thought to regulate inflammation in myeloid cells. In this manuscript we report the mouse and rat homologs of MEFV. The murine gene contains ten exons with a coding sequence of 2304 bp, while the rat homolog has nine exons with a coding sequence of 2253 bp. A considerable amino acid sequence homology was observed between the mouse and human (47. 6% identity and 65. 5% similarity) and between the mouse and rat genes (73. 5% identity and 82. 1% similarity). The predicted rodent proteins have several important domains and signals found in human pyrin, including a B-box zinc finger domain, Robbins-Dingwall nuclear localization signal, and coiled-coil domain. However, perhaps because of an ancient frame-shift mutation, neither the mouse nor the rat protein has an intact C-terminal B30. 2 domain, in which most FMF-associated mutations have been found in human MEFV. Nevertheless, like the human gene, mouse Mefv is expressed in peripheral blood granulocytes but not lymphocytes. Consistent with its expression in granulocytes, Mefv was detected at high levels in the primary follicles and marginal zones of the splenic white pulp. Mefv is localized on mouse Chromosome (Chr) 16, region A3-B1, extending a region of synteny with human Chr 16p13. 3. Development of knockout and knockin mouse models may provide further insights into the functional evolution of this gene.","answer":"{\\"Disease\\": [\\"recessive disorder\\", \\"familial mediterranean fever\\", \\"fever\\", \\"serositis\\", \\"Familial Mediterranean fever\\", \\"FMF\\", \\"synovitis\\"]}"},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Simulated leg-length discrepancy: its effect on mean center-of-pressure position and postural sway.Abstract 1:We hypothesized that leg-length discrepancies of as little as 1 cm would induce a significant postural shift and increase the extent of postural sway . We had 14 normal volunteers st and on a force platform with their feet in a st and ard position  . Center-of-pressure data  were recorded at 100Hz for 20 seconds while the subjects stood barefoot with no lifts or ( in r and om order ) with lifts of 1 , 2 , 3 , and 4 cm under their left and right feet . From these data we derived the mean center-of-pressure position and the extent of postural sway .  Lifts of as little as 1 cm shifted the mean center-of-pressure toward the longer leg to a statistically significant extent ( p less than 0.001 ) , the mean difference compared with the barefoot condition being 6.1 % of the distance between the feet ; increasing the discrepancy did not proportionately increase the effect . The postural sway ( total travel of the center-of-pressure ) in a mediolateral direction increased significantly with a 1 cm discrepancy ( p less than 0.01 ) , and continued to increase in proportion to the magnitude of the discrepancy . There were no effects on anteroposterior position or sway and no influence of left-right dominance . These results support our hypothesis that a leg-length discrepancy of as little as 1 cm may be biomechanically importantTitle 2:Development of gait performance and dynamic hip and knee joint loading after containment improving surgery in patients with Legg-Calvé-Perthes disease.Abstract 2:Current surgery outcome evaluations in patients with Legg-Calvé-Perthes disease ( LCPD ) are usually based on static radiological changes . The aim of the present study was to assess the development of characteristic gait parameters and passive hip range of motion ( ROM ) measurements during the postoperative period up to healed stage of the femoral head represented by Stulberg classification . Twelve children ( 10 male , 2 female ) with unilateral diagnosis of LCPD and 19 healthy control subjects at the same age participated in this prospect i ve longitudinal study .  Instrumented gait analysis  was performed preoperatively , 13.4 ( ±1.7 ) , and 28.0 ( ±4.4 ) months postoperatively . At final follow-up , the mean leg length of the involved side was reduced by 1.10 (±0.53)cm compared to the non-involved side . In addition , a significant reduction in maximum knee flexion ( -26 % , p=0.037 ) and knee flexion/extension ROM ( -26 % , p=0.017 ) in stance was still present in the patient group compared to controls indicating a \\" stiff knee gait pattern \\" . In contrast , the sagittal plane hip parameters , the ipsilateral trunk lean toward the involved stance limb , and the knee and hip joint loading during gait normalized during the postoperative period . The results of the present study should motivate further exploration if patients with LCPD stiffen their knees to compensate for leg length discrepancy . Besides the st and ard radiological evaluation of the surgery outcome , instrumented gait analysis is a valuable method of recording functional deficits and early recognition of the need for physiotherapeutic treatment or insole supply in patients with LCPDTitle 3:Effects of Experimental Leg Length Discrepancies on Body Posture and Dental OcclusionAbstract 3:Abstract The purpose of this study was to quantitatively evaluate the effects of experimental leg length discrepancies on body posture and dental occlusion .  Thirty asymptomatic subjects ( 15 males and 15 females , ages 19 - 33 , mean age 25.6 years ) were included in this study and r and omly assigned to one of two groups based on a table of r and om numbers . The only difference between group A and group B was the sequence of testing . Experimental leg length discrepancies were provided by using ten types of insoles with heights ranging from one to ten mm at one mm intervals , placed under both feet . The MatScan ( Nitta Corp. , Osaka , Japan ) system was used to measure changes in body posture ( center of foot pressure : COP ) while subjects maintained the following three postural positions : 1 . natural st and ing posture ( control ) ; 2 . control with a heel lift under the right foot ; or 3 . control with a heel lift under the left foot . The T-Scan II system ( Nitta Corp. , Osaka , Japan ) was used to analyze the results of changes in dental occlusion ( center of occlusal force : COF ) in the above-mentioned three postural positions . When subjects used a heel lift of six mm or more under the right foot , lateral weight distribution ( LWD ) shifted to the right side compared to the control ( p<0.05 ) . When a heel lift of four mm or more was used under the left foot , LWD shifted to the left side compared to the control ( p<0.05 ) . When subjects used a heel lift of eight mm or more under the right foot , occlusal force shifted to the right side compared to the control ( p<0.05 ) . When subjects used a heel lift of seven mm or more under the left foot , occlusal force shifted to the left side compared to the control ( p<0.05 ) . Based on these findings , it was concluded that leg length discrepancy affected body posture and dental occlusionTitle 4:Posture and balance control in patients with acromegaly: results of a cross-sectional study.Abstract 4:Acromegaly is a chronic debilitating disease that presents with multiple systemic manifestations , including changes in body composition , joint abnormalities , muscular impairment and visual disturbances . This study aim ed to assess posture and body balance in acromegalic patients and to establish the correlation between these measures . Twenty-eight acromegalic patients and a similar number of control subjects matched for sex , age , weight , height and body mass index underwent  postural evaluation using the photogrammetry and measurement of balance using the stabilometry in two tasks : feet apart , eyes open and feet together , eyes closed . In comparison with the control group , the acromegalic group presented postural deviations in lateral views in the vertical alignment of the trunk ( P=0.001 for the right side and P=0.021 for the left ) , the hip angle ( P=0001 for the right side and P=0.016 for the left side ) and horizontal alignment of the pelvis ( P=0.017 for the right and P<0.001 for the left side ) . Compared with healthy subjects , the acromegalic patients presented displacement of the centre of pressure in both the anterior-posterior direction and the medial-lateral direction in both evaluated tasks . We observed significant correlations between balance measures and the following posture evaluation variables : distance between the lower limbs , horizontal alignment of the head and vertical alignment of the head . Our results suggest that posture and balance need to be evaluated for acromegalic patients in clinical practice , as there are significant postural imbalances and deviations in these patientsTitle 5:Leg length and offset differences above 5mm after total hip arthroplasty are associated with altered gait kinematics.Abstract 5:We aim ed to investigate the relationship between postoperative leg length/offset ( LL/OS ) reconstruction and gait performance after  total hip arthroplasty ( THA ) . In the course of a prospect i ve r and omized controlled trial , 60 patients with unilateral hip arthrosis received cementless THA  through a minimally-invasive anterolateral surgical approach . One year post-operatively , LL and global OS restoration were analyzed and compared to the contralateral hip on AP pelvic radiographs . The combined postoperative limb length/OS reconstruction of the operated hip was categorized as restored ( within 5 mm ) or non-restored ( more than 5 mm reduction or more than 5 mm increment ) . The acetabular component inclination , anteversion and femoral component anteversion were evaluated using CT scans of the pelvis and the femur . 3D gait analysis of the lower extremity and patient related outcome measures ( HHS , HOOS , EQ-5D ) were obtained pre-operatively , six months and twelve months post-operatively by an observer blinded to radiographic results . Component position of cup and stem was comparable between the restored and non-restored group . Combined LL and OS restoration within 5 mm result ed in higher Froude number ( p<0.001 ) , normalized walking speed ( p<0.001 ) and hip range-of-motion ( ROM ) ( p=0.004 ) during gait twelve months postoperatively , whereas gait symmetry was comparable regardless of LL and OS reconstruction at both examinations . Clinical scores did not show any relevant association between the accuracy of LL or OS reconstruction and gait six/twelve months after THA . In summary , postoperative LL/OS discrepancies larger than 5 mm relate to unphysiological gait kinematics within the first year after THA . DRKS00000739 , German Clinical Trials Register","answer":"We found most of the published data that we analyzed to be inconsistent , and very little data was obtained on the correlation between LLD severity and changes in body posture stability during st and ing and walking .However , the results of the present review study are in line with previous observational studies , which describe asymmetry in the lower limbs corresponding to biomechanical parameters such as gait kinematics , kinetics , and other parameters described during static ( st and ing ) postural balance ."},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: Molecular and serological investigation of 2019-nCoV infected patients: implication of multiple shedding routeshttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC7048229/SHA: da81f0d3a12ab7faa09148acb6564271474e9e02Authors: Zhang, Wei; Du, Rong-Hui; Li, Bei; Zheng, Xiao-Shuang; Yang, Xing-Lou; Hu, Ben; Wang, Yan-Yi; Xiao, Geng-Fu; Yan, Bing; Shi, Zheng-Li; Zhou, PengDate: 2020-02-17DOI: 10.1080/22221751.2020.1729071License: cc-byAbstract: In December 2019, a novel coronavirus (2019-nCoV) caused an outbreak in Wuhan, China, and soon spread to other parts of the world. It was believed that 2019-nCoV was transmitted through respiratory tract and then induced pneumonia, thus molecular diagnosis based on oral swabs was used for confirmation of this disease. Likewise, patient will be released upon two times of negative detection from oral swabs. However, many coronaviruses can also be transmitted through oral–fecal route by infecting intestines. Whether 2019-nCoV infected patients also carry virus in other organs like intestine need to be tested. We conducted investigation on patients in a local hospital who were infected with this virus. We found the presence of 2019-nCoV in anal swabs and blood as well, and more anal swab positives than oral swab positives in a later stage of infection, suggesting shedding and thereby transmitted through oral–fecal route. We also showed serology test can improve detection positive rate thus should be used in future epidemiology. Our report provides a cautionary warning that 2019-nCoV may be shed through multiple routes. Text: Coronaviruses (CoVs) belong to the subfamily Orthocoronavirinae in the family Coronaviridae and the order Nidovirales. A human coronavirus (SARS-CoV) caused the severe acute respiratory syndrome coronavirus (SARS) outbreak in 2003. Most recently, an SARS-related CoV was implicated as the etiological agent responsible for the outbreak in Wuhan, central China. This outbreak is estimated to have started on 12th December 2019 and 17,332 laboratory confirmed cases with 361 deaths as of 3rd February 2020 in China [1] . The virus has spread to 23 other countries by travellers from Wuhan [1] . Typical symptoms are fever, malaise, shortness of breath and in severe cases, pneumonia [2] [3] [4] . The disease was first called unidentified viral pneumonia. We quickly identified the etiological agent, termed 2019-nCoV (virus name designated by the World Health Organization). The newly identified virus is an SARS-related virus (SARSr-CoV) but shares only 74.5% genome identity to SARS-CoV [2] . We developed molecular detection tools based on viral spike genes. Our previous studies indicate that qPCR method can be used for the detection of 2019-nCoV in oral swabs or in bronchoalveolar lavage fluid (BALF) [5] . Additionally, we developed IgM and IgG detection methods using a cross-reactive nucleocapsid protein (NP) from another SARSr-CoV Rp3 [6] , which is 92% identical to 2019-nCoV NP. Using these serological tools, we demonstrate viral antibody titres increase in patients infected with 2019-nCoV [5] . Like SARS-CoV, 2019-nCoV induced pneumonia through respiratory tract by clinical observation. Therefore, the presence of viral antigen in oral swabs was used as detection standard for 2019-nCoV. Similarly, two times of oral swabs negative in a 24-h interval was considered as viral clearance by patients officially. Here we launched an investigation of 2019-nCoV in a Wuhan hospital, aiming to investigate the other possible transmission route of this virus. Human samples, including oral swabs, anal swabs and blood samples were collected by Wuhan pulmonary hospital with the consent from all patients and approved by the ethics committee of the designated hospital for emerging infectious diseases. Two investigations were performed. In the first investigation, we collected samples from 39 patients, 7 of which were in severe conditions. In the second investigation, we collected samples from 139 patients, yet their clinical records were not available. We only showed patients who were viral nucleotide detection positive. Patients were sampled without gender or age preference unless where indicated. For swabs, 1.5 ml DMEM+2% FBS medium was added in each tube. Supernatant was collected after 2500 rpm, 60 s vortex and 15-30 min standing. Supernatant from swabs were added to lysis buffer for RNA extraction. Serum was separated by centrifugation at 3000 g for 15 min within 24 h of collection, followed by 56°C 30 min inactivation, and then stored at 4°C until use. Whenever commercial kits were used, manufacturer's instructions were followed without modification. RNA was extracted from 200 μl of samples with the High Pure Viral RNA Kit (Roche). RNA was eluted in 50 μl of elution buffer and used as the template for RT-PCR. QPCR detection method based on 2019-nCoV S gene can be found in the previous study [5] . In brief, RNA extracted from above used in qPCR by HiScript® II One Step qRT-PCR SYBR® Green Kit (Vazyme Biotech Co., Ltd). The 20 μl qPCR reaction mix contained 10 μl 2× One Step SYBR Green Mix, 1 μl One Step SYBR Green Enzyme Mix, 0.4 μl 50 × ROX Reference Dye 1, 0.4 μl of each primer (10 μM) and 2 μl template RNA. Amplification was performed as follows: 50°C for 3 min, 95°C for 30 s followed by 40 cycles consisting of 95°C for 10 s, 60°C for 30 s, and a default melting curve step in an ABI 7500 machine. In-house anti-SARSr-CoV IgG and IgM ELISA kits were developed using SARSr-CoV Rp3 NP as antigen, which shared above 90% amino acid identity to all SARSr-CoVs, as reported previously [5] . For IgG test, MaxiSorp Nunc-immuno 96 well ELISA plates were coated (100 ng/well) overnight with recombinant NP. Human sera were used at 1:20 dilution for 1 h at 37°C. An anti-Human IgG-HRP conjugated monoclonal antibody (Kyab Biotech Co., Ltd, Wuhan, China) was used at a dilution of 1:40,000. The OD value (450-630) was calculated. For IgM test, Maxi-Sorp Nunc-immuno 96 wellELISA plates were coated (500 ng/well) overnight with anti-human IgM (µ chain). Human sera were used at 1:100 dilution for 40 min at 37°C, followed by anti-Rp3 NP-HRP conjugated (Kyab Biotech Co., Ltd, Wuhan, China) at a dilution of 1:4000. The OD value (450-630) was calculated. In the first investigation, we aimed to test whether viral positive can be found in anal swab and blood as well as oral swabs. We conducted a molecular investigation to patients in Wuhan pulmonary hospital, who were detected as oral swabs positive for 2019-nCoV upon admission. We collected blood, oral swabs and anal swabs for 2019-nCoV qPCR test using previously established method [5] . We found 15 patients who still carry virus following days of medical treatments. Of these patients, 8 were oral swabs positive (53.3%), 4 were anal swabs positive (26.7%), 6 blood positives (40%) and 3 serum positives (20%). Two patients were positive by both oral swab and anal swab, yet none of the blood positive was also swabs positive. Not surprisingly, all serum positives were also whole serum positive (Table 1 ). In summary, viral nucleotide can be found in anal swab or blood even if it cannot be detected in oral swabs. It should be noted that although swabs may be negative, the patient might still be viremic. We then did another investigation to find out the dynamic changes of viral presence in two consecutive studies in both oral and anal swabs in another group of patients. The target patients were those who received around 10 days of medical treatments upon admission. We tested for both viral antibody and viral nucleotide levels by previously established method [5] . We showed that both IgM and IgG titres were relatively low or undetectable in day 0 (the day of first sampling). On day 5, an increase of viral antibodies can be seen in nearly all patients, which was normally considered as a transition from earlier to later period of infection ( Figure 1 and supplementary table 1 ). IgM positive rate increased from 50% (8/16) to 81% (13/16), whereas IgG positive rate increased from 81% (13/16) to 100% (16/16). This is in contrast to a relatively low detection positive rate from molecular test (below). For molecular detection, we found 8 oral swabs positive (50%) and 4 anal swabs (25%) in these 16 people on day 0. On day 5, we were only able to find 4 oral swabs positive (25%). In contrast, we found 6 anal swabs positive (37.5%). When counting all swab positives together, we found most of the positives came from oral swab (8/10, 80%) on day 0. However, this trend appears to change on day 5. We found more (6/8, 75%) anal swab positive than oral swab positive (4/8, 50%). Another observation is the reoccurrence of virus in 6 patients who were detected negative on day 0. Of note, 4 of these 6 viral positives were from anal swabs ( Table 2) . These data suggested a shift from more oral positive during early period (as indicated by antibody titres) to more anal positive during later period might happen. Within 1 month of the 2019-nCoV disease outbreak, we rapidly developed molecular and serological detection tools. This is the first molecular and serological study on this virus after the initial identification of 2019-NCoV from 7 patients diagnosed with unidentified viral pneumonia [5] . We detected the virus in oral swabs, anal swabs and blood, thus infected patients can potentially shed this pathogen through respiratory, fecal-oral or body fluid routes. In addition, we successfully applied serology test a large population and showed which could greatly improved detection positive rate. We show that the current strategy for the detection of viral RNA in oral swabs used for 2019-nCoV diagnosis is not perfect. The virus may be present in anal swabs or blood of patients when oral swabs detection negative.  In SARS-CoV and MERS-CoV infected patients, intestinal infection was observed at later stages of infection [7] [8] [9] . However, patients infected with 2019-nCoV may harbour the virus in the intestine at the early or late stage of disease. It is also worth to note none of the patients with viremia blood had positive swabs. These patients would likely be considered as 2019-nCoV negative through routine surveillance, and thus pose a threat to other people. In contrast, we found viral antibodies in near all patients, indicating serology should be considered for 2019-nCoV epidemiology. A possible shift from oral positive during early infection to anal swab positive during late infection can be observed. This observation implied that we cannot discharge a patient purely based on oral swabs negative, who may still shed the virus by oral-fecal route. Above all, we strongly suggest using viral IgM and IgG serological test to confirm an infection, considering the unreliable results from oral swabs detection. In summary, we provide a cautionary warning that 2019-nCoV may be transmitted through multiple routes. Both molecular and serological tests are needed to definitively confirm a virus carrier.Question: Is oral swab for detecting 2019-nCOV infection, sufficient?","answer":"the current strategy for the detection of viral RNA in oral swabs used for 2019-nCoV diagnosis is not perfect. The virus may be present in anal swabs or blood of patients when oral swabs detection negative."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"IGF\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Atorvastatin protects against contrast-induced nephropathy via anti-apoptosis by the upregulation of Hsp27 in vivo and in vitro. Contrast-induced nephropathy (CIN) is an iatrogenic acute renal failure occurring following the intravascular injection of iodinated radiographic contrast medium. However, the regulatory mechanisms for CIN remain to be fully elucidated. The present study aimed to investigate whether atorvastatin protects against CIN via anti‑apoptotic effects by the upregulation of Hsp27 in vivo and in vitro. To determine whether atorvastatin attenuated CIN, the inflammatory response and apoptosis in vivo and in vitro, a rat model of iopamidol‑induced CIN was used, and human embryonic proximal tubule (HK2) cell damage was assessed. The rats were assigned into four groups (n=10 per group), as follows: Control rats; rats+atorvastatin; rats + iopamidol; rats+iopamidol+atorvastatin. In vitro, the HK2 cells were treated with iopamidol in the presence or absence of atorvastatin, heat shock protein (Hsp)27 small interfering (si)RNA or pcDNA3.1‑Hsp27. The renal tissues were examined histopathologically and collected for western blot analysis. The results showed that atorvastatin ameliorated the apoptosis and deterioration of renal function (P<0.05). Furthermore, atorvastatin reduced the iopamidol‑induced activity of B cell lymphoma‑2 (Bcl‑2)‑associated X protein (Bax)/caspase‑3 and increased the expression of Bcl‑2 in vivo and in vitro. Notably, following treatment with Hsp27 siRNA or pcDNA3.1‑Hsp27, it was found that iopamidol enhanced or weakened the upregulation of Bax/caspase‑3 and downregulation of Bcl‑2 in the HK2 cells, respectively. The results of the present study suggested that atorvastatin protected against contrast‑induced renal tubular cell apoptosis through the upregulation of Hsp27 in vivo and in vitro.","answer":"{\\"Gene\\": [\\"caspaseu20113\\", \\"Hsp27\\", \\"Bclu20112\\", \\"heat shock protein (Hsp)27\\", \\"(Bclu20112)u2011associated X protein\\", \\"Bax\\", \\"B cell lymphomau20112\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Application of single - and dual-energy CT brain tissue segmentation to PET monitoring of proton therapy The purpose of this work was to evaluate the ability of single and dual energy computed tomography (SECT, DECT) to estimate tissue composition and density for usage in Monte Carlo (MC) simulations of irradiation induced β (+) activity distributions. This was done to assess the impact on positron emission tomography (PET) range verification in proton therapy. A DECT-based brain tissue segmentation method was developed for white matter (WM), grey matter (GM) and cerebrospinal fluid (CSF). The elemental composition of reference tissues was assigned to closest CT numbers in DECT space (DECTdist). The method was also applied to SECT data (SECTdist). In a validation experiment, the proton irradiation induced PET activity of three brain equivalent solutions (BES) was compared to simulations based on different tissue segmentations. Five patients scanned with a dual source DECT scanner were analyzed to compare the different segmentation methods. A single magnetic resonance (MR) scan was used for comparison with an established segmentation toolkit. Additionally, one patient with SECT and post-treatment PET scans was investigated. For BES, DECTdist and SECTdist reduced differences to the reference simulation by up to 62% when compared to the conventional stoichiometric segmentation (SECTSchneider). In comparison to MR brain segmentation, Dice similarity coefficients for WM, GM and CSF were 0.61, 0.67 and 0.66 for DECTdist and 0.54, 0.41 and 0.66 for SECTdist. MC simulations of PET treatment verification in patients showed important differences between DECTdist / SECTdist and SECTSchneider for patients with large CSF areas within the treatment field but not in WM and GM. Differences could be misinterpreted as PET derived range shifts of up to 4 mm. DECTdist and SECTdist yielded comparable activity distributions, and comparison of SECTdist to a measured patient PET scan showed improved agreement when compared to SECTSchneider. The agreement between predicted and measured PET activity distributions was improved by employing a brain specific segmentation applicable to both DECT and SECT data.","answer":"{\\"AnatomicalStructure\\": [\\"GM\\", \\"WM\\", \\"grey matter\\", \\"brain tissue\\", \\"tissues\\", \\"tissue\\", \\"white matter\\", \\"tissue composition\\", \\"brain\\"], \\"Bacterium\\": [], \\"BiologicFunction\\": [], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [\\"cerebrospinal fluid\\", \\"CSF\\"], \\"BodySystem\\": [], \\"Chemical\\": [], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"improved\\", \\"source\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"proton therapy\\", \\"scanned\\", \\"monitoring\\", \\"PET scans\\", \\"dual energy computed tomography\\", \\"SECT\\", \\"DECT-based\\", \\"PET scan\\", \\"PET\\", \\"proton irradiation\\", \\"magnetic resonance (MR) scan\\", \\"single\\", \\"DECT\\", \\"dual-energy CT\\", \\"positron emission tomography\\", \\"evaluate\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [], \\"MedicalDevice\\": [\\"scanner\\"], \\"Organization\\": [], \\"PopulationGroup\\": [], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"simulations\\", \\"experiment\\", \\"simulation\\", \\"validation\\", \\"analyzed\\"], \\"SpatialConcept\\": [\\"areas\\"], \\"Virus\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Arsenic\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Progressive post-yield behavior of human cortical bone in shear. Bone fragility depends on its post-yield behavior since most energy dissipation in bone occurs during the post-yield deformation. Previous studies have investigated the progressive changes in the post-yield behavior of human cortical bone in tension and compression using a novel progressive loading scheme. However, little is known regarding the progressive changes in the post-yield behavior of bone in shear. The objective of this short study was to address this issue by testing bone specimens in an inclined double notch shear configuration using the progressive loading protocol. The results of this study indicated that the shear modulus of bone decreased with respect to the applied strain, but the rate of degradation was about 50% less than those previously observed in compression and tension tests. In addition, a quasi-linear relationship between the plastic and applied strains was observed in shear mode, which is similar to those previously reported in tension and compression tests. However, the viscous responses of bone (i.e. relaxation time constants and stress magnitude) demonstrated slight differences in shear compared with those observed in tension and compression tests. Nonetheless, the results of this study suggest that the intrinsic mechanism of plastic deformation of human cortical bone may be independent of loading modes.","answer":"{\\"Chemical\\": []}"},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: I want to build a supervised model to detect novel objects from only a few annotated examples.Keyphrases: object detection imagesDataset description:COCO: The MS COCO (Microsoft Common Objects in Context) dataset is a large-scale object detection, segmentation, key-point detection, and captioning dataset. The dataset consists of 328K images.FSOD: Few-Shot Object Detection Dataset (FSOD) is a high-diverse dataset specifically designed for few-shot object detection and intrinsically designed to evaluate thegenerality of a model on novel categories.DublinCity: A novel benchmark dataset that includes a manually annotated point cloud for over 260 million laser scanning points into 100'000 (approx.) assets from Dublin LiDAR point cloud [12] in 2015.FewRel 2.0: A more challenging task to investigate two aspects of few-shot relation classification models: (1) Can they adapt to a new domain with only a handful of instances? (2) Can they detect none-of-the-above (NOTA) relations?Options:- A: COCO  B: FSOD  C: DublinCity  D: FewRel 2.0","answer":"COCO"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: fruitless tunes functional flexibility of courtship circuitry during development}Article:Abstract:Drosophila male courtship is controlled by the male-specific products of the fruitless( fruM) gene and its expressing neuronal circuitry. fruM is considered a master gene that controls all aspects of male courtship. By temporally and spatially manipulating fruM expression, we found that fruM is required during a critical developmental period for innate courtship toward females, while its function during adulthood is involved in inhibiting male–male courtship. By altering or eliminating fruM expression, we generated males that are innately heterosexual, homosexual, bisexual, or without innate courtship but could acquire such behavior in an experience-dependent manner. These findings show that fruM is not absolutely necessary for courtship but is critical during development to build a sex circuitry with reduced flexibility and enhanced efficiency, and provide a new view about how fruM tunes functional flexibility of a sex circuitry instead of switching on its function as conventionally viewed.Introduction:Drosophila male courtship is one of the best understood innate behaviors in terms of genetic and neuronal mechanisms( Dickson, 2008; Yamamoto and Koganezawa, 2013). It has been well established that the fruitless( fru) gene and its expressing neurons control most aspects of such innate behavior( Ito et al., 1996; Manoli et al., 2005; Ryner et al., 1996; Stockinger et al., 2005). The male-specific products of the P1 promoter of the fru gene( fruM) are expressed in ~2000 neurons, which are inter-connected to form a sex circuitry from sensory neurons to motor neurons( Cachero et al., 2010; Lee et al., 2000; Manoli et al., 2005; Stockinger et al., 2005; Usui-Aoki et al., 2000; Yu et al., 2010). fruM function is necessary for the innate courtship behavior and sufficient for at least some aspects of courtship( Baker et al., 2001; Demir and Dickson, 2005; Manoli et al., 2005). Thus, the study of fruM function in controlling male courtship serves as an ideal model to understand how innate complex behaviors are built into the nervous system by regulatory genes( Baker et al., 2001). Although fruM serves as a master gene controlling Drosophila male courtship, we recently found that males without fruM function, although did not court if raised in isolation, were able to acquire at least some courtship behaviors if raised in groups( Pan and Baker, 2014). Such fruM-independent but experience-dependent courtship acquisition requires another gene in the sex determination pathway, the doublesex( dsx) gene( Pan and Baker, 2014). dsx encodes male- and female-specific DSX proteins( DSXM and DSXF, respectively)( Burtis and Baker, 1989), and DSXM is expressed in ~700 neurons in the central nervous system( CNS), the majority of which also express fruM( Rideout et al., 2010; Robinett et al., 2010). It has been found that the fruM and dsxM co-expressing neurons are required for courtship in the absence of fruM function( Pan and Baker, 2014). Thus fruM-expressing neurons, especially those co-expressing dsxM, control the expression of courtship behaviors even in the absence of FRUM function. Indeed, although the gross neuroanatomical features of the fruM-expressing circuitry are largely unaffected by the loss of fruM( Manoli et al., 2005; Stockinger et al., 2005), detailed analysis revealed morphological changes of many fruM-expressing neurons( Cachero et al., 2010; Kimura et al., 2005; Kimura et al., 2008; Mellert et al., 2010). Recent studies further reveal that FRUM specifies neuronal development by recruiting chromatin factors and changing chromatin states, and also by turning on and off the activity of the transcription repressor complex( Ito et al., 2012; Ito et al., 2016; Sato et al., 2019a; Sato et al., 2019b; Sato and Yamamoto, 2020). That FRUM functions as a transcription factor to specify development and/or physiological roles of certain fruM-expressing neurons, and perhaps the interconnection of different fruM-expressing neurons to form a sex circuitry raises important questions regarding when fruM functions and how it contributes to the sex circuitry( e. g., how the sex circuitry functions differently with different levels of FRUM), especially in the background that fruM is not absolutely necessary for male courtship( Pan and Baker, 2014). To at least partially answer these questions, we temporally or spatially knocked down fruM expression and compared courtship behavior in these males with that in wild-type males or fruM null males and revealed crucial roles of fruM during a narrow developmental window for the innate courtship toward females. We also found that the sex circuitry with different fruM expression has distinct function such that males could be innately heterosexual, homosexual, bisexual, or without innate courtship but could acquire such behavior in an experience-dependent manner. Thus, fruM tunes functional flexibility of the sex circuitry instead of switching on its function as conventionally viewed.Discussion:Previous findings show that fruM expression commences at the wandering third-instar larval stage, peaks at the pupal stage, and thereafter declines but does not disappear after eclosion( Lee et al., 2000), which suggests that fruM may function mainly during development for adult courtship behavior despite of no direct evidence. Here we temporally knocked down fruM expression in different developmental stages for 2 days and found that males with fruM knocked down during pupation rarely courted, while males with fruM knocked down during adulthood courted normally toward females. This is the first direct evidence that fruM is required during development but not adulthood for female-directed courtship behavior. A caveat of these experiments is that while fruM expression is effectively knocked down upon 2 day induction of fruM microRNA, it is not restored acutely after transferring to permissive temperature, although it is restored in adulthood if induction of fruM microRNA was performed at earlier stages( stages 1–5). Such a caveat does not compromise the above conclusion as knocking down fruM during pupation( stage 5) almost eliminated male courtship while knocking down at later stages have minor or no effect on male courtship. Consistent with these behavioral findings, knocking down fruM during stages 5 and 6, but not later stages, results in developmental defect in the gustatory receptor neurons innervating VNC. In addition to the role of fruM during development to specify female-directed courtship, we also found a role of fruM during adulthood in suppressing male–male courtship, as males with fruM knocked down or tra overexpressed during adulthood displayed enhanced male–male courtship or male chaining behaviors. Note that a previous study found that removal of transformer 2( tra2) specifically during adulthood using a temperature sensitive tra2 allele induced 8 of 96 females to show male-type courtship behaviors( Belote and Baker, 1987), which suggests that expression of FRUM and DSXM( by removal of tra2 function in females) during adulthood is sufficient to masculinize CNS to some extent and induce a small fraction of females to display male-like courtship behaviors. Recent studies also found that fruM expression in the Or47b-expressing olfactory receptor neurons as well as their neuronal sensitivity depend on social experiences during adulthood( Hueston et al., 2016; Sethi et al., 2019). Based on all these findings, we propose that fruM expression during pupation is crucial for neuronal development and reconstruction of adult sex circuitry that allows innate courtship toward females, and its expression during adulthood may be activity dependent in at least some neurons and modulates some aspects of courtship( e. g., inhibits male–male courtship). Thus, there are at least two separate mechanisms that fruM contributes to the sex circuitry, one during a critical developmental period to build the female-directed innate courtship into that circuitry, and the other during adulthood to modulate neuronal physiology in an experience-dependent manner. Most importantly, we revealed striking flexibility of the fly sex circuitry by manipulating fruM expression. We listed four cases with fruM manipulation here for comparison:( 1) males with a sex circuitry having wild-type fruM function have innate heterosexual courtship, as they court readily toward females, but do not court males no matter how long they meet;( 2) males with a sex circuitry having no fruM function lose the innate courtship ability, but have the potential to acquire courtship toward males, females, and even other species in an experience-dependent manner;( 3) males with a sex circuitry having limited fruM expression( e. g., 40%) have innate homosexual courtship, as they court readily toward other males, but rarely court females;( 4) males with a sex circuitry having limited fruM expression outside brain( but intact fruM expression in brain) are innately bisexual, as they court equally toward females or males. Although previous studies found that different fruM alleles( e. g., deletions, inversions, or insertions related to fru) showed very different courtship abnormalities( Anand et al., 2001; Villella et al., 1997), it was very hard to link fruM function to the flexibility of sex circuitry and often seen as allele-specific or background-dependent phenotypes. Our study using relatively simple genetic manipulations that generate dramatical different courtship behaviors promoted us to speculate a different view about the role of fruM: instead of simply being a master gene that controls all aspects of male courtship, fruM is not absolutely necessary for courtship, but changes the wiring of the sex circuitry during development such that the sex circuitry may function in very different ways, ranging from innately heterosexual, homosexual, bisexual, to largely experience-dependent acquisition of the behavior. Such flexibility of the sex circuitry is tuned by different fruM expression, such that changes of fruM regulatory regions during evolution would easily select a suitable functional mode of the sex circuitry.","answer":"Innate behaviors are behaviors that do not need to be learned . They include activities such as nest building in birds and web spinning in spiders . Another behavior that has been extensively studied , and which is generally considered to be innate , is courtship in fruit flies . Male fruit flies serenade potential mates by vibrating their wings to create a complex melody . This behavior is under the control of a gene called ‘fruitless’ , which gives rise to several distinct proteins , including one that is unique to males . For many years , this protein – called FruM – was thought to be the master switch that activates courtship behavior . But recent findings have challenged this idea . They show that although male flies that lack FruM fail to show courtship behaviors if raised in isolation , they can still learn them if raised in groups . This suggests that the role of FruM is more complex than previously thought . To determine how FruM controls courtship behavior , Chen et al . have used genetic tools to manipulate FruM activity in male flies at different stages of the life cycle and distinct cells of the nervous system . The results revealed that FruM must be present during a critical period of development – but not adulthood – for male flies to court females . However , FruM strongly influences the type of courtship behavior the male flies display . The amount and location of FruM determines whether males show heterosexual , homosexual or bisexual courtship behaviors . Adult flies with lower levels of FruM show an increase in homosexual courtship and a decrease in heterosexual courtship . These findings provide a fresh view on how a master gene can generate complex and flexible behaviors . They show that fruitless , and the FruM protein it encodes , work distinctly at different life cycles to modify the type of courtship behavior shown by male flies , rather than simply switching courtship behavior on and off . Exactly how FruM acts within the fruit fly brain to achieve these complex effects requires further investigation ."},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the thomas  fermi ( tf ) equation has proved useful for the treatment of many physical phenomena that include atoms@xcite , molecules@xcite , atoms in strong magnetic fields@xcite , crystals@xcite and dense plasmas@xcite among others .for that reason there has been great interest in the accurate solution of that equation , and , in particular , in the accurate calculation of the slope at origin@xcite . besides, the mathematical aspects of the tf equation have been studied in detail@xcite .some time ago liao@xcite proposed the application of a technique called homotopy analysis method ( ham ) to the solution of the tf equation and stated that \`\` it is the first time such an elegant and explicit analytic solution of the thomas  fermi equation is given '' .this claim is surprising because at first sight earlier analytical approaches are apparently simpler and seem to have produced much more accurate results@xcite .recently , khan and xu@xcite improved liao s ham by the addition of adjustable parameters that improve the convergence of the perturbation series .the purpose of this paper is to compare the improved ham with a straightforward analytical procedure based on pad approximants@xcite supplemented with a method developed some time ago@xcite . in section [ sec : ham ]we outline the main ideas of the ham , in section [ sec : hpm ] apply the hankel  pad method ( hpm ) to the tf equation , and in section [ sec : conclusions ] we compare the ham with the hpm and with other approaches .in order to facilitate later discussion we outline the main ideas behind the application of the ham to the tf equation .the tf equation @xmath0 is an example of two  point nonlinear boundary  value problem . when solving this ordinary differential equation one faces problem of the accurate calculation of the slope at origin @xmath1 that is consistent with the physical boundary conditions indicated in equation ( [ eq : tf ] ) .    in what followswe choose the notation of khan and xu@xcite whose approach is more general than the one proposed earlier by liao@xcite .they define the new solution @xmath2 , where @xmath3 and rewrite the tf equation as @xmath4 where @xmath5 is the inverse of the slope at origin ( @xmath6 ) and @xmath7 is an adjustable parameter .khan and xu@xcite state that the solution to eq .( [ eq : tf2 ] ) can be written in the form @xmath8 that reduces to liao s expansion@xcite when @xmath9 .    in principlethere is no reason to assume that the series ( [ eq : g_series ] ) converges and no proof is given in that sense@xcite . besides , the partial sums of the series ( [ eq : g_series ] ) will not give the correct asymptotic behaviour at infinity@xcite as other expansions do@xcite .liao@xcite and kahn and xu@xcite do not use the ansatz ( [ eq : g_series ] ) directly to solve the problem but resort to perturbation theory .for example ,kahn and xu@xcite base their approach on the modified equation @xmath10 = qhbar mathcal{n}% left [ phi ( xi ; q),gamma ( q)right ]   label{eq : ham} ] ] where @xmath11 and @xmath12 are linear and nonlinear operators , respectively , @xmath13 is a perturbation parameter and @xmath14 is another adjustable parameter . besides , @xmath15 is a conveniently chosen initial function and @xmath16 becomes the solution to equation ( [ eq : tf2 ] ) when @xmath17@xcite .both @xmath16 and @xmath18 are expanded in a taylor series about @xmath19 as in standard perturbation theory , and @xmath20 is another adjustable parameter@xcite .the authors state that ham is a very flexible approach that enables one to choose the linear operator and the initial solution freely@xcite and also to introduce several adjustable parameters@xcite .however , one is surprised that with so many adjustable parameters the results are far from impressive , even at remarkable great perturbation orders@xcite .for example the @xmath21  ] pad approximant of the ham series yields @xmath22 with three exact digits@xcite , while the @xmath23  ] pad approximant of the @xmath24 expansion@xcite provides slightly better results@xcite . a more convenient expansion of the solution of the tf equation leads to many more accurate digits@xcite with less terms .in what follows we outline a simple , straightforward analytical method for the accurate calculation of @xmath1 . in order to facilitate the application of the hpm we define the variables @xmath25 and @xmath26 ,so that the tf equation becomes @xmath27 -f(t)f^{prime } ( t)-2t^{2}f(t)^{3}=0   label{eq : tf3} ] ] we expand the solution @xmath28 to this differential equation in a taylor series about @xmath29 : @xmath30 where the coefficients @xmath31 depend on @xmath32 . on substitution of the series ( [ eq : f_series ] ) into equation ( [ eq : tf3 ] ) we easily calculate as many coefficients @xmath31 as desired ; for example , the first of them are @xmath33    the hpm is based on the transformation of the power series ( [ eq : f_series ] ) into a rational function or pad approximant @xmath34(t)=frac{sum_{j=0}^{m}a_{j}t^{j}}{sum_{j=0}^{n}b_{j}t^{j } } label{eq:[m / n]} ] ] one would expect that @xmath35 in order to have the correct limit at infinity ; however , in order to obtain an accurate value of @xmath36 it is more convenient to choose @xmath37 , @xmath38 as in previous applications of the approach to the schrdinger equation ( in this case it was called riccati  pad method ( rpm))@xcite .the rational function ( [ eq:[m / n ] ] ) has @xmath39 coefficients that we may choose so that @xmath40,t)=mathcal{o}(t^{2n+d+1}) ] and the coefficient @xmath41 remains undetermined .if we require that @xmath40,t)=mathcal{o}% ( t^{2n+d+2}) ] we have another equation from which we obtain @xmath36 . however , it is convenient to proceed in a different ( and entirely equivalent ) way and require that @xmath34(t)-sum_{j=0}^{2n+d+1}f_{j}t^{j}=mathcal{o}(t^{2n+d+2 } ) label{eq:[m / n]2} ] ] in order to satisfy this condition it is necessary that the hankel determinant vanishes @xmath42 where @xmath43 is the dimension of the hankel matrix .each hankel determinant is a polynomial function of @xmath36 and we expect that there is a sequence of roots @xmath44} ] , @xmath45 that converges towards the actual value of @xmath46 for a given value of @xmath47 .we compare sequences with different values of @xmath47 for inner consistency ( all of them should give the same limit ) .notice that a somewhat similar idea was also proposed by tu@xcite , although he did not develop it consistently .present approach is simple and straightforward : we just obtain the taylor coefficients @xmath31 from the differential equation ( [ eq : tf3 ] ) in terms of @xmath36 , derive the hankel determinant , and calculate its roots . since @xmath48 is the first nonzero coefficient that depends on @xmath36 we choose hankel sequences with @xmath49 .the hankel determinant @xmath50 exhibits many roots and their number increases with @xmath51 .if we compare the roots of @xmath50 with those of @xmath52 we easily identify the sequence @xmath44} ] that converges towards the actual value of @xmath36 .[ fig : logconv ] shows @xmath53}-2f_{2}^{[d-1,d]}right|  ] for @xmath54 that provides a reasonable indication of the convergence of the sequence of roots .we clearly appreciate the great convergence rate of the sequences with @xmath55 and @xmath56 . for example , for @xmath55 and @xmath57 it is approximately given by @xmath58}-2f_{2}^{[d-1,3]}right|=14.2times 10^ { -0.705d} ] . from the sequences for @xmath57 we estimate @xmath59 which we believe is accurate to the last digit .we are not aware of a result of such accuracy in the literature with which we can compare our estimate .it is certainly far more accurate than the result obtained by kobayashi et al@xcite by numerical integration that is commonly chosen as a benchmark@xcite .present rational approximation to the tf function is completely different from previous application of the pad approximants , where the slope at origin was determined by the asymptotic behaviour of at infinity@xcite .our approach applies to @xmath60 and the slope at origin is determined by a local condition at that point ( [ eq:[m / n]2 ] ) which results in the hankel determinant ( [ eq : hankel ] ) . in this senseour approach is similar to ( although more systematic and consistent than ) tu s one@xcite as mentioned above .once we have the slope at origin we easily obtain an analytical expression for @xmath61 in terms of the rational approximation ( [ eq:[m / n ] ] ) to @xmath28 . in order to have the correct behaviour at infinity we choose @xmath62@xcite .table  [ tab : u(x ) ] shows values of @xmath61 and its first derivative for @xmath63 ( the approximation is obviously much better for @xmath64 ) given by the approximant @xmath65  ] .our results are in remarkably agreement with the numerical calculation of kobayashi et al@xcite and are by far much more accurate than those provided by the ham@xcite .notice that we are comparing a @xmath65  ] pad approximant on the straightforward series expansion ( [ eq : f_series ] ) with @xmath66  ] and @xmath67  ] approximants on an elaborated perturbation series@xcite .any accurate analytical expression of the solution @xmath61 to the tf equation requires an accurate value of the unknown slope at origin @xmath1 , and the hpm provides it in a simple and straightforward way . in this sensethe hpm appears to be preferable to other accurate approaches@xcite and is far superior to the ham@xcite .notice for example that our estimate @xmath68}=-1.588  ] , based on a rational approximation @xmath69  ] , is better than the result provided by a @xmath21  ] pad approximant on the improved ham perturbation series@xcite . besides , by comparing table 2 of khan and xu@xcite with our fig .[ fig : logconv ] one realizes the different convergence rate of both approaches .one should also take into account that the hpm does not have any adjustable parameter for tuning up its convergence properties , while , on the other hand , the \`\` flexible '' ham with some such parameters plus a pad summation results in a much smaller convergence rate@xcite .    we also constructed a pad approximant@xmath65  ] from the series ( [ eq : f_series ] ) and obtained the tf function and its derivative with an accuracy that outperforms the @xmath66  ] and @xmath21  ] pad approximants on the ham perturbation series@xcite .it is clear that the hpm is by far simpler , more straightforward , and much more accurate than the ham .in addition to the physical utility of the hpm we think that its mathematical features are most interesting .although we can not provide a rigorous proof of the existence of a convergent sequence of roots for each nonlinear problem , or that the sequences will converge towards the correct physical value of the unknown , a great number of successful applications to the schrdinger equation@xcite suggest that the hpm is worth further investigation .notice that we obtain a global property of the tf equation @xmath1 from a local approach : the series expansion about the origin ( [ eq : f_series ] ) .the fact that our original rational approximation ( [ eq:[m / n ] ] ) does not have the correct behaviour at infinity is not at all a problem because we may resort to a more conventient expansion@xcite once we have an accurate value of the unknown slope at origin .d .. 2d .. 12d .. 12 & & + 1 & 0.424008 & 0.273989 + 5 & 0.078808 & 0.023560 + 10 & 0.024315 & 0.0046028 + 20 & 0.005786 & 0.00064727 + 30 & 0.002257 & 0.00018069 + 40 & 0.001114 & 0.00006969 + 50 & 0.000633 & 0.00003251 + 60 & 0.000394 & 0.0000172 + 70 & 0.0002626&0.000009964 + 80 & 0.0001838 & 0.000006172 + 90 & 0.0001338 & 0.000004029 + 100&0.0001005 & 0.000002743 + 1000&0.000000137&0.00000000040 +","answer":"we discuss a recently proposed analytic solution to the thomas  fermi ( tf ) equation and show that earlier approaches provide more accurate results .  in particular , we show that a simple and straightforward rational approximation to the tf equation yields the slope at origin with unprecedented accuracy , as well as remarkable values of the tf function and its first derivative for other coordinate values ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Cloning and characterization of the murine B-cell specific transcriptional coactivator Bob1. From a murine B-cell cDNA-library we have cloned a cDNA encoding the murine B-cell specific coactivator mBob1. The protein is the murine homologue to the recently described human coactivator Bob1 (hBob1), also referred to as OBF-1 or OCA-B. We have also characterized the genomic mBob1 clone. Analysis of its intron-exon structure has allowed identification of a C-terminal splice variant. mBob1 is B-cell restricted, and is found in all B-cell lines representing different stages of B-cell differentiation. mBob1 interacts with the octamer transcription factors Oct-1 and Oct-2 and stimulates transcription mediated by these factors.","answer":"{\\"CellLine\\": [\\"B - cell lines\\"], \\"CellType\\": [], \\"DNA\\": [\\"cDNA\\", \\"murine B - cell cDNA - library\\"], \\"Protein\\": [\\"human coactivator Bob1\\", \\"mBob1\\", \\"murine B - cell specific coactivator\\", \\"OBF - 1\\", \\"Oct - 1\\", \\"hBob1\\", \\"Bob1\\", \\"OCA - B\\", \\"C - terminal splice variant\\", \\"murine B - cell specific transcriptional coactivator\\", \\"octamer transcription factors\\", \\"genomic mBob1 clone\\", \\"Oct - 2\\", \\"transcription factors\\"], \\"RNA\\": []}"},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(BACKGROUND AND OBJECTIVES) One of the sites most frequently invaded by gastric cancer is the mesocolon; however, the UICC does not mention this anatomical site as an adjacent structure involved in gastric cancer. The purpose of this study was to characterize and classify mesocolon invasion from gastric cancer.(METHODS) We examined 806 patients who underwent surgery for advanced gastric carcinoma from 1992 to 2007 at the Department of Surgery, Gangnam Severance Hospital, Korea. Among these, patients who showed macroscopically direct invasion into the mesocolon were compared to other patients with advanced gastric cancer.(RESULTS) The curability, number and extent of nodal metastasis, and the survival of the mesocolon invasion group were significantly worse than these factors in the T3 group. However, the survival of the mesocolon invasion group after curative resection was much better than that of patients who had incurable factors.Question:Should direct mesocolon invasion be included in T4 for the staging of gastric cancer?Answer:","answer":"MAYBE"},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(OBJECTIVE) The purpose of this study was to evaluate the value of elevated cardiac troponin I (cTnI) for prediction of complicated clinical course and in-hospital mortality in patients with confirmed acute pulmonary embolism (PE).(METHODS AND RESULTS) This study was a retrospective chart review of patients diagnosed as having PE, in whom cTnI testing was obtained at emergency department (ED) presentation between January 2002 and April 2006. Clinical characteristics; echocardiographic right ventricular dysfunction; inhospital mortality; and adverse clinical events including need for inotropic support, mechanical ventilation, and thrombolysis were compared in patients with elevated cTnI levels vs patients with normal cTnI levels. One hundred sixteen patients with PE were identified, and 77 of them (66%) were included in the study. Thirty-three patients (42%) had elevated cTnI levels. Elevated cTnI levels were associated with inhospital mortality (P = .02), complicated clinical course (P<.001), and right ventricular dysfunction (P<.001). In patients with elevated cTnI levels, inhospital mortality (odds ratio [OR], 3.31; 95% confidence interval [CI], 1.82-9.29), hypotension (OR, 7.37; 95% CI, 2.31-23.28), thrombolysis (OR, 5.71; 95% CI, 1.63-19.92), need for mechanical ventilation (OR, 5.00; 95% CI, 1.42-17.57), and need for inotropic support (OR, 3.02; 95% CI, 1.03-8.85) were more prevalent. The patients with elevated cTnI levels had more serious vital parameters (systolic blood pressure, pulse, and oxygen saturation) at ED presentation.Question:Can elevated troponin I levels predict complicated clinical course and inhospital mortality in patients with acute pulmonary embolism?Answer:","answer":"YES"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:The 2020 severe acute respiratory syndrome coronavirus 2 pandemic has led to an increasing number of telemedicine clinician-patient encounters through telephone or videoconference. This provides a particular challenge in cancer care, where discussions frequently pertain to serious topics and are preferably performed in person. In this review, we use the SPIKES (Setting, Perception, Invitation, Knowledge, Empathy/Emotion, and Strategy/Summarize) protocol as a framework for how to approach the discussion of serious news through telemedicine. We discuss the practical and technical aspects of preparation for a remote conversation and review some differences, limitations, and advantages of these discussions. The greatest challenge with the medium is the loss of the ability to read and display nonverbal cues. Vigilant attention to proven communication strategies and solicitation of patient involvement with the discussion can allow the care provider to display empathy at a distance. Having serious discussions through telemedicine is likely unavoidable for many providers in this unprecedented time. This summary provides some strategies to help to maintain the high standard of care that we all seek for our patients who are receiving serious news.","answer":"[\\"Prevention\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:A novel method for preparing complete antigens of gonyautoxin 2,3 and their feature of immunogenicity.In this paper, a novel method was proposed to prepare artificial antigens of gonyaulax parlaytic shellfish toxin 2 and 3 (GTX2,3). An intermediate GTX2,3-aldehyde was first synthesized by activating the NH2 group of the 2nd and 8th amino acid residues with three different aldehydes and two artificial complete antigens GTX2,3-aldehyde-bovine serum albumin (BSA) and GTX2,3-aldehyde- keyhole limpet hemocyanin (KLH) were then prepared by cross-linking the intermediate with BSA or KLH. The successful preparation of the two complete antigens was confirmed by UV spectral scanning, HPLC, production of antibodies with titer of 1.28 × 10(4) from mice immunized with the two complete antigens, indirect ELISA and Western-blot. In conclusion, the synthesized complete antigens have strong immunogenicity, which provides a solid foundation for preparing GTX2,3 monoclonal antibody and rapid detection kit.","answer":"{\\"Chemical\\": [\\"GTX2,3\\", \\"gonyautoxin 2,3\\", \\"amino acid\\", \\"NH2\\", \\"GTX2,3-aldehyde\\", \\"aldehydes\\"], \\"Protein\\": [\\"bovine serum albumin\\", \\"KLH\\", \\"BSA\\", \\"keyhole limpet hemocyanin\\"]}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Effects of a partially home-based exercise program for women with gestational diabetes.Abstract 1:To examine the effectiveness of a partially home-based, moderate-intensity aerobic exercise program for women with gestational diabetes.                This was a randomized experimental design. Thirty-three women with gestational diabetes were randomly assigned to the exercise or the no-exercise group. Subjects underwent hemoglobin A1C assay and submaximal cycle ergometer fitness tests at baseline and at study conclusion. Subjects kept diaries of home fasting and 2-hour postprandial blood glucose determinations. Exercise subjects were asked to exercise for 30 minutes three to four times weekly at 70% of estimated maximal heart rate for the weeks of study participation. Two exercise sessions weekly were supervised by the investigator, and two were unsupervised at home. Control-group subjects were asked to maintain their current activity level.                Daily fasting and postprandial blood glucose levels, hemoglobin A1C, incidence of exogenous insulin therapy, and incidence of newborn hypoglycemia were not different between the groups. There was a training effect in the exercise group (P = .005) but not in the control group (P = .25). A significant decline in daily grams of carbohydrate consumed was observed in the control group (P = .03), but not in the exercise group (P = .97). No complications were found in the subjects who exercised.                A partially home-based exercise program did not reduce blood glucose levels, but did result in a modest increase in cardiorespiratory fitness. The intervention appeared safe.Title 2:Effect of exercise on blood pressure in pregnant women with a high risk of gestational hypertensive disorders.Abstract 2:To prospectively determine whether moderate exercise during pregnancy lowers blood pressure.                A randomized, controlled trial with one test group and one control group. All subjects have a history of mild hypertension, gestational hypertensive disorders or a family history of hypertensive disorders. Subjects were recruited before 14 weeks' gestation. After four weeks of observation, the subjects were randomly assigned to either the exercise or control group. The exercise group visited the laboratory three times a week for 10 weeks (18-28 gestation weeks) to perform 30 minutes of exercise at Rating of Perceived Exertion level 13.                A total of 16 pregnant women (mean age, 30 years) participated. The mean metabolic equivalent during exercise sessions was 4.7 (SD = 0.8). Blood pressure measurements were compared before and after the 10-week exercise period in the two groups. Systolic blood pressures did not change significantly, but diastolic blood pressure (DBP) in the exercise group decreased by 3.5 mm Hg, while that in the control group increased by 1.1 mm Hg. Thus, the pre-post change in DBP differed by 4.6 mm Hg between groups. Exercise treatment reduced the diastolic blood pressure to a near-significant level in the exercise group (t = 2.34, df = 7, P = .052). Percent body fat did not differ between the exercise and control groups either before or after exercise treatment. ANOVA revealed that pregnancy had a significant effect (F(1, 14) = 5.7, P = .03) on increasing the percentage of fat, but exercise treatment did not (F(1, 14) = .18, P = .68). Estimated energy expenditure in overall daily physical activities during the intervention did not differ between the two groups despite the inclusion of exercise.                This study detected a strong trend that 10 weeks of moderate exercise lowered the diastolic blood pressure among pregnant women at risk of hypertensive disorders. The reductions were probably due to the effect of exercise itself, not to weight or overall daily physical activity levels.","answer":"There is insufficient evidence for reliable conclusions about the effects of exercise on prevention of pre-eclampsia and its complications.[Note: The four citations in the awaiting classification section of the review may alter the conclusions of the review once assessed.]"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Regiospecific and conformationally restrained analogs of melphalan and DL-2-NAM-7 and their affinities for the large neutral amino acid transporter (system LAT1) of the bloodxe2x80x93brain barrierPaper sections:<p>The treatment of malignant brain tumors represents a significant clinical challenge. Patients often present with disabling neurological syndromes, undergo rapid deterioration, and respond poorly to current therapies. Despite recent developments in treatment strategies, including combination therapy, tumor-targeted ligands, tissue-specific chemotherapy, and attempts at manipulating discrete molecular and cellular signaling pathways, therapeutic outcomes remain very poor.1–3 Although many effective anticancer drugs in numerous therapeutic classes are available for treating peripheral cancers, most anticancer drugs are ineffective for treating CNS tumors, in large part due to their inability to cross the blood–brain barrier (BBB) from the systemic circulation into the tumor and peritumoral areas in therapeutic concentrations.1,4</p><p>The permeability of the protective BBB to xenobiotics such as chemotherapeutic agents depends upon a number of factors, including molecular weight, lipid solubility, lipid and protein binding, metabolism, and efflux out of the CNS, as well as on prior treatments. 3,4 Attempts to compromise the integrity of the BBB in order to overcome its normal protective role and facilitate delivery of chemotherapy to the brain include MRI-guided ultrasound and transient hyper-osmotic disruption.4 Although transient disruption of the BBB shows promise in improving the CNS delivery of chemotherapeutic agents, there is some concern about potential tissue damage and neurological side effects. Another approach might be to take advantage of natural transporter proteins present at the intact BBB membrane in order to increase the CNS delivery of novel chemotherapeutic agents that are also designed as transporter substrates.</p><p>A number of amino acid transporters are expressed at the BBB in order to promote the uptake of amino acids from the systemic circulation into the brain. Such transporters are necessary for normal brain function. The large neutral amino acid transporter (System LAT1) facilitates the uptake of neutral amino acids, such as L-leucine and L-phenylalanine (1), in a saturable and stereospecific manner.5–7 The system LAT1 transporter is expressed on both the capillary luminal and abluminal membranes, has the greatest transport capacity of the BBB amino acid influx transporters, and mediates the uptake of the largest number of amino acids into brain.5–7 Thus, the system LAT1 transporter may be regarded as a versatile, high-capacity target for transporting appropriately designed therapeutic agents into the brain without disrupting the integrity of the BBB.</p><p>Melphalan (2) is an established anticancer agent and nitrogen mustard derivative of the system LAT1 substrate L-phenylalanine (Fig. 1). However, as a moderately low-affinity substrate for system LAT1, with an estimated Km of ~90–150 μM,8,9 it shows poor brain penetration and is an inferior candidate for the treatment of brain tumors. Conformational restriction of the phenylalanine molecule to afford DL-2-amino-1,2,3,4,-tetrahydronaphthoic acid (3) improved affinity for the system LAT1 transporter (Km = 7.1 μM).10 The rigid amino acid, BCH (4), also has good affinity for the system LAT1 transporter.10,11 Subsequent studies have suggested that other mustard analogs may be designed with improved affinity for system LAT1 compared to melphalan.10–12 Thus, it may be possible to improve CNS delivery through design and development of novel chemotherapeutic agents structurally related to melphalan that incorporate a more conformationally restrained amino acid scaffold, such as 3, thereby improving system LAT1 transporter affinity.12 The melphalan analogs 5a and 5c have each been reported to have higher affinity for the system L transporter (Ki = ~25 and ~0.2 μM, respectively) than melphalan.10 Also, 5c (DL-2-NAM-7) possesses enhanced in vitro antitumor activity and reduced myelosuppressive activity when compared to melphalan. 11 Furthermore, studies have shown that 5c is rapidly taken up into brain by the blood–brain barrier system LAT1 transporter (Vmax = 0.26 nmol/min/g; Km = 0.19 μM).10</p><p>Placing the mustard moiety at the C-7 position in 5 affords an isomer (5c) that has significantly higher affinity for system LAT1 than the C-5 compound 5a. However, it is not known whether the optimal position for the mustard moiety is at C-7, since the affinity of the C-6 and C-8 isomers 5b and 5d, respectively, have not been reported.</p><p>The goals of the current study were to prepare all the isomeric forms of DL-2-NAM-7 (5c) in order to determine the aromatic substitution position of the nitrogen mustard moiety that affords optimal affinity for the system LAT1 transporter, and to also prepare a number of more conformationally defined analogs of DL-2-NAM, in order to assess the effect of further conformational restriction on system LAT1 transporter affinity. In this respect the more conformationally restrained indane analog of DL-2-NAM-7, compound 6, was considered worthy of evaluation as a system LAT1 transporter ligand. Also, compounds incorporating the extremely rigid amino acid 4 into their structure were believed to be of potential interest due the high affinity of this amino acid for the system LAT1 transporter.13,14</p><p>In this study, all four isomers (5a–5d) of DL-2-NAM were prepared, as well as the structurally related analogs 6 and 7, and their affinities for the system LAT1 transporter were assessed by competitive L-[14C]-leucine uptake inhibition utilizing a modification15 of the in situ rat brain perfusion method of Takasato et al.16</p><p>Mustard analogs of the various amino acid targets were synthesized from precursor hydantoins, which were nitrated to afford a mixture of isomeric products. These isomeric mixtures were not separated, but catalytically reduced to the corresponding isomeric aromatic amines. These mixtures were then reacted with ethylene oxide to afford a mixture of the N-[bis-(ethylhydroxy)-amino isomers.</p><p>In the synthesis of compounds 5a–5d (Scheme 1), initial nitration of hydantoin 817 afforded a mixture of all 4-nitro isomers, which were reduced to their amino derivatives (10) followed by conversion to a mixture of the bis-(2-hydroxyethyl)-amino analogs 11 with ethylene oxide. Isomer 14 could be obtained in a pure form by fractional crystallization, and the resulting mother liquors could be fractionated by preparative HPLC chromatography to afford isomers 12, 13 and 15. Each bis-(2-hydroxyethyl)-amino isomer was then converted to the corresponding amino acid mustard by reaction with phosphoryl chloride followed by acid hydrolysis. The final mustard products, 5a–5d, were further purified by preparative HPLC prior to biological evaluation.18</p><p>In the synthesis of the indane mustard 6 (Scheme 2), initial nitration of hydantion 1617 afforded a mixture of the 4-nitro (minor) and 5-nitro (major) analogs (17), which were not separated, but converted to their corresponding amino analogs (18) utilizing H2/Pd–C 10%/DMP, and then to their bis(2-hydroxyethyl)-amino analogs. Isomer 19 was obtained pure by silica gel chromatography. However, an isomerically pure sample of the corresponding 4-isomer could not be obtained. Mustard 6 was obtained from 19 as described above for products 5a–5d, and was purified by preparative HPLC prior to biological evaluation.18</p><p>The synthesis of mustard 7 from hydantoin 2019 utilized a similar procedure to that described for the indane mustard 6 (Scheme 3), affording a mixture of the 5-(minor) and 7-(major)-nitro isomers (21). Isomer 23 could be obtained by fractional crystallization of the isomeric mixture obtained from the reaction of ethylene oxide with 22 and was then converted to mustard 7 as previously described. An isomerically pure sample of the 5-isomer of 22 could not be obtained.</p><p>The structures of all the amino acid mustards were confirmed by 1H NMR, and HRMS.20</p><p>System LAT1 transporter affinities of the tested compounds were determined using the in situ rat brain perfusion technique12, which measured the concentration-dependent inhibition of L-[14C]-leucine uptake into rat brain by the amino acid analogues. The relative capacity of the tested compounds to inhibit L-[14C]-leucine uptake across the blood–brain barrier was determined as Ki (IC50) values, and the data were summarized in Table 1.</p><p>The data in Table 1 clearly indicate that in the 2-NAM series of compounds, the optimal position for the mustard moiety is at C-7 of the 1,2,3,4-tetrahydronaphthalene ring. The previously unreported isomers 5b and 5d had >1000 times lower affinity for the system LAT1 transporter than DL-2-NAM-7 (5c) and isomer 5a had 100 times less affinity for the transporter than 5c. Further restriction of the conformational flexibility of the 2-NAM scaffold appeared to be detrimental to system LAT1 binding, since the indane analog 6 and the rigid analog 7 had 60 and 25 times less affinity, respectively, for the transporter than 5c, but approximately matched affinity for 5a. It is important to note that both 6 and 7 were superior ligands than melphalan (2) at the system LAT1 transporter and may show improved delivery to brain and activity against brain tumors.</p>","answer":"Regiospecific and conformationally restrained analogs of melphalan and DL-2-NAM-7 have been synthesized and their affinities for the large neutral amino acid transporter (LAT1) of the bloodxe2x80x93brain barrier have been determined to assess their potential for accessing the CNS via facilitated transport. Several analogs had Ki values in the range 2.1xe2x80x938.5 xcexbcM with greater affinities than that of either L-phenylalanine (Ki = 11 xcexbcM) or melphalan (Ki = 55 xcexbcM), but lower than DL-2-NAM-7 (Ki = 0.08 xcexbcM). The results indicate that regiospecific positioning of the mustard moiety on the aromatic ring in these analogs is very important for optimal affinity for the large neutral amino acid transporter, and that conformational restriction of the DL-2-NAM-7 molecule in benzonorbornane and indane analogs leads to 25- to 60-fold loss, respectively, in affinity."},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: A novel approach for transferring knowledge across related natural language understanding tasks.Keyphrases: natural language inference textDataset description:SuperGLUE: SuperGLUE is a benchmark dataset designed to pose a more rigorous test of language understanding than GLUE. SuperGLUE has the same high-level motivation as GLUE: to provide a simple, hard-to-game measure of progress toward general-purpose language understanding technologies for English.MultiNLI: The Multi-Genre Natural Language Inference (MultiNLI) dataset has 433K sentence pairs. Its size and mode of collection are modeled closely like SNLI.GLUE: General Language Understanding Evaluation (GLUE) benchmark is a collection of nine natural language understanding tasks, including single-sentence tasks CoLA and SST-2, similarity and paraphrasing tasks MRPC, STS-B and QQP, and natural language inference tasks MNLI, QNLI, RTE and WNLI.DialoGLUE: DialoGLUE is a natural language understanding benchmark for task-oriented dialogue designed to encourage dialogue research in representation-based transfer, domain adaptation, and sample-efficient task learning. It consisting of 7 task-oriented dialogue datasets covering 4 distinct natural language understanding tasks.KLEJ: The KLEJ benchmark (Kompleksowa Lista Ewaluacji Językowych) is a set of nine evaluation tasks for the Polish language understanding task. Key benchmark features:   It contains a diverse set of tasks from different domains and with different objectives.ConceptNet: ConceptNet is a knowledge graph that connects words and phrases of natural language with labeled edges. Its knowledge is collected from many sources that include expert-created resources, crowd-sourcing, and games with a purpose.SNLI: The SNLI dataset (Stanford Natural Language Inference) consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral. Premises are image captions from Flickr30k, while hypotheses were generated by crowd-sourced annotators who were shown a premise and asked to generate entailing, contradicting, and neutral sentences.Options:- A: SuperGLUE  B: MultiNLI  C: GLUE  D: DialoGLUE  E: KLEJ  F: ConceptNet  G: SNLI","answer":"[\\"MultiNLI\\", \\"SNLI\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Expression of the nucleoside diphosphate kinase in human skin cancers: an immunohistochemical study. Expression of nucleoside diphosphate (NDP) kinase, which is homologous to the nm23 gene product in a variety of species, has been found to be inversely associated with metastatic potential. However, the relationship remains controversial according to the tumor cell types and experimental system, with conflicting results from different research groups. In order to determine whether NDP kinase expression serves as a marker for metastatic potential in human skin cancer, we assessed the levels of NDP kinase expression in 9 keratoacanthomas (KAs), 26 squamous cell carcinomas (SCCs), and 25 basal cell carcinomas (BCCs) using immunohistochemistry. The expression of NDP kinase was intense in KA and SCC compared with BCC. However, the difference of NDP kinase expression between KA and SCC was not statistically significant. And there was no statistically significant difference in NDP kinase expression between SCC with metastasis and SCC without metastasis. Our results contradict the hypothesis concerning the possible role of nm23 gene as a metastatic suppressor gene in human skin cancer. The mechanism of overexpression in various tumor cell types and its biological significance in cutaneous carcinogenesis remain to be determined.","answer":"{\\"CellLine\\": [], \\"CellType\\": [\\"tumor cell types\\"], \\"DNA\\": [\\"nm23 gene\\"], \\"Protein\\": [\\"nucleoside diphosphate kinase\\", \\"nucleoside diphosphate (NDP) kinase\\", \\"NDP kinase\\", \\"nm23 gene product\\"], \\"RNA\\": []}"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Endoscopically confirmed gastric and/or duodenal ulcers on Day 1. Endoscopically confirmed active upper gastrointestinal hemorrhage on Day 1. Current or past history of aspirin-induced asthma or hypersensitivity to NSAIDs. Past or planned surgery affecting gastric acid secretion. Clinically significant hepatic or renal disorder. Serious cardiac dysfunction, hypertension, or hematological disorder.","answer":"{\\"Condition\\": [\\"hepatic disorder\\", \\"upper gastrointestinal hemorrhage\\", \\"hypersensitivity to NSAIDs\\", \\"cardiac dysfunction\\", \\"hypertension\\", \\"duodenal ulcers\\", \\"hematological disorder\\", \\"renal disorder\\", \\"gastric\\", \\"asthma\\"], \\"Device\\": [], \\"Drug\\": [\\"NSAIDs\\", \\"aspirin\\"], \\"Measurement\\": [], \\"Mood\\": [\\"planned\\"], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [\\"past history\\"], \\"Person\\": [], \\"Procedure\\": [\\"Endoscopically\\", \\"surgery\\"], \\"Qualifier\\": [\\"Clinically significant\\", \\"Serious\\", \\"Endoscopically confirmed\\", \\"affecting gastric acid secretion\\", \\"aspirin-induced\\"], \\"ReferencePoint\\": [\\"Day 1\\"], \\"Scope\\": [\\"Past or planned\\", \\"asthma or hypersensitivity to NSAIDs\\", \\"hepatic or renal disorder\\", \\"Current or past history\\", \\"cardiac dysfunction, hypertension, or hematological disorder\\", \\"gastric and/or duodenal ulcers\\"], \\"Temporal\\": [\\"active\\", \\"Past\\", \\"on Day 1\\", \\"Current\\"], \\"Value\\": [], \\"Visit\\": []}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: A reinforcement learning based model for machine comprehension.Keyphrases: machine comprehension textDataset description:TriviaQA: TriviaQA is a realistic text-based question answering dataset which includes 950K question-answer pairs from 662K documents collected from Wikipedia and the web. This dataset is more challenging than standard QA benchmark datasets such as Stanford Question Answering Dataset (SQuAD), as the answers for a question may not be directly obtained by span prediction and the context is very long.UIT-ViQuAD: A new dataset for the low-resource language as Vietnamese to evaluate MRC models. This dataset comprises over 23,000 human-generated question-answer pairs based on 5,109 passages of 174 Vietnamese articles from Wikipedia.UIT-ViNewsQA: UIT-ViNewsQA is a new corpus for the Vietnamese language to evaluate healthcare reading comprehension models. The corpus comprises 22,057 human-generated question-answer pairs.HoME: HoME (Household Multimodal Environment) is a multimodal environment for artificial agents to learn from vision, audio, semantics, physics, and interaction with objects and other agents, all within a realistic context. HoME integrates over 45,000 diverse 3D house layouts based on the SUNCG dataset, a scale which may facilitate learning, generalization, and transfer.LogiQA: LogiQA consists of 8,678 QA instances, covering multiple types of deductive reasoning. Results show that state-of-the-art neural models perform by far worse than human ceiling.SQuAD: The Stanford Question Answering Dataset (SQuAD) is a collection of question-answer pairs derived from Wikipedia articles. In SQuAD, the correct answers of questions can be any sequence of tokens in the given text.Options:- A: TriviaQA  B: UIT-ViQuAD  C: UIT-ViNewsQA  D: HoME  E: LogiQA  F: SQuAD","answer":"[\\"TriviaQA\\", \\"SQuAD\\"]"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Histone supply regulates S phase timing and cell cycle progression}Article:Abstract:Eukaryotes package DNA into nucleosomes that contain a core of histone proteins. During DNA replication, nucleosomes are disrupted and re-assembled with newly synthesized histones and DNA. Despite much progress, it is still unclear why higher eukaryotes contain multiple core histone genes, how chromatin assembly is controlled, and how these processes are coordinated with cell cycle progression. We used a histone null mutation of Drosophila melanogaster to show that histone supply levels, provided by a defined number of transgenic histone genes, regulate the length of S phase during the cell cycle. Lack of de novo histone supply not only extends S phase, but also causes a cell cycle arrest during G2 phase, and thus prevents cells from entering mitosis. Our results suggest a novel cell cycle surveillance mechanism that monitors nucleosome assembly without involving the DNA repair pathways and exerts its effect via suppression of CDC25 phosphatase String expression.Introduction:Chromatin assembly during DNA replication is crucial for the repackaging of newly synthesized DNA and for maintaining or erasing histone modifications. During this process, pre-existing or so-called parental histones are recycled and assembled into nucleosomes together with de novo synthesized histones( Alabert and Groth, 2012; Annunziato, 2012). To compensate for the high demand of histone proteins during DNA replication, the canonical histones H1, H2A, H2B, H3, and H4, which are encoded by multiple gene copies in higher eukaryotes, are highly and exclusively expressed in S phase of the cell cycle( Marzluff et al., 2008). The assembly of chromatin is mediated by an interplay of components of the DNA replication machinery and histone chaperones, which mediate the deposition of histones into nucleosomes( Alabert and Groth, 2012; Annunziato, 2012). Apparently, the pace of DNA synthesis is tightly coupled to the assembly of newly synthesized DNA into chromatin. Multiple studies showed that the depletion of the histone chaperones Asf1 and CAF-1 results in a slow down of DNA synthesis during S phase( Hoek and Stillman, 2003; Ye et al., 2003; Nabatiyan and Krude, 2004; Groth et al., 2007; Takami et al., 2007) preceding the accumulation of DNA damage in mammalian cells( Hoek and Stillman, 2003; Ye et al., 2003). Also, diminishing histone supply during S phase through knock down of SLBP, which is required for histone mRNA stability and translation, decreases the rate of DNA synthesis( Zhao et al., 2004). A recent study that targeted SLBP together with FLASH, a factor that is required for histone mRNA transcription and processing( Barcaroli et al., 2006; Yang et al., 2009), revealed that replication fork progression depends on nucleosome assembly potentially through a mechanism based on a feedback from the histone chaperone CAF-1 to the replicative helicase and/or the unloading of PCNA from newly synthesized DNA upon nucleosome assembly( Groth et al., 2007; Mejlvang et al., 2014). The coupling of replication fork progression and nucleosome assembly might compensate for short-term fluctuations in histone availability( Mejlvang et al., 2014). However, it is still unclear whether chromatin integrity is monitored after or during DNA replication. Genome integrity during S phase is governed by the ATR/Chk1 and ATM/Chk2 checkpoint mechanisms that sense replication stress and DNA damage, respectively( Bartek and Lukas, 2007; Cimprich and Cortez, 2008). Lack of CAF-1 or Asf1 function leads to accumulation of DNA damage and activation of the ATM/Chk2 pathway( Hoek and Stillman, 2003; Ye et al., 2003). These findings led to the hypothesis that chromatin assembly is monitored indirectly through accumulation of DNA lesions in response to stalled replication forks. However, since these chaperones have multiple functions such as unwinding of DNA during replication, in DNA repair( Gaillard et al., 1996; Green and Almouzni, 2003; Schöpf et al., 2012) as well as other nuclear processes( Quivy et al., 2004; Houlard et al., 2006). These multiple functions of these chaperones make it difficult to assess the direct effects of defective chromatin assembly. Taking advantage of a histone null mutation in a higher eukaryote that recently became available in Drosophila melanogaster( Günesdogan et al., 2010), we directly addressed the requirement of canonical histone supply for DNA replication and cell cycle progression in a developing organism. By reintroducing a defined number of transgenic histone genes into the histone null mutant background, we show that the rate of DNA replication is coupled to the number of histone genes present in the genome and that histone supply is critical to coordinate S phase length with the developmental program. Surprisingly, cells that completely lacked de novo histone synthesis replicate DNA at a reduced rate, but complete S phase and arrest in cell cycle without accumulating DNA damage. This cell cycle arrest is mediated by suppressing the accumulation of transcripts encoding the CDC25 phosphatase String and provides evidence for a chromatin assembly surveillance mechanism that is independent of the known S phase checkpoints.Discussion:We used a recently generated null mutation for canonical histones to address the consequences of histone deprivation during metazoan development. In addition to canonical histones, eukaryotes express histone variants that can replace canonical histones in a specific genomic context( Banaszynski et al., 2010). Our results show that these histone variants do not compensate for the lack of canonical histone synthesis with regard to chromatin assembly and cell cycle progression. This could be due to insufficient expression of variant histones from their endogenous promoters as it has been shown for the variant histone H3. 3, which can fully replace its canonical counterpart, histone H3, but only if it is expressed from within a histone gene unit like the canonical histone( Hödl and Basler, 2012). Alternatively, it could reflect structural divergence of the histone variants as in the case of His2Av( van Daal et al., 1988) and dBigH1( Perez-Montero et al., 2013). It will be interesting to test whether individual histone mutations, like a mutation in H2B which does not have a variant histone in Drosophila( Talbert et al., 2012), will cause a similar cell cycle arrest as the histone null mutation HisC. Our results provide evidence that canonical histone supply directly affects the rate of DNA synthesis( Figure 2L–N). This observation is in line with studies that targeted either histone chaperones( Hoek and Stillman, 2003; Ye et al., 2003; Nabatiyan and Krude, 2004; Groth et al., 2007; Takami et al., 2007) or histone mRNA through SLBP or FLASH( Zhao et al., 2004; Barcaroli et al., 2006; Mejlvang et al., 2014) to interfere with chromatin assembly in tissue culture cells. However, previous work on SLBP in multicellular organisms revealed pleiotropic effects( Sullivan et al., 2001; Lanzotti et al., 2002; Pettitt et al., 2002). Our data illustrate that an extension of the S phase duration caused by diminished histone supply allows a faithful completion of S phase and transition from G2 into M phase of the cell cycle. This S phase extension is likely to be caused by a direct effect of lowered histone availability on replication fork progression( Groth et al., 2007; Mejlvang et al., 2014) and not by a lack of origin firing, although we cannot exclude this possibility completely. It was previously shown that postblastodermal development in Drosophila embryos proceeds largely uncoupled from progression through cell cycles 14–16( Edgar et al., 1994; Meyer et al., 2002). Therefore, histone availability limits S phase duration and appears to be a critical link between cell division and development. In the absence of de novo histone synthesis, we find that cells arrest in G2 phase of the cell cycle without activating the known ATM/Chk2 and ATR/Chk1 checkpoints. This observation is in contrast to previous studies on CAF-1, which found that cells arrest in S phase and accumulate DNA damage( Hoek and Stillman, 2003; Ye et al., 2003). This discrepancy might in part be explained by the fact that histone chaperones also have a direct function in DNA repair( Schöpf et al., 2012); and thus, in the presence of an intact DNA repair/chromatin assembly machinery in HisC mutants, DNA is replicated without the accumulation of damage, even when histone supply is restricted to the parental load of histones. Alternatively, the accumulation of DNA damage in histone chaperone-depleted cells might be the consequence of a prolonged replication slow down, since it was shown that neither ATM/Chk2 nor ATR/Chk1 are activated as an immediate consequence of histone deprivation but only after prolonged incubation times( >48 hr)( Mejlvang et al., 2014). Based on our DNA quantification experiments, we found that the bulk of DNA replication in HisC mutants is completed by about 2 hr after entry into S phase, which might differ from the timeframe required to develop significant DNA damage. Interestingly, we find that HisC mutant cells become TUNEL positive by about 6 hr after they enter S phase 15, which might reflect secondary DNA damage and/or cell death. Nevertheless, we found a moderate increase of γH2Av staining during late S phase in HisC mutant embryos. Our data indicate, however, that cells that resolved UVC-induced DNA damage, and therefore entered mitosis can do so with levels of γH2Av comparable to those we observe in HisC mutants. Thus, it is plausible that the slight increase in γH2Av in HisC mutants could result from incomplete turnover of γH2Av rather than directly reflect DNA damage that could activate the S phase checkpoints. Turnover of γH2Av was shown to require the Tip60 chromatin-remodelling complex( Kusch et al., 2004), which may be affected by the altered chromatin structure in HisC mutants. Alternatively, H2Av was recently shown to be phosphorylated independent of ATM/ATR by the chromosomal tandem kinase JIL-1( Jin et al., 1999; Thomas et al., 2014), which may also be influenced by the changed chromatin topology in HisC mutants. Both, the ATM/Chk2 and ATR/Chk1 checkpoints are known to act on CDC25 phosphatases by phosphorylation and protein destabilization( Bartek and Lukas, 2007) and it was shown in Drosophila that string transcripts accumulate normally in embryos that suffered from DNA damage( Su et al., 2000). In contrast, we find that HisC mutant cells fail to accumulate string transcripts when arrested in G2. This finding was surprising since it was shown that the temporal and spatial expression pattern of string is essentially unchanged in embryos that are arrested in G2 by mutations in string or in mitotic Cyclins( Edgar et al., 1994). Thus, this difference is likely due to the failure of HisC mutant embryos to assemble chromatin, resulting in a diminished nucleosome density as shown by the presence of excess MNase hypersensitive DNA. Although we cannot rule out that the lower abundance of histone proteins itself directly contributes to the G2 arrest, this possibility seems unlikely since histone levels rapidly decrease in G2 cells where the chromatin assembly surveillance should act( Marzluff et al., 2008). It remains unclear how the presence of unassembled chromatin is linked to the regulation of string, but the effect is specific, since string transcript accumulation is the only limiting factor to overcome the G2 arrest in HisC-mutant embryos. The subsequent mitosis in HisC mutants is completed and cells enter into the next cell cycle. Given that HisC mutant cells enter mitosis with presumably about half of the nucleosomes present in wild type chromatin, the mitotic defects like lagging anaphase chromosomes appear surprisingly mild. These defects could reflect problems in loading of structural components that are required for chromosome condensation and sister chromatid cohesion, like Cohesins and Condensins, which are proposed to require contact to chromatin rather than naked DNA( Bernard et al., 2001; Nonaka et al., 2002; Tada et al., 2011). Taken together, our results suggest that incomplete chromatin assembly is monitored by a novel surveillance mechanism that can block cell cycle progression at the G2/M transition in Drosophila. Our findings now pave the way to address key questions regarding the orchestration of DNA synthesis and chromatin formation as well as the control of chromatin integrity during cell cycle progression.","answer":"As a cell prepares to divide , it goes through four distinct stages . First , it grows in size ( G1 phase ) ; next it copies its entire DNA content ( S phase ) ; then it grows some more ( G2 phase ) ; and , last , it splits into two new cells ( M phase ) . During S phase , groups of histone proteins that normally stick together to tightly package the DNA are pulled apart in order to make the DNA accessible for copying . After the DNA has been duplicated , both copies of the DNA strand need to be repackaged . Therefore , after copying the DNA the cell rapidly reassembles the DNA–histone complexes ( called nucleosomes ) , using a combination of old and newly synthesized histones to do so . A cell can adjust how quickly it copies DNA according to the availability of these histone proteins , which is important because copying DNA without the resources to package it could expose the DNA to damage . Here , Günesdogan et al . investigate how a cell controls these processes using a mutant of the fruit fly Drosophila melanogaster that completely lacks the genes required to make histones . Cells that lack histones copy their DNA very slowly but adding copies of histone genes back into these flies speeds up the rate at which DNA is copied . Günesdogan et al . ask whether the slower speed of DNA replication in cells without new histones is connected to preventing DNA damage . However , these cells can still copy all their DNA , despite being unable to package it , so the higher risk of making mistakes is not enough to stop S phase . In fact , indications suggest that DNA damage detection methods continue to work as normal in cells without histones: these cells can get all the way to the end of G2 phase without any problems . To go one step further and start splitting in two , a cell needs to switch on another gene , called string in the fruit fly and CDC25 in vertebrates , which makes an enzyme required for the cell division process . Normal cells switch on string during G2 phase , but cells that lack histones do not—and therefore do not enter M phase . Günesdogan et al . show that turning on string by a genetic trick is sufficient to overcome this cell cycle arrest and drive the cells into M phase . String could therefore form part of a surveillance mechanism that blocks cell division if DNA–histone complexes are not assembled correctly ."},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: A robust facial landmark detection model that is more robust to noise and occlusion.Keyphrases: facial landmark detection imageDataset description:WFLW: The Wider Facial Landmarks in the Wild or WFLW database contains 10000 faces (7500 for training and 2500 for testing) with 98 annotated landmarks. This database also features rich attribute annotations in terms of occlusion, head pose, make-up, illumination, blur and expressions.SoF: The Specs on Faces (SoF) dataset, a collection of 42,592 (2,662×16) images for 112 persons (66 males and 46 females) who wear glasses under different illumination conditions. The dataset is FREE for reasonable academic fair use.UTKFace: The UTKFace dataset is a large-scale face dataset with long age span (range from 0 to 116 years old). The dataset consists of over 20,000 face images with annotations of age, gender, and ethnicity.AFLW: The Annotated Facial Landmarks in the Wild (AFLW) is a large-scale collection of annotated face images gathered from Flickr, exhibiting a large variety in appearance (e.g., pose, expression, ethnicity, age, gender) as well as general imaging and environmental conditions. In total about 25K faces are annotated with up to 21 landmarks per image.300W: The 300-W is a face dataset that consists of 300 Indoor and 300 Outdoor in-the-wild images. It covers a large variation of identity, expression, illumination conditions, pose, occlusion and face size.Options:- A: WFLW  B: SoF  C: UTKFace  D: AFLW  E: 300W","answer":"[\\"WFLW\\", \\"AFLW\\", \\"300W\\"]"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:In many real world situations, collective decisions are made using voting. Moreover, scenarios such as committee or board elections require voting rules that return multiple winners. In multi-winner approval voting (AV), an agent may vote for as many candidates as they wish. Winners are chosen by tallying up the votes and choosing the top- @math candidates receiving the most votes. An agent may manipulate the vote to achieve a better outcome by voting in a way that does not reflect their true preferences. In complex and uncertain situations, agents may use heuristics to strategize, instead of incurring the additional effort required to compute the manipulation which most favors this http URL this paper, we examine voting behavior in multi-winner approval voting scenarios with complete information. We show that people generally manipulate their vote to obtain a better outcome, but often do not identify the optimal manipulation. Instead, voters tend to prioritize the candidates with the highest utilities. Using simulations, we demonstrate the effectiveness of these heuristics in situations where agents only have access to partial information.Cited Abstract(s):[1]: Amazon’s Mechanical Turk is an online labor market where requesters post jobs and workers choose which jobs to do for pay. The central purpose of this article is to demonstrate how to use this Web site for conducting behavioral research and to lower the barrier to entry for researchers who could benefit from this platform. We describe general techniques that apply to a variety of types of research and experiments across disciplines. We begin by discussing some of the advantages of doing experiments on Mechanical Turk, such as easy access to a large, stable, and diverse subject pool, the low cost of doing experiments, and faster iteration between developing theory and executing experiments. While other methods of conducting behavioral research may be comparable to or even better than Mechanical Turk on one or more of the axes outlined above, we will show that when taken as a whole Mechanical Turk can be a useful tool for many researchers. We will discuss how the behavior of workers compares with that of experts and laboratory subjects. Then we will illustrate the mechanics of putting a task on Mechanical Turk, including recruiting subjects, executing the task, and reviewing the work that was submitted. We also provide solutions to common problems that a researcher might face when executing their research on this platform, including techniques for conducting synchronous experiments, methods for ensuring high-quality work, how to keep data private, and how to maintain code security.[2]: Many mathematical frameworks aim at modeling human preferences, employing a number of methods including utility functions, qualitative preference statements, constraint optimization, and logic formalisms. The choice of one model over another is usually based on the assumption that it can accurately describe the preferences of humans or other subjects processes in the considered setting and is computationally tractable. Verification of these preference models often leverages some form of real life or domain specific data; demonstrating the models can predict the series of choices observed in the past. We argue that this is not enough: to evaluate a preference model, humans must be brought into the loop. Human experiments in controlled environments are needed to avoid common pitfalls associated with exclusively using prior data including introducing bias in the attempt to clean the data, mistaking correlation for causality, or testing data in a context that is different from the one where the data were produced. Human experiments need to be done carefully and we advocate a multi-disciplinary research environment that includes experimental psychologists and AI researchers. We argue that experiments should be used to validate models. We detail the design of an experiment in order to highlight some of the significant computational, conceptual, ethical, mathematical, psychological, and statistical hurdles to testing whether decision makers' preferences are consistent with a particular mathematical model of preferences.[3]: We study the causal effects of financial incentives on the quality of crowdwork. We focus on performance-based payments (PBPs), bonus payments awarded to workers for producing high quality work. We design and run randomized behavioral experiments on the popular crowdsourcing platform Amazon Mechanical Turk with the goal of understanding when, where, and why PBPs help, identifying properties of the payment, payment structure, and the task itself that make them most effective. We provide examples of tasks for which PBPs do improve quality. For such tasks, the effectiveness of PBPs is not too sensitive to the threshold for quality required to receive the bonus, while the magnitude of the bonus must be large enough to make the reward salient. We also present examples of tasks for which PBPs do not improve quality. Our results suggest that for PBPs to improve quality, the task must be effort-responsive: the task must allow workers to produce higher quality work by exerting more effort. We also give a simple method to determine if a task is effort-responsive a priori. Furthermore, our experiments suggest that all payments on Mechanical Turk are, to some degree, implicitly performance-based in that workers believe their work may be rejected if their performance is sufficiently poor. Finally, we propose a new model of worker behavior that extends the standard principal-agent model from economics to include a worker's subjective beliefs about his likelihood of being paid, and show that the predictions of this model are in line with our experimental findings. This model may be useful as a foundation for theoretical studies of incentives in crowdsourcing markets.[4]: Game theory, the formalized study of strategy, began in the 1940s by asking how emotionless geniuses should play games, but ignored until recently how average people with emotions and limited foresight actually play games. This book marks the first substantial and authoritative effort to close this gap. Colin Camerer, one of the field's leading figures, uses psychological principles and hundreds of experiments to develop mathematical theories of reciprocity, limited strategizing, and learning, which help predict what real people and companies do in strategic situations. Unifying a wealth of information from ongoing studies in strategic behavior, he takes the experimental science of behavioral economics a major step forward. He does so in lucid, friendly prose. Behavioral game theory has three ingredients that come clearly into focus in this book: mathematical theories of how moral obligation and vengeance affect the way people bargain and trust each other; a theory of how limits in the brain constrain the number of steps of \\"I think he thinks . . .\\" reasoning people naturally do; and a theory of how people learn from experience to make better strategic decisions. Strategic interactions that can be explained by behavioral game theory include bargaining, games of bluffing as in sports and poker, strikes, how conventions help coordinate a joint activity, price competition and patent races, and building up reputations for trustworthiness or ruthlessness in business or life. While there are many books on standard game theory that address the way ideally rational actors operate, Behavioral Game Theory stands alone in blending experimental evidence and psychology in a mathematical theory of normal strategic behavior. It is must reading for anyone who seeks a more complete understanding of strategic thinking, from professional economists to scholars and students of economics, management studies, psychology, political science, anthropology, and biology.[5]: This book, which comprises eight chapters, presents a comprehensive critical survey of the results and methods of laboratory experiments in economics. The first chapter provides an introduction to experimental economics as a whole, with the remaining chapters providing surveys by leading practitioners in areas of economics that have seen a concentration of experiments: public goods, coordination problems, bargaining, industrial organization, asset markets, auctions, and individual decision making.","answer":"In this paper we begin to move beyond simply simulation and re-purposed data to studying the preferences and decision making behavior of actual decision makers in realistic settings [2] . This goal, of collecting focused data, is perhaps most well known from the field of experimental economics [5] and behavioral game theory [4] . Essentially, we can use payments to individuals to study how they would act in real-world settings. There are a number of best practices for providing appropriate incentives to individuals or over crowd-working platforms to study decision making [1] [3] ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Conformers of Gaseous Serine The myriad conformers of the neutral form of natural amino acid serine (Ser) have been investigated by systematic computations with reliable electronic wave function methods. A total of 85 unique conformers were located using the MP2/cc-pVTZ level of theory. The 12 lowest-energy conformers of serine fall within a 8 kJ mol(-1) window, and for these species, geometric structures, precise relative energies, equilibrium and vibrationally averaged rotational constants, anharmonic vibrational frequencies, infrared intensities, quartic and sextic centrifugal distortion constants, dipole moments, and (14)N nuclear quadrupole coupling constants were computed. The relative energies were refined through composite focal-point analyses employing basis sets as large as aug-cc-pV5Z and correlation treatments through CCSD(T). The rotational constants for seven conformers measured by Fourier-transform microwave spectroscopy are in good agreement with the vibrationally averaged rotational constants computed in this study. Our anharmonic vibrational frequencies are compared to the large number of experimental vibrational absorptions attributable to at least six conformers.","answer":"{\\"AnatomicalStructure\\": [], \\"Bacterium\\": [], \\"BiologicFunction\\": [], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [\\"serine\\", \\"amino acid\\", \\"species\\", \\"Serine\\", \\"Ser\\", \\"Gaseous\\"], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [], \\"Food\\": [], \\"HealthCareActivity\\": [], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [\\"MP2/cc-pVTZ level\\", \\"aug-cc-pV5Z\\", \\"electronic wave function methods\\", \\"CCSD(T)\\"], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"composite focal-point analyses\\", \\"correlation treatments\\"], \\"SpatialConcept\\": [\\"conformers\\", \\"geometric structures\\", \\"Conformers\\", \\"myriad conformers\\"], \\"Virus\\": []}"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:proven acute deep venous thrombosis, less than 21 days and who were referred to the interventional radiology department.","answer":"{\\"Condition\\": [\\"deep venous thrombosis\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [], \\"Mood\\": [\\"referred to\\"], \\"Multiplier\\": [\\"less than 21 days\\"], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [], \\"Procedure\\": [], \\"Qualifier\\": [\\"acute\\", \\"proven\\"], \\"ReferencePoint\\": [], \\"Scope\\": [], \\"Temporal\\": [], \\"Value\\": [], \\"Visit\\": [\\"interventional radiology department\\"]}"},{"question":"Below is an abstract from a computer science research paper. Given this abstract, your task is to extract all unique relationships between entities of the following types:- \\"USED-FOR\\": For instance, \\"Our method models user proficiency\\" -> [\\"method\\", \\"user proficiency\\", \\"USED-FOR\\"].- \\"EVALUATE-FOR\\": For instance, \\"We evaluate our method using F1-measure\\" -> [\\"F1-measure\\", \\"method\\", \\"EVALUATE-FOR\\"].- \\"FEATURE-OF\\": For instance, \\"prior knowledge of the model\\" -> [\\"prior knowledge\\", \\"model\\", \\"FEATURE-OF\\"].- \\"HYPONYM-OF\\": For instance, \\"TUIT is a software library\\" -> [\\"TUIT\\", \\"software library\\", \\"HYPONYM-OF\\"].- \\"PART-OF\\": For instance, \\"We incorporate NLU module into the system.\\" -> [\\"NLU module\\", \\"system\\", \\"PART-OF\\"].- \\"COMPARE\\": For instance, \\"Unlike the quantitative prior, the qualitative prior is often ignored\\" -> [\\"quantitative prior\\", \\"qualitative prior\\", \\"COMPARE\\"].- \\"CONJUNCTION\\": For instance: \\"obtained from human expert or knowledge base\\" -> [\\"human expert\\", \\"knowledge base\\", \\"CONJUNCTION\\"].Format your output as a json array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<Entity_B>\\", \\"<RELATION_A_B>\\"]. An example output might look like:[[\\"neural networks\\", \\"classification\\", \\"USED-FOR\\"], [\\"neuron\\", \\"neural network\\", \\"PART-OF\\"]].If no relations are found, please return an empty array [].Abstract:An empirical comparison of CFG filtering techniques for LTAG and HPSG is presented. We demonstrate that an approximation of HPSG produces a more effective CFG filter than that of LTAG. We also investigate the reason for that difference.","answer":"[[\\"CFG filtering techniques\\", \\"LTAG\\", \\"USED-FOR\\"], [\\"that\\", \\"LTAG\\", \\"USED-FOR\\"], [\\"CFG filter\\", \\"that\\", \\"COMPARE\\"], [\\"approximation of HPSG\\", \\"CFG filter\\", \\"USED-FOR\\"], [\\"CFG filtering techniques\\", \\"HPSG\\", \\"USED-FOR\\"], [\\"LTAG\\", \\"HPSG\\", \\"COMPARE\\"]]"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:a 62-year - old woman presented with a palpable mass in the right breast . mammography ( fig .a needle biopsy of the breast nodule was performed , and the following diagnosis was made : \\" prominent aggregation of foamy histiocytes associated with diffuse infiltration of lymphoplasma cells , neutrophils , and lymphoid follicles . \\" the possibility of xanthogranulomatous mastitis , plasma cell mastitis , and the like was suggested .periodic acid - schiff staining with prior diastase treatment ( d - pas ) and ziehl - neelsen staining for identifying microorganisms were all negative .six months later , a follow - up sonographic examination showed no changes in the size or echo - density of the nodule .the skin of the overlying area showed inflammatory change , and the patient underwent surgical excision .it was firm in consistency , and a 2.8 cm2.5 cm ill - defined lobulated mass - like lesion was found on sectioning .fibrosis and histiocytic infiltrates in a storiform fashion were observed under low - power microscopic examination .most breast parenchyma was replaced by histiocytes , inflammatory cells , and fibrosis , and these inflammatory cell infiltrates extended into the adjacent fat tissue ( fig .the most prominently recognizable cells were histiocytes with large vesicular nuclei and abundant , clear cytoplasm .furthermore , some of the histiocytes had intact lymphocytes , plasma cells , and red blood cells within the cytoplasm ( fig .the infiltrating histiocytes showed strong immunoreactivity for s-100 protein ( 1:2,000 , polyclonal , dako , carpinteria , ca , usa ) in their nuclei and cytoplasm ( fig .cd68 ( 1:100 , clone pgm1 , dako ) on the histiocytes demonstrated a granular cytoplasmic staining pattern ( fig . 1e ) .cd21 ( 1:50 , clone 1f8 , dako ) highlighted a follicular dendritic cell meshwork in the scattered germinal centers of reactive lymphoid follicles .immunohistochemical staining for igg ( 1:200 , clone a57h , dako ) and igg4 ( 1:200 , clone hp6025 , invitrogen , carlsbad , ca , usa ) ( fig .more specifically , the number of igg4- and igg - expressing plasma cells in five high power fields ( hpf ) were counted , added together , and then divided by 5 to obtain the mean count .the igg4/igg ratio was also calculated from the mean count of igg4 and igg . since the surgical excision, the patient has been in good general condition without a recurrent mass lesion in the breast for more than 10 months .she has visited for follow - up , including a regular sonographic examination of her treated breast , every 6 months since the excision .no further treatments , such as steroid therapy , have been conducted , and no other masses have been detected .rdd was initially described as sinus histiocytosis with massive lymphadenopathy.1 it usually presents in children and young adults with bilateral cervical lymphadenopathy , and shows typical histologic features , including fibrosis , marked dilatation of sinuses with mixed inflammatory cells , and numerous histiocytic infiltration.9 in particular , infiltrating histiocytes have one large nucleus , conspicuous central nucleoli , and abundant clear and/or acidophilic cytoplasm .emperiopolesis of lymphocytes , plasma cells , and red blood cells by large histiocytes is evident .immunohistochemically , the histiocytes show reactivity for s-100 protein and cd68 , which is helpful to verify the diagnosis of rdd .extranodal manifestations can be present in any part of the body , including the breast . compared to nodal rdd , extranodal rdd demonstrates more fibrosis , infrequent typical histiocytes , and a lesser degree of emperipolesis . to the best of our knowledge ,26 cases of rdd in the breast have been reported in the english literature,4 and the present case is the first report in korea .mass - forming lesions in breast , as manifestations of inflammatory infiltration , are occurred in variable diseases . with hitiocytic infiltration ,several differential diagnoses can be considered , including langerhans ' cell histiocytosis , granulomatous lobular mastitis , extranodal rdd , and erdheim - chester disease , which are summarized in table 1 .previously reported breast rdds have included mammary manifestation of systemic rdd as well as primary rdd in mammary parenchyma and subcutis . in one case of mammary manifestation of systemic rdd ,the patient had a history of rdd in the thigh and inguinal lymph node , and a mammary lesion consisting of numerous tiny nodules measuring up to 0.5 cm was found during routine screening.10 primary rdds of breast have been found in women of various ages , presenting as a painless , palpable mass for a few months duration.4 they were initially regarded as malignancies clinically and radiologically , and in all cases , excision or core needle biopsies were performed for diagnostic treatment . amongreported 26 cases , 3 patients had local recurrence ranging from 5 months to 2.5 years , and 1 died of disseminated rdd after 2 months post - operation . to date , all reported cases of rdd have shown characteristic histological findings .our case showed storiform sclerosing fibrosis with plasmacytic infiltration , rendering obliteration of preexisting normal breast lobules .more than 50 igg4 + plasma cells / hpf or over 40% igg4/igg can be considered highly specific diagnostic criteria for igg4-related sclerosing disease.3 recently , both secondary breast involvement of a systemic igg4-related sclerosing disease and primary igg4-related sclerosing mastitis have also been reported.3 five cases of primary igg4-related sclerosing disease of the breast have been reported in the english literature.11,12 ogiya et al.8 reported the first such case ; the patient suffered from bilateral swelling of the breast and elevated serum igg4 , and was successfully treated by steroid therapy.11 cheuk et al.11 subsequently described four cases of igg4-related sclerosing disease in the breast , and proposed the term igg4-related sclerosing mastitis.12 in that report , the patients presented with painless masses in the breast , and underwent surgical excision without recurrence . compared with lymphocytic mastitis and granulomatous mastitis , igg4-related mastitis shows denser igg4 + plasmacytic infiltration ( 272 - 495/hpf ) with higher igg4/igg ratios in the range of 49 - 85% . a possible link between rdd and igg4-relatedsclerosing disease has been suggested because they have some overlapping histological features . in 2009 , kuo et al.10 described a cutaneous rdd with numerous igg4-positive plasma cells , which was the first report of overlapping findings between the two diseases.5 - 7,13 plasmacytic infiltration is a relatively consistent finding in rdd , and fibrosis is also common in extranodal cases .our case also demonstrated features of igg4-related sclerosing lesions such as fibrosis and many igg4-positive plasma cells in the lesion in addition to the typical histological findings of rdd . in the present case ,the mean count of igg4-positive cells was 100.2/hpf , and the ratio of igg4-positive plasma cells to igg - positive plasma cells was 56.7% , which met the diagnostic criteria of igg4-related sclerosing disease histologically . to the best of our knowledge ,this is the first case of rdd in the breast associated with prominent igg4-positive plasmacytic infiltration and fibrosis .although the diagnostic criteria of igg4-related sclerosing disease are established , diagnosis should be made carefully , considering clinical , laboratory , radiologic , and histological features .igg4-related sclerosing disease is now considered an immunity matter , and steroid therapy is known to be effective .some authors have suggested that steroid therapy , which is now considered the choice of treatment for igg4-related sclerosing disease , could be a useful treatment modality for rdd with features of igg4-related sclerosing disease.6 to clarify the pathogenic relationships between these two diseases , comprehensive studies that consider clinical , laboratory , radiologic , and histopathologic features are required .","answer":"rosai - dorfman disease ( rdd ) can present in any anatomic site , but breast involvement is rarely reported .  recently , a relationship between rdd and igg4-related sclerosing disease has been suggested .  here we report another case of rdd with overlapping features of igg4-related sclerosing disease occurring in a right breast of a 62-year - old female . on microscopic examination ,  the mass demonstrated a characteristic zonal pattern of proliferation of large polygonal histiocytes and lymphoplasma cells with stromal fibrosis .  emperipolesis was observed in histiocytes with abundant cytoplasm , which showed immunoreactivity for s-100 protein and cd68 ; the diagnosis of rdd was made .  sheets of plasma cells in the fibrotic stroma demonstrated positive reactions for igg and igg4 .  the mean count of igg4-positive plasma cells was 100.2/high power field , and the ratio of igg4/igg was 56.7% .  additional findings of stromal fibrosis and obliteration of preexisting breast lobules suggested overlapping features with igg4-related sclerosing disease ."},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:thermodynamics and statistical physics provide the key to understanding many physics phenomena and are therefore very important part of the secondary school physics curriculum .a difficulty in their thorough understanding together with the corresponding formulae is in the statistical treatment of a large number of atoms or molecules .quantities like _ internal energy _ or _mean quadratic velocity _ are given by the _ averages _ of those atributed to individual molecules .internal energy is connected with the temperature .the averaging is based on the underlying maxwell - boltzmann distribution .it goes beyond the secondary school curriculum to formally show , that this is the distribution which does not change in time under influence of the collisions among the molecules .moreover , most distributions of the momenta of molecules will converge to maxwell - boltzmann form as a result of molecular collisions .we present here a simulation applet which explains these features of thermodynamics without the need of formal mathematical formulae .the topic of using applets for teaching physics is widely discussed in the literature , see e.g. @xcite and @xcite and references therein .there are many simulations and applets , some also available on the web , e.g.  @xcite .the teacher can choose among them if he or she wants to support the explanation in the classroom or refer the pupils to some supporting material .it is a matter of appropriatness to the particular topic which is being explained . in our simulationswe have put emphasis on i ) explaining the correspondence between gas energy and mean quadratic velocity calculated from the temperature and those really measured  if this was possible on individual molecules ; and ii ) explain the random nature of the velocities of the molecules .our simulations are freely available on the web @xcitethe simulation shows _ two - dimensional _ gas of 500 single - atom molecules .collisions of atoms are treated as elastic collisions of circles ; this determines the angle of scattering and the outgoing momenta .thus , strictly speaking , the gas is not ideal but rather described by the van der waals equation of state .it is dilute , however , so that ideal gas relations can be applied .collisions with the walls of the container are elastic , except for one wall which can be \`\` heated '' .we chose to perform the simulation in two dimensions since in such a case we can show all molecules straightforwardly and do not need to do any projections to a plane , which might be confusing . on the other hand, we have to keep in mind that this changes some relations .the ( mean ) internal energy of the gas is @xmath0 where @xmath1 is the number of atoms , @xmath2 is the temperature and @xmath3 the boltzmann constant .intentionally we display the factor @xmath4instead of @xmath5indicating that we are in two dimensions .correspondingly , the relation for mean quadratic velocity reads @xmath6 where @xmath7 is the mass of the atom and the factor 2 is due to two dimensions .velocities are distributed according to the maxwell distribution , which in two dimensions takes the form @xmath8the simulation always shows a rectangular container with the gas .the color of the atom is chosen from a spectrum between blue ( slow atoms ) and red ( fast atoms ) . in figure[ f : gas ]        we show how the simulation looks like .three of the sides always bounce off the atoms elastically .one side can be made into a heater / cooler . in that case ,its temperature can be set to some value . when the atoms bounce off this side , their velocity is determined randomly according to maxwell distribution ( eq .  ( [ md ] ) ) with the temperature parameter set to that of the heater / cooler and direction inwards the containter .    in a different setting , one of the sides is replaced by a piston which can be moved eigter by pressing arrow buttons in the simulation window or by clicking a draging .additional windows can be displayed .one of them contains the histogram of the velocity distribution which is updated in real time .another one shows the graph of the time dependence of the gas energy compared with the value which the energy is expected to have according to the temperature of the heated wall . in the last auxilliary windowthe values of the actual energy , expected energy and mean quadratic velocity are displayed .the temperature ranges between 50 and 500  k and the typical velocities are of the order of hundreds of m.s@xmath9 . with 500 atoms the typical energy is of the order of few electronvolts .the simulation can be initiated in such a way that each atom has exactly the velocity @xmath10 given by eq .( [ meanvel ] ) , with random direction . during initialisationone time step is effectively performed and some collisions can occur , thus some velocities may slightly change .nevertheless , the initial velocity histogram shows just one very narrow peak ( figure  [ f : th ] left ) .the simulation can then be started and the user can observe how the velocity distribution quickly broadens and becomes maxwellian as a result of the collisions , see fig .[ f : th ] .it is interesting to run the simulation step by step since the process is very quick .      in this mode of the simulation ,one of the walls of the container can be set to a temperature different from that of the gas .then is is interesting to observe the plot of the time dependence of the gas energy , which we show in figure  [ f : enrg ] .it shows the expected value corresponding to the temperature of the heating or cooling wall , and the actual energy of the gas obtained by summing up kinetic energies of all atoms . on average, the actual energy converges to the expected one , and thermal fluctuations are clearly visible .it is also interesting to observe the velocity histogram ( figure  [ f : hth ] ) .        hereone can realise the connection between the temperature , the energy , and the distribution of velocities .it can be seen how the distribution broadens and the peak of the histogram ( the most probable velocity ) moves to higher values with increasing temperature , and vice versa , lower temperature leads to narrower histogram with a peak at lower velocity .one can also demonstrate the effect of pressing and releasing of the gas .one of the sides of the container is then turned into a piston .the piston should be moved slowly slower than the typical velocity of the atoms .otherwise the presentation is somewhat unrealistic .one can see that when the piston is pressing the volume , atoms are bounced off it with higher velocity than they had before and this increases the energy of the gas . this can be observed in the plot of energy as a function of time and on the velocity histogram . increasing the volume with the help of the piston leads to the inverse effect .we have also prepared a simulation of the brownian motion .two larger circles with masses hundred times larger than the atoms are immersed into the gas which is initiated at the temperature of 250  k. as a result of the collisions they begin to move .the trajectory they have passed is shown in the simulation ( figure  [ f : brown ] ) .one can also monitor their distance from the initial position as a function of time in a dedicated window .we believe that our simulations can serve as a valuable supporting tool for explaining some features of the ideal gas .we plan to enlarge the collection of the addressed effects in the future .","answer":"we describe an educational simulation of some effects within the gas of hard spheres .  the focus of the presented simulation is on the comprehension of random character of the velocity of molecules in the gas and of the energy at fixed temperature .  it allows to point out the connection between the temperature , the energy , and the velocity of the molecules ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:RNActive® Technology: Generation and Testing of Stable and Immunogenic mRNA Vaccines Developing effective mRNA vaccines poses certain challenges concerning mRNA stability and ability to induce sufficient immune stimulation and requires a specific panel of techniques for production and testing. Here, we describe the production of stabilized mRNA with enhanced immunogenicity, generated using conventional nucleotides only, by introducing changes to the mRNA sequence and by complexation with the nucleotide-binding peptide protamine (RNActive® technology). Methods described here include the synthesis, purification, and protamine complexation of mRNA vaccines as well as a comprehensive panel of in vitro and in vivo methods for evaluation of vaccine quality and immunogenicity.","answer":"{\\"AnatomicalStructure\\": [], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"production\\", \\"immune stimulation\\", \\"immunogenicity\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [\\"Immunogenic\\", \\"vaccines\\", \\"Vaccines\\", \\"vaccine\\", \\"mRNA\\", \\"nucleotides\\", \\"nucleotide-binding peptide protamine\\", \\"protamine\\"], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [], \\"Food\\": [], \\"HealthCareActivity\\": [\\"evaluation\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [\\"RNActiveu00ae Technology\\"], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"Testing\\", \\"testing\\"], \\"SpatialConcept\\": [\\"mRNA sequence\\", \\"in vivo\\"], \\"Virus\\": []}"},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Can a given genotype exhibit opposite fitness effects (beneficial and detrimental) within the same environment?Context: Mutations beneficial in one environment may cause costs in different environments, resulting in antagonistic pleiotropy. Here, we describe a novel form of antagonistic pleiotropy that operates even within the same environment, where benefits and deleterious effects exhibit themselves at different growth rates.The hfq mutations were beneficial, deleterious or neutral at an intermediate growth rate (0.5 h(-1)) and one changed from beneficial to deleterious within a 36 min difference in doubling time.Two genetic models exist to explain the evolution of ageing - mutation accumulation (MA) and antagonistic pleiotropy (AP).Under AP, late-acting deleterious mutations accumulate because they confer beneficial effects early in life.Many marker loci responded in opposite directions to selection for late- and early-life fitness, indicating negative genetic correlations or trade-offs between those traits. Indirect evidence suggested that some negative genetic correlations were due to antagonistic pleiotropy.Here, we describe a novel form of antagonistic pleiotropy that operates even within the same environment, where benefits and deleterious effects exhibit themselves at different growth rates.The basis of antagonistic pleiotropy in hfq mutations that have opposite effects on fitness at slow and fast growth rates.Here, we describe a novel form of antagonistic pleiotropy that operates even within the same environment, where benefits and deleterious effects exhibit themselves at different growth rates","answer":"yes"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:A subclone named M5 with enhanced metastatic abilities in liver and a subclone named SCP 51 with enhanced metastatic abilities in liver and lymph node were isolated by in vivo selection of SW480 cells through a process described in our previous studies [18-20].","answer":"Method"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Role of IKK1 and IKK2 in lipopolysaccharide signaling in human monocytic cells. Mononuclear phagocytes play a major role in immune and inflammatory responses. Bacterial lipopolysaccharide (LPS) induces monocytes to express a variety of genes by activating the NF-kappaB / Rel transcription factor family. Recently, we have reported that the tumor necrosis factor and interleukin 1 signaling pathways activate two kinases, IKK1 and IKK2. Phosphorylation of the IkappaB cytoplasmic inhibitors, IkappaBalpha, IkappaBbeta, and IkappaBepsilon, by these kinases triggers proteolytic degradation and the release of NF-kappaB / Rel proteins into the nucleus. At present, the role of the IKKs in LPS signaling has not been investigated. Here, we report that LPS induces IKK activity in human monocytes and THP-1 monocytic cells. The kinetics of activation of kinase activity in monocytic cells are relatively slow with maximal activity observed at 60 min, which coincides with the degradation of IkappaBs and the nuclear translocation of NF-kappaB. In transfection experiments, overexpression of wild type IKK1, a dominant negative mutant IKK1 (K44M), or wild type IKK2 did not affect LPS-induced kappaB-dependent transcription in monocytic cells. In contrast, a dominant negative mutant of IKK2 inhibited LPS induction of kappaB-dependent transcription in a dose-dependent manner. These results indicate that LPS induction of kappaB-dependent gene expression in human monocytic cells requires activation of IKK2.","answer":"{\\"CellLine\\": [\\"THP - 1 monocytic cells\\"], \\"CellType\\": [\\"monocytes\\", \\"human monocytic cells\\", \\"Mononuclear phagocytes\\", \\"human monocytes\\", \\"monocytic cells\\"], \\"DNA\\": [], \\"Protein\\": [\\"NF - kappaB / Rel transcription factor family\\", \\"IkappaBalpha\\", \\"IkappaB\\", \\"IkappaBepsilon\\", \\"NF - kappaB / Rel\\", \\"kappaB\\", \\"NF - kappaB / Rel proteins\\", \\"IkappaB cytoplasmic inhibitors\\", \\"wild type IKK2\\", \\"IKK1\\", \\"dominant negative mutant IKK1\\", \\"IKK\\", \\"tumor necrosis factor\\", \\"IKK2\\", \\"IkappaBs\\", \\"interleukin 1\\", \\"NF - kappaB\\", \\"IkappaBbeta\\", \\"K44M\\"], \\"RNA\\": []}"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:(M)ExampleofmutantdiplotenecellwithnormalHP1betaaccumulationtotheXYbody.","answer":"[]"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Modern neural networks are over-parametrized.In particular, each rectified linear hidden unit can be modified by a multiplicative factor by adjusting input and out- put weights, without changing the rest of the network.Inspired by the Sinkhorn-Knopp algorithm, we introduce a fast iterative method for minimizing the l2 norm of the weights, equivalently the weight decay regularizer.It provably converges to a unique solution.Interleaving our algorithm with SGD during training improves the test accuracy.For small batches, our approach offers an alternative to batch- and group- normalization on CIFAR-10 and ImageNet with a ResNet-18.Deep Neural Networks (DNNs) have achieved outstanding performance across a wide range of empirical tasks such as image classification BID1 , image segmentation (He et al., 2017) , speech recognition (Hinton et al., 2012a) , natural language processing (Collobert et al., 2011) or playing the game of Go BID16 .These successes have been driven by the availability of large labeled datasets such as ImageNet BID13 , increasing computational power and the use of deeper models (He et al., 2015b) .Althoughthe expressivity of the function computed by a neural network grows exponentially with depth BID12 Telgarsky, 2016) , in practice deep networks are vulnerable to both over-and underfitting (Glorot & Bengio, 2010; BID1 He et al., 2015b) . Widely usedtechniques to prevent DNNs from overfitting include regularization methods such as weight decay BID2 , Dropout (Hinton et al., 2012b) and various data augmentation schemes BID1 BID17 BID19 He et al., 2015b) . Underfittingcan occur if the network gets stuck in a local minima, which can be avoided by using stochastic gradient descent algorithms (Bottou, 2010; Duchi et al., 2011; BID18 BID0 , sometimes along with carefully tuned learning rate schedules (He et al., 2015b; Goyal et al., 2017) .Training deepnetworks is particularly challenging due to the vanishing/exploding gradient problem. It has been studiedfor Recurrent Neural networks (RNNs) (Hochreiter et al., 2001 ) as well as standard feedforward networks (He et al., 2015a; BID7 . After a few iterations, the gradients computed during backpropagation become either too small or too large, preventing the optimization scheme from converging. This is alleviated byusing non-saturating activation functions such as rectified linear units (ReLUs) BID1 or better initialization schemes preserving the variance of the input across layers (Glorot & Bengio, 2010; BID7 He et al., 2015a) . Failure modes that preventthe training from starting have been theoretically studied by Hanin & Rolnick (2018) .Two techniques in particularhave allowed vision models to achieve \\"super-human\\" accuracy. Batch Normalization (BN) wasdeveloped to train Inception networks (Ioffe & Szegedy, 2015) . It introduces intermediate layersthat normalize the features by the mean and variance computed within the current batch. BN is effective in reducing trainingtime, provides better generalization capabilities after training and diminishes the need for a careful initialization. Network architectures such as ResNet(He et al., 2015b) and DenseNet (Huang et al., 2016) use skip connections along with BN to improve the information flow during both the forward and backward passes. DISPLAYFORM0 Figure 1: Matrices W kand W k+1 are updated by multiplying the columns of the first matrix with rescaling coefficients. The rows of the second matrix are inverselyrescaled to ensure that the product of the two matrices is unchanged. The rescaling coefficients are strictly positiveto ensure functional equivalence when the matrices are interleaved with ReLUs. This rescaling is applied iteratively to each pairof adjacent matrices. In this paper, we address the more complex cases ofbiases, convolutions, max-pooling or skip-connections to be able to balance modern CNN architectures.However, BN has some limitations. In particular, BN only works well with sufficientlylarge batch sizes (Ioffe & Szegedy, 2015; Wu & He, 2018) . For sizes below 16 or 32, the batch statistics havea high variance and the test error increases significantly. This prevents the investigation of highercapacity modelsbecause large, memory-consuming batches are needed in order for BN to work in its optimal range. In many use cases, including video recognition (Carreira& Zisserman, 2017) and image segmentation (He et al., 2017) , the batch size restriction is even more challenging because the size of the models allows for only a few samples per batch. Another restriction of BN is that it is computationallyintensive, typically consuming 20% to 30% of the training time. Variants such as Group Normalization (GN) (Wu & He, 2018) cover some of the failure modes of BN.In this paper, we introduce a novel algorithm to improve both the training speed and generalization accuracy of networks by using their over-parameterization to regularize them. In particular, we focus on neural networks that are positive-rescalingequivalent BID8 , i.e. whose weights are identical up to positive scalings and matching inverse scalings. The main principle of our method, referred to as Equi-normalization (ENorm), is illustrated in Figure 1 for the fullyconnected case. We scale two consecutive matrices with rescaling coefficients that minimizethe joint p norm of those two matrices. This amounts to re-parameterizing the network under the constraint of implementingthe same function. We conjecture that this particular choice of rescaling coefficients ensures a smoothpropagation of the gradients during training.A limitation is that our current proposal, in its current form, can only handle learned skipconnections like those proposed in type-C ResNet. For this reason, we focus on architectures, in particular ResNet18, for which the learningconverges with learned skip-connection, as opposed to architectures like ResNet-50 for which identity skip-connections are required for convergence.In summary,• We introduce an iterative, batch-independent algorithm that re-parametrizes the network within the space of rescaling equivalent networks, thus preserving the function implemented by the network; • We prove that the proposed Equi-normalization algorithm converges to a unique canonical parameterization of the network that minimizes the global p norm of the weights, or equivalently, when p = 2, the weight decay regularizer; • We extend ENorm to modern convolutional architectures, including the widely used ResNets, and show that the theoretical computational overhead is lower compared to BN (×50) and even compared to GN (×3); • We show that applying one ENorm step after each SGD step outperforms both BN and GN on the CIFAR-10 (fully connected) and ImageNet (ResNet-18) datasets.• Our code is available at https://github.com/facebookresearch/enorm. The paper is organizedas follows. Section 2 reviews related work. Section 3 defines our Equinormalizationalgorithm for fully-connected networksand proves the convergence. Section4 shows how to adapt ENorm to convolutional neural networks (CNNs). Section 5 details how to employ ENormfor training neural networks and Section 6 presents our experimental results.","answer":"Fast iterative algorithm to balance the energy of a network while staying in the same functional equivalence class"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Frequency of circulating Tregs with demethylated FOXP3 intron 1 in melanoma patients receiving tumor vaccines and potentially Treg-depleting agents. Regulatory T cells (Tregs) are thought to inhibit antitumor immune responses, and their depletion could therefore have a synergistic effect with therapeutic cancer vaccines. We investigated the impact of three medications on blood Treg frequency in vaccinated cancer patients.  Experimental Design To date, the most specific marker for human Tregs is demethylation in the DNA that encodes the transcription factor FOXP3. Thus, we used a FOXP3 methylation-specific quantitative PCR assay (MS-qPCR) to measure Treg frequencies in the peripheral blood mononuclear cells (PBMCs) of melanoma patients. The patients participated in three clinical trials that combined tumor vaccines with potential Treg-depleting agents : low-dose cyclophosphamide , anti-CD25 monoclonal antibody daclizumab , and the IL-2/diphtheria toxin fusion protein denileukin diftitox .  results In the nine control patients, blood Treg frequencies varied over time; there was a 46% reduction in one patient. In treated patients, a more than 2-fold decrease in Tregs was observed in one out of 11 patients receiving cyclophosphamide and in four out of 13 receiving daclizumab, but there was no such Treg decrease in any of the six patients who received denileukin diftitox. As a positive control, a more than 2-fold increase in blood Tregs was detected in four out of nine patients who were treated with interleukin-2.  conclusions We used a MS-qPCR method that detects Tregs but not other activated T lymphocytes; however, none of the Treg-depleting strategies that we tested led, in the majority of patients, to a conservative 50% reduction in blood Tregs.sentence: The patients participated in three clinical trials that combined tumor vaccines with potential Treg-depleting agents : low-dose cyclophosphamide , anti-CD25 monoclonal antibody daclizumab , and the IL-2/diphtheria toxin fusion protein denileukin diftitox .","answer":"[]"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:Biological systems can share and collectively process information to yield emergent effects, despite inherent noise in communication. While man-made systems often employ intricate structural solutions to overcome noise, the structure of many biological systems is more amorphous. It is not well understood how communication noise may affect the computational repertoire of such groups. To approach this question we consider the basic collective task of rumor spreading, in which information from few knowledgeable sources must reliably flow into the rest of the population. In order to study the effect of communication noise on the ability of groups that lack stable structures to efficiently solve this task, we consider a noisy version of the uniform PULL model. We prove a lower bound which implies that, in the presence of even moderate levels of noise that affect all facets of the communication, no scheme can significantly outperform the trivial one in which agents have to wait until directly interacting with the sources. Our results thus show an exponential separation between the uniform PUSH and PULL communication models in the presence of noise. Such separation may be interpreted as suggesting that, in order to achieve efficient rumor spreading, a system must exhibit either some degree of structural stability or, alternatively, some facet of the communication which is immune to noise. We corroborate our theoretical findings with a new analysis of experimental data regarding recruitment in Cataglyphis niger desert ants.Cited Abstract(s):[1]: A broadcast network of N+1 nodes is considered in which each binary digit transmitted by each node is received by every other node via a binary symmetric channel of given transition probability. The errors on these channels are independent over transmitters, receivers and time. Each node has a binary state, and the problem is to construct a distributed algorithm to find the parity of the set of states with some given reliability. It is shown that this can be done with O(ln(lnN)) bits of communication from each node. Communicating all the node states to one node can be accomplished with only marginally more communication. >[2]: We prove the first nontrivial (superlinear) lower bound in the noisy broadcast model, defined by El Gamal in [Open problems presented at the @math workshop on Specific Problems in Communication and Computation sponsored by Bell Communication Research, in Open Problems in Communication and Computation, T. M. Cover and B. Gopinath, eds., Springer-Verlag, New York, 1987, pp. 60-62]. In this model there are @math processors @math , each of which is initially given a private input bit @math . The goal is for @math to learn the value of @math , for some specified function @math , using a series of noisy broadcasts. At each step a designated processor broadcasts one bit to all of the other processors, and the bit received by each processor is flipped with fixed probability (independently for each recipient). In 1988, Gallager [IEEE Trans. Inform. Theory, 34 (1988), pp. 176-180] gave a noise-resistant protocol that allows @math to learn the entire input with constant probability in @math broadcasts. We prove that Gallager's protocol is optimal, up to a constant factor. Our lower bound follows by reduction from a lower bound for generalized noisy decision trees, a new model which may be of independent interest. For this new model we show a lower bound of @math on the depth of a tree that learns the entire input. While the above lower bound is for an @math -bit function, we also show an @math lower bound for the number of broadcasts required to compute certain explicit boolean-valued functions, when the correct output must be attained with probability at least @math for a constant parameter @math (this bound applies to all threshold functions as well as any other boolean-valued function with linear sensitivity). This bound also follows by reduction from a lower bound of @math on the depth of generalized noisy decision trees that compute the same functions with the same error. We also show a (nontrivial) @math lower bound on the depth of generalized noisy decision trees that compute such functions with small constant error. Finally, we show the first protocol in the noisy broadcast model that computes the Hamming weight of the input using a linear number of broadcasts.[3]:","answer":"The line of research initiated by El-Gamal [3] , also studies a broadcast problem with noisy interactions. The regime however is rather different from ours: all @math agents hold a bit they wish to transmit to a single receiver. This line of research culminated in the @math lower bound on the number of messages shown in [2] , matching the upper bound shown many years sooner in [1] ."},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:A common technique to improve speed and robustness of learning in deep reinforcement learning (DRL) and many other machine learning algorithms is to run multiple learning agents in parallel. A neglected component in the development of these algorithms has been how best to arrange the learning agents involved to better facilitate distributed search. Here we draw upon results from the networked optimization and collective intelligence literatures suggesting that arranging learning agents in less than fully connected topologies (the implicit way agents are commonly arranged in) can improve learning. We explore the relative performance of four popular families of graphs and observe that one such family (Erdos-Renyi random graphs) empirically outperforms the standard fully-connected communication topology across several DRL benchmark tasks. We observe that 1000 learning agents arranged in an Erdos-Renyi graph can perform as well as 3000 agents arranged in the standard fully-connected topology, showing the large learning improvement possible when carefully designing the topology over which agents communicate. We complement these empirical results with a preliminary theoretical investigation of why less than fully connected topologies can perform better. Overall, our work suggests that distributed machine learning algorithms could be made more efficient if the communication topology between learning agents was optimized.Cited Abstract(s):[1]: This paper presents Natural Evolution Strategies (NES), a recent family of black-box optimization algorithms that use the natural gradient to update a parameterized search distribution in the direction of higher expected fitness. We introduce a collection of techniques that address issues of convergence, robustness, sample complexity, computational complexity and sensitivity to hyperparameters. This paper explores a number of implementations of the NES family, such as general-purpose multi-variate normal distributions and separable distributions tailored towards search in high dimensional spaces. Experimental results show best published performance on various standard benchmarks, as well as competitive performance on others.[2]: In this paper we introduce a restart-CMA-evolution strategy, where the population size is increased for each restart (IPOP). By increasing the population size the search characteristic becomes more global after each restart. The IPOP-CMA-ES is evaluated on the test suit of 25 functions designed for the special session on real-parameter optimization of CEC 2005. Its performance is compared to a local restart strategy with constant small population size. On unimodal functions the performance is similar. On multi-modal functions the local restart strategy significantly outperforms IPOP in 4 test cases whereas IPOP performs significantly better in 29 out of 60 tested cases.[3]: We explore the use of Evolution Strategies (ES), a class of black box optimization algorithms, as an alternative to popular MDP-based RL techniques such as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show that ES is a viable solution strategy that scales extremely well with the number of CPUs available: By using a novel communication strategy based on common random numbers, our ES implementation only needs to communicate scalars, making it possible to scale to over a thousand parallel workers. This allows us to solve 3D humanoid walking in 10 minutes and obtain competitive results on most Atari games after one hour of training. In addition, we highlight several advantages of ES as a black box optimization technique: it is invariant to action frequency and delayed rewards, tolerant of extremely long horizons, and does not need temporal discounting or value function approximation.","answer":"There have been many variants of Evolution Strategies over the years, such as CMA-ES [2] which also updates the covariance matrix of the Gaussian distribution, Natural Evolution strategies [1] where the inverse of the Fisher Information Matrix of search distributions is used in the gradient update rule, and, of course, the Evolution Strategies of [3] (which we build on) which was modified for scalability in DRL. However, in all the approaches described above, agents are organized in an implicit fully-connected centralized topology."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Fisetin regulates obesity by targeting mTORC1 signaling. Fisetin, a flavonol present in vegetables and fruits, possesses antioxidative and anti-inflammatory properties. In this study, we have demonstrated that fisetin prevents diet-induced obesity through regulation of the signaling of mammalian target of rapamycin complex 1 (mTORC1), a central mediator of cellular growth, cellular proliferation and lipid biosynthesis. To evaluate whether fisetin regulates mTORC1 signaling, we investigated the phosphorylation and kinase activity of the 70-kDa ribosomal protein S6 kinase 1 (S6K1) and mTORC1 in 3T3-L1 preadipocytes. Fisetin treatment of preadipocytes reduced the phosphorylation of S6K1 and mTORC1 in a time- and concentration-dependent manner. To further our understanding of how fisetin negatively regulates mTORC1 signaling, we analyzed the phosphorylation of S6K1, mTOR and Akt in fisetin-treated TSC2-knockdown cells. The results suggested that fisetin treatment inhibits mTORC1 activity in an Akt-dependent manner. Recent studies have shown that adipocyte differentiation is dependent on mTORC1 activity. Fisetin treatment inhibited adipocyte differentiation, consistent with the negative effect of fisetin on mTOR. The inhibitory effect of fisetin on adipogenesis is dependent of mTOR activity, suggesting that fisetin inhibits adipogenesis and the accumulation of intracellular triglycerides during adipocyte differentiation by targeting mTORC1 signaling. Fisetin supplementation in mice fed a high-fat diet (HFD) significantly attenuated HFD-induced increases in body weight and white adipose tissue. We also observed that fisetin efficiently suppressed the phosphorylation of Akt, S6K1 and mTORC1 in adipose tissue. Collectively, these results suggest that inhibition of mTORC1 signaling by fisetin prevents adipocyte differentiation of 3T3-L1 preadipocytes and obesity in HFD-fed mice. Therefore, fisetin may be a useful phytochemical agent for attenuating diet-induced obesity.","answer":"[[\\"fisetin\\", \\"REGULATOR\\", \\"mTOR\\"], [\\"fisetin\\", \\"REGULATOR\\", \\"S6K1\\"], [\\"Fisetin\\", \\"INHIBITOR\\", \\"S6K1\\"], [\\"fisetin\\", \\"REGULATOR\\", \\"Akt\\"], [\\"fisetin\\", \\"DOWNREGULATOR\\", \\"mTORC1\\"], [\\"fisetin\\", \\"REGULATOR\\", \\"70-kDa ribosomal protein S6 kinase 1\\"], [\\"fisetin\\", \\"REGULATOR\\", \\"mTORC1\\"], [\\"fisetin\\", \\"INHIBITOR\\", \\"S6K1\\"], [\\"fisetin\\", \\"INHIBITOR\\", \\"mTORC1\\"], [\\"Fisetin\\", \\"INHIBITOR\\", \\"mTORC1\\"], [\\"fisetin\\", \\"REGULATOR\\", \\"kinase\\"], [\\"fisetin\\", \\"REGULATOR\\", \\"mammalian target of rapamycin complex 1\\"], [\\"fisetin\\", \\"DOWNREGULATOR\\", \\"mTOR\\"], [\\"fisetin\\", \\"INHIBITOR\\", \\"Akt\\"], [\\"Fisetin\\", \\"REGULATOR\\", \\"mTORC1\\"]]"},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: aegypti and Ae. albopictus [11] . Transmission in Asia occurs in an urban cycle whereby the mosquito spreads the disease from an infected human to an uninfected human, following an epidemiological pattern similar to dengue fever [12] . The 2005-2006 epidemic of CHIKV in La Reunion islands in the Indian Ocean, spurred the discovery of a new vector species, Ae. albopictus [5] . Wrecking over one-third of the island's population, this epidemic peaked its devastation between January and February 2006, when over 46,000 cases came into light every week, including 284 deaths [5, 13] . Ae. albopictus is common in urban areas of the United States and is already flourishing in 36 states, raising grave concerns to the immunologically naive populace of the United States [14] . Accordingly, this review elaborately details the epidemiology and global expansion of CHIKV, describes its clinical features and pathogenesis and its symptoms and complications, and finally nominates a possible vaccine approach against CHIKV infection. CHIKV has been isolated into three genotypes based on phylogenetic studies. These genotypes, based on the gene sequences of an Envelope protein (E1), are Asian, East/Central/ South African, and West African [4, 11, 15] . Using phylogenetic models, Cherian et al. estimate that the Asian genotype of CHIKV emerged between 50 and 310 y ago, and the West and East African genotypes diverged between 100 and 840 y ago [15] . Since then, CHIKV has come a long way, with several mutations incorporated, and has continued to wreak epidemics in several regions. Recent activities of CHIKV include the Indian epidemic in 2005-2006, which was followed by a sudden explosion of cases in 2007. An estimated 1.3 million people across 13 states were reported to be infected in India [12, 16] , and CHIKV was also widespread in Malaysia, Sri Lanka, and Indonesia [17] . In July-August of 2007, CHIKV was reported in Italy, probably brought in by travelers from CHIKV-prone regions of India, Africa, and Indian Ocean islands such as Mauritius, Madagascar, and Seychelles. Few of the Italian isolates were found to have evolved from the Kerala isolate, which was associated with a A226V shift in E1 gene that represents a successful evolutionary adaptation in the mosquito vector similar to the ones observed in Reunion Island [2, 18, 19] . In recent times, with an increase in global travel, the risk for spreading CHIKV to non-endemic regions has heightened [1] . Several travelers have brought CHIKV home with them after visiting areas with actively infected populations [12, 20] . Such cases have been documented in European countries, Australia, Asia, and the United States [8, 21] . The United States has already reported at least twelve cases of travel-associated CHIKV, while France has reported 850 cases, and the United Kingdom 93 [8, 14] . Beyond this, CHIKV-infected travelers have also been diagnosed in Australia, Belgium, Canada, Czech Republic, French Guiana, Germany, Hong Kong, Italy, Japan, Kenya, Malaysia, Martinique, Norway, Switzerland, and Sri Lanka [21] . Some travelers were viremic, worrying public health officials about the spread of CHIKV to new areas [1, 8] . The incubation time for CHIKV is relatively short, requiring only 2-6 d with symptoms usually appearing 4-7 d post-infection [22] . Vazeille et al. detected CHIKV in the salivary glands of Ae. albopictus only 2 d after infection [5] . Upon infection, CHIKF tends to present itself in two phases. The first stage is acute, while the second stage, experienced by most but not all, is persistent, causing disabling polyarthritis. Characteristics of the acute phase include an abrupt onset of fever, arthralgia, and in some cases, maculopapular rash [6, 23] . The acute phase causes such intense joint and muscular pain that makes movement very difficult and prostrates its victims [6, 20] . Ninety-five percent of infected adults are symptomatic after infection, and of these, most become disabled for weeks to months as a result of decreased dexterity, loss of mobility, and delayed reaction. Eighteen months after disease onset, 40% of patients are found to still have anti-CHIKV IgM [6, 18, 23, 24] . The chronic stage of CHIKF is characterized by polyarthralgia that can last from weeks to years beyond the acute stage [6] . CHIKV has been shown to attack fibroblasts, explaining the involvement of muscles, joints, and skin connective tissues. The high number of nociceptive nerve endings found within the joints and muscle connective tissues can explain pain associated with CHIKF [25, 26] . More than 50% of patients who suffer from severe CHIKF are over 65 y old, and more than 33% of them die. Most adults who suffer from severe CHIKF have underlying medical conditions [6, 24, 27] . The other group that is disproportionately affected by severe CHIKV is children. Other complications associated with CHIKV, from most common to least common, include respiratory failure, cardiovascular decompensation, meningoencephalitis, severe acute hepatitis, severe cutaneous effects, other central nervous system problems, and kidney failure [6, 18, 20, 23, 24, 26, 27] . CHIKV undertakes a complex replication cycle upon host infection (Figure 2 ), which makes its genome susceptible to mutations  [28, 29] . For instance, Ae. aegypti, responsible for epidemics in Kenya, Comoros, and Seychelles, carried CHIKV with an alanine in the 226 position of the E1 gene (E1-A226) [4, 18] . However, when the virus struck La Reunion Islands, a decline in population of Ae. aegypti, due to massive dichlorodiphenyltrichloroethane usage and dearth of Ae. albopictus species' www.plosntds.org population, resulted in an ecological pressure, favoring replacement of alanine at position 226 with valine (E1-A226V) [5] . This mutation allowed CHIKV's secondary vector species, Ae. albopictus, to supplement Ae. aegypti as its primary vector [5] . Within a year, the E1-A226V mutation was present in La Reunion Island, and Ae. albopictus apparently vectored the large epidemic infecting 34% of La Reunion Island's population [5] . All of the CHIKV strains isolated from Mayotte carried the E1-A226V mutation, and the mutation was also found in Madagascar in 2007 [5] . The E1-A226V mutation was not present at the beginning of the Indian Ocean Islands outbreak (before September 2005). However, more than 90% of later viral strains found there had incorporated the mutation (December-March 2006), indicating a genotype switch during the winter season [5, 18, 20] . The E1-A226V mutation also enabled an increase in infectivity of Ae. albopictus when compared to its infectivity of Ae. aegypti [4, 11, 18, 30] , and with several factors taken together, Ae. albopictus has become the new preferred and more lethal vector for CHIKV [4, 5, 11] . In fact, Tsetsarkin et al. found that a Green Fluorescent Protein tagged E1-A226V virus was 100 times more infective to Ae. albopictus than it was to Ae. aegypti [4] . In all the Indian Ocean Islands, Ae. albopictus became the main vector for CHIKV within 1-2 y after CHIKV was introduced to the region [31] . Of note is that Ae. aegypti has most likely been established in North America for over 300 y, while Ae. albopictus has been in many areas of the US, since 1985, primarily in Florida [32] and since then has expanded its range in the country. Reiskind et al. set out to determine if Ae. aegypti and Ae. albopictus mosquitoes captured in Florida were susceptible to CHIKV infection by a La Reunion isolate [32] . Each mosquito tested was highly susceptible to infection by a full-length infectious clone of the La Réunion Island isolate, CHIKV LR2006 OPY1 strain. Even though the Ae. albopictus strains were more susceptible to infection, overall ecology and differences in human biting patterns need to be studied further Characteristically, there are two rounds of translation: (+) sense genomic RNA (49S9 = 11.7 kb) acts directly as mRNA and is partially translated (59 end) to produce non-structural proteins (nsp's). These proteins are responsible for replication and formation of a complementary (2) strand, the template for further (+) strand synthesis. Subgenomic mRNA (26 S = 4.1 kb) replication occurs through the synthesis of full-length (2) intermediate RNA, which is regulated by nsp4 and p123 precursor in early infection and later by mature nsp's. Translation of the newly synthesized sub-genomic RNA results in production of structural proteins such as Capsid and protein E2-6k-E1 (from 39 end of genome). Assembly occurs at the cell surface, and the envelope is acquired as the virus buds from the cell and release and maturation almost simultaneous occurred. Replication occurs in the cytoplasm and is very rapid (,4 h) [28, 29] . doi:10.1371/journal.pntd.0000623.g002 www.plosntds.org to gain a more accurate understanding of a potential CHIKV epidemic in the US [32] . During the 7 d preceding birth, no human mother has been reported to transmit the disease vertically. However, about 50% of newborns delivered while the mother was infected with CHIKV contracted the disease from their mother, despite the method of delivery. Furthermore, there have been instances of CHIKV transmission from mother to fetus causing congenital illness and fetal death [33] . During the 2005-2006 La Reunion Island outbreaks, Ramful et al. discovered that mothers could transmit CHIKV to their progeny during the perinatal period (Day 24 to Day +1) [33, 34] , and it is associated with a high degree of morbidity. By mean Day 4 of life, all of the neonates were symptomatic for CHIKV, exhibiting common CHIKF symptoms. Six neonates were confirmed to have contracted CHIKV and developed mengoencephalitis. Of those mothers who, during the La Reunion Island epidemic, were infected long before delivery, only three fetal deaths were reported [12, 33] . Ramful et al. theorized that motherto-child transmission most likely happens transplacentally shortly before delivery [33] . A similar study by Gerardin et al. reported nineteen cases of neonatal infection associated with intrapartum maternal viremia that progressed to develop encephalitis owing to vertical transmission from infected mothers [34] . Clinical and epidemiological similarities with dengue fever make CHIKV diagnosis difficult, which may lead physicians to misdiagnose CHIKV as dengue fever; therefore, the incidence of CHIKV may actually be higher than currently believed (Table 1 ) [6, 12, 35] . The amount of time elapsed since disease onset is the most critical parameter when choosing a diagnostic test. CHIKV can be detected and isolated by culturing with mosquito cells (C6/36), Vero cells (mammalian), or in mice [26] . However, this method can take at least a week and only achieves a high sensitivity during the viremic phase, which usually only lasts up to 48 h after the bite. Five days post-infection, the viral isolation approach has a low sensitivity but is still the preferred method for detecting the CHIKV strain [12, 26, 31, 35] . RT-PCR on the other hand is a faster and more sensitive method that can be used within the first week of disease onset [26] , and it is currently the most sensitive method for detecting and quantifying viral mRNA [4, 36] . Classic serological detection, by assays such as ELISA [37] , immunofluorescence [5, 38] , complement binding, and haemagglutination inhibition [39] , constitutes the second diagnostic tool used for biological diagnosis of CHIKV infection. These proven techniques are useful for detection of Antigen in mosquitoes during epidemiological studies. These assays detect virus-specific IgM and IgG, however the sensitivity and specificity of these assays has been poorly characterized. Viral competence, or the potential of viral infection and transmission, is an important parameter that can be quantified by ELISA, viral culture, and PCR. A study by Ng et al. showed biomarkers indicative of severe CHIKV infection [40] . They found decreased levels of RANTES and increased levels of Interleukin-6 (IL-6) and Interleukin-1b (IL-1b) that could be sued for CHIKV detection in patients as indicators of CHIKV-driven cytokine storm. Couderc et al. demonstrate another cytokine, type-I IFN, as a key player in the progression to CHIKV infection [26] . Using an IFN-a/b null mouse model, they demonstrated evidence of muscles, joints, and skin as privileged CHIKV targets, which is consistent with human pathology. Although Ng et al. concluded that RANTES levels were significantly suppressed in severe CHIKF patients [40] , interestingly, an increase in levels of RANTES has been observed in dengue infection [41] . Since the symptoms of CHIKF mimic those of dengue fever, results obtained from this study strongly suggest that RANTES could be a potential distinctive biomarker that differentiates between these two clinically similar diseases. There are no approved antiviral treatments currently available for CHIKV [1, 3, 12, 42] . Currently, CHIKF is treated symptomatically, usually with non-steroidal anti-inflammatory drugs or steroids, bed rest, and fluids. Movement and mild exercise are thought to decrease stiffness and morning arthralgia, but heavy exercise may exacerbate rheumatic symptoms. Corticosteroids may be used in cases of debilitating chronic CHIKV infection. There is a debate about the appropriateness of chloroquine as treatment for unresolved, non-steroidal anti-inflammatory drugresistant arthritis [43] .Question: What happens after  host infection?","answer":"CHIKV undertakes a complex replication cycle upon host infection (Figure 2 ), which makes its genome susceptible to mutations"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: Fig. 12 compares three models - single frame classifier(logistic regression), baseline LSTM classifier and the LSTM classifierinitialized with weights from the Composite Model as the number of labelledvideos per class is varied. Note that having one labelled video means havingmany labelled 16 frame blocks. We can see that for the case of very fewtraining examples, unsupervised learning gives a substantial improvement. Forexample, for UCF-101, the performance improves from 29.6% to 34.3% whentraining on only one labelled video. As the size of the labelled dataset grows,the improvement becomes smaller. Even for the full UCF-101 dataset we still get aconsiderable improvement from 74.5% to 75.8%. On HMDB-51, the improvement isfrom 42.8% to 44.0% for the full dataset (70 videos per class) and 14.4% to19.1% for one video per class. Although, the improvement in classification byusing unsupervised learning was not as big as we expected, we still managed toyield an additional improvement over a strong baseline. We discuss some avenuesfor improvements later.Question: What is the impact of number of training videos on the performance of supervised and unsupervised tasks?","answer":"As the number of training videos increases the performance of supervised and unsupervised tasks increases."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:With severe systemic alteration;In the use of antibiotics and anti-inflammatories in the last three months;With periodontium with periodontal parameters different from those established in the inclusion criteria.Individuals with clinical signs of parafunctional habits;Smoking;Individuals who have performed other restorations in the last 12 months;Pregnant women and infants;Periodontal sites that presented bleeding during crevicular fluid collection or sites that prevent proper collection of clinical parameters.","answer":"{\\"Condition\\": [\\"Pregnant\\", \\"clinical signs of parafunctional habits\\", \\"systemic alteration\\"], \\"Device\\": [], \\"Drug\\": [\\"antibiotics\\", \\"anti-inflammatories\\"], \\"Measurement\\": [], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [\\"Smoking\\"], \\"Person\\": [\\"women\\", \\"infants\\"], \\"Procedure\\": [\\"other restorations\\"], \\"Qualifier\\": [\\"severe\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"antibiotics and anti-inflammatories\\", \\"Pregnant women\\"], \\"Temporal\\": [\\"in the last three months\\", \\"in the last 12 months\\"], \\"Value\\": [], \\"Visit\\": []}"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:We report changes in viral load over time in a 27-day-old neonate with coronavirus disease 2019 who presented with fever, cough, and vomiting. Severe acute respiratory syndrome coronavirus 2 RNA was detected in the nasopharynx, oropharynx, stool, saliva, plasma, and urine. The highest viral RNA copies in nasopharynx decreased over time while viral load in stool remained high.","answer":"[\\"Case Report\\"]"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Meets criteria for Major Depressive Episode, by Diagnostic Statistical Manual of Mental Disorder - IV (TR) criteria Clinically significant agitation /aggression for which either 1) the frequency of agitation /aggression as assessed by the NPI is 'Very frequently', or 2) the frequency of agitation /aggression as assessed by the NPI is 'Frequently' AND the severity of the agitation as assessed by the NPI is 'Moderate', or 'Marked' Clinically significant delusions for which either 1) the frequency of delusions as assessed by the NPI is 'Very frequently', or 2) the frequency of delusions as assessed by the NPI is 'Frequently' AND the severity of the delusions as assessed by the NPI is 'Moderate', or 'Marked' Clinically significant hallucinations for which either 1) the frequency of hallucinations as assessed by the NPI is 'Very frequently', or 2) the frequency of hallucinations as assessed by the NPI is 'Frequently' AND the severity of the hallucinations as assessed by the NPI is 'Moderate', or 'Marked' Treatment with psychotropic medications in the 2 weeks prior to randomization with the exception of approved treatments for dementia (ChEIs and memantine), selective serotonin reuptake inhibitor antidepressants, and trazodone (if used as an aid to facilitate sleep and not as an antidepressant); other psychotropics (with the exclusion of antipsychotics), if stable for 3 months, may be allowed only with Steering Committee approval on a case by case basis. Note that antipsychotics are expressly prohibited. Treatment with methylphenidate is contraindicated in the opinion of the study physician Failure of treatment with methylphenidate in the past for apathy after convincing evidence of an adequate trial as judged by study physician Treatment with a medication that would prohibit the safe concurrent use of methylphenidate such as monoamine oxidase inhibitors and tricyclic antidepressants Need for acute psychiatric hospitalization or is suicidal Uncontrolled hypertension (medication non-compliance or past 3 months with a diastolic reading of 105 as verified by compartment pressure of the rectus sheath (CPRS)) Symptomatic coronary artery disease deemed to be significant by study physician at the time of screening Lack of appetite that results in significant unintentional weight loss as determined by the study physician in the last three months Significant communicative impairments Current participation in a clinical trial or in any study that may add significant burden or affect study outcomes Hyperthyroidism, advanced arteriosclerosis, symptomatic cardiovascular disease, serious structural cardiac abnormalities, cardiomyopathy, serious heart rhythm abnormalities, or a family history of sudden death or death related to heart problems Glaucoma, pheochromocytoma, or known or suspected hypersensitivity to methylphenidate or its excipients Central Nervous System (CNS) abnormalities (e.g., cerebral aneurysm) and/or other vascular abnormalities such as vasculitis or pre-existing stroke, motor tics or a family history or diagnosis of Tourette's syndrome, seizures (convulsions, epilepsy), or abnormal EEGs Any condition that, in the opinion of the study physician, makes it medically inappropriate or risky for the patient to enroll in the trial","answer":"{\\"Condition\\": [\\"Uncontrolled hypertension\\", \\"arteriosclerosis\\", \\"seizures\\", \\"stroke\\", \\"suicidal\\", \\"convulsions\\", \\"delusions\\", \\"agitation\\", \\"hypersensitivity\\", \\"Major Depressive Episode\\", \\"epilepsy\\", \\"coronary artery disease\\", \\"agitation /aggression\\", \\"death related to heart problems\\", \\"communicative impairments\\", \\"unintentional weight loss\\", \\"structural cardiac abnormalities\\", \\"hallucinations\\", \\"medication non-compliance\\", \\"pheochromocytoma\\", \\"Touretteu0027s syndrome\\", \\"sudden death\\", \\"Central Nervous System (CNS) abnormalities\\", \\"Glaucoma\\", \\"cardiovascular disease\\", \\"dementia\\", \\"EEGs\\", \\"Lack of appetite\\", \\"cerebral aneurysm\\", \\"cardiomyopathy\\", \\"heart rhythm abnormalities\\", \\"vasculitis\\", \\"vascular abnormalities\\", \\"Hyperthyroidism\\", \\"motor tics\\"], \\"Device\\": [], \\"Drug\\": [\\"other psychotropics\\", \\"antipsychotics\\", \\"tricyclic antidepressants\\", \\"its excipients\\", \\"selective serotonin reuptake inhibitor antidepressants\\", \\"methylphenidate\\", \\"memantine\\", \\"monoamine oxidase inhibitors\\", \\"methylphenidate or its excipients\\", \\"trazodone\\", \\"ChEIs\\", \\"medication that would prohibit the safe concurrent use of methylphenidate\\", \\"psychotropic medications\\"], \\"Measurement\\": [\\"compartment pressure of the rectus sheath (CPRS)\\", \\"NPI\\", \\"Diagnostic Statistical Manual of Mental Disorder - IV (TR) criteria\\", \\"diastolic reading\\"], \\"Mood\\": [], \\"Multiplier\\": [\\"frequency of hallucinations\\", \\"frequency of agitation /aggression\\", \\"frequency of delusions\\"], \\"Negation\\": [\\"with the exception of\\", \\"with the exclusion of\\"], \\"Observation\\": [\\"known\\", \\"family history\\", \\"suspected\\", \\"prohibit\\", \\"diagnosis\\", \\"Need for\\"], \\"Person\\": [], \\"Procedure\\": [\\"psychiatric hospitalization\\", \\"treatments for dementia\\"], \\"Qualifier\\": [\\"Uncontrolled\\", \\"advanced\\", \\"as determined by the study physician\\", \\"Significant\\", \\"symptomatic\\", \\"Clinically significant\\", \\"as verified by compartment pressure of the rectus sheath (CPRS)\\", \\"significant\\", \\"severity of the delusions\\", \\"serious\\", \\"severity of the agitation\\", \\"Symptomatic\\", \\"related to heart problems\\", \\"abnormal\\", \\"stable\\", \\"severity of the hallucinations\\"], \\"ReferencePoint\\": [\\"randomization\\", \\"time of screening\\"], \\"Scope\\": [\\"frequency of agitation /aggression as assessed by the NPI is u0027Very frequentlyu0027, or 2) the frequency of agitation /aggression as assessed by the NPI is u0027Frequentlyu0027 AND the severity of the agitation as assessed by the NPI is u0027Moderateu0027, or u0027Markedu0027\\", \\"sudden death or death related to heart problems\\", \\"known or suspected\\", \\"family history or diagnosis\\", \\"treatments for dementia (ChEIs and memantine), selective serotonin reuptake inhibitor antidepressants, and trazodone\\", \\"monoamine oxidase inhibitors and tricyclic antidepressants\\", \\"frequency of delusions as assessed by the NPI is u0027Very frequentlyu0027, or 2) the frequency of delusions as assessed by the NPI is u0027Frequentlyu0027 AND the severity of the delusions as assessed by the NPI is u0027Moderateu0027, or u0027Markedu0027\\", \\"convulsions, epilepsy\\", \\"ChEIs and memantine\\", \\"medication non-compliance or past 3 months with a diastolic reading of 105 as verified by compartment pressure of the rectus sheath (CPRS)\\", \\"u0027Moderateu0027, or u0027Markedu0027\\", \\"frequency of hallucinations as assessed by the NPI is u0027Very frequentlyu0027, or 2) the frequency of hallucinations as assessed by the NPI is u0027Frequentlyu0027 AND the severity of the hallucinations as assessed by the NPI is u0027Moderateu0027, or u0027Markedu0027\\"], \\"Temporal\\": [\\"in the last three months\\", \\"pre-existing\\", \\"in the 2 weeks prior to randomization\\", \\"acute\\", \\"concurrent\\", \\"past 3 months\\", \\"for 3 months\\", \\"at the time of screening\\"], \\"Value\\": [\\"Frequently\\", \\"Marked\\", \\"Very frequently\\", \\"Moderate\\", \\"105\\", \\"Meets\\"], \\"Visit\\": []}"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:[5] showed a 45% reduction in requirements for analgesics during the intraoperative period after clonidine premedication compared to standard premedication in patients undergoing bypass surgery.","answer":"Background"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:NoneContext before the citation:The latter question is tackled by applicationspecific evaluation, where a measure is tested within the framework of a certain application, e.g. word sense disambiguation (Patwardhan et al., 2003) or malapropism detection (Budanitsky and Hirst, 2006). Mathematical analysis can assess a measure with respect to some formal properties, e.g. whether a measure is a metric (Lin, 1998).4 However, mathematical analysis cannot tell us whether a measure closely resembles human judgments or whether it performs best when used in a certain application. According to Budanitsky and Hirst (2006), there are three prevalent approaches for evaluating SR measures: mathematical analysis, applicationspecific evaluation and comparison with human judgments.Citation Sentence:The latter question is tackled by applicationspecific evaluation , where a measure is tested within the framework of a certain application , e.g. word sense disambiguation ( Patwardhan et al. , 2003 ) or malapropism detection ( Budanitsky and Hirst , 2006 ) .Context after the citation:Lebart and Rajman (2000) argue for application-specific evaluation of similarity measures, because measures are always used for some task. But they also note that evaluating a measure as part of a usually complex application only indirectly assesses its quality. A certain measure may work well in one application, but not in another. Application-based evaluation can only state the fact, but give little explanation about the reasons.","answer":"Background"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Increased H+ efflux is sufficient to induce dysplasia and necessary for viability with oncogene expression}Article:Abstract:Intracellular pH( pHi) dynamics is increasingly recognized as an important regulator of a range of normal and pathological cell behaviors. Notably, increased pHi is now acknowledged as a conserved characteristic of cancers and in cell models is confirmed to increase proliferation and migration as well as limit apoptosis. However, the significance of increased pHi for cancer in vivo remains unresolved. Using Drosophila melanogaster, we show that increased pHi is sufficient to induce dysplasia in the absence of other transforming cues and potentiates growth and invasion with oncogenic Ras. Using a genetically encoded biosensor we also confirm increased pHi in situ. Moreover, in Drosophila models and clonal human mammary cells we show that limiting H+ efflux with oncogenic Raf or Ras induces acidosis and synthetic lethality. Further, we show lethality in invasive primary tumor cell lines with inhibiting H+ efflux. Synthetic lethality with reduced H+ efflux and activated oncogene expression could be exploited therapeutically to restrain cancer progression while limiting off-target effects.Introduction:Dysregulated pH is a common characteristic of cancer cells, which have a lower extracellular pH( pHe) and higher intracellular pH( pHi) than normal cells. The lower pHe of tumors, confirmed by pH-sensitive PET radiotracers, MR spectroscopy and MRI( Zhang et al., 2010), contributes to local metastatic invasion( Cardone et al., 2005; Rofstad et al., 2006; Stock et al., 2008; Stock and Schwab, 2009; Busco et al., 2010; Estrella et al., 2013). Increased pHi enables a number of cancer cell behaviors, including promoting cell proliferation( Pouysségur et al., 1982; Kapus et al., 1994; Putney and Barber, 2003), glycolytic metabolism( Reshkin et al., 2000; Dietl et al., 2010; Webb et al., 2011), migration( Denker and Barber, 2002; Patel and Barber, 2005; Frantz et al., 2008; Stock and Schwab, 2009), and invasion( Reshkin et al., 2000; Hinton et al., 2009), as well as limiting apoptosis( Matsuyama et al., 2000; Lagadic-Gossmann et al., 2004). The higher pHi of cancer cells is paradoxical because increased production of metabolic acids generated by aerobic glycolysis would be predicted to lower pHi. However, many cancers have elevated expression or activity of proteins that facilitate increased pHi, including carbonic anhydrase 9( Swietach et al., 2007), H+-ATPases( Martinez-Zaguilan et al., 1993; Sennoune et al., 2004; Hinton et al., 2009), the ubiquitously expressed Na+-H+ exchanger NHE1( McLean et al., 2000; Miraglia et al., 2005; Chiang et al., 2008; Yang et al., 2011) and the monocarboxylate transporter family members MCT1 and MCT4( Pinheiro et al., 2010; Halestrap, 2013). Therapeutic targeting of these proteins to reduce H+ efflux and lower pHi has been suggested for limiting cancer progression( Webb et al., 2011; Harguindey et al., 2013), based primarily on findings with xenograft models and isolated cells. Xenograft tumor growth is suppressed by inhibiting NHE1( Lagarde et al., 1988; Yang et al., 2011) or MCT1( Sonveaux et al., 2008; Colen et al., 2011) activity. In cell models, inhibiting NHE1 activity reduces viability of breast cancer( Reshkin et al., 2003) and leukemic cells( Rich et al., 2000; Reshkin et al., 2003), and silencing MCT4 expression with RNA interference decreases survival of renal carcinoma cells( Gerlinger et al., 2012). Although previous studies suggest important roles for pH dynamics in regulating cancer cell behaviors, whether increased pHi is sufficient or necessary for cancer progression in vivo remains unresolved. To better understand how H+ efflux and increased pHi affect cancer cell behaviors we asked two distinct but related questions. First, is increased pHi by NHE1 over-expression in the absence of other transforming signals sufficient to induce dysplasia? Second, is H+ efflux by NHE1 necessary for oncogene-induced dysplasia? We found that over-expression of Drosophila melanogaster Dnhe2, an ortholog of mammalian NHE1, causes dysplasia, increases proliferation and facilitates oncogene-induced cell invasion in vivo. Additionally, we found that reducing H+ efflux genetically or pharmacologically limits oncogene-induced increases in proliferation and has synthetic lethality with oncogenic Raf in the Drosophila retina as well as in human mammary epithelial cells expressing oncogenic RasV12.Discussion:With the advent of low-cost whole genome sequencing, personalized chemotherapeutic treatments currently dominate discussion of new cancer therapies. However, the balkanization of cancers by causative mutation or tissue of origin ignores the shared disease physiology in most cancers as highlighted by the ‘hallmarks of cancer’( Hanahan and Weinberg, 2011). Dysregulated pHi is an emerging hallmark of cancer that is associated with traditional hallmarks, including resisting cell death, sustaining proliferative signaling, activating invasion and metastasis, deregulating cellular energetics and tumor-promoting inflammation. Therefore, targeting pHi-regulatory proteins in cancer cells could address distinct pathological characteristics in parallel. Our data provide an in vivo functional corollary of the established increased pHi and upregulation of H+ efflux mechanisms in cancer cells. Building on previous reports that NHE1 activity and expression is increased in human cancers( McLean et al., 2000; Miraglia et al., 2005; Chiang et al., 2008; Yang et al., 2011), we show that engineered over-expression of an NHE1 ortholog in vivo increased pHi by ∼0. 3 pH units, which is comparable to the increase seen with oncogene transformation. Moreover, over-expression of Dnhe2 was sufficient to induce dysplasia and hyper-proliferation phenotypes, and it enhanced oncogene-mediated invasion. Further, co-expressing RasV12 and Dnhe2 had a strong, synergistic effect on growth and invasion. A similar synergistic effect between expression of RasV12 and the C subunit of the V-ATPase, Vha44 was recently reported( Petzoldt et al., 2013), which supports the ability of increased H+ efflux to enhance RasV12-induced phenotypes. However, Vha44 enhances invasion with RasV12 but not activated Src or Abl, suggesting an oncogene-specific synergy. Important to determine in future studies are the relative effects of increased pHi on growth and invasion, and whether decreased pHe contributes to the non-autonomous effects we observed in imaginal discs. Our data also indicate that reducing H+ efflux in cancer cells suppresses multiple pathological characteristics in parallel. Previous studies identified distinct responses to reduced H+ efflux, such as tumor growth in xenograft models( Lagarde et al., 1988; Sonveaux et al., 2008; Colen et al., 2011; Yang et al., 2011) or viability of isolated cancer cells( Rich et al., 2000; Reshkin et al., 2003). We now show progressive effects of limiting H+ efflux with oncogene expression, including initially suppressing hyper-proliferation and dysplasia, followed by decreasing pHi, and culminating in a synthetic lethal interaction with histological features of coagulative necrosis. Coagulative necrosis is characteristically found within the central region of solid tumors( Searle et al., 1975; Lagarde et al., 1988), and is thought to be induced by extreme physiological cellular stresses. Removing Dnhe2 in an otherwise wild type genetic background decreased pHi but had no effect on larval tissue morphology. Dnhe2null retinal pHi in pupae was slightly higher than in larvae but not significantly different compared with wild type. These data suggest that in the absence of Dnhe2, pHi homeostasis during metamorphosis can be maintained by alternative ion transport mechanisms, changes in cellular buffering capacity and/or metabolic changes. While our Drosophila studies evaluate synthetic lethality in the ~20% Dnhe2 homozygous mutant ‘escaper’ flies that survive to eclosion, our studies in several transformed cell lines also show a synthetic lethality interaction, suggesting a conserved mechanism. The synthetic lethal interaction we observed suggests H+ efflux is necessary for dissipating oncogene-generated acids, most likely from increased glycolytic metabolism. Our studies further show that these lethal interactions occur in two genetically complex, physiologically adapted invasive tumor cell lines. Our data build on the long-standing observation of increased pHi in cancer cells and suggest several new directions for future investigation. First, our findings indicate that the biosensor pHluorin can be used to resolve pHi dynamics in vivo during tumor formation and metastasis and whether there are spatially distinct pHi dynamics within a tumor that might inform us about tumor properties and plasticity. Second, the rough eye phenotype induced with GMR > Dnhe2 provides a new model for genetic screens to identify pH-sensitive pathways and previously unrecognized pH sensors regulating cell growth and tissue architecture. Dysplasia with increased pHi in the absence of oncogenes is likely in part dependent on cancer-promoting pH sensors( Schönichen et al., 2013), including focal adhesion kinase( FAK) and the actin regulatory protein cofilin that support tumor growth and metastasis( Wang et al., 2007; Cance et al., 2013) and have increased activity at higher pHi( Frantz et al., 2008; Choi et al., 2013). Third, the synthetic lethality we show suggests that therapeutic strategies targeting H+ efflux transporters or pH sensors with selective roles in oncogene-induced responses could limit metastatic progression with minimal off-target effects.","answer":"An individual can develop cancer if cells in their body gain genetic mutations that enable the cells to divide more rapidly and move—or metastasize—to other tissues and organs . These mutations can alter the chemistry of the cell; for example , the inside of a cancer cell is much more alkaline ( has a higher pH ) than the inside of a normal cell . This helps the cancer cells to grow and divide rapidly , and move to other parts of the body , but it is not clear how important this change in pH within the cell is for the development of cancer . Previous studies have shown that many cancer cells increase the amounts or activities of the proteins that remove hydrogen ions from the cell , and so make the inside of a cell more basic . Here , Grillo-Hill et al . increased the amount of one of these proteins , NHE1 , in fruit flies to study its effects on healthy cells . The experiments showed that the larval cells that produced more NHE1 were more alkaline than normal cells , and this caused the cells to become less organized and grow more rapidly . Grillo-Hill et al . also found that NHE1 can work together with the oncogene RasV12 that promotes cancer development to enhance migration within the developing wings of the larvae . Next , Grillo-Hill et al . tested whether the change in pH is necessary for cells to become cancerous . Flies missing the gene that makes NHE1 appeared normal . However , if these cells also have the oncogene Raf—which , like RasV12 , promotes cancer—the inside of the cells gradually became so acidic that they died . Grillo-Hill et al . also found that blocking the activity of NHE1 in human cancer cells could lead to increased death but does not increase the death of normal cells . Grillo-Hill et al . 's findings show that increasing the internal pH of healthy cells leads to characteristics similar to those found in cancer cells . Furthermore , cancer cells can die if they become more acidic . This suggests that targeting pH levels could guide the development of treatments for cancer that selectively kill cancer cells while leaving normal cells unharmed ."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Stance stability with unilateral and bilateral light touch of an external stationary objectAbstract 1:Unilateral light fingertip touch of a stationary object has a significant stabilizing effect on postural sway during stance . The purpose of this study was to find out if this effect is enhanced by bilateral light touch of parallel stationary objects . The postural sway of 54 healthy subjects was tested in four stance conditions : no touch ; unilateral left light touch of the left h and le of a walker ; unilateral right light touch of the right h and le of the same walker ; and bilateral light touch of the two h and les . During testing , subjects stood blindfolded on two foam pads placed on the left and right force plates of the Tetrax balance system . Testing in each condition lasted 45 s and was executed twice in a r and om order . As expected , postural sway was significantly reduced by unilateral left or right light fingertip touch . It was significantly further decreased by bilateral light touch . In addition , light touch conditions were associated with a reduction in pressure fluctuations between the heel and forefoot of the same foot as well as those of the contralateral foot , with a concomitant increase in weight shift fluctuations between the two feet . The decrease in postural sway with bilateral light touch suggests cortical modulation of the bilateral touch inputs , with enhancement of the stabilizing responseTitle 2:Effects of light fingertip touch on postural responses in subjects with diabetic neuropathyAbstract 2:Objectives : To investigate the potential benefits from lightly touching an external supporting device on automatic postural responses to support surface translations , in subjects with profound sensory neuropathy in the feet due to diabetes mellitus ( DM-PN ) . Methods : Eight subjects with DM-PN and 10 age matched controls were tested under r and omly ordered conditions of no fingertip touch ( NT ) , light touch ( LT ; < 1 N ) , and heavy touch ( HT , as needed ) of a stationary touch plate , during three backward translation velocities of the support surface at 10 , 20 , and 30 cm/s . Dependent variables included response latencies , CoP velocity , and the slope of the relation between centre of pressure ( CoP ) velocity and translation velocity as a measure of response scaling . Results : Postural response latencies were significantly longer and scaling of initial response magnitude in proportion to translation velocity was significantly smaller in the DM-PN subjects compared to the control subjects . LT had no significant effect on response latencies of the DM-PN patients . Fingertip touch increased the slope of the scaling of postural response magnitude in both groups . However , DM-PN subjects had to use HT to improve response scaling , whereas control subjects improved scaling with LT as well as HT . LT significantly increased rightward CoP velocity towards the touch plate in all subjects . Conclusions : LT did not reduce the latency or improve the scaling of automatic postural responses in subjects with peripheral neuropathy . The major effect of LT on the automatic postural responses of the DM-PN subjects was in increasing CoP velocity towards the side of the supporting device . HT in neuropathy subjects and LT in age matched control subjects increased the sensitivity of initial postural response scaling , suggesting that somatosensory substitution from a cane in the h and could be used to improve the magnitude of medium latency postural responses to slips and tripsTitle 3:The use of a safety harness does not affect body sway during quiet standing.Abstract 3:BACKGROUND Postural sway during quiet st and ing reduces when somatosensorial information is provided by an active or passive \\" light touch \\" of different body parts with a surface . The contact of the safety harness with the body could induce a similar effect , leading to an undesirable side effect in the balance evaluation . METHODS This study investigated if a safety harness system , commonly used in balance studies , affects body sway during the balance evaluation . Healthy adults stood as quietly as possible for 60s in a comfortable position on a force plate . First , we performed an experiment on the light-touch effect with 10 subjects to determine the necessary sample size for the main investigation . Then , 60 subjects completed four tasks where the use of the safety harness and the visual information were manipulated . Area , root-mean square , speed , and frequency of the center of pressure displacement were analyzed . FINDINGS A light touch decreased postural sway on both visual conditions but there was no effect of the use of a safety harness on sway when quietly st and ing , independent of the visual information . Postural sway increased on both somatosensorial conditions when the visual information was not provided . INTERPRETATION This result shows that the safety harness does not interfere with the evaluation what is of major importance to method ological aspects of balance evaluationTitle 4:Effectiveness of fingertip light contact in reducing postural sway in older people.Abstract 4:BACKGROUND AND OBJECTIVE haptic cues from fingertip light touch ( LT ) with a stationary surface reduce postural sway even at non-mechanically supportive force levels . Aim of this study was to determine the effects of LT on postural sway in older compared with younger persons . SUBJECTS twenty young ( age 20 - 29 , mean 23.9 + 2.5 ) and 20 older participants ( age 65 - 83 , mean 74.3 + 6.4 ) . METHODS subjects stood in the semi-t and em position on a firm surface , and their postural sway was quantified using a force platform . Experimental trials , r and omised across subjects , included two sight conditions ( vision and no vision ) and three contact conditions ( no touch , NT ; light touch , LT ; and force touch , FT ) . The measured parameters were the length and the area of centre of pressure sway ( COP-L and COP-A ) and the mean velocity of COP displacements in the anterior-posterior ( COP-AP ) and medial-lateral ( COP-ML ) direction . RESULTS for all variables , the analysis showed significant differences between contact conditions , sight conditions and age . Contact-age interaction was significant between NT and LT conditions , with older participants showing greater decrease in postural sway than younger participants , but not between FT and LT conditions . CONCLUSIONS results indicate that the effectiveness of LT in reducing postural sway may be greater in older than in younger persons , perhaps because in older persons haptic cues from upper extremity might counterbalance sub- clinical sensory loss in the lower extremities . This finding supports the hypothesis that older people may sometimes use a walking aid as an informative device and suggests that during balance training external aids should not be usedTitle 5:Stabilization of posture by precision touch of the index finger with rigid and flexible filamentsAbstract 5:Abstract . Light touch of the index finger with a stationary surface at non-mechanically supportive force levels ( < 100 g ) greatly attenuates the  body sway of st and ing subjects . In three experiments , we evaluated the properties of finger contact and of the contacted object necessary to produce postural stabilization in subjects st and ing heel-to-toe with eyes closed , as well as how accurately h and position can be controlled . Experiment 1 involved finger contact with flexible filaments of different bending strengths , a flat surface , and an imagined spatial position . Contact with the flat surface was most effective in attenuating sway ; the flexible filaments were much less effective but still significantly better than imagined contact . Experiment 2 compared the effectiveness of finger contact with a flexible filament , a rigid filament of the same diameter , a flat surface , and an imagined spatial position . The rigid filament and flat surface conditions were equally effective in attenuating body sway and were greatly superior to contact with the flexible filament , which was superior to imagined contact . Experiment 3 included five conditions : arms by sides ; finger \\" contact \\" with an imagined spatial position ; finger contact with a flat surface ; finger contact with a flexible filament attempting to maintain it bent ; and contact with the flexible filament attempting not to bend it . The arms by sides and finger \\" contact \\" with an imagined position conditions did not differ significantly ; all three conditions involving actual finger contact showed significantly less center of pressure and h and sway , but contact with the flat surface was most effective in attenuating both postural and h and displacement . In all three experiments , the level of force applied in fingertip contact conditions was far below that necessary to provide mechanical stabilization . Our findings indicate that : ( 1 ) stimulation of a small number of receptors in the fingertip is adequate to allow stabilization of sway , ( 2 ) fingertip force levels as low as 5–10 g provide some stabilization , ( 3 ) contact with a stationary spatial referent is most effective , and ( 4 ) independent control of arm and torso occurs when finger contact is allowedTitle 6:Haptic feedback from manual contact improves balance control in people with Parkinson's disease.Abstract 6:Parkinson 's disease ( PD ) de grade s balance control . Haptic ( touch and proprioception ) feedback from light contact with a stationary surface inadequate to mechanically stabilize balance improves balance control in healthy people . In this study we tested whether PD impairs use of haptic cues independent of mechanical support to control balance . We measured postural sway in thirteen individuals with PD ( H&Y 1 - 3 , median=2 , Q1=2 , Q3=2 ) and thirteen age-matched controls balancing in a widened , sharpened Romberg stance in four conditions : eyes-closed , no manual contact ; eyes-closed light-touch contact ( < 1N ) , eyes-closed , unrestricted contact ; and eyes-open , no contact .  To determine whether PD-severity affects any of these balance strategies , PD participants were tested on- and off-medication , and using the more- and less-affected body side in the stance and manual contact . Individuals with PD simultaneously maintained non-supportive fingertip contact and balance in this task without practice . PD participants swayed more than control participants ( ML CP p=0.010 ; shoulder p<0.001 ) , but manual contact reduced sway . Non-supportive manual contact stabilized balance more than vision ( p<0.05 ) . PD-severity factors had no significant effect ( p>0.05 ) . We conclude the effect of PD on balance is not specific to vision or haptic feedback . Nevertheless , haptic cues from manual contact , independent of mechanical support , improve balance control in individuals with PD . We discuss the implication that PD or associated dopaminergic pathways do not directly affect haptic feedback balance control mechanisms , including arm/posture coordination and proprioceptive integrationTitle 7:Effects of different types of light touch on postural swayAbstract 7:Abstract . When a st and ing person applies a light finger touch to an external stable object ,  postural sway  is reduced . We tested a hypothesis that two factors related to touch can induce this effect , the presence of a stable reference point and the modulation of contact forces leading to tissue deformation . Force platform signals were analyzed while subjects stood quietly with or without additional light touch to an external object ( contact forces under 1 N ) . The point of touch on the body was manipulated . We also investigated the effects of active touch vs fixation of a finger at a point in external space . The results show that touch to the head or neck can be more effective in reducing body sway than a finger touch . A larger reduction in sway was observed when the finger was fixed in a clip ( the net forces between the clip and the point of its fixation to the st and were under 1 N ) as compared to a free light touch to a pad . The subjects showed a reduction in postural sway while holding a load suspended using a pulley system ; in this situation , contact with the load via the pulley provided modulation of contact forces but not a fixed reference point . This finding emphasizes the importance of such factors as stability of the contact point and modulation of contact forces , as compared to active touch or to an implicit task of stabilizing the kinematic chain . The system of postural stabilization can reduce postural sway , making use of either of two sources of sensory information associated with touch , one related to providing a fixed reference point in space , and the other related to transient force changes at the point of contact related to the sway","answer":"Such effect was more evident when the applied vertical force was greater than 1N , but if individuals with poor balance took more advantage of the light touch than healthy ones it depended on the source of their balance problems and not the amount of the applied force .These findings suggested that the maintenance of the fingertip lightly touching an external surface could provide additional somatosensory information for individuals with poor balance and then it could be used as a strategy to improve the control of upright st and ing during intervention programs"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Calcineurin activates transcription from the GM-CSF promoter in synergy with either protein kinase C or NF-kappa B / AP-1 in T cells. Two cis-acting elements GM-kappa B / GC-box and CLE0, of the granulocyte-macrophage colony-stimulating factor (GM-CSF) gene are required for maximal induction in Jurkat T cells by costimulation with phorbol-12-myristate acetate (PMA) and Ca2 + ionophore (A23187). The GM-kappa B sequence is recognized by NF-kappa B, which is mainly induced by PMA. The CLE0 sequence interacts with factors, related to a PMA-induced AP-1 and a PMA / A23187-induced NF-AT. We examined whether signal transducing components in T cells can activate transcription of the GM-CSF gene. Cotransfection of NF-kappa B (p50 / p65) -or AP-1 (c-Jun / c-Fos) -expression vectors into Jurkat cells with a luciferase reporter containing the GM-CSF promoter did not stimulate transcription from the GM-CSF promoter. In contrast, cotransfection with a combination of NF-kappa B and AP-1 significantly augmented transcription from the GM-CSF promoter containing the GM-kappa B / GC-box and the CLE0 (AP-1 / NF-AT). Expression of a constitutively active calcineurin (CN), a Ca2 + / calmodulin-dependent protein phosphatase, potentiated by two fold the transcriptional activation by NF-kappa B / AP-1. Both constitutively active forms of CN and protein kinase C (PKC) synergistically activated transcription from the GM-CSF promoter. These results suggest that cooperation among NF-kappa B -, AP-1-and NF-AT-binding sequences is required for induction of the GM-CSF gene through PKC-and Ca2 +-signaling pathways downstream of T cell activation.","answer":"{\\"CellLine\\": [\\"Jurkat T cells\\", \\"T cells\\", \\"Jurkat cells\\"], \\"CellType\\": [\\"T cells\\"], \\"DNA\\": [\\"luciferase reporter\\", \\"CLE0 sequence\\", \\"cis - acting elements\\", \\"GM - CSF gene\\", \\"GM - kappa B sequence\\", \\"which\\", \\"granulocyte - macrophage colony - stimulating factor (GM - CSF) gene\\", \\"GM - CSF promoter\\", \\"NF - kappa B - , AP - 1 - and NF - AT - binding sequences\\", \\"NF - kappa B (p50 / p65) - or AP - 1 (c - Jun / c - Fos) - expression vectors\\", \\"CLE0\\", \\"GM - kappa B / GC - box\\"], \\"Protein\\": [\\"PMA - induced AP - 1\\", \\"GM - CSF\\", \\"CN\\", \\"calcineurin\\", \\"/ AP - 1\\", \\"PKC\\", \\"granulocyte - macrophage colony - stimulating factor\\", \\"PMA / A23187 - induced NF - AT\\", \\"Calcineurin\\", \\"AP - 1\\", \\"NF - kappa B\\", \\"protein kinase C\\", \\"AP - 1 / NF - AT\\", \\"Ca2 + / calmodulin - dependent protein phosphatase\\"], \\"RNA\\": []}"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:abell 2218 is a very rich galaxy cluster ( richness class 4 , according to abell et al .1989 ) , characterized by a large velocity dispersion of the galaxy population ( @xmath1  km / s , le borgne et al .1992 ) , and a high x - ray temperature and luminosity ( @xmath2  kev , see e.g. markevitch 1997 , @xmath3 erg / s  km / s / mpc and @xmath4 in the energy band 0.54.4 kev , see e.g. kneib et al .1996 ) .    these properties , coupled to a relatively small distance ( @xmath5 , le borgne et al .1992 ) , made this cluster an attractive target for studies of the sunyaev - zeldovich effect ( birkinshaw & hughes 1994 ) , and one of the closest clusters where gravitational arcs are detected .the amazing concentration of gravitational arcs and arclets has stimulated a huge observational effort first to get sub - arcsec imaging ( from the ground , see , e.g. kneib et al .1995 , and from space with hst , kneib et al .1996 ) , and then to get spectra of the arcs ( ebbels et al .1997 ) .the optical and near - ir observations have allowed a very detailed modelling of the mass distribution within the cluster ( kneib et al .1996 ) , confirmed later to a great level of accuracy , ( ebbels et al .it was found that the cluster mass distribution is bi - modal , with the main concentration centred on the cd galaxy .the x - ray surface brightness , as obtained via rosat observations , does not trace the gravitational potential as derived from the lensing analysis , a possible indication that the x - ray emitting gas is far from hydrostatic equilibrium ( kneib et al . 1996 ) .this would also explain the discrepancy in the x - ray and lensing mass estimates ( markevitch 1997 ) .in this paper we report on the mid - ir observations of abell 2218 done with isocam on - board esa s _ infrared space observatory _ ( iso ) satellite .the high sensitivity of isocam allows us to determine the photometric properties of lensed and cluster galaxies in the mid - ir band , thus widening the wavelength coverage of their spectra .mid - ir observations are critical in understanding the intrinsic nature of these distant galaxies , since a starburst is known to emit a large fraction of its energy in the mid - ir , due to dust grain re - processing of the emitted radiation .abell 2218 was observed on march 3 , 1996 and again on february 28 , 1997 as part of an iso program of observations of lensing galaxy clusters with arcs and arclets : abell 370 , abell 2218 , cl2244 - 02 and ms2137 - 23 .an important criterion for target selection was to choose the clusters with the brightest arcs in the optical , spatially extended and the farthest from the lens , due to the limited spatial resolution of iso .+ the observations were performed by rastering in microscanning mode yielding to very deep isocam images of the galaxy cluster .the pixel field - of - view was 3@xmath6 and the microscanning steps were 7@xmath6 in both directions of the 5x5 raster .the cluster was imaged in the 4 filter bands , lw1 [ 4 - 5@xmath0 m ] , lw2 [ 5 - 8.5@xmath0 m ] , lw7 [ 8.5 - 11@xmath0 m ] , and lw3 [ 12 - 18@xmath0 m ] , at 5 or 10 sec integration times for a total observing time of 5.5 hours , covering a field of more than 2x2 arcminutes .the data reduction was done partly within the idl based ( iso)cam interactive analysis ( cia ) package ( ott et al . , 1997 ) and partly through the usage ofc++ based multi - resolution median transform ( _ wavelet _ ) techniques ( starck j .- l .et al , 1997 ) .cross - correlation of the two methods allows us to increase the reliability of source detection .the lw1 , lw2 and lw3 maps are presented in figures 1 & 2a , as overlays on top of the hst image ( courtesy j .-kneib ) of abell 2218 .    in the cluster core, no arclet is detected at a significant level at any wavelength in the mid - ir .this non - detection of arcs or arclets contrasts with our recent mid - ir imaging of abell 370 ( metcalfe et al .1997 ) , where the a0 giant arc is clearly detected as the main feature and emitter in the cluster core at 15@xmath0 m .but this giant arc is already a prominent feature in the optical , ( first giant arc discovered ) , whereas arcs and arclets are fainter in abell 2218 .+ the cd galaxy which is apparently centred on the cluster potential is clearly detected in the lw1 & lw2 filter bands . at 4.5@xmath0 m ( rest - frame wavelength 3.8 @xmath0 m )the cd emission is extended , covering part of the optical halo ; at 7@xmath0 m the emission is much more confined to the centre , but with an extension along the optical major axis , probably contaminated by the neighbouring merging dwarf galaxies . at 10@xmath0 m and 15@xmath0 mit lies just above the detection limit of isocam and no statement can be made on its extension .the mid - ir spectral energy distribution up to 15@xmath0 m seems to follow a simple rayleigh - jeans tail of the cold stellar component as found in optically - selected normal early - type galaxies ( e , s0 , s0a ) in the virgo cluster ( boselli et al .1998 ) . but due to the contamination by close - by galaxies it is very difficult to estimate the 4.5@xmath0 m flux of the cd .+ the brightest cluster member galaxies are also detected at 4.5 @xmath0 m and 7 @xmath0 m . at the redshift of the cluster the 4.5 @xmath0 m emission is mostly coming again from cold stellar photospheres .the 7 @xmath0 m ( lw2 band ) ( rest - frame 5.7 @xmath0 m ) emission includes a small fraction of pah emission but comes mainly again from the cold stellar photospheres . at 10 & 15 micronsmost of cluster members have vanished ( ie . are below or very close to our detection limit ) , as expected for normal early - type galaxies ( ellipticals ) where there is only the rayleigh - jeans tail mid - ir emission from cold stellar photospheres , in dust & gas poor cluster core ellipticals .+ still one cluster member galaxy # 373 ( numbering system from le borgne et al .1992 in the following ) is detected at 15@xmath0 m , but also at 4.5 @xmath0 m and 7 @xmath0 m , it has a cart - wheel like aspect , from the ring surrounding it and is probably a big face - on spiral galaxy .the 4.5@xmath0 m and 7@xmath0 m emission comes mostly from the nucleus whereas the 15@xmath0 m originates apparently from the ring structure .it could be pah and small hot grain emission enhanced by star formation in tidal shocks in the ring.    object # 323 is detected at 15 @xmath0 m .this object was suspected to be an arclet candidate in the first deep multi - filter ground - based imaging ( pello et al .1992 ) , since it appeared as a fine unresolved extended structure , together with another 32 arclets in total .it is classified as one of the 235 arclet candidates in the first hst observation of abell 2218 ( kneib et al .however , as noted by kneib et al . , it was also suspected not to be a strongly lensed object when comparison is made with shear orientation .this was again confirmed by ebbels et al .( 1997 ) , object # 323 being very elongated but at an angle of 45 degrees from the shear direction .identification of several absorption features in its spectrum reveal it to be a cluster member at a redshift of z=0.179 , a spiral seen edge - on .    to our surprisethe brightest source by far from 7@xmath0 m to 15@xmath0 m is object # 395 , an apparently insignificant z=0.1032 ( le borgne 1992 ) foreground sb galaxy , showing an ultraviolet excess and a strong h@xmath7 emission line , both indicating strong star formation of massive stars .most of this mid - ir emission could then originate from the reprocessing by the small hot dust heated by a strong uv radiation field .the second strongest emitter at long wavelength ( from 10@xmath0 m to 15@xmath0 m ) , but much less at shorter wavelengths is object # 317 , a lensed galaxy at z=0.474 ( ebbels et al .1997 ) , a rather red object from the visible to the mid - ir .first indications show that this type of lensed object is common on our larger field imaging towards lensing clusters ( metcalfe et al .1998 in preparation )      birkinshaw m. , hughes j.p .1994 , 420 , 33 boselli a. , lequeux j. , sauvage m. et al ., in press , 1998 .ebbels t. et al . 1997 , astro - ph/9703169 , in press kneib j .-, mellier y. , pell r. et al .1995 , 303 , 27 kneib j .-, ellis r.s ., smail i. , sharples r.m .1996 , 471 , 643 le borgne j .- f . ,pell r. , sanahuja b. 1992 , 95 , 87 markevitch m. 1997 , astro - ph/9704106 , in press metcalfe et al .1997 , to appear in 1997 moriond conf .mamon g. ed .pell r. , le borgne j.f ., sanahuja b. , mathez g. , fort b. , 266 , 6 ott s. et al .1997 , in hunt g. , payne ( eds ) asp conf . series vol .125 starck j .- l .et al . , \`\` imaging processing and data analysis in the physical sciences : the multiscale approach '' , cambridge univ","answer":"we report on the mid - infrared imaging at 5 , 7 , 10 & 15 @xmath0 m of the galaxy cluster abell 2218 obtained with the isocam instrument onboard esa s infrared space observatory ( iso ) , as part of an on - going program to image gravitational arcs and arclets in distant clusters .  several cluster galaxies as well as field galaxies are detected .  we discuss their mid - ir flux properties ."},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: I want to create an adversarial text classifier.Keyphrases: text classificationDataset description:DailyDialog++: Consists of (i) five relevant responses for each context and (ii) five adversarially crafted irrelevant responses for each context.MultiNLI: The Multi-Genre Natural Language Inference (MultiNLI) dataset has 433K sentence pairs. Its size and mode of collection are modeled closely like SNLI.SNLI: The SNLI dataset (Stanford Natural Language Inference) consists of 570k sentence-pairs manually labeled as entailment, contradiction, and neutral. Premises are image captions from Flickr30k, while hypotheses were generated by crowd-sourced annotators who were shown a premise and asked to generate entailing, contradicting, and neutral sentences.ImageCLEF-DA: The ImageCLEF-DA dataset is a benchmark dataset for ImageCLEF 2014 domain adaptation challenge, which contains three domains: Caltech-256 (C), ImageNet ILSVRC 2012 (I) and Pascal VOC 2012 (P). For each domain, there are 12 categories and 50 images in each category.ConvAI2: The ConvAI2 NeurIPS competition aimed at finding approaches to creating high-quality dialogue agents capable of meaningful open domain conversation. The ConvAI2 dataset for training models is based on the PERSONA-CHAT dataset.GYAFC: Grammarly’s Yahoo Answers Formality Corpus (GYAFC) is the largest dataset for any style containing a total of 110K informal / formal sentence pairs. Yahoo Answers is a question answering forum, contains a large number of informal sentences and allows redistribution of data.Options:- A: DailyDialog++  B: MultiNLI  C: SNLI  D: ImageCLEF-DA  E: ConvAI2  F: GYAFC","answer":"[\\"MultiNLI\\", \\"SNLI\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Naloxone\\", ...], \\"Disease\\" : [\\"Hypotensive\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Comparative cognitive and subjective side effects of immediate-release oxycodone in healthy middle-aged and older adults. This study measured the objective and subjective neurocognitive effects of a single 10-mg dose of immediate-release oxycodone in healthy, older (> 65 years), and middle-aged (35 to 55 years) adults who were not suffering from chronic or significant daily pain. Seventy-one participants completed 2 separate study days and were blind to medication condition (placebo, 10-mg oxycodone). Plasma oxycodone concentration peaked between 60 and 90 minutes postdose (P < .01) and pupil size, an indication of physiological effects of the medication, peaked at approximately 90 to 120 minutes postdose (P < .01). Significant declines in simple and sustained attention, working memory, and verbal memory were observed at 1 hour postdose compared to baseline for both age groups with a trend toward return to baseline by 5 hours postdose. For almost all cognitive measures, there were no medication by age-interaction effects, which indicates that the 2 age groups exhibited similar responses to the medication challenge. This study suggests that for healthy older adults who are not suffering from chronic pain, neurocognitive and pharmacodynamic changes in response to a 10-mg dose of immediate-release oxycodone are similar to those observed for middle-aged adults. PERSPECTIVE: Study findings indicate that the metabolism, neurocognitive effects, and physical side effects of oral oxycodone are similar for healthy middle-aged and older adults. Therefore, clinicians should not avoid prescribing oral opioids to older adults based on the belief that older adults are at higher risk for side effects than younger adults.","answer":"{\\"Chemical\\": [\\"oxycodone\\"], \\"Disease\\": [\\"pain\\", \\"declines in working memory, and verbal memory\\", \\"chronic pain\\", \\"declines in simple and sustained attention, working memory, and verbal memory\\", \\"declines in simple and sustained attention\\"]}"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:While neural networks can be trained to map from one specific dataset to another, they usually do not learn a generalized transformation that can extrapolate accurately outside the space of training.For instance, a generative adversarial network (GAN) exclusively trained to transform images of cars from light to dark might not have the same effect on images of horses.This is because neural networks are good at generation within the manifold of the data that they are trained on.However, generating new samples outside of the manifold or extrapolating \\"out-of-sample\\" is a much harder problem that has been less well studied.To address this, we introduce a technique called neuron editing that learns how neurons encode an edit for a particular transformation in a latent space.We use an autoencoder to decompose the variation within the dataset into activations of different neurons and generate transformed data by defining an editing transformation on those neurons.By performing the transformation in a latent trained space, we encode fairly complex and non-linear transformations to the data with much simpler distribution shifts to the neuron's activations.We showcase our technique on image domain/style transfer and two biological applications: removal of batch artifacts representing unwanted noise and modeling the effect of drug treatments to predict synergy between drugs.Many experiments in biology are conducted to study the effect of a treatment or a condition on a set of samples.For example, the samples can be groups of cells and the treatment can be the administration of a drug.However, experiments and clinical trials are often performed on only a small subset of samples from the entire population.Usually, it is assumed that the effects generalize in a context-independent manner without mathematically attempting to model the effect and potential interactions with the context.However, mathematically modeling the effect and potential interactions with background information would give us a powerful tool that would allow us to assess how the treatment would generalize beyond the samples measured.We propose a neural network-based method for learning a general edit function corresponding to treatment in the biological setting.While neural networks offer the power and flexibility to learn complicated ways of transforming data from one distribution to another, they are often overfit to the training dataset in the sense that they only learn how to map one specific data manifold to another, and not a general edit function.Indeed, popular neural network architectures like GANs pose the problem as one of learning to generate the post-treatment data distributions from pre-treatment data distributions.Instead, we reframe the problem as that of learning an edit function between the preand post-treatment versions of the data, that could be applied to other datasets.We propose to learn such an edit, which we term neuron editing, in the latent space of an autoencoder neural network with non-linear activations.First we train an autoencoder on the entire population of data which we are interested in transforming.This includes all of the pre-treatment samples and the post-treatment samples from the subset of the data on which we have post-treatment measurements.The internal layers of this autoencoder represent the data with all existing variation decomposed into abstract features (neurons) that allow the network to reconstruct the data accurately BID28 BID4 BID17 BID24 .Neuron editing involves extracting differences between the observed pre-and post-treatment activation distributions for neurons in this layer and then applying them to pre-treatment data from the rest of the population to synthetically generate post-treatment data.Thus performing the edit node-by-node in this space actually encodes complex multivariate edits in the ambient space, performed on denoised and meaningful features, owing to the fact that these features themselves are complex non-linear combinations of the input features.While neuron editing is a general technique that could be applied to the latent space of any neural network, even GANs themselves, we instead focus exclusively on the autoencoder in this work to leverage three of its key advantages.First, we seek to model complex distribution-to-distribution transformations between large samples in high-dimensional space.While this can be generally intractable due to difficulty in estimating joint probability distributions, research has provided evidence that working in a lower-dimensional manifold facilitates learning transformations that would otherwise be infeasible in the original ambient space BID32 BID21 BID29 .The non-linear dimensionality reduction performed by autoencoders finds intrinsic data dimensions that esentially straighten the curvature of data in the ambient space.Thus complex effects can become simpler shifts in distribution that can be computationally efficient to apply.Second, by performing the edit to the neural network internal layer, we allow for the modeling of some context dependence.Some neurons of the internal layer have a drastic change between preand post-treatment versions of the experimental subpopulation, while other neurons such as those that encode background context information not directly associated with treatment have less change in the embedding layer.The latter neurons are less heavily edited but still influence the output jointly with edited neurons due to their integration in the decoding layers.These edited neurons interact with the data-context-encoding neurons in complex ways that may be more predictive of treatment than the experimental norm of simply assuming widespread generalization of results context-free.Third, editing in a low-dimensional internal layer allows us to edit on a denoised version of the data.Because of the reconstruction penalty, more significant dimensions are retained through the bottleneck dimensions of an autoencoder while noise dimensions are discarded.Thus, by editing in the hidden layer, we avoid editing noise and instead edit significant dimensions of the data.We note that neuron editing makes the assumption that the internal neurons have semantic consistency across the data, i.e., the same neurons encode the same types of features for every data manifold.We demonstrate that this holds in our setting because the autoencoder learns a joint manifold of all of the given data including pre-and post-treatment samples of the experimental subpopulation and pre-treatment samples from the rest of the population.Recent results show that neural networks prefer to learn patterns over memorizing inputs even when they have the capacity to do so BID31 .Wedemonstrate that neuron editing extrapolates better than generative models on two important criteria. First, as to the original goal, the predicted change on extrapolated data more closely resembles the predicted change on interpolated data. Second, the editing process produces more complex variation, since it simply preserves the existing variation in the data rather than needing a generator to learn to create it. We comparethe predictions from neuron editing to those of several generationbased approaches: a traditional GAN, a GAN implemented with residual blocks (ResnetGAN) to show generating residuals is not the same as editing BID26 , and a CycleGAN BID33 . While in otherapplications, like natural images, GANs have shown an impressive ability to generate plausible individual points, we illustrate that they struggle with these two criteria. We also motivatewhy neuron editing is performed on inference by comparing against a regularized autoencoder that performs the internal layer transformations during training, but the decoder learns to undo the transformation and reconstruct the input unchanged BID0 .In the followingsection, we detail the neuron editing method. Then, we motivatethe extrapolation problem by trying to perform natural image domain transfer on the canonical CelebA dataset . We then move to twobiological applications where extrapolation is essential: correcting the artificial variability introduced by measuring instruments (batch effects), and predicting the combined effects of multiple drug treatments (combinatorial drug effects) BID1 .In this paper, we tackled a data-transformation problem inspired by biological experimental settings: that of generating transformed versions of data based on observed pre-and post-transformation versions of a small subset of the available data.This problem arises during clinical trials or in settings where effects of drug treatment (or other experimental conditions) are only measured in a subset of the population, but expected to generalize beyond that subset.Here we introduce a novel approach that we call neuron editing, for applying the treatment effect to the remainder of the dataset.Neuron editing makes use of the encoding learned by the latent layers of an autoencoder and extracts the changes in activation distribution between the observed pre-and post treatment measurements.Then, it applies these same edits to the internal layer encodings of other data to mimic the transformation.We show that performing the edit on neurons of an internal layer results in more realistic transformations of image data, and successfully predicts synergistic effects of drug treatments in biological data.Moreover, we note that it is feasible to learn complex data transformations in the non-linear dimensionality reduced space of a hidden layer rather than in ambient space where joint probability distributions are difficult to extract.Finally, learning edits in a hidden layer allows for interactions between the edit and other context information from the dataset during decoding.Future work along these lines could include training parallel encoders with the same decoder, or training to generate conditionally.","answer":"We reframe the generation problem as one of editing existing points, and as a result extrapolate better than traditional GANs."},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:(A)Stridelength(cm)inthefootprinttest.","answer":"[]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Lack of IL-12 signaling in human allergen-specific Th2 cells. IL-12 is a powerful skewer of CD4 + T cell responses toward the Th1 phenotype by inducing IFN-gamma production in naive Th cells. In the present study we addressed the question of whether IL-12 can reverse established Th2 responses into Th1 / Th0 responses by inducing IFN-gamma production in memory Th2 cells. To this aim, allergen-specific CD4 + T cell clones (TCC) were generated from the peripheral blood of three atopic patients, and their cytokine profiles were analyzed. The majority of these TCC exhibited a strongly polarized Th2 cytokine profile, and the production of IFN-gamma could not be induced by exogenous IL-12. Only those TCC with low IFN-gamma levels in the absence of IL-12 responded to IL-12 by additional enhancement of IFN-gamma production. The IL-12 nonresponsiveness of the Th2 clones was further evident by the total lack of IL-12-induced phosphorylation of STAT4 (signal transducer and activator of transcription-4), a transcription factor that is typically involved in IL-12 signaling. Consequently, IL-12 also failed to induce the DNA-binding activity of STAT4-containing complexes in the nuclei of these Th2 clones. All TCC expressed equal levels of the low-affinity IL-12R beta1 subunit. Our results indicate that human allergen-specific Th cells with strongly polarized Th2 cytokine profiles do not respond to IL-12 and, therefore, can not be induced to produce IFN-gamma. The apparent high frequency of IL-12-nonresponsive Th cells within the allergen-specific populations in atopic patients predicts a limited skewing potential of IL-12 in the case of established Th2 responses, but only affecting newly recruited naive Th cells.","answer":"{\\"CellLine\\": [\\"Th cells\\", \\"memory Th2 cells\\", \\"human allergen - specific Th2 cells\\", \\"Th2 clones\\", \\"allergen - specific CD4 + T cell clones\\", \\"naive Th cells\\", \\"TCC\\", \\"IL - 12 - nonresponsive Th cells\\"], \\"CellType\\": [\\"CD4 + T cell\\"], \\"DNA\\": [], \\"Protein\\": [\\"IL - 12\\", \\"transcription factor\\", \\"IL - 12R\\", \\"signal transducer and activator of transcription - 4\\", \\"IL - 12 -\\", \\"IFN - gamma\\", \\"low - affinity IL - 12R beta1 subunit\\", \\"STAT4 - containing complexes\\", \\"cytokine\\", \\"STAT4\\"], \\"RNA\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Comparison of intravenous and intra-arterial urokinase thrombolysis for acute ischaemic stroke . Intravenous fibrinolysis ( IVF ) with rt-PA ( alteplase ) provides significant benefits in acute ischaemic stroke when it is given within the first three hours following stroke onset . Intra-arterial fibrinolysis ( IAF ) with pro-urokinase in PROACT II study provides quite the same benefit in the first 6 hours . IVF and IAF have never been compared . To compare the efficacy and safety of IVF and IAF with urokinase given within the first 6 hours of acute ischaemic stroke . Patients fulfilling the selection criteria were randomly assigned to receive urokinase 900,000 units via intravenous or intra-arterial routes . This randomised monocentre study was done between December 1995 and August 1997 . The primary outcome was defined as the number of patients with a modified Rankin score of 2 or less . Secondary outcomes included mortality , frequency of symptomatic intracranial haemorrhage ( SIH ) , neurological and functional scores . Fourteen patients were given IVF and 13 IAF . The study was terminated by the National Health Authorities when 27 patients had been included because of the mortality rate . Seven patients ( 26 % ) died , 4 in the IV group ( oedematous infarct in 3 and recurrence in 1 ) , 3 in the IA group ( SIH in 2 , and oedematous infarct in 1 ) . Patients given IVF were treated significantly earlier ( 4:16 h vs 5:24 h ; p=.007 ) . Although IA patients showed greater and earlier improvement there was no significant difference in primary and secondary outcomes . Because of premature termination , the trial was too small to provide any reliable and conclusive results . Intra-arterial fibrinolysis began significantly later than IV fibrinolysis but it gave non-significantly better results in this prematurely terminated study .","answer":"{\\"Intervention\\": [\\"Intravenous fibrinolysis ( IVF ) with rt-PA ( alteplase )\\", \\"IAF\\", \\"IVF\\", \\"urokinase\\", \\"Intra-arterial fibrinolysis ( IAF ) with pro-urokinase\\"], \\"Outcome\\": [\\"frequency of symptomatic intracranial haemorrhage ( SIH )\\", \\"number of patients with a modified Rankin score of 2 or less\\", \\"mortality\\", \\"neurological and functional scores\\", \\"efficacy and safety\\"], \\"Participant\\": [\\"27\\", \\"acute ischaemic stroke\\", \\"Fourteen\\"]}"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:varicocele is the abnormal tortuosity and dilation of the testicular veins ( the pampiniform plexus ) of more than 2 mm caused by venous reflux in the testes ( 1 - 5 ) .the prevalence of palpable varicocele is 15% in the general male population and 21% - 39% in subfertile men ( 6 - 8 ) .varicocele is among the most common causes of reduced sperm count and quality , leading to infertility and subfertility ( 9 ) .physical examination is the standard diagnostic method for detecting varicocele , but the diagnosis of asymptomatic and impalpable varicocele is difficult .venous reflux is an important standard for the diagnosis of varicocele because reflux of more than 1 s increases the likelihood of infertility ( 10 ) .color doppler ultrasonography ( cdus ) is the most sensitive , non - invasive diagnostic method for diagnosing varicocele .it has a sensitivity of 93% , while clinical examination has a sensitivity of approximately 71% ( 11 ) .cdus evaluates varicocele based on venous diameter , the presence or absence of reflux , and other relevant factors .in this study , we explored the correlation between ultrasonography ( us ) and semen analysis parameters .this cross - sectional study was conducted in a university hospital , and the local research and ethics committee approved the research protocol .patients with clinically confirmed or suspected varicocele ( n = 134 ) were recruited for the study .patients with secondary varicocele , traumatic injury , other pathologic disorders of the testis ( e.g. tumor , hydrocele , spermatocele ) , or inflammation of the testis or epididymis were excluded . using a toshiba ultrasonography instrument ( tokyo , japan ) with a linear , multi - frequency probe ( 5 - 8.5 mhz ) , a primary cdus analysis was performed with all cases , and patients with venous diameters of more than 2 mmthe evaluated parameters were the venous diameter of the pampiniform plexus , the presence or absence of venous reflux on both sides , and the longitude and transverse diameters of the testes .reflux of longer than 1 s was considered pathologic , while flow volume was calculated by multiplying the area by the mean velocity .varicocele in the selected cases was classified as grade 0 ( 2 - 2.5 mm ) , grade 1 ( 2.5 - 3 mm ) , grade 2 ( 3 - 3.5 mm ) , or grade 3 ( > 3.5 mm ) .then patients were referred to a laboratory for semen analysis , including semen volume and sperm morphology , count , and motility .analysis was performed based on the world health organization laboratory manual issued in 1993 ( 9 ) .the semen analysis parameters and cdus findings for the samples with venous reflux of longer than 1 s and those with venous reflux of less than 1 s were compared between using student s t - test .the mean age of the selected patients was 34.3  6.2 years ( range : 23 - 50 years ) . among the participants, 19 had a history of cigarette smoking ( 19.2% ) , 12 a history of alcohol use ( 12.1% ) , and 9 ( 9.1% ) a history of mumps , while 41 had a history of surgery ( 6 bilateral and 7 unilateral varicocele surgery ) .the results for testes size measured in two dimensions and varicocele size are summarized in tables 1 and 2 .all patients had left varicocele , while right varicocele was observed in 53 cases ( table 2 ) .the average size of varicocele on the left side was significantly greater than that of right - side varicocele ( p < 0.001 ) .most varicocele on both sides was grade 1 ( 42.4% ) ( figure 1 ) .the average semen volume of participants was 2.6  1.2 ml , the average sperm motility was 48.9  24.4% , and the average sperm count was 45.1  58.2 million .the correlation coefficients between varicocele size and sperm count in the left and right testes were -0.6 and -0.7 , respectively ( p = 0.001 ) .the correlation coefficients between varicocele size and sperm motility in the left and right testes were -0.61 and -0.78 , respectively ( p = 0.035 ) .the correlation coefficients between varicocele size and abnormal sperm morphology in the left and right testes were 0.53 and 0.74 , respectively ( p = 0.04 ) .the correlation coefficient between varicocele size and semen volume in the left and right testes was -0.61 ( p = 0.045 ) .the correlation coefficients of testes size with sperm count , sperm motility , abnormal sperm morphology , and semen volume were 0.35 - 0.49 , 0.3 - 0.48 , 0.25 - 0.45 , and 0.15 - 0.25 , respectively ( p = 0.3 ) .seventy - one ( 71 ) of 99 patients with left varicocele ( 71.7% ) had reflux of longer than 1 s , while 14 of 53 patients with right varicocele ( 26.4% ) had reflux of longer than 1 s. the sperm analysis parameters , varicocele size , and testes size were compared between the samples with reflux of longer than 1 s and reflux of less than 1 s in each testis ( tables 4 and 5 ) . for the left testis , the groups had significant differences in semen volume , motility , morphology , and count ( p < 0.05 ) but not testis size ( p > 0.05 ) . patients with reflux had significantly greater varicocele size than patients without reflux ( p < 0.05 ) ( table 4 ) .similar findings were obtained for 14 patients with reflux of longer than 1 seconds on the right testis . for right - side varicocele ,varicocele size was significantly greater in patients with reflux than patients without reflux ( p < 0.05 ) .right testis size was not significantly different between the two groups ( p > 0.05 ) ( table 5 ) . in this investigation ,the cut - off point for diagnosis of varicocele was 2 mm and had acceptable sensitivity but not adequate specificity .therefore , we decided to select a cut - off point with higher specificity , ppv , and npv . using statistical analysis, we determined that 2.6 mm was a reliable cut - off value to more effectively detect varicocele .we showed that semen analysis parameters , including semen volume and sperm morphology , count , and motility , had significant correlations with varicocele diameter but not testes size .one study ( 12 ) , which compared sperm analysis data and cdus findings for 62 patients with varicocele , did not find any significant correlations between the analyzed parameters .this discrepancy with present results can be related to technical faults because ultrasonography is an operator - dependent technique .in addition , semen analysis results depend on the quality of the laboratory tools and technician s skills . two studies ( 13 , 14 ) found that patients with spermatogenesis disorder had smaller testes . although the present research also found a relationship between testes size and spermatogenesis disorder , this relationship was not statistically significant , which might be due to the lack of a standard method for measuring testes size in this study . in the present results , patients with reflux of longer than 1 seconds and those with reflux of less than 1 seconds had significantly different semen analysis parameters and varicocele size .similar findings were reported by ( 15 ) , who found a significant correlation between bilateral reflux and persistent reflux with sperm abnormalities .our inclusion criterion was varicocele diameter of more than 2 mm , resulting in the exclusion of 35 men with a history of infertility from the study .however , further analysis revealed that a cut - off point of 2.6 mm in the supine position during the valsalva maneuver was more reliable and efficient at detecting patients with varicocele ( 14 ) used a cut - off point of 2.48 mm in the standing position without the valsalva maneuver .we recommend that patients with a varicocele diameter of less than 2 mm be evaluated for venous reflux because reflux can occur without increasing the diameter of the pampiniform vein .","answer":"backgroundvaricocele , one of the most common causes of sperm abnormalities in men , is the dilation of the testicular vein ( the pampiniform venous plexus ) by more than 2 mm .  ultrasonography is the primary imaging procedure for varicocele diagnosis .  the venous diameter is evaluated using b - mode sonography , and venous reflux is assessed using color doppler sonography.objectivesin this study , we investigated the association of ultrasound findings with sperm parameters in patients with varicocele.methodsninety-nine patients with clinically diagnosed varicocele were included in this study , which was performed at a university imaging center .  patients were evaluated for pampiniform venous plexus diameter , venous reflux , and testicular size on both sides .  semen analysis was performed for all patients .  the ultrasonography parameters and semen analysis data were compared to assess the correlations between the results.resultsthe semen analysis parameters , including semen volume and sperm morphology , count , and motility , significant correlations with the diameter of the varicocele vein but were not correlated with testes size .  in addition , the patients with reflux of longer than 1 s and those with reflux of less than 1 s had significant differences in sperm parameters and varicocele size.conclusionsour study showed that ultrasonography findings can be a good predictor of sperm parameters in patients with varicocele ."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Inverse Correlation between Promoter Strength and Excision Activity in Class 1 Integrons}Article:Abstract:Class 1 integrons are widespread genetic elements that allow bacteria to capture and express gene cassettes that are usually promoterless. These integrons play a major role in the dissemination of antibiotic resistance among Gram-negative bacteria. They typically consist of a gene( intI) encoding an integrase( that catalyzes the gene cassette movement by site-specific recombination), a recombination site( attI1), and a promoter( Pc) responsible for the expression of inserted gene cassettes. The Pc promoter can occasionally be combined with a second promoter designated P2, and several Pc variants with different strengths have been described, although their relative distribution is not known. The Pc promoter in class 1 integrons is located within the intI1 coding sequence. The Pc polymorphism affects the amino acid sequence of IntI1 and the effect of this feature on the integrase recombination activity has not previously been investigated. We therefore conducted an extensive in silico study of class 1 integron sequences in order to assess the distribution of Pc variants. We also measured these promoters' strength by means of transcriptional reporter gene fusion experiments and estimated the excision and integration activities of the different IntI1 variants. We found that there are currently 13 Pc variants, leading to 10 IntI1 variants, that have a highly uneven distribution. There are five main Pc-P2 combinations, corresponding to five promoter strengths, and three main integrases displaying similar integration activity but very different excision efficiency. Promoter strength correlates with integrase excision activity: the weaker the promoter, the stronger the integrase. The tight relationship between the aptitude of class 1 integrons to recombine cassettes and express gene cassettes may be a key to understanding the short-term evolution of integrons. Dissemination of integron-driven drug resistance is therefore more complex than previously thought.Introduction:Integrons are natural genetic elements that can acquire, exchange and express genes within gene cassettes. The integron platform is composed of a gene, intI, that encodes a site-specific recombinase, IntI, a recombination site, attI, and a functional promoter, Pc, divergent to the integrase gene[1]( Figure 1). Gene cassettes are small mobile units composed of one coding sequence and a recombination site, attC. Integrons exchange gene cassettes through integrase-catalyzed site-specific recombination between attI and attC sites, resulting in the insertion of the gene cassette at the attI site, or between two attC sites, leading to the excision of the gene cassette( s) from the gene cassette array[2]–[6]. Multi-resistant integrons( MRI) contain up to eight gene cassettes encoding antibiotic resistance. To date, more than 130 gene cassettes have been described, conferring resistance to almost all antibiotic classes[7]. MRI play a major role in the dissemination of antibiotic resistance among Gram-negative bacteria, through horizontal gene transfer[8]. Five classes of MRI have been described on the basis of the integrase coding sequence, class 1 being the most prevalent[8]. Gene cassettes are usually promoterless, and their genes are transcribed from the Pc promoter, as in an operon( Figure 1), the level of transcription depending on their position within the integron[9],[10]. Among class 1 MRIs, several Pc variants have been defined on the basis of their −35 and −10 hexamer sequences. Four Pc variants have been named according to their sequence homology with the σ70 promoter consensus and their estimated respective strengths, as follows: PcS for ‘Strong’, PcW for ‘Weak’( PcS being 30-fold stronger than PcW), PcH1 for Hybrid 1 and PcH2 for Hybrid 2, these two latter Pc variants containing the −35 and −10 hexamers of PcW and PcS in opposite combinations( Table 1), and having intermediate strengths[11]–[13]. More recently, a new variant was reported to be significantly stronger than PcS[14], and we therefore named it ‘Super-Strong’ or PcSS. Three other Pc variants have been described but their strength has not been determined; for simplicity, we named these Pc promoters PcIn42, PcIn116 and PcPUO, as they are carried by integrons In42 and In116 and by plasmid pUO901, respectively[15]–[17]. Nesvera and co-workers found a C to G mutation 2 bp upstream of the −10 hexamer in PcW and showed that this mutation increased promoter efficiency by a factor of 5[18]. This mutation creates a ‘TGN’ extended −10 motif that is known to increase the transcription efficiency of σ70 promoters in E. coli[19]. Also, class 1 integrons occasionally harbor a second functional promoter named P2, located in the attI site and created by the insertion of three G residues, optimizing the spacing( 17 bp) between potential −35 and −10 hexamer sequences[9]( Figure 1). Given the diversity of Pc variants and the range of their respective strengths, an identical array of gene cassettes should be differently expressed depending on the Pc variant present in the integron platform. However, the distribution of Pc variants among the numerous class 1 integrons has never been comprehensively studied. In class 1 MRIs, the Pc promoter is located within the integrase coding sequence( Figure 1). Some of the base substitutions in the −35 and/or −10 hexamer sequences defining the different Pc variants actually correlate with amino acid changes in the IntI1 sequence. These variations in the IntI1 protein sequence could potentially influence integrase recombination activity and define different IntI1 catalytic variants. We first performed an extensive in silico examination of all class 1 integron sequences available in databases in order to determine the prevalence of Pc variants and, therefore, the prevalence of IntI1 variants. We then estimated the strength of all Pc variants and Pc-P2 combinations in the same reporter gene assay, as well as the excision and integration activity of the main IntI1 variants. We found a very unequal distribution of the Pc variants, and a negative correlation between the strength of the Pc variant and the recombination efficiency of the corresponding IntI1 protein.Discussion:In this study we found marked polymorphism of the gene cassette promoter Pc( 13 variants), corresponding to ten variants of the class 1 integrase IntI1. The 13 Pc variants were defined on the basis of the −35 and −10 hexamers and the sequence upstream of the −10 box. Indeed almost 20% of the 321 integrons analyzed here harbored a TGN-10 motif that characterized an extended −10 promoter. This feature was mainly associated with the weak PcW variant( 41. 8% of PcW-containing integrons) and increased the efficiency of this promoter by a factor of 15. In view of its frequency and its strength difference relative to PcW, we propose that this promoter, designated PcWTGN-10, be considered as a Pc variant distinct from PcW. Furthermore, 9% of the 321 integrons contained the P2 promoter, which was almost exclusively associated with the PcW variant( 17. 2% of PcW-containing integrons, Table 2). As in previous studies, we found that transcriptional activity was mainly driven by P2 in the PcW-P2 combination[9],[11]. We also observed the same effect with PcH1. Altogether, there are no fewer than 20 distinct gene cassette promoter configurations for class 1 integrons, but their frequencies are very different. Five main combinations emerged from the dataset, defining five levels of promoter strength. The distribution and strength of the gene cassette promoters were as follows: PcW-P2<PcW≈PcWTGN-10<PcS≈PcH1( distribution, Table 2) and PcW<PcH1<PcW-P2<PcWTGN-10<PcS( respectively 4. 5-, 7-, 15- and 25-fold more active than PcW; Figure 1 and Figure 2). The multiplicity of gene-cassette promoters displaying different strengths indicates that a given antibiotic resistance gene cassette will be differently expressed depending on which Pc variant is present in the integron. For example, we used an E. coli strain containing a class 1 integron with PcW, PcS or PcWTGN-10, and with aac( 6′)-Ib as the first cassette. The tobramycin MIC was 8-fold higher when the cassette was expressed from PcS or PcWTGN-10 than from PcW( data not shown). Our findings indicate that, in class 1 integrons, gene cassette expression is mainly controlled by the strongest Pc variants( PcS, PcH2, PcWTGN-10 and PcW-P2, in 55% of cases). Another important and previously unnoticed feature of class 1 integrons is the variability of the IntI1 primary sequence linked to the diversity of Pc variants. Among the 10 IntI1 variants identified, three( IntI1R32_H39, IntI1R32_N39 and IntI1P32_H39) accounted for almost 96% of class 1 integrases( Table 3). We found that these three main IntI1s displayed similar integration efficiencies, independently of the attC sites tested, whereas they had extremely different excision activities, depending on the nature of the amino acid at position 32 and/or 39. The R32P and H39N substitutions each drastically reduced the capacity of the integrase to promote recombination between the attCaadA7 and attCVCR sites( by 336- and 51-fold, respectively). In the integrase of the Vibrio cholerae chromosomal integron VchIntIA, the aa found at the position equivalent to residue 32 is basic, while the aa at position equivalent to residue 39 is a histidine( K21 and H28, respectively[24]), showing that, among IntI1 variants, IntI1R32_H39 is its closest relative. The crystal structure of VchIntIA bound to an attC substrate showed that these amino acids are located within an α-helix involved in attC binding[26]. This α-helix is conserved in the predicted structure of IntI1 and presumably plays the same role in recombination[24]. Thus, mutations of aa 32 and 39 in IntI1 might perturb the binding and thus undermine the recombination efficiency of attC×attC. The positively charged aa R32 may also play a role in the interaction with the attC site in the attI×attC recombination reaction. Indeed, a R32P substitution in both IntI1*R32_H39 and IntI1*R32_N39 reduced the integration frequency, but to a lesser extent than in an excision reaction( Table 3 and Figure 3). In contrast, aa H39 does not seem to be involved in the integration reaction. The attI×attC and attC×attC recombination reactions may thus involve different regions of the integrase. Indeed, Demarre and collaborators isolated two IntI1R32_H39 mutants, IntI1P109L and IntI1D161G, that showed much higher integration efficiencies[24]. Interestingly, we found a correlation between Pc strength and integrase excision activity: the weaker the Pc variant, the more active the IntI1. Among the four integrases tested, IntI1R32_H39, which was the most prevalent IntI1 in our dataset( Table 3), had the most efficient excision activity and also displayed higher excision than integration activity. Integrons with this integrase contain either the PcW variant, leading to a weak expression of the gene cassette array, or the PcH1 variant, associated with slightly higher expression( 4. 5-fold). PcW-containing integrons could compensate for a low level of antibiotic resistance expression by the high excision efficiency of IntI1R32_H39, which confers a marked capacity for cassette rearrangement, in order to place the required gene cassette closer to Pc. In a recent study, Gillings et al suggested that chromosomal class 1 integrons from environmental β-proteobacteria might be ancestors of current clinical class 1 integrons[27]. The integrons they described all encoded IntI1R32_H39 and contained the PcW variant. We suspect that, under antibiotic selective pressure, these “ancestor” integrons may have evolved to enhance gene cassette expression, without modifying the potential for cassette reorganization, either through a single mutation( conversion of PcW to PcH1) or by the creation of a second promoter, P2, that is seven times more active. The high frequency of PcH1( 27. 3%) likely reflects its successful selection. P2 probably arises less frequently, as it requires the insertion of three G. We have recently shown that the expression of IntI1 is regulated via the SOS response, a LexA binding site overlapping its promoter[22]. Interestingly, when P2 is created, the insertion of three G disrupts the LexA binding site, probably leading to constitutive expression of IntI1. In a context of stronger antibiotic selective pressure, the need to express gene cassettes more efficiently could have led to the selection of more efficient Pc sequences( such as PcS and PcWTGN-10) at the expense of IntI1 excision activity, resulting in the stabilization of successful cassette arrays. This hypothesis is consistent with the observation that integrons bearing IntI1R32_N39 or IntI1P32_H39 tend to harbor larger gene cassette arrays than those bearing IntI1R32_H39( Figure S2). The tight relationship between the aptitude of class 1 integrons to recombine and to express gene cassettes may be one key to understanding short-term integrase evolution. Different antibiotic selective pressures might select different evolutionary compromises. Thus, integron-driven drug resistance is more complex than previously thought.","answer":"Integrons are widespread bacterial genetic elements able to capture and express gene cassettes that often encode antibiotic resistance determinants . Gene cassettes are usually promoterless and are transcribed from a common promoter , Pc . Pc is located within the coding sequence of the integron integrase , IntI , which is the key element catalyzing the integration and excision of gene cassettes . Several Pc variants , associated with different integrase amino acid sequences , have been described , but the influence of these differences on integrase activity has never been investigated . Here , we show that Pc is highly polymorphic , conferring a wide range of antibiotic resistance . Furthermore , we found that different Pc variants are associated with different integrase excision activities: the weaker the Pc variant , the more active the integrase . These results point to evolutionary compromises between the expression and mobility of drug resistance determinants located on integrons ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Role of telomeres in vascular senescence.Telomeres are DNA regions composed of TTAGGG repeats that are located at the ends of chromosomes. Specific proteins associate with the telomeres and form non-nucleosomal DNA-protein complexes that serve as protective caps for the chromosome ends. There is accumulating evidence that progressive telomere shortening is closely related to cardiovascular disease. For example, vascular cell senescence has been reported to occur in human atherosclerotic lesions and this change is associated with telomere shortening. Impairment of telomere integrity causes vascular dysfunction, which is prevented by the activation of telomerase. Mice with short telomeres develop hypertension and exhibit impaired neovascularization. Short telomeres have also been reported in the leukocytes of patients with cardiovascular disease or various cardiovascular risk factors. Although it remains unclear whether short telomeres directly cause cardiovascular disease, manipulation of telomere function is potentially an attractive strategy for the treatment of vascular senescence.","answer":"{\\"AnatomicalEntity\\": [\\"leukocytes\\", \\"chromosome\\", \\"Telomeres\\", \\"telomere\\", \\"vascular\\", \\"chromosomes\\", \\"cardiovascular\\", \\"atherosclerotic lesions\\", \\"telomeres\\", \\"vascular cell\\"]}"},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Brown Adipose Tissue in Morbidly Obese SubjectsAbstract 1:Background Cold-stimulated adaptive thermogenesis in brown adipose tissue ( BAT ) to increase energy expenditure is suggested as a possible therapeutic target for the treatment of obesity . We have recently shown high prevalence of BAT in adult humans , which was inversely related to body mass index ( BMI ) and body fat percentage ( BF% ) , suggesting that obesity is associated with lower BAT activity . Here , we examined BAT activity in morbidly obese subjects and its role in cold-induced thermogenesis ( CIT ) after applying a personalized cooling protocol . We hypothesize that morbidly obese subjects show reduced BAT activity upon cold exposure . Methods and Findings After applying a personalized cooling protocol for maximal non-shivering conditions , BAT activity was determined using positron-emission tomography and computed tomography ( PET-CT ) .  Cold-induced BAT activity  was detected in three out of 15 morbidly obese subjects . Combined with results from lean to morbidly obese subjects ( n = 39 ) from previous study , the collective data show a highly significant correlation between BAT activity and body composition ( P<0.001 ) , respectively explaining 64 % and 60 % of the variance in BMI ( r = 0.8 ; P<0.001 ) and BF% ( r = 0.75 ; P<0.001 ) . Obese individuals demonstrate a blunted CIT combined with low BAT activity . Only in BAT-positive subjects ( n = 26 ) mean energy expenditure was increased significantly upon cold exposure ( 51.5±6.7 J/s versus 44.0±5.1 J/s , P = 0.001 ) , and the increase was significantly higher compared to BAT-negative subjects ( + 15.5±8.9 % versus + 3.6±8.9 % , P = 0.001 ) , indicating a role for BAT in CIT in humans . Conclusions This study shows that in an extremely large range of body compositions , BAT activity is highly correlated with BMI and BF% . BAT-positive subjects showed higher CIT , indicating that BAT is also in humans involved in adaptive thermogenesis . Increasing BAT activity could be a therapeutic target in ( morbid ) obesityTitle 2:Housing-related activity in rats: effects on body weight, urinary corticosterone levels, muscle properties and performanceAbstract 2:The cage systems commonly used for housing laboratory rats often result in sedentary and overweight animals , as a consequence of restricted opportunities for physical activity combined with ad libitum feeding . This can have implication s both for animal well-being and for the experimental outcome . Physical activity has several known positive effects on health and lifespan , and physical fitness might therefore be incorporated into the animal welfare concept . The aim of this study was to investigate if and how pen housing affects the physical activity and fitness of rats . Thirty-two juvenile male Sprague-Dawley rats were r and omly assigned to two different housing systems for a 4-week period . Sixteen rats were kept individually in st and ard Makrolon type III cages ( 42 × 26 × 18 cm ) furnished with black plastic tubes ( singly-housed , SI ) . The remaining rats were kept in groups of eight , housed in large floor pens ( 150 × 210 cm ) , which were furnished with various objects to increase environmental complexity ( pen-housed , PH ) . The body weight gain , and food and water intake of the rats were measured . During weeks 3 or 4 , home cage behaviour , urinary cortiosterone/creatinine ratios ( CO/CR ) , and muscle strength on an inclined plane , were measured . Enzyme activities and glycogen content were measured in tissue sample s from m. triceps brachii taken after euthanization at the end of the study . There were no significant differences between groups for food and water intake , but PH rats weighed 14 % less than SI rats after 4 weeks , and PH rats also had a more diverse behavioural pattern than SI rats . PH rats had significantly higher oxidative capacity ( 28 % more citrate synthase ( CS ) ) and greater glycogen content ( 28 % ) in their muscle sample s than SI rats . The PH rats performed significantly better on the inclined plane , both in the muscle strength test ( mean angle 75 ± 0.5 ° for PH rats and 69 ± 0.4 ° for SI rats ) and the endurance strength test ( mean time 233 ± 22 s for PH rats and 73 ± 14 s for SI rats ) . There was a negative correlation between body weight and results on the inclined plane for the PH rats . There were no significant differences between housing types with respect to CO/CR ratios . In conclusion , the large pen represents an environment that stimulates physical activity and more varied behaviour , which should be beneficial for the welfare of the animalTitle 3:Impact of environmental enrichment in mice. 1: Effect of housing conditions on body weight, organ weights and haematology in different strainsAbstract 3:Currently , environmental enrichment is a very common means of improving animal well-being , especially for laboratory animals . Although environmental enrichment seems to be a possible way for improving the well-being of animals , the consideration of housing laboratory animals should not only focus solely on animal well-being , manpower and economics but also on the precision and accuracy of the experimental results . The purpose of the present study was to evaluate the effects of enriched cages ( nest box , nesting material , climbing bar ) on body weight , haematological data and final organ weights .  BALB/c , C57BL/6 and A/J mice , originated from Harlan Winkelmann , were used for the experiments - 16 animals of each strain . Animals at 3 weeks of age were marked and separated r and omly to enriched or non-enriched cages , in groups of four , half for each housing condition . Both cages were type III Makrolon cages , only the enriched cages contained a nest box , a wood bar for climbing and nesting material . Animals were kept in a clean animal room under specific pathogen free ( SPF ) conditions . Body weights were recorded every week . Blood sample s were collected at 14 weeks of age ( white blood cells ( WBC ) , red blood cells ( RBC ) , haemoglobin ( HGB ) , and haematocrit ( HCT ) were analysed ) . At 15 weeks of age , the animals were euthanized by CO2 in their home cages , and final body weight and organ weights ( heart , liver , kidney , adrenal , spleen and uterus ) were recorded immediately . Although nearly all the test variables were not affected by environmental enrichment in their mean values , the enriched group showed higher coefficients of variation in many variables , and strain differences of both housing conditions were not consistent . The influences of enrichment were shown to be strain- and test-dependent . Such effects may lead to an increase in the number of animals which is necessary or may change the experimental results , especially when a study , using enriched housing conditions , focuses on strain differences . Since the same enrichment design can result in different influences , a positive or a negative or no adverse effect , due to the strain and the variables studied , research ers need to collect more information before enrichment design s are introduced into experimental plansTitle 4:Housing conditions influence the survival and body composition of ageing ratsAbstract 4:Ad libitum fed male Sprague-Dawley rats were r and omly assigned to be housed individually ( n=32 ) or four in each cage ( n=32 ) from five to 23 months of age .  Body weight and body composition by bioimpedance analysis were monitored longitudinally . An equation for analysis of body composition was developed . Deaths and causes of death were recorded . Of the individually housed animals ( H1 ) 16 percent died , while 44 percent of those housed four in a cage ( H4 ) died , the most common causes of death being circulatory failure , nephritis and tumours of the hypophysis . Body weight increased in both groups over time , significantly more for H4 from 6months of age . Both fat free mass and total body fat increased in both groups over time . Fat in percent of body weight increased up to an age of 14months . H4 animals had significantly more fat from 11 to 20 months of age but lost weight , mostly fat when approaching 23months of age . The occiput-sacrum length of the animals increased up to 11months of age and stayed then constant . Animals in both groups grew also in the cross-sectional dimension . The H1 animals continued to grow all the time , while the growth of the H4 animals stopped at the age of 17 months , when the mortality started to become pronounced . It is concluded that housing conditions can modulate the outcome of the ageing of sedentary and otherwise not treated rats in long-term experiments . Further , the feasibility of monitoring body composition longitudinally with bioimpedance analysis was demonstratedTitle 5:Glucocorticoids decrease body weight and food intake and inhibit appetite regulatory peptide expression in the hypothalamus of rats.Abstract 5:The aim of the present study was to investigate the effects of glucocorticoids ( GCs ) on appetite and gene expression of the hypothalamic appetite regulatory peptides , neuropeptide Y ( NPY ) , agouti-related protein ( AGRP ) and cocaine and amphetamine-regulated transcript ( CART ) , in non-obese and obese rats . Both non-obese and obese rats were r and omly assigned to three groups : normal saline , low- and high-dose GC groups ( NSG , LDG and HDG , respectively ) , which received an intraperitoneal injection with normal saline ( 0.2 ml/100 g ) or hydrocortisone sodium succinate at 5 and 15 mg/kg , respectively , for 20 days . The expression levels of NPY , AGRP and CART mRNA in the hypothalamus were measured by real-time quantitative PCR . Non-obese and obese rats were found to undergo weight loss after GC injection , and a higher degree of weight loss was observed in the HDG rats . The average and cumulative food intakes in the obese and non-obese rats injected with high-dose GC were lower compared to that in the NSG ( p<0.05 ) . mRNA expression levels of the orexigenic neuropeptides , NPY and AGRP , and the anorexigenic neuropeptide , CART , were significantly lower in the HDG than levels in the NSG for both the obese and non-obese rats ( p<0.05 ) . GC treatment decreased appetite and body weight , induced apparent glucolipid metabolic disturbances and hyperinsulinemia , while down-regulated mRNA expression levels of the orexigenic neuropeptides , NPY and AGRP , and anorexigenic neuropeptide , CART , in the hypothalamus in the rats . The mechanism which induces this neuropeptide expression requires further studyTitle 6:SYRCLE’s risk of bias tool for animal studiesAbstract 6:Background Systematic Review s ( SRs ) of experimental animal studies are not yet common practice , but awareness of the merits of conducting such SRs is steadily increasing . As animal intervention studies differ from r and omized clinical trials ( RCT ) in many aspects , the methodology for SRs of clinical trials needs to be adapted and optimized for animal intervention studies . The Cochrane Collaboration developed a Risk of Bias ( RoB ) tool to establish consistency and avoid discrepancies in assessing the method ological quality of RCTs . A similar initiative is warranted in the field of animal experimentation . Methods We provide an RoB tool for animal intervention studies ( SYRCLE ’s RoB tool ) . This tool is based on the Cochrane RoB tool and has been adjusted for aspects of bias that play a specific role in animal intervention studies . To enhance transparency and applicability , we formulated signalling questions to facilitate judgment . Results The result ing RoB tool  for animal studies contains 10 entries . These entries are related to selection bias , performance bias , detection bias , attrition bias , reporting bias and other biases . Half these items are in agreement with the items in the Cochrane RoB tool . Most of the variations between the two tools are due to differences in design between RCTs and animal studies . Shortcomings in , or unfamiliarity with , specific aspects of experimental design of animal studies compared to clinical studies also play a role . Conclusions SYRCLE ’s RoB tool is an adapted version of the Cochrane RoB tool . Widespread adoption and implementation of this tool will facilitate and improve critical appraisal of evidence from animal studies . This may subsequently enhance the efficiency of translating animal research into clinical practice and increase awareness of the necessity of improving the method ological quality of animal studies","answer":"Whilst housing did not affect body weight , both food intake and visceral adipose tissue mass were significantly higher in individually compared with socially housed animals .A combination of emotional stress and lack of social thermoregulation likely contributed to these effects ."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Hospitalised children aged 3-mo to 5-yrs (in Darwin, children have to be Indigenous)Have features of severe pneumonia on admission (temperature >37.5 celsius or a history of fever at home or observed at the referring clinic, age-adjusted tachypnoea [respiratory rate>50 if <12-months; respiratory rate>40 if >12-months] with chest wall recession and/or oxygen saturation <92% in air), and consolidation on chest X-ray as diagnosed by treating clinicianAfter 1-3 days of IV antibiotics, are afebrile, with improved respiratory symptoms and signs, oxygen saturation>90% in air and are ready to be switched to oral amoxicillin-clavulanate, andHave symptoms of no longer than 7 days at point of hospitalisation.","answer":"{\\"Condition\\": [\\"chest wall recession\\", \\"consolidation\\", \\"tachypnoea\\", \\"pneumonia\\", \\"symptoms\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [\\"temperature\\", \\"oxygen saturation\\", \\"respiratory rate\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [\\"children\\", \\"age\\", \\"aged\\"], \\"Procedure\\": [\\"chest X-ray\\"], \\"Qualifier\\": [\\"severe\\"], \\"ReferencePoint\\": [\\"hospitalisation\\"], \\"Scope\\": [\\"chest wall recession and/or oxygen saturation u003c92% in air\\", \\"temperature u003e37.5 celsius or a history of fever at home or observed at the referring clinic, age-adjusted tachypnoea [respiratory rateu003e50 if u003c12-months; respiratory rateu003e40 if u003e12-months] with chest wall recession and/or oxygen saturation u003c92% in air\\"], \\"Temporal\\": [\\"no longer than 7 days at point of hospitalisation\\"], \\"Value\\": [\\"u003c12-months\\", \\"u003e50\\", \\"u003e40\\", \\"3-mo to 5-yrs\\", \\"u003e37.5 celsius\\", \\"u003e12-months\\", \\"u003c92% in air\\"], \\"Visit\\": [\\"Hospitalised\\"]}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Effectiveness of massage, sucrose solution, herbal tea or hydrolysed formula in the treatment of infantile colic.Abstract 1:The aim of the study was to evaluate the effectiveness of massage, sucrose solution, herbal tea or hydrolysed formula, each used individually in the treatment of infantile colic.                The term colic describes a group of symptoms that occur frequently in infants, consisting of paroxysmal abdominal pain and severe crying. Infant colic is of importance for both parents and the community health services that provide families with care, and is therefore an important clinical problem that is amenable to nursing interventions.                This prospective and randomised-controlled study involved 175 infants in Turkey.                Data were gathered by using Wessel criteria; parents wrote a daily structured diary, recording the onset and duration of crying. Patients were assigned randomly into four different intervention groups (massage, sucrose solution, herbal tea and hydrolysed formula) and control group. Duration of crying following each intervention was recorded in the diary by parents for a one week period.                There was a significant reduction in crying hours per day in all intervention groups. The difference between mean duration of total crying (hours/day) before and after the intervention infants in hydrolysed formula group was found higher than massage, sucrose and herbal tea group. The difference between mean duration of total crying(hours/day) before and after the intervention infants in massage group was found lower than other intervention groups and all groups.                Our findings demonstrated that varied interventions such as administration of massage, sucrose solution, herbal tea and hydrolysed formula are effective in the treatment of colic. The difference between mean duration of total crying (hours/day) before and after the intervention in hydrolysed formula group was found higher than other intervention groups. Hydrolysed formula was the most effective in reducing the duration of crying (hours/day) when compared with the other intervention groups. Massage intervention yielded the least symptomatic improvement among all the interventions.                Colic treatment models used in this study can be used by nurses in neonatal and primary healthcare settings as an aid to families for the treatment of infantile colic.Title 2:Infant massage improves mother-infant interaction for mothers with postnatal depression.Abstract 2:Postnatal depression can have long term adverse consequences for the mother-infant relationship and the infant's development. Improving a mother's depression per se has been found to have little impact on mother-infant interaction. The aims of this study were to determine whether attending regular massage classes could reduce maternal depression and also improve the quality of mother-infant interaction.                Thirty-four primiparous depressed mothers, median 9 weeks postpartum, identified as being depressed following completion of the Edinburgh Postnatal Depression Scale (EPDS) at 4 weeks postpartum, were randomly allocated either to an infant massage class and a support group (massage group) or to a support group (control group). Each group attended for five weekly sessions. Changes in maternal depression and mother-infant interaction were assessed at the beginning and the end of the study by comparing EPDS scores and ratings of videotaped mother-infant interaction.                The EPDS scores fell in both groups. Significant improvement of mother-infant interaction was seen only in the massage group.                The sample size was small and had relatively high dropout. It was not possible to distinguish which aspects of the infant massage class contributed to the benefit.                This study suggests that learning the practice of infant massage by mothers is an effective treatment for facilitating mother-infant interaction in mothers with postnatal depression.Title 3:Massage therapy by mothers enhances the adjustment of circadian rhythms to the nocturnal period in full-term infants.Abstract 3:The objective of this study was to investigate the effect of massage therapy on phase adjustment of rest-activity and melatonin secretion rhythms to the nocturnal period in full-term infants. Rest-activity cycles of infants (measurement 1, n = 16) were measured by actigraphy before and after 14 days of massage therapy (starting at age 10 [+/-4] d) and subsequently at 6 and 8 weeks of age. 6-Sulphatoxymelatonin excretion was assessed in urine samples at 6, 8, and 12 weeks of age (measurement 2, n = 21). At 8 weeks the controls revealed one peak of activity at approximately 12 midnight (11 p.m.-3 a.m.) and another one at approximately 12 noon (11 a.m.-3 p.m.), whereas in the treated group, a major peak was early in the morning (3 a.m.-7 a.m.) and a secondary peak in the late afternoon (3 p.m.-7 p.m.). At 12 weeks, nocturnal 6-sulphatoxymelatonin excretions were significantly higher in the treated infants (1346.38 +/- 209.40 microg/night vs 823.25 +/- 121.25 microg/night, respectively; <.05). It is concluded that massage therapy by mothers in the perinatal period serves as a strong time cue, enhancing coordination of the developing circadian system with environmental cues.Title 4:Developmental and temperament outcomes of sensory stimulation in healthy infants.Abstract 4:Eighty-one healthy, full-term infants were randomly assigned to a control group or one of three experimental conditions: daily administration of a cephalocaudal stroking procedure; placement on a multisensory hammock that provided auditory, vestibular, and tactile stimulation during expected sleep cycles; and a combination of the prior two treatments. All interventions were given during the first 3 months of life. Infants in the control group received the natural stimulation provided in their home environments without additional supplementation. Four- and 8-month assessments were done using the Bayley Scales of Infant Development and the Revised Infant Temperament Questionnaire. There were no significant treatment effects on weight or psychomotor development. Although infants receiving unimodal stimulation obtained lower 8-month cognitive development scores than infants in other experimental and control groups, their scores were within normal range. Control group infants achieved the most optimum mood and distractibility scores at both 4 and 8 months.Title 5:Postnatal depression and mother and infant outcomes after infant massage.Abstract 5:Postnatal depression can be a long lasting condition which affects both the mother and her baby. A pilot study indicated that attending baby massage improved maternal depression and mother-infant interactions. The current study further investigates any benefits of baby massage for mothers with postnatal depression and their infants.                Mothers scoring (3)13 on the Edinburgh Postnatal Depression Scale (EPDS) at 4 weeks postpartum were randomly assigned to attend baby massage classes (n=31) or a support group (n=31). They completed depression, anxiety and Infant Characteristics Questionnaires and were filmed interacting with their infants before and after 6 intervention sessions, and at one year. Thirty four non-depressed mothers also completed the study.                More of the massage than support group mothers showed a clinical reduction in EPDS scores between four weeks and outcome (p<0.05). At one year, massage-group mothers had non-depressed levels of sensitivity of interaction with their babies, whereas the support group did not. There were no other differences in either mother or child between the two intervention groups. Depressed mothers did not achieve control depression or anxiety scores at one year.                For ethical reasons, the study did not include a control group of depressed mothers who did not receive an intervention.                Both intervention groups showed reductions in depression scores across the study period, but the massage group did better on some indices. They also had somewhat better interactions with their infants at one year, but these effects were limited.Title 6:[Effect of infantile touching on behavior development in infants].Abstract 6:nanTitle 7:[Effects of touch on growth and mentality development in normal infants].Abstract 7:To determine the effects of conducting Touch to infants upon their growth and mental development, sleeping and disease conditions, as well as the difference of effects of conducting Touch among infants of different month age.                310 normal full-term infants aged 0-6 months were divided randomly into Touch group (n = 208) and control group (n = 102). Parents of Touch group were asked to conduct Touch to their infants 2-3 times/day, lasting 15-20 minutes every time, for at least 3 months. Intelligence tests were performed to infants of both groups at the beginning of the experiment and 6 months later (CDCC measurement table was employed). Data such as height, weight, circumferences of head and chest, sleeping, feeding and disease conditions etc. were recorded each month in a successive period of 6 months. Statistical analysis was conducted using SPSS 10.0.                (1) The average score of mental development (MDI) was 7.4 higher, with a statistically significant difference, among the infants who began to receive touch within 3 months after birth than those infants with the same age in control group. The average score of psychomotor development index (PDI) was 5.8 higher, with a statistically significant difference, among the infants who began to receive touch within 3 months after birth than those infants with the same age in control group. Infants who began to receive touch within 3 months after birth slept remarkably better than those in control group did. No significant difference was found in scores of MDI and PDI and sleeping condition between infants who began to receive touch 3 months after birth and the infants with the same age in the control group. (2) Weight gain and growth in chest circumference in infants receiving touch within one month after birth were significantly better compared with the infants of the same age in the control group. There was no significant difference in values of height and head circumference between the two groups. There was no significant difference in values of height and head circumference between the two groups. (3) No significant difference in the incidence rates of acute respiratory infection and diarrhea disease was found between the touch group and control group.                (1) Growth and mental development of infants can be improved by touch. Tthe earlier to conduct touch the better the effects. (2) Touch helps improve sleeping condition in infants.Title 8:Salivary cortisol and behavioral state responses of healthy newborn infants to tactile-only and multisensory interventions.Abstract 8:To compare changes in stress reactivity (measured via the biomarker salivary cortisol) and behavioral state in healthy newborn infants immediately following 1 of 2 interventions: (1) tactile-only stimulation or (2) a multisensory, auditory, tactile, visual, and vestibular stimulation with a control group.                A randomized prospective design pilot study.                Normal newborn nurseries of 2 midwestern perinatal centers.                Forty healthy newborn infants receiving standard nursing care.                Infants were randomly assigned to receive 15 minutes of tactile-only, auditory, tactile, visual, and vestibular, or no stimulation 30 minutes before feeding. Saliva samples were collected before, immediately following, and 10 minutes postintervention. Behavioral state was judged every minute.                Tactile-only group infants had the largest increase in cortisol levels, followed by control group infants. In contrast, infants who received the multisensory intervention showed a significant steady decline in cortisol. Asleep was the predominant state for all 3 groups and cry was minimal.                Tactile-only stimulation may increase infant stress reactivity while the benefit of the multisensory auditory, tactile, visual, and vestibular intervention may be in the reduction of infant stress reactivity. Interventions appeared to have minimal effect on stress reactivity based on behavioral state.","answer":"These findings do not currently support the use of infant massage with low-risk groups of parents and infants. Available evidence is of poor quality, and many studies do not address the biological plausibility of the outcomes being measured, or the mechanisms by which change might be achieved. Future research should focus on the impact of infant massage in higher-risk groups (for example, demographically and socially deprived parent-infant dyads), where there may be more potential for change."},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:related workContext before the citation:In other methods, lexical resources are specifically tailored to meet the requirements of the domain (Rosario and Hearst, 2001) or the system (Gomez, 1998). Some methods of semantic relation analysis rely on predefined templates filled with information from processed texts (Baker et al., 1998).Citation Sentence:In other methods , lexical resources are specifically tailored to meet the requirements of the domain ( Rosario and Hearst , 2001 ) or the system ( Gomez , 1998 ) .Context after the citation:Such systems extract information from some types of syntactic units (clauses in (Fillmore and Atkins, 1998; Gildea and Jurafsky, 2002; Hull and Gomez, 1996); noun phrases in (Hull and Gomez, 1996; Rosario et al., 2002)). Lists of semantic relations are designed to capture salient domain information. In the Rapid Knowledge Formation Project (RKF) a support system was developed for domain experts. It helps them build complex knowledge bases by combining components: events, entities and modifiers (Clark and Porter, 1997).","answer":"Background"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Runs of Homozygosity Implicate Autozygosity as a Schizophrenia Risk Factor}Article:Abstract:Autozygosity occurs when two chromosomal segments that are identical from a common ancestor are inherited from each parent. This occurs at high rates in the offspring of mates who are closely related( inbreeding), but also occurs at lower levels among the offspring of distantly related mates. Here, we use runs of homozygosity in genome-wide SNP data to estimate the proportion of the autosome that exists in autozygous tracts in 9, 388 cases with schizophrenia and 12, 456 controls. We estimate that the odds of schizophrenia increase by ∼17% for every 1% increase in genome-wide autozygosity. This association is not due to one or a few regions, but results from many autozygous segments spread throughout the genome, and is consistent with a role for multiple recessive or partially recessive alleles in the etiology of schizophrenia. Such a bias towards recessivity suggests that alleles that increase the risk of schizophrenia have been selected against over evolutionary time.Introduction:Schizophrenia is a highly(. 70–. 80) heritable[1] neurodevelopmental disorder that has a lifetime prevalence of ∼0. 4%[2]. As with most complex disorders, the specific genetic variants that account for a majority of the heritability of schizophrenia remain to be discovered. Two primary factors may explain the difficulty in identifying risk variants. First, the results of genome-wide association studies( GWAS) make it clear that a very large number of genes contribute to schizophrenia risk, and the overall population risk attributable to any one risk variant must be small[3]. Second, although common causal variants almost certainly play an important role in the genetic etiology of schizophrenia[4],[5], it is likely that the frequency distribution of schizophrenia risk alleles is biased towards the rare end of the spectrum[5]. Both of these factors are consistent with selection keeping schizophrenia risk alleles with the largest effects rare, such that no single allele can contribute much to population risk. If schizophrenia risk alleles have been selected against across evolutionary time( have been under “purifying” selection), another prediction is that schizophrenia risk alleles will be biased towards being recessive. This bias, called directional dominance, occurs in traits subject to purifying selection because selection more efficiently purges the additive and dominant alleles with the strongest effects, leaving the remaining pool of segregating alleles more recessive than otherwise expected[6]. Directional dominance has traditionally been inferred from observations of inbreeding depression, the tendency for offspring of close genetic relatives to have higher rates of congenital disorders and lower fitness[7]. Fitness traits such as survival, reproduction, resistance to disease, and predator avoidance tend to show more inbreeding depression than traits under less intense selection[8]. Interestingly, there are numerous reports of inbreeding effects on human complex traits such as heart disease[9], hypertension[10], osteoporosis[11], cancer[12], and IQ[13],[14]. Studies that have investigated inbreeding effects on schizophrenia using pedigree data suggest that close( e. g., cousin-cousin) inbreeding is a risk factor[15],[16],[17],[18],[19],[20], although three studies have failed to find the predicted effect[21],[22],[23]. However, close inbreeding cannot be a major contributor to schizophrenia risk in industrialized countries given its rarity( <1% of marriages)[24] and the modest increase in the odds of schizophrenia among highly inbred offspring( ∼2- to 5-fold)[15],[16],[17],[18],[19]. Nevertheless, inbreeding is a matter of degree; when distant relatives are considered, everyone is inbred to some degree. It is likely that the parents of the vast majority of people alive today share a common ancestor within ∼15 generations[25]. Although such “distant” inbreeding would be prohibitively difficult to detect from pedigrees, it can leave signals in the genome that are detectable using genome-wide single nucleotide polymorphism( SNP) data. The inbreeding coefficient of an individual, F, is defined as the probability that two randomly chosen alleles at a homologous locus within an individual are identical by descent( IBD, identical because they are inherited from a common ancestor)[26]. Homozygosity arising from the inheritance of two IBD genomic segments is termed autozygosity. Most estimates of F assume that marker data are independent, and provide an aggregate measure of homozygosity at measured variants across the genome[27]. Recently, however, several investigators have used runs of homozygosity( ROHs; long stretches of homozygous SNPs) to infer autozygososity, and have investigated whether the proportion of the genome that exists in such ROHs, Froh, predicts complex traits[28],[29],[30],[31],[32],[33],[34],[35]. Of several alternative estimates of F, including F estimated by treating markers independently and F estimated from pedigree information, Keller, Visscher, and Goddard[25] recently concluded that Froh is optimal for inferring the degree of genome-wide autozygosity and for detecting inbreeding effects. However, given the small variation in genome-wide Froh in unselected samples( e. g., SD ∼. 005), large sample sizes( e. g., >12, 000) are necessary to detect inbreeding depression for likely effect sizes in samples not selected for recent inbreeding[25]. Studies investigating the effects of Froh on human complex traits with samples sizes <3, 000 and that failed to find significant inbreeding effects[28],[33],[34],[35],[36] are likely to have been underpowered. That said, the only study of Froh in schizophrenia[29] found a very large inbreeding effect, but the effect was observed in a small sample( n = 322) and was significant only for ROHs caused by common haplotypes. The present study uses imputed SNP data from 17 schizophrenia case-control datasets( total N = 21, 844) that are part of the Psychiatric GWAS Consortium( PGC)[3],[37] to investigate whether Froh is associated with higher risk of schizophrenia. We also use an ROH mapping approach to investigate whether specific areas of the genome are predictive of case-control status when autozygous. This study represents the largest investigation to date on the potential consequences of autozygosity as estimated using Froh, and may help elucidate the genetic architecture and natural history of schizophrenia.Discussion:Inbreeding has had a central place in population genetics since its inception, but until recently, the effects of inbreeding could only be investigated from careful analysis of pedigrees and only for close inbreeding. SNP data allows investigation into the effects of potentially very distant inbreeding in non-selected samples, and allows insight into where the signal comes from in the genome. However, unless samples are specifically selected based on inbreeding, very large samples are required to reliably detect effects of autozygosity due to the low variation between individuals in their levels of autozygosity. The present investigation used SNP data from a large sample to conclude that autozygosity is a risk factor for schizophrenia. If the relationship between Froh and schizophrenia is due to directional dominance, such that schizophrenia risk alleles are more recessive than otherwise expected, this suggests that alleles that increase the risk of schizophrenia have been under negative selection ancestrally.","answer":"Inbreeding occurs when genetic relatives have offspring . Because all humans are related to one another , even if very distantly , all people are inbred to various degrees . From a genetic standpoint , it is well known that inbreeding increases the risk that a child will have a rare recessive genetic disease , but there is also increasing interest in understanding whether inbreeding is a risk factor for more common , complex disorders such as schizophrenia . In this investigation , we used single-nucleotide polymorphism data to quantify the degree to which 9 , 388 schizophrenia cases and 12 , 456 controls were inbred , and we tested the hypothesis that people whose genome shows higher evidence of being inbred are at higher risk of having schizophrenia . We estimate that the odds of schizophrenia increase by ∼17% for every 1% increase in inbreeding . This finding is consistent with a role for multiple recessive or partially recessive alleles in the etiology of schizophrenia , and it suggests that genetic variants that increase the risk of schizophrenia have been selected against over evolutionary time ."},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey of Connection-Chains Detection Techniques Chapter Title:  A. Similarity-Based 1. Abstract of Cited Paper (BIB001):  One widely-used technique by which network attackers attain anonymity and complicate their apprehension is by employing stepping stones: they launch attacks not from their own computer but from intermediary hosts that they previously compromised. We develop an efficient algorithm for detecting stepping stones by monitoring a site's Internet access link. The algorithm is based on the distinctive characteristics (packet size, timing) of interactive traffic, and not on connection contents, and hence can be used to find stepping stones even when the traffic is encrypted. We evaluate the algorithm on large Internet access traces and find that it performs quite well. However, the success of the algorithm is tempered by the discovery that large sites have many users who routinely traverse stepping stones for a variety of legitimate reasons. Hence, stepping-stone detection also requires a significant policy component for separating allowable stepping-stone pairs from surreptitious access. 2. Abstract of Cited Paper (BIB002):  Intruders usually log in through a chain of multiple computer systems to hide their origins before breaking into their targets, which makes tracing difficult. In this paper we present a method to find the connection chain of an intruder for tracing back to the origin. We focus on telnet and rlogin as interactive applications intruders use to log in through hosts. 3. Abstract of Cited Paper (BIB003):  Network based intrusions have become a serious threat to the users of the Internet. Intruders who wish to attack computers attached to the Internet frequently conceal their identity by staging their attacks through intermediate \\"stepping stones\\". This makes tracing the source of the attack substantially more difficult, particularly if the attack traffic is encrypted. In this paper, we address the problem of tracing encrypted connections through stepping stones. The incoming and outgoing connections through a stepping stone must be correlated to accomplish this. We propose a novel correlation scheme based on inter-packet timing characteristics of both encrypted and unencrypted connections. We show that (after some filtering) inter-packet delays (IPDs) of both encrypted and unencrypted, interactive connections are preserved across many router hops and stepping stones. The effectiveness of this method for correlation purposes also requires that timing characteristics be distinctive enough to identify connections. We have found that normal interactive connections such as telnet, SSH and rlogin are almost always distinctive enough to provide correct correlation across stepping stones. The number of packets needed to correctly correlate two connections is also an important metric, and is shown to be quite modest for this method. 4. Abstract of Cited Paper (BIB004):  Network based intruders seldom attack directly from their own hosts, but rather stage their attacks through intermediate \\"stepping stones\\" to conceal their identity and origin. To identify attackers behind stepping stones, it is necessary to be able to correlate connections through stepping stones, even if those connections are encrypted or perturbed by the intruder to prevent traceability.The timing-based approach is the most capable and promising current method for correlating encrypted connections. However, previous timing-based approaches are vulnerable to packet timing perturbations introduced by the attacker at stepping stones. In this paper, we propose a novel watermark-based correlation scheme that is designed specifically to be robust against timing perturbations. The watermark is introduced by slightly adjusting the timing of selected packets of the flow. By utilizing redundancy techniques, we have developed a robust watermark correlation framework that reveals a rather surprising result on the inherent limits of independent and identically distributed (iid) random timing perturbations over sufficiently long flows. We also identify the tradeoffs between timing perturbation characteristics and achievable correlation effectiveness. Experiments show that the new method performs significantly better than existing, passive, timing-based correlation in the presence of random packet timing perturbations. 5. Abstract of Cited Paper (BIB005):  Intruders on the Internet often prefer to launch network intrusions indirectly, i.e., using a chain of hosts on the Internet as relay machines using protocols such as Telnet or SSH. This type of attack is called a stepping-stone attack. In this paper, we propose and analyze algorithms for stepping-stone detection using ideas from Computational Learning Theory and the analysis of random walks. Our results are the first to achieve provable (polynomial) upper bounds on the number of packets needed to confidently detect and identify encrypted stepping-stone streams with proven guarantees on the probability of falsely accusing non-attacking pairs. Moreover, our methods and analysis rely on mild assumptions, especially in comparison to previous work. We also examine the consequences when the attacker inserts chaff into the stepping-stone traffic, and give bounds on the amount of chaff that an attacker would have to send to evade detection. Our results are based on a new approach which can detect correlation of streams at a fine-grained level. Our approach may also apply to more generalized traffic analysis domains, such as anonymous communication. 6. Abstract of Cited Paper (BIB006):  Timing-based active watermarking schemes are developed to trace back attackers through stepping stone connections or anonymizing networks. By slightly changing packet timing, these schemes achieve robust correlation for encrypted network connections under timing perturbation. However, the manipulation on packet timing makes the schemes themselves a potential target of intelligent attackers. In this paper, we analyze the secrecy of the timing-based active watermarking techniques for tracing through stepping stones, and propose an attack scheme based on analyzing the packet delays between adjacent stepping stones. We develop attack techniques to infer important watermark parameters, and to recover and duplicate embedded watermarks. The resulting techniques enable an attacker to defeat the tracing systems in certain cases by removing watermarks from the stepping stone connections, or replicating watermarks in non-stepping stone connections. We also develop techniques to determine in real-time whether a stepping stone connection is being watermarked for trace-back purposes. We have performed substantial experiments using real-world data to evaluate these techniques. The experimental results demonstrate that for the watermark scheme being attacked (1) embedded watermarks can be successfully recovered and duplicated when the watermark parameters are not chosen carefully, and (2) the existence of watermarks in a network flow can always be quickly detected.Literature Review:","answer":"If two connections ci and cj belong to the same connectionchain C, then they are more likely to share some common invariant features. Therefore, one could devise a similarity measure to compare the connections, and flag similar ones as candidates for being part of the same connection-chain. Two classes of similarity measures have been proposed in the literature: content-based measures and timing-based measures. A content-based measure computes similarity by analyzing the packets' contents (payload), whereas the timingbased measure computes similarity by analyzing the packets' timing characteristics. If the connections are not encrypted, then a content-based measure works well. Basically, a character appearing in a given connection is assured to appear later in time in either a downstream or upstream connection of the same connectionchain. A naive measure is to simply perform a brute-force text matching between packets' contents BIB002 . Another simple measure is to trace unique strings, for instance a login greeting message BIB002 . Yet, another simple measure is to compute frequencies of characters traveling through connections BIB001 . In addition to introducing the connection-chain problem, Staniford-Chen and Heberlein are first to propose a contentbased similarity measure, which they referred to as thumbprint BIB001 . In essence, a thumbprint is a real vector that is computed based on frequencies of characters traversing a connection during a specified time period . It serves as a condensed signature that can be used to differentiate ( Zhang et al. proposed a simple yet effective timing-based measure BIB002 . The measure exploits the distinctive ON/OFF patterns observed in interactive traffic. Specifically, observing an interactive connection reveals a pattern of alternating ON and OFF periods. An ON period is when the user is typing on her keyboard, while an OFF period is when she is idle. The authors devised a similarity measure that computes coincident transition from OFF periods to ON periods among a set of connections. Using this measure, connections with similar transitions are correlated. Deviation is another timing-based measure proposed by BIB003 . The measure relies on the following idea. As packets flow through a connection, the total size of transferred bytes tends to increase monotonically in time. Therefore, if two connections belong to the same connection-chain, then their total size of transferred bytes should grow at a similar rate. Obviously, this measure only works if the packet sizes are not altered at the stepping-stones. The authors formally developed this concept and used it to correlate connections. Wang et al. proposed a timing-based measure that correlates connections based on the inter-packet delay (IPD) in forward flows BIB004 . In interactive traffic, IPD is a reflection of the typing dynamics of a user. Hence, the authors propose that they are unique and preserved through a connection-chain. They developed a similarity measure to compute and compare connections' IPDs. Blum et al. proposed a timing-based measure that correlates connections by counting packets observed in a time interval BIB006 . They also showed how many packets are needed to declare whether two connections belong to a connection-chain or not. He and Tong adapted a signal processing approach to detect connection chains  . In this approach, a connection is modeled as a point process  , where the points represent the stream of packets in the given connection. Two connections are part of a connection chain, if their corresponding processes can be shown to exhibit a casual mapping (bijection). On the other hand, two connections are not part of a connection chain, if their corresponding processes are shown to be independent. To search for casual mappings between connections, the authors proposed two algorithms. One of the algorithms is timingbased, one that employs a delay constraint to search for possible mapping between incoming and outgoing packets. The other one uses a memory constraint to perform the same task. Wang and Reeves proposed an active timing-based measure BIB005 . The idea is to embed a specially designed watermark into the flow of packets. If such watermark reappears later in another connection, then the two connections are part of the same connection-chain. The proposed watermark is essentially a modification of inter-packet timing between some selected packets. Peng et al. studied the secrecy of such watermarks and whether they can be detected BIB007 . They found out that embedded watermarks can be successfully recovered and duplicated if they are not designed carefully. Also, the existence of watermarks can always be quickly detected."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Tolvaptan and its potential in the treatment of hyponatremia. Tolvaptan is a selective arginine vasopressin (AVP) V (2) receptor blocker used to induce free water diuresis in the treatment of euvolemic or hypervolemic hyponatremia. Currently the orally active medication is in the final stages prior to approval by the FDA for outpatient therapy. It appears to be safe and effective at promoting aquaresis and raising serum sodium levels in both short- and long-term studies. Tolvaptan is also effective for treatment of congestive heart failure (CHF) exacerbation, but whether there are long standing beneficial effects on CHF is still controversial. Prolonged use of tolvaptan leads to increased endogenous levels of AVP and perhaps over-stimulation of V (1A) receptors. Theoretically this activation could lead to increased afterload and cardiac myocyte fibrosis, causing progression of CHF. However, after 52 weeks of tolvaptan therapy there was no worsening of left ventricular dilatation. In addition, tolvaptan is metabolized by the CYP3A4 system; thus physicians should be aware of the potential for increased interactions with other medications. Tolvaptan is a breakthrough in the therapy of hyponatremia as it directly combats elevated AVP levels associated with the syndrome of inappropriate secretion of antidiuretic hormone, congestive heart failure, and cirrhosis of the liver.","answer":"[[\\"tolvaptan\\", \\"SUBSTRATE\\", \\"CYP3A4\\"], [\\"tolvaptan\\", \\"ACTIVATOR\\", \\"V (1A) receptors\\"], [\\"tolvaptan\\", \\"INDIRECT-UPREGULATOR\\", \\"AVP\\"], [\\"Tolvaptan\\", \\"INHIBITOR\\", \\"arginine vasopressin (AVP) V (2) receptor\\"], [\\"Tolvaptan\\", \\"INDIRECT-REGULATOR\\", \\"AVP\\"]]"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the first inclusive clinical description of what is today termed gne myopathy appeared in 1984 in a special issue ( foreschrift ) of the journal of neurological sciences honoring the departure of lord walton from newcastle .that phenotypic description noted the unique quadriceps sparing myopathy and identified the first ( and still the largest ) ethnic cluster of this disease in jews originating from iran ( persia ) . in the four decades since this descriptiona lot of knowledge about the genetic basis of this myopathy has been gained , especially after the identification of the defective gene involved in this myopathy , udp - n - acetylglucosamine 2-epimerase / n - acetylmannosamine kinase or gne .it became clear that this muscle disease ( called for many years hereditary inclusion body myopathy or hibm ) is not limited to a single closed society .furthermore , the identification of the gene led to the recognition that the distal myopathy with rimmed vacuoles ( dmrv ) described originally in japan   is in fact the same muscle disorder . thus recentlya group of investigators working for many years in the field suggested to term the condition gne myopathy  .the current report reviews the world wide distribution of gne myopathy which is unusual because in one large region of the world only a single homozygous mutation leads to the disease in the vast majority of patients while in other parts of the globe the variability of the mutations is very high ( currently over 150 are known ) .the first report of gne myopathy was in a cluster of patients from jewish descent originating from iran .however , very quickly afterwards jews from neighboring countries like uzbekistan , afghanistan , and iraq were diagnosed to have this condition on clinical grounds ( later confirmed by molecular genetics ) .this was not surprising as the jewish communities in these countries originated from the ancient persian jewish community that was present in the region since the sixth century bc .furthermore , they all share a 700 kb haplotype in the region of gne indicating a robust founder haplotype .but in the recent 15 years this p.m743 t mutation has been identified in jewish clusters with less clear historical origin to the persian jews ( e.g. jewish families from syria and bukhara ) and in karaites from egypt .the latter is an isolated sect that departed from main judaism around the tenth century .even more surprising was the identification in israel of several gne myopathy patients of different muslim arabs families ( of both beduin and palestinian origins ) with the same homozygous mutation and haplotype .thus , we reported that there is a middle eastern cluster of gne myopathy   which we postulated to be at least 1300 years old ( when islam was created ) .the typical clinical features of gne myopathy in its homozygous m743 t form have been reported by us in the past [ 1 , 6 ] . now with more than 150 patients examined personally by one of us ( za ) in israel and abroad over more than three decades the disease features of this cluster are well established .onset is in early adulthood ( third - fourth decade ) with drop foot as the typical first sign ( can be somewhat asymmetric at the onset ) . with progression the leg proximal musculature becomes affected ( mainly the iliopsoas and hamstrings but also the gluteii ) with marked preservation of the quadriceps power ( this quadriceps sparing usually lasts through the disease course ) .the calf muscles ( gatrocnemius mainly ) may become weak at the early stages , but usually are affected later when the proximal musculature is markedly weak too .upper limb involvement is usually delayed by at least a decade with proximal weakness that can involve the shoulder girdle being the first upper limb involvement .distal weakness in the hands can also appear at this stage and some patients have marked long finger flexors weakness as the only distal involvement at this stage ( reminiscent of the classical sporadic ibm sign ) .the neck muscles ( mainly flexors ) become affected in the last stages of the disease .there is no clinical cardiac involvement and respiratory insufficiency might only be a terminal feature of a bedridden patient .the progression rate is slow and patients lose their ambulation usually not before 1015 years from onset and some maintain it for more than 25 years .several of our patients reached the eight s decade of life , although they were very incapacitated .there is some variability in the above description , mainly with age of onset that can be as early as 17 and as late as 48 years .also , the rate of progression can more rapid ( and even very fast in few ) with early loss of ambulation .this usually occurs in those patients with marked involvement of the quadriceps from early stages ( about 35% of affected individuals ) .there are few atypical presentations , the most important one is in patients who have onset in the proximal musculature of the legs without distal weakness .mild facial weakness was seen only in few patients ( most were from the karaite families ) .there is one homozygous female who currently at age 78 years shows no weakness ( her brother and niece are homozygous and affected ) .more reports of gne myopathy with the middle eastern mutation p.m743 t came recently from even wider geographical area .muslim families were described from tunisia   and from other locations in the persian gulf region ( e.g. kuwait , as reported by urtizberea et al at the asian oceanian myology congress , bangkok march 2015 ) .a cluster of gne myopathy patients due to p.m743 t mutation was identified in a small town ( sangesar ) in northern iran .many belong to the bahai religion ( a relatively new religion originating in persia during the 19th century ) .genetic studies in order to identify the common  middle eastern haplotype were not performed in these families , but we assume that it is identical .thus a regional founder mutation of gne myopathy seems to exist in the middle east and eastern part of north africa , spanning through a large area from iran to tunisia .this founder mutation includes families belonging to two large ( jewish and islam ) and two small ( karaites and bahai ) religious groups .if indeed the suggestion of our unpublished data that this haplotype is 2500 years old is confirmed , can we explain this distribution ? historically , king cyrus ( named koresh in hebrew and persian ) ruled this whole area roughly from 560530 bc .he allowed various deported peoples ( including the jews ) to return to their relevant homelands and enlarged the trade in the region .its presence in the smaller  younger religious group is probably derived from this original population ; one could postulate cross marriage or rely on theories of the emergence of these religious sects from judaism .the sangegar cluster was postulated to arise from either intermarriage with members of a close jewish community or the religious conversion of regional inhabitants . to date with the available data one can only speculate where exactly in old iran / persia did the m743 t emerge .a cluster of gne myopathy patients with a previously described   mutation p.i618 t was identified in bulgaria .currently , there is no detailed report of this cluster but about 50 such patients were diagnosed , all are probably homozygous for this mutation , and all are of roma / gypsy origin .most of their clinical features are within the common range of gne myopathy phenotype , but there may be few unusual features in this cluster ( e.g. onset in the hands ) .it seems not surprising that such a socially isolated community will harbor a recessive mutation that will be the founder of a cluster .in fact only in recent years has the gypsy community of bulgaria been recognized as a founder community , and few other neuromuscular disorders founder mutations have been identified in it .the origin of the european roma ethnicity is still debated   and its discussion is beyond the scope of this review . however , one of the leading theories is that this community originated in india and slowly spread from there to eastern europe , reaching it in the 13 - 14 centuries ad . very interestingly ,in the last ( march 2015 ) asian oceanian myology congress in bangkok , two groups from india have reported on their gne mutation observations .preethis - kumar et al from southern india described a common founder mutation ( p.v727 m ) which was also found in other regions ( khadilker et al from mumbai ) .however , the latter group has identified several native patients originating from western india ( rajasthan ) who were homozygous for p.i618 t , the founder mutation in the roma cluster .it is tempting to speculate that such a finding supports the theory of the origin of the roma / gypsies of bulgaria being western india and not the more distant southern india region .more research is of course needed to identify a common haplotype between the two clusters to confirm this hypothesis , although such observation can not settle the social science debate .the number of patients with gne myopathy identified in japan is higher than that reported from the large middle eastern clusters ( totaling more than 200 ) . given its country origin an island with historical periods of isolation , one would expect to find a clear community founder mutation .numerous mutations have been described and a large fraction of the patients are compound heterozygotes . among the identified mutations , two are more common : p.v603land p.d207v .the p.v603l mutation was also identified in neighboring countries ( korea and northern china ) .this mutation seems to be a founder mutation for the region , or at least for japan .two more mutations were reported with higher frequency in asian countries : p.a662v in south east asia and the already mentioned p.v727 m in southern india ( which was reported in thailand and malaysia ) .these mutations may be of a founder nature in these regions but more formal studies are needed to confirm  it .another potential founder mutation ( p.a409 t ) was described in a cohort of gne myopathy patients from the british islands .most of the patients harboring it were from north uk ( scotland and ireland ) .patients from other uk regions carried other mutations , some uniquely reported and some found also in other countries around the world .gne myopathy is relatively easy to identify clinically with its unique distal onset and quadriceps sparing . with increasing recognition ,the epidemiology of this myopathy is of special interest since there seems to be a paradoxical distribution : a geographically large diversified ( ethnically and religiously ) region has a clear founder mutation ( and most probably a clear founder haplotype ) . its historical origin andspread is intriguing . on the other hand a more potentially isolated and clearly localized country with a relatively high prevalence of the disease ( japan )the list of currently identified founder mutations ( table  1 ) may be increased in the future when more gne clusters will be identified .","answer":"abstractgne myopathy ( previous names : hibm , dmrv , ibm2 ) is a unique distal myopathy with quadriceps sparing .  this recessively inherited myopathy has been diagnosed in various regions of the world with more than 150 disease - causing mutations already identified .  several of those are proven or suspected to be founder mutations in certain regional clusters and are described in this review .  the review also discusses some historical aspects that might be relevant to the mutational distribution ."},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the galactic thin and thick disks are two distinct stellar populations in terms of age distributions and kinematics .the chemical trends in the two systems are also most likely different although recent works give conflicting results , see e.g. chen et al .( 2000 ) and fuhrmann  ( 1998 ) .we show that the abundance trends for oxygen are different for the thin and thick disks .the selection of thin and thick disk stars was based on kinematics and is fully described in bensby et al .( 2003a , in prep ) .we calculated gaussian probabilities for each star that it belongs to the thin and thick disk respectively ,using the galactic velocity components @xmath6 , @xmath7 , and @xmath8 of the stars . stars with high probabilities of belonging to either the thin or the thick disk were then selected .the sample consists of 21 thick disk stars and 42 thin disk stars .spectra were obtained with the ces spectrograph on the eso 3.6 m telescope with a a resolution of @xmath9 and a signal - to - noise @xmath10 .telluric lines were divided out using spectra from fast rotating b stars .further details are given in bensby et al .( 2003b , in prep ) .oxygen abundances were determined through fitting of synthetic spectra to the observed spectra . the forbidden oxygen line at 6300  that has a blend of nickel in its right wing . at low metallicitiesthis blend is often negligible , but becomes severe at higher metallicities .this is illustrated in fig .  1 where we plot synthetic and observed spectra for three stars at different metallicities .fe and ni abundances have been determined from our feros spectra ( r@xmath11 ) by measuring equivalent widths of approximately 140 fei , 30 feii , and 50 nii lines for each star ( bensby et al .2003a in prep . )the two plots in fig .2 presents our results .these are our findings : + * 1 . *the thin and thick disk stars clearly show different abundance trends .this is a strong indication of their disparate origin and different epochs of formation . +* 2 . * a turn - down for @xmath2  ] at @xmath5sim -0.35  ] for the thick disk stars , from being roughly flat , continuing down to solar values .this feature is most likely a signature of the onset of snia . +the thin disk stars show a shallow decrease when going from the lowest metallicities to solar values , _ not _ showing a knee .this implies that the star formation rate in the thin disk was quite low compared to that in the thick disk . +* 4 . * at super - solar metallicities the trend found at sub - solar metallicities continues linearly for the thin disk stars .in contrast nissen and edvardsson  ( 1992 ) found @xmath2  ] to level out at these metallicities .however , they did not take the nii blend in the [ oi ] line into account , which becomes important at these metallicities , see fig .  1 .this result has implications for different models of supernova yields , and will be investigated further .all stars have also been observed with the feros spectrograph and abundances for other elements have been determined ( na , mg , al , si , ca , sc , ti , v , cr , mn , fe , co , ni , zn , y , ba , eu ) . for the @xmath12-elementswe find the same signature from the onset of snia in the thick disk which appears to be absent in the thin disk , see feltzing et al .( 2002 ) and bensby et al .( 2003a , in prep ) , in good agreement with the trends we find for oxygen .a few stars merits , due to their positions in fig .  2 , further comments : two thick disk stars at @xmath5sim-0.3  ] and one thin disk star at @xmath5sim-0.6  ] .the latter may be due to the fact that the thick disk also contain stars with \`\` cold '' kinematics .the first two are a bit harder to understand but their kinematics might have been heated through close encounters or they might have been kicked - out from a double or multiple stellar system .","answer":"first results from a study into the abundance trends of oxygen in the galactic thin and thick disks are presented .  oxygen abundances for 21 thick disk and 42 thin disk f and g dwarf stars based on very high resolution spectra ( @xmath0 ) and high signal - to - noise ( @xmath1 ) of the faint forbidden oxygen line at 6300  have been determined .  we find that @xmath2  ] for the thick disk stars show a turn - down , i.e. the \`\` knee '' , at [ fe / h ] between @xmath3 and @xmath4 dex indicating the onset of sne type ia .  the thin disk stars on the other hand show a shallow decrease going from @xmath5 sim -0.7  ] to the highest metallicities with no apparent \`\` knee '' present indicating a slower star formation history .     # 1_#1 _ # 1_#1 _ =    # 1 1.25 in .125 in .25 in"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Graph Neural Networks (GNNs) for prediction tasks like node classification or edge prediction have received increasing attention in recent machine learning from graphically structured data.However, a large quantity of labeled graphs is difficult to obtain, which significantly limit the true success of GNNs.Although active learning has been widely studied for addressing label-sparse issues with other data types like text, images, etc., how to make it effective over graphs is an open question for research.  In this paper, we present the investigation on active learning with GNNs for node classification tasks.  Specifically, we propose a new method, which uses node feature propagation followed by K-Medoids clustering of the nodes for instance selection in active learning.With a theoretical bound analysis we justify the design choice of our approach.In our experiments on four benchmark dataset, the proposed method outperforms other representative baseline methods consistently and significantly.Graph Neural Networks (GNN) (Kipf & Welling, 2016; Veličković et al., 2017; Hamilton et al., 2017; Wu et al., 2019) have been widely applied in many supervised and semi-supervised learning scenarios such as node classifications, edge predictions and graph classifications over the past few years.Though GNN frameworks are effective at fusing both the feature representations of nodes and the connectivity information, people are longing for enhancing the learning efficiency of such frameworks using limited annotated nodes.This property is in constant need as the budget for labeling is usually far less than the total number of nodes.For example, in biological problems where a graph represents the chemical structure (Gilmer et al., 2017; Jin et al., 2018 ) of a certain drug assembled through atoms, it is not easy to obtain a detailed analysis of the function for each atom since getting expert labeling advice is very expensive.On the other hand, people can carefully design a small \\"seeding pool\\" so that by selecting \\"representative\\" nodes or atoms as the training set, a GNN can be trained to get an automatic estimation of the functions for all the remaining unlabeled ones.Active Learning (AL) (Settles, 2009; Bodó et al., 2011) , following this lead, provides solutions that select \\"informative\\" examples as the initial training set.While people have proposed various methods for active learning on graphs (Bilgic et al., 2010; Kuwadekar & Neville, 2011; Moore et al., 2011; Rattigan et al., 2007) , active learning for GNN has received relatively few attention in this area.Cai et al. (2017) and Gao et al. (2018) are two major works that study active learning for GNN.The two papers both use three kinds of metrics to evaluate the training samples, namely uncertainty, information density, and graph centrality.The first two metrics make use of the GNN representations learnt using both node features and the graph; while they might be reasonable with a good (well-trained) GNN model, the metrics are not informative when the label budget is limited and/or the network weights are under-trained so that the learned representation is not good.On the other hand, graph centrality ignores the node features and might not get the real informative nodes.Further, methods proposed in Cai et al. (2017) ; Gao et al. (2018) only combine the scores using simple linear weighted-sum, which do not solve these problems principally.We propose a method specifically designed for GNN that naturally avoids the problems of methods above 1 .Our method select the nodes based on node features propagated through the graph structure, 1 Our code will be released upon acceptance.making it less sensitive to inaccuracies of representation learnt by under-trained models.Then we cluster the nodes using K-Medoids clustering; K-Medoids is similar to the conventional K-Means, but constrains the centers to be real nodes in the graph.Theoretical results and practical experiments prove the strength of our algorithm.• We perform a theoretical analysis for our method and study the relation between its classification loss and the geometry of the propagated node features.• We show the advantage of our method over Coreset (Sener & Savarese, 2017) by comparing the bounds.We also conjecture that similar bounds are not achievable if we use raw unpropagated node features.• We compare our method with several AL methods and obtain the best performance over all benchmark datasets.We study the active learning problem in the node classification task for Graph Convolution Networks (GCNs).We propose a propagated node feature selection approach (FeatProp) to comply with the specific structure of GCNs and give a theoretical result characterizing the relation between its classification loss and the geometry of the propagated node features.Our empirical experiments also show that FeatProp outperforms the state-of-the-art AL methods consistently on most benchmark datasets.Note that FeatProp only focuses on sampling representative points in a meaningful (graph) representation, while uncertainty-based methods select the active nodes from a different criterion guided by labels, how to combine that category of methods with FeatProp in a principled way remains an open and yet interesting problem for us to explore.","answer":"This paper introduces a clustering-based active learning algorithm on graphs."},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Could divalent metal transporter 1 deficiency lead to anemia?Context: The divalent metal transporter 1 (DMT1) is a major iron transporter required for iron absorption and erythropoiesis. Loss of DMT1 function results in microcytic anemia.Dysfunction of human DMT1 is associated with several pathologies such as iron deficiency anemia hemochromatosis, Parkinson's disease and Alzheimer's disease, as well as colorectal cancer and esophageal adenocarcinoma, making DMT1 an attractive target for drug discovery.Deficiency of the divalent metal transporter 1 (DMT1) leads to hypochromic microcytic anemia. We have previously shown that DMT1 deficiency impairs erythroid differentiation and induces apoptosis of erythroid cells.We propose that DMT1 deficiency negatively affects metabolism and life span of mature erythrocytes; two other aspects of defective erythropoiesis which contribute to the pathophysiology of the disease.Hypochromic microcytic anemia associated with ineffective erythropoiesis caused by recessive mutations in divalent metal transporter 1 (DMT1) can be improved with high-dose erythropoietin supplementation.Belgrade rats exhibit microcytic, hypochromic anemia and systemic iron deficiency due to a glycine-to-arginine mutation at residue 185 in a metal ion transporter of a divalent metal transporter/divalent cation transporter/solute carrier 11 group A member 2 or 3 (DMT1/DCT1/SLC11A2), a member of the natural-resistance-associated macrophage protein (Nramp) family.Deficiency of the divalent metal transporter 1 (DMT1) leads to hypochromic microcytic anemiaBelgrade rats exhibit microcytic, hypochromic anemia and systemic iron deficiency due to a glycine-to-arginine mutation at residue 185 in a metal ion transporter of a divalent metal transporter/divalent cation transporter/solute carrier 11 group A member 2 or 3 (DMT1/DCT1/SLC11A2), a member of the natural-resistance-associated macrophage protein (Nramp) familyBACKGROUND/AIMS: Deficiency of the divalent metal transporter 1 (DMT1) leads to hypochromic microcytic anemia.Microcytic anemia (mk/mk) mice defective in DMT1 and wild-type mice were exposed to either bleomycin or saline via intratracheal instillation and the resultant lung injury was compared.Deficiency of the divalent metal transporter 1 (DMT1) leads to hypochromic microcytic anemia.The divalent metal transporter 1 (DMT1) is a major iron transporter required for iron absorption and erythropoiesis.This mutation severely impairs the iron transport capability of DMT1, leading to systemic iron deficiency and anemia.","answer":"yes"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: We present a new region-based image segmentation algorithm that generates state-of-the-art resultsKeyphrases: image segmentation imagesDataset description:SBD: The Semantic Boundaries Dataset (SBD) is a dataset for predicting pixels on the boundary of the object (as opposed to the inside of the object with semantic segmentation). The dataset consists of 11318 images from the trainval set of the PASCAL VOC2011 challenge, divided into 8498 training and 2820 test images.Dialogue State Tracking Challenge: The Dialog State Tracking Challenges 2 & 3 (DSTC2&3) were research challenge focused on improving the state of the art in tracking the state of spoken dialog systems. State tracking, sometimes called belief tracking, refers to accurately estimating the user's goal as a dialog progresses.Synscapes: Synscapes is a synthetic dataset for street scene parsing created using photorealistic rendering techniques, and show state-of-the-art results for training and validation as well as new types of analysis.BSDS500: Berkeley Segmentation Data Set 500 (BSDS500) is a standard benchmark for contour detection. This dataset is designed for evaluating natural edge detection that includes not only object contours but also object interior boundaries and background boundaries.PhraseCut: PhraseCut is a dataset consisting of 77,262 images and 345,486 phrase-region pairs. The dataset is collected on top of the Visual Genome dataset and uses the existing annotations to generate a challenging set of referring phrases for which the corresponding regions are manually annotated.AQUA: The question-answer (QA) pairs are automatically generated using state-of-the-art question generation methods based on paintings and comments provided in an existing art understanding dataset. The QA pairs are cleansed by crowdsourcing workers with respect to their grammatical correctness, answerability, and answers' correctness.Options:- A: SBD  B: Dialogue State Tracking Challenge  C: Synscapes  D: BSDS500  E: PhraseCut  F: AQUA","answer":"[\\"SBD\\", \\"BSDS500\\"]"},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: We estimated the R0 of 2019-nCoV at 2.56 (95% CI: 2.49&minus;2.63). Conclusion: The under-reporting was likely to have occurred during the first half of January 2020 and should be considered in future investigation. Text: A novel coronavirus (2019-nCoV) infected pneumonia infection, which is deadly [1] , was first identified in Wuhan, China in December 2019 [2] . The virus causes a range of symptoms including fever, cough, and shortness of breath [3] . The cumulative number of reported cases slowly increased to cumulative 41 cases by 1 January 2020, and rapidly increased after 16 January 2020. As of 26 January 2020, the still ongoing outbreak had resulted in 2066 (618 of them are in Wuhan) confirmed cases and 56 (45 of them were in Wuhan) deaths in mainland China [4] , and sporadic cases exported from Wuhan were reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and the United States, please see the World Health Organization (WHO) news release via https://www.who.int/csr/don/en/ from 14 to 21 January 2020. Using the number of cases exported from Wuhan to other countries, a research group at Imperial College London estimated that there had been 4000 (95%CI: 1000-9700) cases in Wuhan with symptoms onset by 18 January 2020, and the basic reproduction number (R 0 ) was estimated at 2.6 (95%CI: 1.5-3.5) [5] . Leung et al. drew a similar conclusion and estimated the number of cases exported from Wuhan to other major cities in China [6] , and the potentials of travel related risks of disease spreading was also indicated by [7] . Due to an unknown reason, the cumulative number of cases remained at 41 from 1 to 15 January 2020 according to the official report, i.e., no new case was reported during these 15 days, which appears inconsistent with the following rapid growth of the epidemic curve since 16 January 2020. We suspect that the 2019-nCoV cases were under-reported roughly from 1 to 15 January 2020. In this study, we estimated the number of unreported cases and the basic reproduction number, R 0 , of 2019-nCoV in Wuhan from 1 to 15 January 2020 based on the limited data in the early outbreak. The time series data of 2019-nCoV cases in mainland China were initially released by the Wuhan Municipal Health Commission from 10 to 20 January 2020 [8] , and later by the National Health Commission of China after 21 January 2020 [9] . The case time series data in December 2019 were obtained from a published study [3] . All cases were laboratory confirmed following the case definition by the national health commission of China [10] . We chose the data up to 24 January 2020 instead of to the present study completion date. Given the lag between timings of case confirmation and news release of new cases, the data of the most recent few days were most likely to be tentative, and thus they were excluded from the analysis to be consistent. We suspected that there was a number of cases, denoted by ξ, under-reported from 1 to 15 January 2020. The cumulative total number of cases, denoted by C i , of the i-th day since 1 December 2019 is the summation of the cumulative reported, c i , and cumulative unreported cases, Ξ i . We have C i = c i + Ξ i , where c i is observed from the data, and Ξ i is 0 for i before 1 January and ξ for i after 15 January 2020. Following previous studies [11, 12] , we modelled the epidemic curve, i.e. , the C i series, as an exponential growi ng Poisson process. Since the data from 1 to 15 January 2020 appeared constant due to unclear reason(s), we removed these data from the fitting of exponential growth. The ξ and the intrinsic growth rate (γ) of the exponential growth were to be estimated based on the log-likelihood, denoted by , from the Poisson priors. The 95% confidence interval (95% CI) of ξ was estimated by the profile likelihood estimation framework with cutoff threshold determined by a Chi-square quantile [13] , χ 2 pr = 0.95, df = 1 . With γ estimated, the basic reproduction number could be obtained by R 0 = 1/M(−γ) with 100% susceptibility for 2019-nCoV presumed at this early stage. Here, the function M(·) was the Laplace transform, i.e., the moment generating function, of the probability distribution for the serial interval (SI) of the disease [11, 14] , denoted by h(k) and k is the mean SI. Since the transmission chain of 2019-nCoV remained unclear, we adopted the SI information from Severe Acute Respiratory Syndrome (SARS) and Middle East Respiratory Syndrome (MERS), which share the similar pathogen as 2019-nCoV [15] [16] [17] . We modelled h(k) as Gamma distributions with mean of 8.0 days and standard deviation (SD) of 3.6 days by averaging the SI mean and SD of SARS, mean of 7.6 days and SD of 3.4 days [18] , and MERS, mean of 8.4 days and SD of 3.8 days [19] . We were also interested in inferring the patterns of the daily number of cases, denoted by ε i for the i-th day, and thus it is obviously that C i = C i−1 + ε i . A simulation framework was developed for the iterative Poisson process such that E[denoted the expectation. The simulation was implemented starting from 1 January 2020 with a cumulative number of cases seed of 40, the same as reported on 31 December 2019. We conducted 1000 samples and calculated the median and 95% CI. The number of 2019-nCoV unreported cases was estimated at 469 (95% CI: 403-540), see Figure 1a , which was significantly larger than 0. This finding implied the occurrence of under-reporting between 1 and 15 January 2020. After accounting for the effect of under-reporting, the R 0 was estimated at 2.56 (95% CI: 2.49-2.63), see Figure 1b , which is consistent with many existing online preprints with range from 2 to 4 [5, [20] [21] [22] . With the R 0 of 2.56 and ξ of 469, the exponential growing framework fitted the cumulative total number of cases (C i ) remarkably well, see Figure 1c iterative Poisson process such thatdenoted the expectation. The simulation was implemented starting from 1 January 2020 with a cumulative number of cases seed of 40, the same as reported on 31 December 2019. We conducted 1000 samples and calculated the median and 95% CI. The number of 2019-nCoV unreported cases was estimated at 469 (95% CI: 403−540), see Figure  1a , which was significantly larger than 0. This finding implied the occurrence of under-reporting between 1 and 15 January 2020. After accounting for the effect of under-reporting, the R0 was estimated at 2.56 (95% CI: 2.49−2.63), see Figure 1b , which is consistent with many existing online preprints with range from 2 to 4 [5, [20] [21] [22] . With the R0 of 2.56 and ξ of 469, the exponential growing framework fitted the cumulative total number of cases (Ci) remarkably well, see Figure 1c , referring to McFadden's pseudo-R-squared of 0.99. show the exponential growth fitting results of the cumulative number of cases (Ci) and the daily number of cases (εi) respectively. In panels (c) and (d), the gold squares are the reported cases, the blue bold curve represents the median of the fitting results, the dashed blue curves are the 95% CI of the fitting results, and the purple shading area represents the time window from 1 to 15 January 2020. In panel (c), the blue dots are the cumulative total, i.e., reported and unreported, number of cases. In panel (d), the grey curves are the 1000 simulation samples. Our estimation of R0 rely on the SI of 2019-nCoV, which remains unknown as of 26 January 2020. In this work, we employed the SIs of SARS and MERS as approximations to that of 2019-nCoV. The determination of SI requires the knowledge of the chain of disease transmission that needs a sufficient number of patient samples and periods of time for follow-up [23] , and thus this is unlikely to be achieved shortly. However, using SIs of SARS and MERS as approximation could provide an panels (a,b) , the green shading area represents the 95% CI (on the horizontal axis), and the vertical green line represents the maximum likelihood estimate (MLE) of the number of unreported cases. With the MLE of R 0 at 2.56, panels (c,d) show the exponential growth fitting results of the cumulative number of cases (C i ) and the daily number of cases (ε i ) respectively. In panels (c,d), the gold squares are the reported cases, the blue bold curve represents the median of the fitting results, the dashed blue curves are the 95% CI of the fitting results, and the purple shading area represents the time window from 1 to 15 January 2020. In panel (c), the blue dots are the cumulative total, i.e., reported and unreported, number of cases. In panel (d), the grey curves are the 1000 simulation samples. Our estimation of R 0 rely on the SI of 2019-nCoV, which remains unknown as of 26 January 2020. In this work, we employed the SIs of SARS and MERS as approximations to that of 2019-nCoV. The determination of SI requires the knowledge of the chain of disease transmission that needs a sufficient number of patient samples and periods of time for follow-up [23] , and thus this is unlikely to be achieved shortly. However, using SIs of SARS and MERS as approximation could provide an insight into the transmission potential of 2019-nCoV at the early outbreak. We note that slightly varying the mean and SD of SI would not affect our main conclusions. The R 0 of 2019-nCoV was estimated at 2.56 (95% CI: 2.49-2.63), and it is generally in line with those of SARS, i.e., 2-5 [19, 24, 25] , and MERS, i.e., 2.7-3.9 [26] . For the simulated daily number of cases (ε i ), see Figure 1d , we found that ε i matched the observed daily number after 17 January 2020, but was significantly larger than the observations from 1 to 17 January 2020. This finding implied that under-reporting was likely to have occurred in the first half of January 2020. We estimated that the reporting rate after 17 January 2020 increased 21-fold (95% CI: [18] [19] [20] [21] [22] [23] [24] [25] compared to the situation from 1 to 17 January 2020 on average. One of the possible reasons was that the official diagnostic protocol was released by WHO on 17 January 2020 [27] , and the diagnosis and reporting efforts of 2019-nCoV infections probably increased. Thereafter, the daily number of newly reported cases started increasing rapidly after 17 January 2020, see Figure 1d . We conducted additional sensitivity analysis by varying the starting date of the under-reporting time window, e.g., 1 January 2020 in the main results, from 2 December 2019 to 3 January 2020, and we report our estimates largely hold. The exact value of the reporting rate was difficult to determine due to lack of serological surveillance data. The reporting rate can be determined if serological surveillance data are available for a population; we would know who was infected (seropositive) and who was not (seronegative), with high confidence. The reporting rate is the ratio of reported cases over the number of seropositive individuals. It was statistically evident that increasing in reporting was likely, and thus it should be considered in the future investigation of this outbreak. Previous preprint suggested cumulative cases of 1723 (95% CI: 427-4471) as of 12 January 2020, and 4000 (95% CI: 1000-9700) as of 18 January 2020 based on the aggregated international export cases [5] . Our analysis yielded cumulative cases of 280 (95% CI: 128-613) as of 12 January 2020, and 609 (95% CI: 278-1333) as of 18 January 2020 based on the exponential growing mechanistic in the early outbreak. Although our estimate case number appeared to have a lower mean than those estimated by Imai et al. [5] , they are not statistically different. This study applied a different screening effort to detect the 2019-nCoV cases from that in Imai et al. [5] . Imai et al. assumed the average screening effort at overseas airports that covered travelers arriving from Wuhan. Whereas we assumed a constant screening effort applied in Wuhan at the same point of time, and then a number of cases (i.e., ξ) should have been reported yet failed to be reported in the first half of January 2020 due to all sorts of reasons. It is not surprising that different assumptions yielded different results, and this difference in screening effort also partly explained why the detected cases out of China mainly presented mild symptoms. Thus, it was reasonable that our estimates appeared lower than those estimated by Imai et al. [5] . It must be emphasized that such a gap in the knowledge would be resolved by serological survey study (for a large population to approximate the actual positive rate) or an explicit estimation of the actual reporting rate. Under-reporting was likely to have occurred and resulted in 469 (95% CI: 403-540) unreported cases from 1 to 15 January 2020. The reporting rate after 17 January 2020 was likely to have increased 21-fold (95% CI: 18-25) compared with the situation from 1 to 17 January 2020 on average, and it should be considered in future investigation. We estimated the R 0 at 2019-nCoV to be 2.56 (95% CI: 2.49-2.63). Author Contributions: All authors conceived the study, carried out the analysis, discussed the results, drafted the first manuscript. All authors have read and agreed to the published version of the manuscript.Question: How was the epidemic curve modelled?","answer":", the C i series, as an exponential growi"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:Telemedicine adoption has rapidly accelerated since the onset of the COVID-19 pandemic. Telemedicine provides increased access to medical care and helps to mitigate risk by conserving personal protective equipment and providing for social/physical distancing to continue to treat patients with a variety of allergic and immunologic conditions. During this time, many allergy and immunology clinicians have needed to adopt telemedicine expeditiously in their practices while studying the complex and variable issues surrounding its regulation and reimbursement. Some concerns have been temporarily alleviated since March 2020 to aid with patient care in the setting of COVID-19. Other changes are ongoing at the time of this publication. Members of the Telemedicine Work Group in the American Academy of Allergy, Asthma & Immunology (AAAAI) completed a telemedicine literature review of online and Pub Med resources through May 9, 2020, to detail Pre-COVID-19 telemedicine knowledge and outline up-to-date telemedicine material. This work group report was developed to provide guidance to allergy/immunology clinicians as they navigate the swiftly evolving telemedicine landscape.","answer":"[\\"Prevention\\"]"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:Brazil's governance of the COVID-19 pandemic has been described as nothing short of tragic by several commentators. President Jair Bolsonaro's dangerous brew of neoliberal authoritarianism, science denialism and ableism has plunged this country into catastrophe. In this article we argue that this form (or lack) of public health governance can best be described as governance without (central) government. We begin with an overview of public health governance in the country before introducing the main theoretical concepts that guide our analysis, namely the notions of 'government by exception' and 'strategic ignorance'. Finally, we sketch the main features of this emerging form of (non)governance of COVID-19. We highlight the new forms of solidarity and mutual aid that have emerged in favelas and Indigenous communities, which have stepped in to fill the void left by a limited federal presence. The article concludes by reflecting on what this collapse of public health reveals about the limitations of democratic governance in the age of Bolsonaro.","answer":"[\\"Prevention\\"]"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Cell-to-cell infection by HIV contributes over half of virus infection}Article:Abstract:Cell-to-cell viral infection, in which viruses spread through contact of infected cell with surrounding uninfected cells, has been considered as a critical mode of virus infection. However, since it is technically difficult to experimentally discriminate the two modes of viral infection, namely cell-free infection and cell-to-cell infection, the quantitative information that underlies cell-to-cell infection has yet to be elucidated, and its impact on virus spread remains unclear. To address this fundamental question in virology, we quantitatively analyzed the dynamics of cell-to-cell and cell-free human immunodeficiency virus type 1( HIV-1) infections through experimental-mathematical investigation. Our analyses demonstrated that the cell-to-cell infection mode accounts for approximately 60% of viral infection, and this infection mode shortens the generation time of viruses by 0. 9 times and increases the viral fitness by 3. 9 times. Our results suggest that even a complete block of the cell-free infection would provide only a limited impact on HIV-1 spread.Introduction:In in vitro cell cultures and in infected individuals, viruses may display two types of replication strategies: cell-free infection and cell-to-cell infection( Sattentau, 2008; Martin and Sattentau, 2009; Talbert-Slagle et al., 2014). Both transmission means require the assembly of infectious virus particles( Monel et al., 2012), which are released in the extracellular medium for cell-free transmission, or concentrated in the confined space of cell-to-cell contacts between an infected cell and bystander target cells in the case of cell-to-cell transmission. It has been shown that most enveloped virus species, including human immunodeficiency virus type 1( HIV-1), a causative agent of AIDS, spread via cell-to-cell infection, and it is considered that the replication efficacy of cell-to-cell infection is much higher than that of cell-free infection( Sattentau, 2008; Martin and Sattentau, 2009; Talbert-Slagle et al., 2014). However, it is technically impossible to let viruses execute only cell-to-cell infection. In addition, since these two infection processes occur in a synergistic( i. e., nonlinear) manner, the additive( i. e., linear) idea that ‘total infection’ minus ‘cell-free infection’ is equal to ‘cell-to-cell infection’ does not hold true universally. Hence, it was difficult to estimate and compare the efficacies of cell-free and cell-to-cell infection, and different reports provided different estimates( Dimitrov et al., 1993; Carr et al., 1999; Chen et al., 2007; Sourisseau et al., 2007; Zhong et al., 2013). Thus, the quantitative information that underlies cell-to-cell infection has yet to be elucidated and its impact on virus spread remains unclear. In this study, through coupled experimental and mathematical investigation, we demonstrate that the efficacy of cell-to-cell HIV-1 infection is 1. 4-fold higher than that of cell-free infection( i. e., cell-to-cell infection accounts for approximately 60% of total infection). We also show that the cell-to-cell infection shortens the generation time of viruses by 0. 9 times, and increases the viral fitness by 3. 9 times. These findings strongly suggest that the cell-to-cell infection plays a critical role in efficient and rapid spread of viral infection. Furthermore, we discuss the role of the cell-to-cell infection in HIV-1 infected individuals, based on in silico simulation with our estimated parameters.Discussion:Through experimental-mathematical investigation, here we quantitatively elucidated the dynamics of the cell-to-cell and cell-free HIV-1 infection modes( Figure 2 and Table 1). We derived the basic reproduction number, R0, and divided it into the numbers of secondly infected cells through the cell-free infection, Rcf, and the cell-to-cell infection, Rcc, respectively( Figure 1B and mathematical appendix in ‘Materials and methods’). Based on our calculated values of these three indexes, we found that about 60% of the viral infection is attributed to the cell-to-cell infection in the in vitro cell culture system( Table 1), which is consistent with previous estimation by Komarova and Wodarz( 2013), Komarova et al.( 2013a), and Komarova et al.( 2013b). In addition, we revealed that the cell-to-cell infection effectively promotes the virus infection by reducing the generation time( ×0. 9 times), and by increasing the Malthus coefficient( ×3. 80 times)( Table 2). When we consider the significance of the cell-to-cell infection in patients infected with HIV-1, it should be noted that the environment of immune cells including CD4+ T-cells in vivo is radically different from the conditions of in vitro cell cultures. For instance, lymphocytes are closely packed in lymphoid tissues such as lymph nodes, and thereby, the frequency for the infected cell to contact with adjacent uninfected cells in vivo would be much higher than that in in vitro cell cultures. In addition, Murooka et al. have directly demonstrated that HIV-1-infected cells converge to lymph nodes and can be vehicles for viral dissemination in vivo( Murooka et al., 2012). Moreover, certain studies have suggested that cell-to-cell viral spread is resistant to anti-viral immunity such as neutralizing antibodies and cytotoxic T lymphocytes( Martin and Sattentau, 2009). Therefore, these notions strongly suggest that the contribution of the cell-to-cell infection for viral propagation in vivo may be much higher than that estimated from the in vitro cell culture system. As another significance of cell-to-cell viral spread, Sigal et al. have suggested that the cell-to-cell infection permits viral replication even under the anti-retroviral therapy( Sigal et al., 2011). This is attributed to the fact that the multiplicity of infection per cell is tremendously higher than that reached by an infectious viral particle. However, in the previous report( Sigal et al., 2011), the contribution of the cell-to-cell infection remained unclear. To further understand the role of the cell-to-cell infection, we quantified the contributions of the cell-to-cell and cell-free infection modes( Table 1). Interestingly, we found that the cell-to-cell infection mode is predominant during the infection. Furthermore, our virtual experiments showed that a complete block of the cell-free infection, which is highly susceptible to current antiviral drugs, provides only a limited impact on the whole HIV-1 infection( Figure 3). Taken together, our findings further support that the cell-to-cell infection can be a barrier to prevent the cure of HIV-1 infection, which is discussed in Sigal et al.( 2011). However, it should be noted that some papers have shown that cell-to-cell spread cannot overcome the action of most anti-HIV-1 drugs( Titanji et al., 2013; Agosto et al., 2014). To fully elucidate this issue, further investigations will be needed. In addition to HIV-1, other viruses such as herpes simplex virus, measles virus, and human hepatitis C virus drive their dissemination via cell-to-cell infection( Sattentau, 2008; Talbert-Slagle et al., 2014). Although the impact of cell-to-cell viral spread is a topic of broad interest in virology, it was difficult to explore this issue by conventional virological experiments, because an infected cell is simultaneously capable of achieving cell-to-cell infection along with producing infectious viral particles. By applying mathematical modeling to the experimental data, here we estimated the sole dynamics of cell-free infection in the cell culture system. The synergistic strategy of experiments with mathematical modeling is a powerful approach to quantitatively elucidate the dynamics of virus infection in a way that is inaccessible through conventional experimental approaches.","answer":"Viruses such as HIV-1 replicate by invading and hijacking cells , forcing the cells to make new copies of the virus . These copies then leave the cell and continue the infection by invading and hijacking new cells . There are two ways that viruses may move between cells , which are known as ‘cell-free’ and ‘cell-to-cell’ infection . In cell-free infection , the virus is released into the fluid that surrounds cells and moves from there into the next cell . In cell-to-cell infection the virus instead moves directly between cells across regions where the two cells make contact . Previous research has suggested that cell-to-cell infection is important for the spread of HIV-1 . However , it is not known how much the virus relies on this process , as it is technically challenging to perform experiments that prevent cell-free infection without also stopping cell-to-cell infection . Iwami , Takeuchi et al . have overcome this problem by combining experiments on laboratory-grown cells with a mathematical model that describes how the different infection methods affect the spread of HIV-1 . This revealed that the viruses spread using cell-to-cell infection about 60% of the time , which agrees with results previously found by another group of researchers . Iwami , Takeuchi et al . also found that cell-to-cell infection increases how quickly viruses can infect new cells and replicate inside them , and improves the fitness of the viruses . The environment around cells in humans and other animals is different to that found around laboratory-grown cells , and so more research will be needed to check whether this difference affects which method of infection the virus uses . If the virus does spread in a similar way in the body , then blocking the cell-free method of infection would not greatly affect how well HIV-1 is able to infect new cells . It may instead be more effective to develop HIV treatments that prevent cell-to-cell infection by the virus ."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:The effects of jaspamide on human cardiomyocyte function and cardiac ion channel activity. Jaspamide (jasplakinolide; NSC-613009) is a cyclodepsipeptide that has antitumor activity. A narrow margin of safety was observed between doses required for efficacy in mouse tumor models and doses that caused severe acute toxicity in rats and dogs. We explored the hypothesis that the observed toxicity was due to cardiotoxicity. Jaspamide was tested in a patch clamp assay to determine its effect on selected cardiac ion channels. Jaspamide (10 μM) inhibited Kv1.5 activity by 98.5%. Jaspamide also inhibited other channels including Cav1.2, Cav3.2, and HCN2; however, the Kv11.1 (hERG) channel was minimally affected. Using spontaneously contracting human cardiomyocytes derived from induced pluripotent stem cells, effects on cardiomyocyte contraction and viability were also examined. Jaspamide (30 nM to 30 μM) decreased cardiomyocyte cell indices and beat amplitude, putative measurements of cell viability and cardiac contractility, respectively. Concentration-dependent increases in rhythmic beating rate were noted at ≤ 6 h of treatment, followed by dose-dependent decreases after 6 and 72 h exposure. The toxic effects of jaspamide were compared with that of the known cardiotoxicant mitoxantrone, and confirmed by multiparameter fluorescence imaging analysis. These results support the hypothesis that the toxicity observed in rats and dogs is due to toxic effects of jaspamide on cardiomyocytes.","answer":"[[\\"jaspamide\\", \\"REGULATOR\\", \\"cardiac ion channel\\"], [\\"Jaspamide\\", \\"NOT\\", \\"hERG\\"], [\\"Jaspamide\\", \\"NOT\\", \\"Kv11.1\\"], [\\"Jaspamide\\", \\"INHIBITOR\\", \\"HCN2\\"], [\\"Jaspamide\\", \\"INHIBITOR\\", \\"Cav1.2\\"], [\\"Jaspamide\\", \\"INHIBITOR\\", \\"Cav3.2\\"]]"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey on Proactive, Active and Passive Fault Diagnosis Protocols for WSNs: Network Operation Perspective Chapter Title:  Active Approaches 1. Abstract of Cited Paper (BIB001):  Accurate and scalable simulation has historically been a key enabling factor for systems research. We present TOSSIM, a simulator for TinyOS wireless sensor networks. By exploiting the sensor network domain and TinyOS's design, TOSSIM can capture network behavior at a high fidelity while scaling to thousands of nodes. By using a probabilistic bit error model for the network, TOSSIM remains simple and efficient, but expressive enough to capture a wide range of network interactions. Using TOSSIM, we have discovered several bugs in TinyOS, ranging from network bit-level MAC interactions to queue overflows in an ad-hoc routing protocol. Through these and other evaluations, we show that detailed, scalable sensor network simulation is possible. 2. Abstract of Cited Paper (BIB002):  Wireless sensor networks involve very large numbers of small, low-power, wireless devices. Given their unattended nature, and their potential applications in harsh environments, we need a monitoring infrastructure that indicates system failures and resource depletion. We describe an architecture for sensor network monitoring, then focus on one aspect of this architecture: continuously computing aggregates (sum, average, count) of network properties (loss rates, energy-levels etc., packet counts). Our contributions are two-fold. First, we propose a novel tree construction algorithm that enables energy-efficient computation of some classes of aggregates. Second, we show through actual implementation and experiments that wireless communication artifacts in even relatively benign environments can significantly impact the computation of these aggregate properties. In some cases, without careful attention to detail, the relative error in the computed aggregates can be as much as 50%. However, by carefully discarding links with heavy packet loss and asymmetry, we can improve accuracy by an order of magnitude. 3. Abstract of Cited Paper (BIB003):  Many Wireless Sensor Network (WSN) applications are composed of a mixture of deployed devices with varying capabilities, from extremely constrained 8-bit \\"Motes\\" to less resource-constrained 32-bit \\"Microservers\\". EmStar is a software environment for developing and deploying complex WSN applications on networks of 32-bit embedded Microserver platforms, and integrating with networks of Motes. EmStar consists of libraries that implement message-passing IPC primitives, tools that support simulation, emulation, and visualization of live systems, both real and simulated, and services that support networking, sensing, and time synchronization. While EmStar's design has favored ease of use and modularity over efficiency, the resulting increase in overhead has not been an impediment to any of our current projects. 4. Abstract of Cited Paper (BIB004):  Author(s): Lewis Girod; Thanos Stathopoulos; Nithya Ramanathan; Eric Osterweil; Tom Schoellhammer; Deborah Estrin 5. Abstract of Cited Paper (BIB005):  An improved cartridge for a plurality of photographic film units of the self-processing type wherein the film units each include an image-recording unit releasably coupled at the leading end to a leading member which comprises elements that can be separated from the finished photographic print and constitute waste that must be disposed of. The cartridge comprises a substantially rectangular container having an exposure aperture in one surface. The cartridge is provided with a trailing and a leading end, the leading end being provided with a film unit dispensing slot for the removal of an exposed image-recording unit from the cartridge. The lower portion of the leading end of the cartridge extends beyond the portion containing the dispensing slot and is arranged to accept and retain the leading member as it is separated from the image-recording unit. The improvement comprises a pair of guide members in the sides of the cartridge extension which guide the leading members into the storage position and significantly simplify and reduce the cost of the cooperating camera construction. 6. Abstract of Cited Paper (BIB006):  For operating system intensive applications, the ability of designers to understand system call performance behavior is essential to achieving high performance. Conventional performance tools, such as monitoring tools and profilers, collect and present their information off-line or via out-of-band channels. We believe that making this information first-class and exposing it to applications via in-band channels on a per-call basis presents opportunities for performance analysis and tuning not available via other mechanisms. Furthermore, our approach provides direct feedback to applications on time spent in the kernel, resource contention, and time spent blocked, allowing them to immediately observe how their actions affect kernel behavior. Not only does this approach provide greater transparency into the workings of the kernel, but it also allows applications to control how performance information is collected, filtered, and correlated with application-level events. ::: ::: To demonstrate the power of this approach, we show that our implementation, DeBox, obtains precise information about OS behavior at low cost, and that it can be used in debugging and tuning application performance on complex workloads. In particular, we focus on the industry-standard SpecWeb99 benchmark running on the Flash Web Server. Using DeBox, we are able to diagnose a series of problematic interactions between the server and the OS. Addressing these issues as well as other optimization opportunities generates an overall factor of four improvement in our SpecWeb99 score, throughput gains on other benchmarks, and latency reductions ranging from a factor of 4 to 47. 7. Abstract of Cited Paper (BIB007):  This paper presents a tool for uncovering bugs due to interactive complexity in networked sensing applications. Such bugs are not localized to one component that is faulty, but rather result from complex and unexpected interactions between multiple often individually non-faulty components. Moreover, the manifestations of these bugs are often not repeatable, making them particularly hard to find, as the particular sequence of events that invokes the bug may not be easy to reconstruct. Because of the distributed nature of failure scenarios, our tool looks for sequences of events that may be responsible for faulty behavior, as opposed to localized bugs such as a bad pointer in a module. An extensible framework is developed where a front-end collects runtime data logs of the system being debugged and an offline back-end uses frequent discriminative pattern mining to uncover likely causes of failure. We provide a case study of debugging a recent multichannel MAC protocol that was found to exhibit corner cases of poor performance (worse than single channel MAC). The tool helped uncover event sequences that lead to a highly degraded mode of operation. Fixing the problem significantly improved the performance of the protocol.We also provide a detailed analysis of tool overhead in terms of memory requirements and impact on the running application. 8. Abstract of Cited Paper (BIB008):  Wireless Sensor Networks (WSNs) are being increasingly deployed in the real world to monitor the environment and large industrial infrastructures. The extreme resource constraints inherent to WSNs, the in situ deployment in harsh environments and the lack of run-time support tools make debugging and maintaining WSN applications very challenging. In particular, run-time debugging tools are required to detect and diagnose complex run-time faults such as race-conditions, which occur due to unexpected interaction with the real-world environment. The ability to repeatedly reproduce the failure by replaying the execution from the trace of events that took place can play a crucial role in debugging such faults. Obtaining such a trace is made difficult due to tight resource constraints. In this paper, we propose a lightweight tracing tool for WSNs which uses a novel control flow tracing and encoding scheme to generate a highly compressed control-flow trace. In addition to the construction of the trace, our tracing tool supports storing the trace in non-volatile memory and querying interface that allows base station to retrieve the trace when needed. We show the effectiveness of our tracing tool through a case-study and illustrate its low overhead through measurements. 9. Abstract of Cited Paper (BIB009):  Due to natural weakness of sensor node in the point of wireless communications, reliable data delivery becomes one of the major challenges in wireless sensor networks. To handle this problem, many schemes in each layer have been proposed in the several literatures. Among those, MintRoute protocol is designed to achieve high reliability by choosing the best qualified path which is mainly measured by the delivery ratio of packets. Moreover, although some literatures provide the simulation and experimental results of performance evaluation, as far as the authors know, there is no previous research works to mention impact on performance by sensor deployment strategies, effect of failure, and the density of nodes. This paper details a simulation study that compare performance of MintRoute at different scenarios. In addition, research challenges will be given through analysis and discussion for performance. 10. Abstract of Cited Paper (BIB010):  In this paper, we propose an active fault diagnosis algorithm based on random walk approach under the Space Information Network (SIN) circumstance. Space information network is much more different with wireless sensor network for its long time delay and its inconstant topology. Therefore the existed fault diagnosis algorithm do not have a perfect performance as we want. The algorithm proposed in this paper, we gather information by random walk approach actively and use compressive sensing approach to deal with signal. Through the simulation we can argue that under the space information network circumstance we can handle the problem much more effectively.Literature Review:","answer":"Currently, in active approaches sensor node debugging is performed using a combination of simulation, visualisation tools, log file interrogation, passive monitoring and tracing programs. Simulations BIB002  help to reduce cost, the length of the deployment cycle, and thereafter reduce the need to repeat the experiments as many times as possible. Nevertheless, it does not replace real hardware requirements, such as real-time network dynamics, environment dynamics, other hardware details, MAC and numerous timings. Log files can obfuscate important events because they capture much unfiltered data. Visualisation tools help to perform real-time information debugging but they do not identify failures. For example, EmStar visualiser BIB004 BIB005 collects the historical data for future reference. Although these tools can identify link quality and neighbour-level connectivity, there is a conflict between these properties because it is possible that the node has no neighbour despite having a high-quality link. Ramanatham et al. BIB008 proposed a protocol, called Sympathy, which is the combination of all the above-mentioned aspects. It collects information from the sensor nodes at runtime, such as a routing table and flow information, to judge the possibility of a fault while maintaining awareness of network exceptions. It provides several command-line and web-accessible mechanisms through which a user can query and control the system. Sympathy provides a ping-about command that flows into the network to ask for information about the nodes. When a node receives a query, it replies with available standard metric packets. In addition, all of the other nodes that have the same information regarding the query requested from the nodes, such as number of packets communicated with, or the time of last communication, transmit the data back to the sink. Sympathy's web interface displays the number of nodes graphically. It also allows the user to query any node to retrieve the requested information and highlight the failure. Performance evaluations show that Sympathy detects the injected network failure accurately with relatively low latency and minimises network traffic. It also integrates a graphical interface that can visualise metrics and environmental data BIB009 . Jiang et al. BIB011 proposed an active fault diagnosis algorithm that actively gathers information based on a random walk approach. It uses a compressive sensing approach to deal with the signal for a space information network (SIN). A SIN is different from WSNs in that a SIN possesses a long time delay and inconsistent topology. Therefore, existing fault diagnosis techniques cannot be applied to SINs. Performance evaluations show that Jiang et al.'s BIB011 algorithm can handle the problem much more effectively under SIN circumstances. Tolle et al. BIB006 suggested that a sensor network application that uses the nucleus management system (NMS) infrastructure. It exports debugging and monitoring information, and sends application metrics. This infrastructure supports the export of counters and statistics that is both easy-to-use and lightweight in terms of network overhead. Zhao et al. BIB001 BIB003 presented an energy-efficient method that continuously computes the in-network processing calculations, such as sum, average, the number of packets lost, energy levels and the number of packets that help in debugging. Kim et al. BIB010 demonstrated the transmission of network metrics from the nodes to the sink; however, this is not a novel idea. In evaluation scenarios, when network traffic increases, the data cannot reach the destination within the specified time. A technique, called Mint-route, includes periodic sending of neighbour tables. It also helps in performing debugging operations at the sink, and is used to avoid network traffic congestion and help minimise delay. Ruan et al. BIB007 proposed the DeBox system, which is motivated by Sympathy's design (as discussed above). Since it exposes minimum states to an application in real time, DeBox exhibits better performance and tuning than passive schemes that give information post facto. Sympathy does not consider performance; it concentrates only on fault detection and debugging, and it enhances a system's transparency and visibility."},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: Which genome browser database for DNA shape annotations is available?Context: GBshape: a genome browser database for DNA shape annotations.Our Genome Browser for DNA shape annotations (GBshape; freely available at http://rohslab.cmb.usc.edu/GBshape/) provides minor groove width, propeller twist, roll, helix twist and hydroxyl radical cleavage predictions for the entire genomes of 94 organisms. Additional genomes can easily be added using the GBshape framework. GBshape can be used to visualize DNA shape annotations qualitatively in a genome browser track format, and to download quantitative values of DNA shape features as a function of genomic position at nucleotide resolution. As biological applications, we illustrate the periodicity of DNA shape features that are present in nucleosome-occupied sequences from human, fly and worm, and we demonstrate structural similarities between transcription start sites in the genomes of four Drosophila species.GBshape can be used to visualize DNA shape annotations qualitatively in a genome browser track format, and to download quantitative values of DNA shape features as a function of genomic position at nucleotide resolution.Our Genome Browser for DNA shape annotations (GBshape; freely available at http://rohslab.cmb.usc.edu/GBshape/) provides minor groove width, propeller twist, roll, helix twist and hydroxyl radical cleavage predictions for the entire genomes of 94 organisms.GBshape can be used to visualize DNA shape annotations qualitatively in a genome browser track format, and to download quantitative values of DNA shape features as a function of genomic position at nucleotide resolution.GBshape can be used to visualize DNA shape annotations qualitatively in a genome browser track format, and to download quantitative values of DNA shape features as a function of genomic position at nucleotide resolution. As biological applications, we illustrate the periodicity of DNA shape features that are present in nucleosome-occupied sequences from human, fly and worm, and we demonstrate structural similarities between transcription start sites in the genomes of four Drosophila species.Whereas higher-order effects, such as chromatin accessibility, cooperativity and cofactors, have been described, DNA shape recently gained attention as another feature that fine-tunes the DNA binding specificities of some transcription factor families. Our Genome Browser for DNA shape annotations (GBshape; freely available at http://rohslab.cmb.usc.edu/GBshape/) provides minor groove width, propeller twist, roll, helix twist and hydroxyl radical cleavage predictions for the entire genomes of 94 organisms.Additional genomes can easily be added using the GBshape framework. GBshape can be used to visualize DNA shape annotations qualitatively in a genome browser track format, and to download quantitative values of DNA shape features as a function of genomic position at nucleotide resolution.Our Genome Browser for DNA shape annotations (GBshape; freely available at http://rohslab.cmb.usc.edu/GBshape/) provides minor groove width, propeller twist, roll, helix twist and hydroxyl radical cleavage predictions for the entire genomes of 94 organisms. Additional genomes can easily be added using the GBshape framework.GBshape can be used to visualize DNA shape annotations qualitatively in a genome browser track format, and to download quantitative values of DNA shape features as a function of genomic position at nucleotide resolution.Our Genome Browser for DNA shape annotations (GBshape; freely available at http://rohslab.cmb.usc.edu/GBshape/) provides minor groove width, propeller twist, roll, helix twist and hydroxyl radical cleavage predictions for the entire genomes of 94 organisms.","answer":"GBshape"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Trends in Adolescent Overweight Perception and Its Association With Psychosomatic Health 2002-2014: Evidence From 33 Countries Perceiving oneself as overweight is common and strongly associated with adolescents' subjective well-being. The prevalence of overweight perceptions and their impact on well-being may have increased over the past decade due to an increase in the salience of weight-related issues. This study examines trends (2002-2014) in the prevalence of adolescent overweight perceptions and their association with psychosomatic complaints. Data from 15-year-old adolescents were obtained between 2002 and 2014 in four rounds of the Health Behaviour in School-aged Children study in 33 countries in Europe and North America (N = 187,511). Design-adjusted logistic regressions were used to quantify changes in overweight perceptions over time. Linear modeling was used to assess change in the association between perceived overweight and self-reported psychosomatic complaint burden, adjusting for overweight status. Among boys, 10 of 33 countries saw an increase in overweight perceptions between 2002 and 2014, with Russia, Estonia, and Latvia showing the most pronounced year-on-year increases. Only England, France, Germany, and Norway saw an increase in the positive association between overweight perceptions and psychosomatic complaints among boys. Among girls, most countries (28/33) saw no change in the prevalence of overweight perceptions, with the prevalence over 40% in most nations. However, in 12 countries, the association between overweight perceptions and psychosomatic complaints increased among girls, with particularly strong changes seen in Scotland and Norway. Evidence is presented which suggests that for adolescent girls in 12 Northern and Western European countries and for boys in four perceiving oneself as overweight may be increasingly deleterious for psychosomatic health.","answer":"{\\"AnatomicalStructure\\": [], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"perceptions\\", \\"perceiving\\", \\"Perception\\", \\"Perceiving\\", \\"perceived\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"overweight\\", \\"positive\\", \\"no change\\", \\"Overweight\\"], \\"Food\\": [], \\"HealthCareActivity\\": [], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [\\"girls\\"], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"Design-adjusted logistic regressions\\", \\"study\\"], \\"SpatialConcept\\": [\\"Northern\\", \\"Countries\\", \\"Western\\", \\"England\\", \\"European countries\\", \\"Germany\\", \\"Europe\\", \\"Estonia\\", \\"countries\\", \\"North America\\", \\"Russia\\", \\"France\\", \\"Norway\\", \\"Latvia\\", \\"Scotland\\"], \\"Virus\\": []}"},{"question":"You will be shown full-text from a biomedical research paper. Given this text, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Carbon monoxide\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Document text:Effects of β-mercaptoethanol on in vitro maturation and glutathione level of buffalo oocytes Aim: The present study was carried out to evaluate the effect of supplementation of β-mercaptoethanol (β-ME) on in vitro maturation rate and glutathione (GSH) level of buffalo oocytes. Materials and Methods: Oocytes were recovered from buffalo’s ovaries collected from government approved slaughter house (near Kamela darwaza, Surat) of Surat Municipal Corporation. The obtained oocytes were in vitro matured in maturation media supplemented with 0 μM (117 oocytes), 100 μM (46 oocytes) and 200 μM (42 oocytes) concentration of β-ME. After 24 h of incubation, maturation rate of oocytes and intra-cellular GSH level were determined. Results: The results showed that the presence of β-ME did not influence (p>0.05) the oocyte maturation rate. However, GSH level increased significantly (p<0.05) in matured oocytes when supplemented with 100 μM and 200 μM β-ME (6.19±0.10 and 6.37±0.20 pmol/oocyte) as compared to control media (4.68±0.26 pmol/oocyte). Conclusion: It was concluded that β-ME may have a potential to increase the meiotic maturation of in vitro cultured oocytes and protect it from oxidative damage. Introduction Buffalo (Bubalus bubalis) plays a prominent role in rural livestock production. Problems like late onset of reproductive maturity, seasonality of breeding, late estrus and long calving interval have been attributed to poor reproductive performance of this species [1]. To cope up with these problems, use of modern biotechnologies, such as in vitro fertilization (IVF) and embryo production are required instead of conventional breeding programs [2]. A major factor affecting in vitro mammalian embryo development is increased oxidative stress [3], which is due to high lipid content of buffalo oocytes [4]. Higher amount of reactive oxygen species (ROS) can alter cellular molecules; induce developmental block, apoptosis and fragmentation of embryos [5]. It has been demonstrated that addition of low molecular thiol compound such as β-mercaptoethanol (β-ME) and cysteamine to the maturation medium causes an increase in intracellular glutathione (GSH) synthesis [6,7] and leads to low oxidative stress in many species [8]. β-ME and GSH both improve the cell survival by decreasing apoptotic cell death under “redox” state [9]. GSH directly influences cell death, while β-ME has an indirect effect by supporting increase in intracellular GSH level [5]. Buffalo oocytes can synthesize de novo during in vitro maturation (IVM) [7] and β-ME increases cumulus cells expansion which help in GSH synthesis [10]. So far as buffalo oocytes are concerned, meagre studies have been carried to know the effects of β-ME on cumulus expansion of oocyte and intracellular GSH content. Therefore, the present study was carried out to evaluate the effect of supplementation of β-ME on IVM rate and GSH level of buffalo oocytes. Materials and Methods Reagents and media All the chemical and media used in the present study were purchased from Sigma (USA). Collection of ovaries Ovaries were collected from sexually matured buffaloes immediately after slaughter from nearby government approved slaughter house (near Kamela darwaza, Surat) of Surat municipal corporation and transported to the laboratory in sterile normal saline (NSS:0.85%) solution fortified with antibiotic (50 μl/L Gentamicin) at 38-39°C temperature. At laboratory, ovaries were washed in 70% ethanol for 1 min. to reduce contamination followed by washing in 0.85% NaCl twice for 1 min. Oocyte recovery After final washing, cumulus oocyte complexes (COCs) were aspirated from non-atretic surface follicles (2-8 mm) using 18-guage needle connected to a 5 ml sterile syringe containing oocyte collection media. Further aspirated oocytes were searched and graded as per Khandoker et al. [11]. A, B and C grade oocytes were used for IVM. Maturation of oocytes After final washing with oocyte collection media, oocytes of A, B and C grade were equally distributed in three groups viz: control Group I (117 oocytes) and treatment Groups-II (46 oocytes) and III (42 oocytes). In control group, only basic maturation media (TCM-199 supplemented with 0.2 mM sodium pyruvate, 10% fetal bovine serum, 3 mg/ml bovine serum albumin and 10 IU/ml hCG) was used while in treatment Group-II and III control media supplemented with 100 µM and 200 µM β-ME respectively was used. Before transferring to maturation media, oocytes were washed once with respective maturation media. Each group was individually placed in 50 μl droplet of maturation medium containing 5-10 oocytes covered with mineral oil in a sterile petridish and kept at 38.5°C, 5% CO2 and 95% humidified air in CO2 for 24 h. GSH content and maturation rate of oocytes Maturation of oocyte assessed on the basis of their cumulus layer expansion as per Khandoker et al. [11]. GSH level estimation of oocytes was carried out in all groups after 24 h of maturation. Oocytes were carefully denuded by repeated pipetting, washed several times in 1x phosphate buffered saline and 10-12 oocytes from each group were stored at −20°C in eppendorf for further use. On the day of assay, the samples were thawed and 500 µl of ice-cold 5% metaphosphoric acid added to each sample. Vortexing performed for 3-5 min. After that sonication was performed for 5 min. Samples were then centrifuged (10 min; 3000 × g) in cryo-centrifuge machine at 4°C and 100 µl of supernatant was recovered. Further estimation of GSH was done with the help of GSH Assay Kit (Calbiochem® USA). Statistical analysis Data pertaining to oocyte maturation were analyzed by SPSS software performing Chi-square test and for data pertaining to GSH level by one-way ANOVA among control and treatment groups. A significance level of p<0.05 was used throughout this study. Results The effects of supplementation of β-ME on IVM rate and GSH level of buffalo oocytes is presented in Table-1. The results showed that the presence of β-ME did not influence the oocyte maturation rate although higher maturation rate was observed in β-ME-100 and 200 μM groups as compared to control. However, intra-cellular GSH level increased significantly (p<0.05) in the presence of 100 and 200 μM β-ME (6.19±0.10 and 6.37±0.20 pmol/oocyte) as compared to control (4.68±0.26 pmol/oocyte). Effects of β-ME on of oocytes and its GSH level in buffalo. βME=βmercaptoethanol, IVM=In vitro maturation, GSH=Glutathione Discussion Antioxidants function as autocrine and paracrine factors that influence growth, differentiation and retardation of developing follicles. Presence of GSH, β-ME is beneficial for follicle development, and there may be an interaction between exogenous antioxidant and developing follicles. Exogenous antioxidants influence follicle growth and nuclear maturation of intra-follicular oocytes. β-ME is a thiol compound, acting as an antioxidant and promotes embryo development [12,13]. The results of the present study revealed that the addition of β-ME (100 µM and 200 µM) to the maturation medium did not increase maturation rate, as also reported in porcine oocytes [14]. However, higher numbers of M-II oocytes were found when denuded oocytes were cultured in maturation medium supplemented with 25 µM β-ME [15]. Similarly, supplementation of β-ME positively influence percentage of oocytes from pre-pubertal Boer goats progressing to metaphase II stage during IVM [16]. It has also been reported that supplementation of β-ME in maturation media have positive effect on expansion of COCs and maturation rate of oocytes of bovine as well as pig [10,17], apart for impact on fertilization rate [18] and improves embryo development rate [19,20]. The effect of β-ME may have been mediated through the synthesis of GSH which is known to play an important role in protecting the cell or embryos from oxidative damage. Exogenous β-ME is able to increase GSH synthesis by reducing cystine to cysteine [21] and increased GSH level promotes embryonic development by maintaining intracellular redox state [22]. In the present study also, significantly higher GSH level was observed in groups having maturation medium supplemented with 100 µM and 200 µM β-ME than control groups. Similar results were found in bovine oocytes and embryos [7,15,22], as well as pig oocytes [12]. GSH itself plays a critical role in protecting the cell from oxidative damages [23-26]. These results warrant the supplementation of exogenous β-ME in basic oocyte maturation medium for improvement of IVF. Conclusion From the present study, it can be concluded that addition of β-ME at different concentration in maturation media helps in the synthesis of GSH that protects the degeneration of oocytes from ROS during IVM and might enhance the process of maturation of oocyte. Authors’ Contributions SSC along with GP designed the experiment and PAP conducted the experiment with the help of ABO. GP and VKS helped in analyzing the data and preparing the manuscript. SSC, GP, VKS and PAP reviewed the manuscript. All authors read and approved the final manuscript. Competing Interests The authors declare that there is no conflict of interests regarding the publication of this paper. References","answer":"{\\"Chemical\\": [\\"reactive oxygen species\\", \\"Gentamicin\\", \\"u03b2mercaptoethanol\\", \\"mineral oil\\", \\"GSH\\", \\"ethanol\\", \\"glutathione\\", \\"cystine\\", \\"NSS\\", \\"cysteamine\\", \\"metaphosphoric acid\\", \\"CO2\\", \\"sterile normal saline\\", \\"ROS\\", \\"NaCl\\", \\"u03b2-mercaptoethanol\\", \\"u03b2-ME\\", \\"phosphate buffered saline\\", \\"Glutathione\\", \\"cysteine\\", \\"thiol\\", \\"sodium pyruvate\\", \\"u03b2ME\\"]}"},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Is ACI-35 a passive vaccine?Context: Two active vaccines targeting either nonphosphorylated (AAD-vac1) and phosphorylated tau (ACI-35) have entered Phase I testing.","answer":"no"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: How is the sequence variability defined in antibodies?Context: Structural and immunochemical data suggest, however, that V3 contains conserved elements which explain its role in binding to virus co-receptors despite its sequence variability.This study, for the first time, describes an in-depth analysis of genetic variation in Vpr using information from global HIV-1 isolates involving a total of 976 Vpr sequencesWe investigated the possible link between enzyme secretion and variability in the linker sequence segment using site-directed mutagenesis and linker domain swapping to construct mutated and chimeric forms of the IgA1 protease fromWe have performed low to high resolution molecular typing to assess the genetic variability of major histocompatibility complex loci (HLA-A, -B, -Cw, -DRB1, and -DQA1) in a large population of European American patients with IIM (n = 571) representing the major myositis autoantibody groupsIn this study, we analyzed the value of IHC versus that of microsatellite instability (MSI) testing in predicting mutation status of the MLH1, MSH2, and MSH6 genes in colorectal carcinomas and adenomas, and explored the frequency and significance of immunohistochemical staining variabilityComputational analyses were used to position the epitope in the context of the virion-associated envelope glycoprotein complex, to determine the variability of the surrounding surface, and to calculate the surface accessibility of possible glycan- and polypeptide-epitope components.ese variations in structure of an expression site for a major, immunoprotective outer membrane protein have important implications for vaccine development and for obtaining an improved understanding of the mechanisms of persistence of ehrlichial infections in humans, domestic animals, and reservoir hosts.The V3 region of the isolates used in the neutralization assay was amplified by PCR, directly sequenced, and analyzed to reveal variability between the consensus HIV-1 sequences and the isolates.","answer":"The variability at each position of the polypeptide chain is defined as:Variability = number of different amino acids at a given position / frequency of the  most common amino acid at given position."},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:We investigate the manipulation of power indices in TU-cooperative games by stimulating (subject to a budget constraint) changes in the propensity of other players to participate to the game. We display several algorithms that show that the problem is often tractable for so-called network centrality games and influence attribution games, as well as an example when optimal manipulation is intractable, even though computing power indices is feasible.Cited Abstract(s):[1]: The Internet and social media have fuelled enormous interest in social network analysis. New tools continue to be developed and used to analyse our personal connections, with particular emphasis on detecting communities or identifying key individuals in a social network. This raises privacy concerns that are likely to exacerbate in the future. With this in mind, we ask the question ‘Can individuals or groups actively manage their connections to evade social network analysis tools?’ By addressing this question, the general public may better protect their privacy, oppressed activist groups may better conceal their existence and security agencies may better understand how terrorists escape detection. We first study how an individual can evade ‘node centrality’ analysis while minimizing the negative impact that this may have on his or her influence. We prove that an optimal solution to this problem is difficult to compute. Despite this hardness, we demonstrate how even a simple heuristic, whereby attention is restricted to the individual’s immediate neighbourhood, can be surprisingly effective in practice; for example, it could easily disguise Mohamed Atta’s leading position within the World Trade Center terrorist network. We also study how a community can increase the likelihood of being overlooked by community-detection algorithms. We propose a measure of concealment—expressing how well a community is hidden—and use it to demonstrate the effectiveness of a simple heuristic, whereby members of the community either ‘unfriend’ certain other members or ‘befriend’ some non-members in a coordinated effort to camouflage their community.[2]: We examine the impact of independent agents failures on the solutions of cooperative games, focusing on totally balanced games and the more specific subclass of convex games. We follow the reliability extension model, recently proposed in [1] and show that a (approximately) totally balanced (or convex) game remains (approximately) totally balanced (or convex) when independent agent failures are introduced or when the failure probabilities increase. One implication of these results is that any reliability extension of a totally balanced game has a non-empty core. We propose an algorithm to compute such a core imputation with high probability. We conclude by outlining the effect of failures on non-emptiness of the core in cooperative games, especially in totally balanced games and simple games, thereby extending observations in [1].[3]: We examine agent failures in weighted voting games. In our cooperative game model, R-WVG, each agent has a weight and a survival probability, and the value of an agent coalition is the probability that its surviving members would have a total weight exceeding a threshold. We propose algorithms for computing the value of a coalition, finding stable payoff allocations, and estimating the power of agents. We provide simulation results showing that on average the stability level of a game increases as the failure probabilities of the agents increase. This conforms to several recent results showing that failures increase stability in cooperative games.[4]: In 1992, Bartholdi, Tovey, and Trick opened the study of control attacks on elections-- attempts to improve the election outcome by such actions as adding deleting candidates or voters. That work has led to many results on how algorithms can be used to find attacks on elections and how complexity-theoretic hardness results can be used as shields against attacks. However, all the work in this line has assumed that the attacker employs just a single type of attack. In this paper, we model and study the case in which the attacker launches a multipronged (i.e., multimode) attack. We do so to more realistically capture the richness of real-life settings. For example, an attacker might simultaneously try to suppress some voters, attract new voters into the election, and introduce a spoiler candidate. Our model provides a unified framework for such varied attacks. By constructing polynomialtime multiprong attack algorithms we prove that for various election systems even such concerted, flexible attacks can be perfectly planned in deterministic polynomial time.[5]: We study the complexity of influencing elections through bribery: How computationally complex is it for an external actor to determine whether by a certain amount of bribing voters a specified candidate can be made the election's winner? We study this problem for election systems as varied as scoring protocols and Dodgson voting, and in a variety of settings regarding homogeneous-vs.-nonhomogeneous electorate bribability, bounded-size-vs.-arbitrary-sized candidate sets, weighted-vs.-unweighted voters, and succinct-vs.-nonsuccinct input specification. We obtain both polynomial-time bribery algorithms and proofs of the intractability of bribery, and indeed our results show that the complexity of bribery is extremely sensitive to the setting. For example, we find settings in which bribery is NP-complete but manipulation (by voters) is in P, and we find settings in which bribing weighted voters is NP-complete but bribing voters with individual bribe thresholds is in P. For the broad class of elections (including plurality, Borda, k-approval, and veto) known as scoring protocols, we prove a dichotomy result for bribery of weighted voters: We find a simple-to-evaluate condition that classifies every case as either NP-complete or in P.[6]: Weighted voting is a classic model of cooperation among agents in decision-making domains. In such games, each player has a weight, and a coalition of players wins the game if its total weight meets or exceeds a given quota. A player's power in such games is usually not directly proportional to his weight, and is measured by a power index, the most prominent among which are the Shapley-Shubik index and the Banzhaf index. In this paper, we investigate by how much a player can change his power, as measured by the Shapley-Shubik index or the Banzhaf index, by means of a false-name manipulation, i.e., splitting his weight among two or more identities. For both indices, we provide upper and lower bounds on the effect of weight-splitting. We then show that checking whether a beneficial split exists is NP-hard, and discuss efficient algorithms for restricted cases of this problem, as well as randomized algorithms for the general case. We also provide an experimental evaluation of these algorithms. Finally, we examine related forms of manipulative behavior, such as annexation, where a player subsumes other players, or merging, where several players unite into one. We characterize the computational complexity of such manipulations and provide limits on their effects. For the Banzhaf index, we describe a new paradox, which we term the Annexation Non-monotonicity Paradox.[7]: We study the effects of bidder collaboration in all-pay auctions. We analyse both mergers, where the remaining players are aware of the agreement between the cooperating participants, and collusion, where the remaining players are unaware of this agreement. We examine two scenarios: the sum-profit model where the auctioneer obtains the sum of all submitted bids, and the max-profit model of crowdsourcing contests where the auctioneer can only use the best submissions and thus obtains only the winning bid. We show that while mergers do not change the expected utility of the participants, or the principal's utility in the sum-profit model, collusion transfers the utility from the non-colluders to the colluders. Surprisingly, we find that in some cases such collaboration can increase the social welfare. Moreover, mergers and, curiously, also collusion can even be beneficial to the auctioneer under certain conditions.[8]: [9]: Hedonic games model agents that decide which other agents they will join, given some preferences on other agents. We study Sybil attacks on such games, by a malicious agent which introduces multiple false identities, so that the outcome of the game is more interesting for itself. First taking Nash stability as the solution concept, we consider two simple manipulations, and show that they are essentially the only possible Sybil manipulations. Moreover, small experiments show that they are seldom possible in random games. We exhibit another simple manipulation on the concepts of (contractual) individual stability afterwards. Then we show that such hedonic games are very sensitive to Sybil manipulations, which contrasts sharply with the Nash case.[10]: Procuring multiple agents with different ability levels to independently solve the same task is common in labor markets, crowdsourcing environments and research and development projects due to two reasons: some agents may fail to provide a satisfactory solution, and the redundancy increases the quality of the best solution found. However, incentivizing large number of agents to compete for one task is difficult; agents need fair ex-ante guaranteed payoffs that consider their ability levels and failure rates to exert efforts. We model such domains as a cooperative game called the Max-Game, where each agent has a weight representing its ability level, and the value of an agent coalition is the maximal weight of the agents in the coalition. When agents may fail, we redefine the value of a coalition as the expected maximal weight of its surviving members. We analyze the core, the Shapley value, and the Banzhaf index as methods of payoff division. Surprisingly, the latter two, which are usually computationally hard, can be computed in polynomial time. Finally, we initiate the study of a new form of sabotage where agents may be incentivized to influence the failure probabilities of their peers, and show that no such incentive is present in a restricted case of Max-Games.[11]: Weighted voting games provide a simple model of decision-making in human societies and multi-agent systems. Such games are described by a set of players, a list of [email protected]? weights, and a quota; a coalition of the players is said to be winning if the total weight of its members meets or exceeds the quota. The power of a player in a weighted voting game is traditionally identified with her Shapley-Shubik index or her Banzhaf index, two classic power measures that reflect the [email protected]?s marginal contribution under different coalition formation scenarios. In this paper, we investigate by how much one can change a [email protected]?s power, as measured by these indices, by modifying the quota. We give tight bounds on the changes in the individual [email protected]?s power that can result from a change in quota. We then describe an efficient algorithm for determining whether there is a value of the quota that makes a given player a dummy, i.e., reduces her power (as measured by both indices) to 0. We also study how the choice of quota can affect the relative power of the players. Finally, we investigate scenarios where [email protected]?s choice in setting the quota is constrained. We show that optimally choosing between two values of the quota is complete for the complexity class PP, which is believed to be significantly more powerful than NP. On the other hand, we empirically demonstrate that even small changes in quota can have a significant effect on a [email protected]?s power.[12]: [13]: We propose a natural model for agent failures in congestion games. In our model, each of the agents may fail to participate in the game, introducing uncertainty regarding the set of active agents. We examine how such uncertainty may change the Nash equilibria (NE) of the game. We prove that although the perturbed game induced by the failure model is not always a congestion game, it still admits at least one pure Nash equilibrium. Then, we turn to examine the effect of failures on the maximal social cost in any NE of the perturbed game. We show that in the limit case where failure probability is negligible new equilibria never emerge, and that the social cost may decrease but it never increases. For the case of nonnegligible failure probabilities, we provide a full characterization of the maximal impact of failures on the social cost under worst-case equilibrium outcomes.","answer":"Results on the reliability extension of a cooperative game [13] [2]3 [2] [2]1 [10] are naturally related. So is the rich literature on , both in non-cooperative and coalitional settings [6] [4] [11] [7] [1] [12] [2]5 and [2]2 in voting. Our framework covers both scenarios, that in which an external perpetrator bribes agents to change their reliabilities, and that in which this is done by a coalition of agents."},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Regioselective Alkylative Cross-Coupling of Remote Unactivated C(sp3)-H BondsPaper sections:<p>The ubiquity of C-H bonds decorating organic molecules presents itself as the ultimate handle of chemical diversification. The ability to selectively and efficiently manipulate these C-H functionalities can greatly expedite and simplify synthetic routes through a greater diversity of potential bond disconnections. However, this ubiquity also poses a considerable selectivity challenge, as the differentiation between unbiased reactive sites can be marginal to largely indistinguishable.1 Metal-catalyzed C-H activation has revolutionized our ability to quickly generate molecular complexity through the installment of new C-C, C-O, C-N, and C-X bonds.2 While metal-catalyzed C-H activation has thrived on the functionalization of C(sp2)-H bonds, the selective functionalization of C(sp3)-H bonds poses an ongoing challenge.3</p><p>Techniques involving hydrogen atom transfer (HAT) have proven useful for the functionalization of intrinsically weak C(sp3)-H bonds.4 Photoredox strategies that facilitate the generation of radical intermediates capable of HAT have expedited the growth of these avenues.5 However, these radical intermediates target the weakest C-H bond in solution capable of polarity matched transition state, which typically lie α to an existing functionality or heteroatom. In the absence of electronic positional bias, functionalization through these methods often occurs indiscriminately at chemically indistinguishable sites.6 The coupling of a transition metal with these strategies has broadly expanded the breadth of bond disconnections through single-electron transmetallation.7 This merger has culminated in the ability to cross-couple alkyl radicals generated from C-H bonds with metal-activated electrophiles to forge new C(sp3)-C(sp2) and C(sp3)-C(sp3) bonds.8 Recent methodology has extended this reactivity to unactivated positions, although it requires a large excess of substrate and may generate mixtures of regioisomers.9</p><p>Our group and the Knowles group has previously demonstrated selective functionalization of distal C(sp3) sites with new C-C bonds through a 1,5-HAT strategy through a photoredox- catalyzed oxidation of a pendent amide moiety.10 The remote carbon radical, generated through a six-membered transition state, is sufficiently long-lived to trap exogenous Michael acceptors to furnish a δ-functionalized amide. This strategy showcases the ability to regioselectively mono-functionalize an unactivated distal methine or methylene in the presence of more electronically or sterically activated C-H bonds.</p><p>We sought to unify the selectivity imparted through 1,5-HAT with the versatility offered through nickel catalysis to selectively alkylate distal bonds. In doing so, one of numerous otherwise indistinguishable methylene sites can be coupled selectively to the wealth of commercially available or easily accessible alkyl bromides.</p><p>We first examined whether the distal alkyl radical generated through 1,5-HAT could be captured by a metal catalyst. Due to the well-established ability of nickel bipyridine complexes to participate in metallophotoredox cross-couplings,11 we chose to screen</p><p>these species in conjunction with our previously established methods10a for forming a distal alkyl radical (Table 1).12 Alkyl trifluoroacetamides are particularly well-suited to directing the 1,5-HAT in the presence of a sufficiently strong base. Interestingly, the reaction only proceeds at remote sites bearing secondary C(sp3)-H bonds (Scheme 2). Other directing groups which decrease the acidity of the N-H proton proved unreactive, including when these systems were run using conditions developed by Knowles10b relying on proton-coupled electron transfer (PCET; Table 1, entries 4–6). Additionally, all of the reactive components are necessary, as removal of light, the photocatalyst, Ni, ligand, or base all result in no product formation (Table 1, entries 7–11).</p><p>Having established that this strategy effectively forges a new C-C bond regioselectively at a distal C-H, we examined its scope. Aliphatic linear amides participate well and are monofunctionalized at the δ-methylene site (Scheme 3). Interestingly, even with the generation of a tertiary site at the δ-position, no second cross-coupling occurs at that site, which differs from the related capture of Michael acceptors.10a In the case of multiple functionalizable sites, secondary positions are selectively functionalized in preference over primary positions, 3fa. In cyclic systems, cross-coupling tends to occur in a trans relationship, probably due to the preference of radical capture of the active Ni catalyst on the sterically less hindered side of the ring (see SI, S5). This allows for alkylation of five and six-membered ring systems with high diastereoselectivity. In substrates featuring more activated C(sp3)-H bonds in positions other than those δ to the amide moiety, functionalization occurs solely at the unactivated, directed site in preference over the weaker, more reactive C(sp3)-H bonds. This allows for the tolerance of sulfonamides (3ja), ethers (3ia and 3la), arenes and alkenes (3oa and 3pa), as well as their adjacent activated C-H bonds, albeit with occasionally diminished yields.</p><p>The scope of the alkyl bromide coupling partner was also explored (Scheme 4). In nearly all cases, the alkyl halide is used in excess to the aliphatic amine, as the alkyl bromide is consumed in a competing reductive homo-coupling. This reductive homo-coupling outcompetes desired cross-coupling in low concentrations of amide, resulting in incomplete conversion of the amide but complete consumption of the alkyl bromide. Most aliphatic alkyl bromides, including ethyl, are tolerated under the reaction conditions (3kb). Other functionalities, including protected alcohols, 3kf, nitriles, 3kg, and alkenes, 3kh, also participate well in the reaction. Interestingly, benzylic bromides are not tolerated, presumably due to the competing off-cycle reduction by the photocatalyst which generates free benzyl radicals. Other heterocycles are tolerated, including dioxolanes, 3ki, phthalimides, 3kk, and pyrroles, 3kl. Aryl bromides are tolerated, 3km, as the primary alkyl bromide is considerably more reactive. Alkyl bromides bearing electronically diverse arene rings are well tolerated under the standard conditions (3kj −3ko). Currently, alkyl bromides are the only productive alkyl halides as chlorides, iodides, and pseudo-halides such as tosylates and triflates are either unreactive or lead to unproductive byproducts. Secondary and tertiary alkyl bromides show diminished yields under the optimized conditions and have thus far only shown modest levels of synthetic efficiency.14</p><p>Isotopically labeled tags can be easily incorporated under these conditions allowing for the isotopic differentiation of otherwise symmetrical groups. The reactivity can also be performed sequentially when there are more potential abstraction sites, allowing for the difunctionalization of 2k with two distinct coupling partners in excellent diastereoselectivity. Alternatively, orthogonal reactivity can be performed to generate quaternary carbon centers through the direct radical capture of a suitable radicalophile.10a This allows for the selective, mild generation of a distal quaternary carbon from a previously unactivated or functionalized methylene site, 4b.</p><p>A potential mechanism that accounts for the observed transformation and regioselectivity is represented by the catalyst system depicted in Scheme 5 (A). The trifluoroacetamide directing group, which is sufficiently acidic to be deprotonated by the phosphate base, is oxidized by an excited-state photocatalyst to generate a neutral amidyl radical, V. This amidyl radical can then abstract a hydrogen atom in a 1,5-HAT fashion from the δ-methylene to afford a carbon-centered radical at the distal position, VI. Meanwhile, a low-valent nickel complex, I, can oxidatively insert into the alkyl bromide to generate a NiIII alkyl species, II. This NiIII can be reduced to a NiII species by the reduced-state photocatalyst which can then trap the distal carbon radical to afford a transient NiIII, VII, which undergoes reductive elimination to afford the newly formed C-C bond and regenerate a catalytically active NiI.</p><p>It should be noted that this reaction proceeds when using either Ni(cod)2 or Ni(glyme)Cl2 as the precatalyst. When using a NiII precatalyst, as in the optimized conditions, a reduction of the catalyst to a low valent Ni species is likely required before entering the catalytic cycle. In the cases where a Ni0 catalyst is used, increased amount of reductively homocoupled alkyl bromide is observed, which likely helps generate the necessary NiI.15</p><p>One perplexing caveat of the reactivity exhibited by the 1,5 HAT/Nickel cross-coupling is the lack of observed reactivity at tertiary positions, especially considering that these positions exhibit a multitude of functionalization methods through 1,5-HAT strategies.13 This lack of reactivity also mirrors that of the more sterically demanding alkyl bromides, as the presumably more sterically encumbered Ni active species demonstrates diminished catalytic efficiency. Despite screening a number of ligands, none produced cross-coupled product in either set of conditions.</p><p>In order to more thoroughly probe the fate of the tertiary radical, several mechanistic studies were performed (Scheme 5). We tested this hypothesis through deuterium labeling of the amidyl N-H and conducting the reaction in deuterated solvent to ensure that any alkyl radical abstraction or reversible 1,5-HAT would incorporate deuterium into the product. The absence of deuterium in the product demonstrates that C-C bond formation is diastereoselective rather than a result of epimerization to the more stable diastereomer after alkylation. Due to the low reactivity of tertiary reactive sites, we hypothesize that the reductive elimination of the tertiary alkyl group to generate a quaternary carbon is relatively slow (C). Instead, it is possible that the long-lived NiIII intermediate could in turn be reduced by the photocatalyst and undergo elimination to generate Ni0 and an alkene.16 Olefinic products are observed with more sluggish substrates which supports the likelihood of this pathway. This was further corroborated by the fact that a variety of olefinic products, primarily the δ-ε alkene, are observed when utilizing substrate 1p. This reactivity of the generated tertiary position enables the formation of unsaturated elimination products that remain as inseparable impurities in some isolated products. Deuteration of the activated position (1c-d4) results in the conservation of the second deuteron in the alkylated product. This indicates that if 1,5-DAT occurs on the generated tertiary center then the process is reversible through either a retro-1,5-DAT or a Ni mediated delivery of a hydrogen atom to the alkyl radical through metalation, reduction, and protonation. It seems likely, therefore, that the 1,5-abstraction and Ni capture may occur in the case of δ-methines, but then results in elimination upon reduction or other unproductive side reactions.</p><p>We have demonstrated functionalization of distal unactivated C(sp3)-H bonds through a photoredox mediated 1,5-HAT and nickel cross-coupling strategy. This allows for the broad diversification of possible synthetic building blocks that can be selectively incorporated at an unactivated distal methylene site. Studies indicate that this coupling is selective for mono-alkylation, resulting in distal tertiary carbon centers.</p>","answer":"The functionalization of unactivated C(sp3)-H bonds poses a significant challenge due to their ubiquity and relative similarity in most organic frameworks. Herein, we describe the use of a combined photoredox and nickel catalytic system for the regioselective C(sp3)-C(sp3) coupling of unactivated C(sp3)-H bonds and alkyl bromides. Positional selectivity is dictated by a 1,5-hydrogen atom transfer (HAT) reaction by a pendent amide. Interception of this radical by a Ni catalyst allows distal alkylation to occur in good yield and excellent selectivity."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Retinal revascularisation in diabetic retinopathy.The case history of a 33-year-old diabetic patient who has had diabetes for 24 years is presented. When first seen in 1975 he had bilateral proliferative retinopathy with new vessels in the retinal periphery. He had large areas of capillary non-perfusion lateral to the macula in the right eye associated with the new vessels. Nine years later, after extensive repeated photocoagulation, revascularisation of large areas previously not perfused were seen. The vessels are in the plane of the retina and do not have the appearance of new vessels.","answer":"{\\"AnatomicalEntity\\": [\\"capillary\\", \\"retinal periphery\\", \\"right eye\\", \\"Retinal\\", \\"macula\\", \\"vessels\\", \\"retina\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Addressing dental fear in children with autism spectrum disorders : a randomized controlled pilot study using electronic screen media . BACKGROUND Dental care is a significant unmet health care need for children with autism spectrum disorders ( ASD ) . Many children with ASD do not receive dental care because of fear associated with dental procedures ; oftentimes they require general anesthesia for regular dental procedures , placing them at risk of associated complications . Many children with ASD have a strong preference for visual stimuli , particularly electronic screen media . The use of visual teaching materials is a fundamental principle in designing educational programs for children with ASD . PURPOSE To determine if an innovative strategy using 2 types of electronic screen media was feasible and beneficial in reducing fear and uncooperative behaviors in children with ASD undergoing dental visits . METHODS We conducted a randomized controlled trial at Boston Children 's Hospital dental clinic . Eighty ( 80 ) children aged 7 to 17 years with a known diagnosis of ASD and history of dental fear were enrolled in the study . Each child completed 2 preventive dental visits that were scheduled 6 months apart ( visit 1 and visit 2 ) . After visit 1 , subjects were randomly assigned to 1 of 4 groups : ( 1 ) group A , control ( usual care ) ; ( 2 ) group B , treatment ( video peer modeling that involved watching a DVD recording of a typically developing child undergoing a dental visit ) ; ( 3 ) group C , treatment ( video goggles that involved watching a favorite movie during the dental visit using sunglass-style video eyewear ) ; and ( 4 ) group D , treatment ( video peer modeling plus video goggles ) . Subjects who refused or were unable to wear the goggles watched the movie using a handheld portable DVD player . During both visits , the subject 's level of anxiety and behavior were measured using the Venham Anxiety and Behavior Scales . Analyses of variance and Fisher 's exact tests compared baseline characteristics across groups . Using intention to treat approach , repeated measures analyses were employed to test whether the outcomes differed significantly : ( 1 ) between visits 1 and 2 within each group and ( 2 ) between each intervention group and the control group over time ( an interaction ) . RESULTS Between visits 1 and 2 , mean anxiety and behavior scores decreased significantly by 0.8 points ( P = .03 ) for subjects within groups C and D. Significant changes were not observed within groups A and B . Mean anxiety and behavior scores did not differ significantly between groups over time , although group A versus C pairwise comparisons showed a trend toward significance ( P = .06 ) . CONCLUSION These findings suggest that certain electronic screen media technologies may be useful tools for reducing fear and uncooperative behaviors among children with ASD undergoing dental visits . Further studies are needed to assess the efficacy of these strategies using larger sample sizes . Findings from future studies could be relevant for nondental providers who care for children with ASD in other medical settings .","answer":"{\\"Intervention\\": [\\"video goggles that involved watching a favorite movie during the dental visit using sunglass-style video eyewear\\", \\"treatment (\\", \\") ;\\", \\"video peer modeling plus video goggles\\", \\")\\", \\"video peer modeling that involved watching a DVD recording of a typically developing child undergoing a dental visit\\", \\"electronic screen media\\", \\"(\\", \\"control ( usual care )\\"], \\"Outcome\\": [\\"Mean anxiety and behavior scores\\", \\"reducing fear and uncooperative behaviors\\", \\"mean anxiety and behavior scores\\"], \\"Participant\\": [\\"Eighty ( 80 )\\", \\"aged 7 to 17 years\\", \\"children\\", \\"autism spectrum disorders ( ASD )\\", \\"dental fear in children with autism spectrum disorders :\\", \\"ASD\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Blind separation of auditory event-related brain responses into independent components.Averaged event-related potential (ERP) data recorded from the human scalp reveal electroencephalographic (EEG) activity that is reliably time-locked and phase-locked to experimental events. We report here the application of a method based on information theory that decomposes one or more ERPs recorded at multiple scalp sensors into a sum of components with fixed scalp distributions and sparsely activated, maximally independent time courses. Independent component analysis (ICA) decomposes ERP data into a number of components equal to the number of sensors. The derived components have distinct but not necessarily orthogonal scalp projections. Unlike dipole-fitting methods, the algorithm does not model the locations of their generators in the head. Unlike methods that remove second-order correlations, such as principal component analysis (PCA), ICA also minimizes higher-order dependencies. Applied to detected-and undetected-target ERPs from an auditory vigilance experiment, the algorithm derived ten components that decomposed each of the major response peaks into one or more ICA components with relatively simple scalp distributions. Three of these components were active only when the subject detected the targets, three other components only when the target went undetected, and one in both cases. Three additional components accounted for the steady-state brain response to a 39-Hz background click train. Major features of the decomposition proved robust across sessions and changes in sensor number and placement. This method of ERP analysis can be used to compare responses from multiple stimuli, task conditions, and subject states.","answer":"{\\"AnatomicalEntity\\": [\\"head\\", \\"scalp\\", \\"brain\\"]}"},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: It is reported that the virus might be bat origin [2] , and the transmission of the virus might related to a seafood market (Huanan Seafood Wholesale Market) exposure [3, 4] . The genetic features and some clinical findings of the infection have been reported recently [4] [5] [6] . Potentials for international spread via commercial air travel had been assessed [7] . Public health concerns are being paid globally on how many people are infected and suspected. Therefore, it is urgent to develop a mathematical model to estimate the transmissibility and dynamic of the transmission of the virus. There were several researches focusing on mathematical modelling [3, 8] . These researches focused on calculating the basic reproduction number (R 0 ) by using the serial intervals and intrinsic growth rate [3, 9, 10] , or using ordinary differential equations and Markov Chain Monte Carlo methods [8] . However, the bat origin and the transmission route form the seafood market to people were not considered in the published models. In this study, we developed a Bats-Hosts-Reservoir-People (BHRP) transmission network model for simulating the potential transmission from the infection source (probably be bats) to the human infection. Since the Bats-Hosts-Reservoir network was hard to explore clearly and public concerns were focusing on the transmission from Huanan Seafood Wholesale Market (reservoir) to people, we simplified the model as Reservoir-People (RP) transmission network model, and R 0 was calculated based on the RP model to assess the transmissibility of the SARS-CoV-2. The reported cases of SARS-CoV-2, which have been named as COVID-19, were collected for the modelling study from a published literature [3] . As reported by Li et al. [3] , the onset date of the first case was on 7 December, 2020, and the seafood market was closed on 1 January, 2020 [11] . The epidemic curve from 7 December, 2019 to 1 January, 2020 was collected for our study, and the simulation time step was 1 day. fourth-order Runge-Kutta method, with tolerance set at 0.001, was used to perform curve fitting. While the curve fitting is in progress, Berkeley Madonna displays the root mean square deviation between the data and best run so far. The coefficient of determination (R 2 ) was employed to assess the goodness-of-fit. SPSS 13.0 (IBM Corp., Armonk, NY, USA) was employed to calculate the R 2 . The Bats-Hosts-Reservoir-People (BHRP) transmission network modelThe BHRP transmission network model was posted to bioRxiv on 19 January, 2020 [12] . We assumed that the virus transmitted among the bats, and then transmitted to unknown hosts (probably some wild animals). The hosts were hunted and sent to the seafood market which was defined as the reservoir of the virus. People exposed to the market got the risks of the infection (Fig. 1) . The BHRP transmission network model was based on the following assumptions or facts:a) The bats were divided into four compartments: susceptible bats (S B ), exposed bats (E B ), infected bats (I B ), and removed bats (R B ). The birth rate and death rate of bats were defined as n B and m B . In this model, we set Ʌ B = n B × N B as the number of the newborn bats where N B refer to the total number of bats. The incubation period of bat infection was defined as 1/ω B and the infectious period of bat infection was defined as 1/γ B . The S B will be infected through sufficient contact with I B , and the transmission rate was defined as β B . b) The hosts were also divided into four compartments: susceptible hosts (S H ), exposed hosts (E H ), infected hosts (I H ), and removed hosts (R H ). The birth rate and death rate of hosts were defined as n H and m H . In this model, we set Ʌ H = n H × N H where N H refer to the total number of hosts. The incubation period of host infection was defined as 1/ω H and the infectious period of host infection was defined as 1/γ H . The S H will be infected through sufficient contact with I B and I H , and the transmission rates were defined as β BH and β H , respectively. c) The SARS-CoV-2 in reservoir (the seafood market) was denoted as W. We assumed that the retail purchases rate of the hosts in the market was a, and that the prevalence of SARS-CoV-2 in the purchases was I H /N H , therefore, the rate of the SARS-CoV-2 in W imported form the hosts was aWI H /N H where N H was the total number of hosts. We also assumed that symptomatic infected people and asymptomatic infected people could export the virus into W with the rate of μ P and μ' P , although this assumption might occur in a low probability. The virus in W will subsequently leave the W compartment at a rate of εW, where 1/ε is the lifetime of the virus. d) The people were divided into five compartments:susceptible people (S P ), exposed people (E P ), symptomatic infected people (I P ), asymptomatic infected people (A P ), and removed people (R P ) including recovered and death people. The birth rate and death rate of people were defined as n P and m P . In this model, we set Ʌ P = n P × N P where N P refer to the total number of people. The incubation period and latent period of human infection was defined as 1/ω P and 1/ω' P . The infectious period of I P and A P was defined as 1/γ P and 1/γ' P . The proportion of asymptomatic infection was defined as δ P . The S P will be infected through sufficient contact with W and I P , and the transmission rates were defined as β W and β P , respectively. We also assumed that the transmissibility of A P was κ times that of I P , where 0 ≤ κ ≤ 1. The parameters of the BHRP model were shown in Table 1 . We assumed that the SARS-CoV-2 might be imported to the seafood market in a short time. Therefore, we added the further assumptions as follows:a) The transmission network of Bats-Host was ignored. b) Based on our previous studies on simulating importation [13, 14] , we set the initial value of W as following impulse function:In the function, n, t 0 and t i refer to imported volume of the SARS-CoV-2 to the market, start time of the simulation, and the interval of the importation. Therefore, the BHRP model was simplified as RP model and is shown as follows:During the outbreak period, the natural birth rate and death rate in the population was in a relative low level. However, people would commonly travel into and out from Wuhan City mainly due to the Chinese New Year holiday. Therefore, n P and m P refer to the rate of people traveling into Wuhan City and traveling out from Wuhan City, respectively. In the model, people and viruses have different dimensions. Based on our previous research [15] , we therefore used the following sets to perform the normalization:In the normalization, parameter c refers to the relative shedding coefficient of A P compared to I P . The normalized RP model is changed as follows:The transmissibility of the SARS-CoV-2 based on the RP modelIn this study, we used the R 0 to assess the transmissibility of the SARS-CoV-2. Commonly, R 0 was defined as the expected number of secondary infections that result from introducing a single infected individual into an otherwise susceptible population [13, 16, 17] . If R 0 > 1, the outbreak will occur. If R 0 < 1, the outbreak will toward an end. In this study, R 0 was deduced from the RP model by the next generation matrix approach [18] . The multiple of the transmissibility of A P to that of I P . The parameters were estimated based on the following facts and assumptions:a) The mean incubation period was 5.2 days (95% confidence interval [CI]: 4.1-7.0) [3] . We set the same value (5.2 days) of the incubation period and the latent period in this study. Thus, ω P = ω' P = 0.1923. b) There is a mean 5-day delay from symptom onset to detection/hospitalization of a case (the cases detected in Thailand and Japan were hospitalized from 3 to 7 days after onset, respectively) [19] [20] [21] . The duration from illness onset to first medical visit for the 45 patients with illness onset before January 1 was estimated to have a mean of 5.8 days (95% CI: 4.3-7.5) [3] . In our model, we set the infectious period of the cases as 5.8 days. Therefore, γ P = 0.1724. c) Since there was no data on the proportion of asymptomatic infection of the virus, we simulated the baseline value of proportion of 0.5 (δ P = 0.5). d) Since there was no evidence about the transmissibility of asymptomatic infection, we assumed that the transmissibility of asymptomatic infection was 0.5 times that of symptomatic infection (κ = 0.5), which was the similar value as influenza [22] . We assumed that the relative shedding rate of A P compared to I P was 0.5. Thus, c = 0.5. e) Since 14 January, 2020, Wuhan City has strengthened the body temperature detection of passengers leaving Wuhan at airports, railway stations, long-distance bus stations and passenger terminals. As of January 17, a total of nearly 0.3 million people had been tested for body temperature [23] . In Wuhan, there are about 2.87 million mobile population [24] . We assumed that there was 0.1 million people moving out to Wuhan City per day since January 10, 2020, and we believe that this number would increase (mainly due to the winter vacation and the Chinese New Year holiday) until 24 January, 2020. This means that the 2.87 million would move out from Wuhan City in about 14 days. Therefore, we set the moving volume of 0.2 million per day in our model. Since the population of Wuhan was about 11 million at the end of 2018 [25] , the rate of people traveling out from Wuhan City would be 0.018 (0.2/11) per day. However, we assumed that the normal population mobility before January 1 was 0.1 times as that after January 10. Therefore, we set the rate of people moving into and moving out from Wuhan City as 0.0018 per day (n P = m P = 0.0018). f) The parameters b P and b W were estimated by fitting the model with the collected data. g) At the beginning of the simulation, we assumed that the prevalence of the virus in the market was 1/100000. h) Since the SARS-CoV-2 is an RNA virus, we assumed that it could be died in the environment in a short time, but it could be stay for a longer time (10 days) in the unknown hosts in the market. We set ε = 0.1. In this study, we assumed that the incubation period (1/ ω P ) was the same as latent period (1/ω' P ) of human infection, thus ω P = ω' P . Based on the equations of RP model, we can get the disease free equilibrium point as: In the matrix:By the next generation matrix approach, we can get the next generation matrix and R 0 for the RP model: The R 0 of the normalized RP model is shown as follows:Our modelling results showed that the normalized RP model fitted well to the reported SARS-CoV-2 cases data (R 2 = 0.512, P < 0.001) (Fig. 2) . The value of R 0 was estimated of 2.30 from reservoir to person, and from person to person and 3.58 from person to person which means that the expected number of secondary infections that result from introducing a single infected individual into an otherwise susceptible population was 3.58. In this study, we developed RP transmission model, which considering the routes from reservoir to person and from person to person of SARS-CoV-2 respectively. We used the models to fit the reported data in Wuhan City, China from published literature [3] . The simulation results showed that the R 0 of SARS-CoV-2 was 3.58 from person to person. There was a research showed that the R 0 of SARS-CoV-2 was 2.68 (95% CI: 2.47-2.86) [8] . Another research showed that the R 0 of SARS-CoV-2 was 2.2 (95% CI: 1.4-3.9) [3] . The different values might be due to the different methods. The methods which Li et al. employed were based on the epidemic growth rate of the epidemic curve and the serial interval [3] . Our previous study showed that several methods could be used to calculate the R 0 based on the epidemic growth rate of the epidemic curve and the serial interval, and different methods might result in different values of R 0 [26] . Our results also showed that the R 0 of SARS-CoV-2 was 2.30 from reservoir to person which was lower than that of person to person. This means that the transmission route was mainly from person to person rather than from reservoir to person in the early stage of the transmission in Wuhan City. However, this result was based on the limited data from a published literature, and it might not show the real situation at the early stage of the transmission. Researches showed that the R 0 of severe acute respiratory syndrome (SARS) was about 2.7-3.4 or 2-4 in Hong Kong, China [27, 28] . Another research found that the R 0 of SARS was about 2.1 in Hong Kong, China, 2.7 in Singapore, and 3.8 in Beijing, China [29] . Therefore, we believe that the commonly acceptable average value of the R 0 of SARS might be 2.9 [30] . The transmissibility of the Middle East respiratory syndrome (MERS) is much lower than SARS. The reported value of the R 0 of MERS was about 0.8-1.3 [31] , with the inter-human transmissibility of the disease was about 0.6 or 0.9 in Middle East countries [32] . However, MERS had a high transmissibility in the outbreak in the Republic of Korea with the R 0 of 2.5-7.2 [33, 34] . Therefore, the transmissibility of SARS-CoV-2 might be higher than MERS in the Middle East countries, similar to SARS, but lower than MERS transmitted in the Republic of Korea. To contain the transmission of the virus, it is important to decrease R 0Question: What is important for containing the transmission?","answer":"to decrease R 0"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:Accumulating evidence shows that microbial co-infection increases the risk of disease severity in humans. There have been few studies about SARS-CoV-2 co-infection with other pathogens. In this retrospective study, 257 laboratory-confirmed COVID-19 patients in Jiangsu Province were enrolled from January 22 to February 2, 2020. They were re-confirmed by real-time RT-PCR and tested for 39 respiratory pathogens. In total, 24 respiratory pathogens were found among the patients, and 242 (94.2 %) patients were co-infected with one or more pathogens. Bacterial co-infections were dominant in all COVID-19 patients, Streptococcus pneumoniae was the most common, followed by Klebsiella pneumoniae and Haemophilus influenzae. The highest and lowest rates of co-infections were found in patients aged 15-44 and below 15, respectively. Most co-infections occurred within 1-4 days of onset of COVID-19 disease. In addition, the proportion of viral co-infections, fungal co-infections and bacterial-fungal co-infections were the highest severe COVID-19 cases. These results will provide a helpful reference for diagnosis and clinical treatment of COVID-19 patients.","answer":"[\\"Diagnosis\\", \\"Treatment\\"]"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: Which loss-of-function ABCC8 mutation is associated with Pulmonary Arterial Hypertension (PAH)?Context: Exome sequencing was performed to identify novel genes in a cohort of 99 pediatric and 134 adult-onset group I PAH patients. Novel rare variants in the gene identified were independently identified in a cohort of 680 adult-onset patients. Variants were expressed in COS cells and function assessed by patch-clamp and rubidium flux analysis.RESULTS: We identified a de novo novel heterozygous predicted deleterious missense variant c.G2873A (p.R958H) in ABCC8 in a child with idiopathic PAH. We then evaluated all individuals in the original and a second cohort for rare or novel variants in ABCC8 and identified 11 additional heterozygous predicted damaging ABCC8 variants. ABCC8 encodes SUR1 (sulfonylurea receptor 1)-a regulatory subunit of the ATP-sensitive potassium channel. We observed loss of ATP-sensitive potassium channel function for all ABCC8 variants evaluated and pharmacological rescue of all channel currents in vitro by the SUR1 activator, diazoxide.CONCLUSIONS: Novel and rare missense variants in ABCC8 are associated with PAH. Identified ABCC8 mutations decreased ATP-sensitive potassium channel function, which was pharmacologically recovered.","answer":"c.G2873A, or p.R958H"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Effect of upper arm brachial basilic and prosthetic forearm arteriovenous fistula on left ventricular hypertrophy . BACKGROUND Creation of an arteriovenous fistula ( AVF ) may increase left ventricular hypertrophy in the hemodialysis population . Aim of this study was to compare the effects of a brachial-basilic ( BB ) AVF and the prosthetic brachial-antecubital forearm loop access ( PTFE ) on cardiac performance . METHODS Patients were randomized to receive BB-AVF or prosthetic brachial-antecubital forearm loop access . Before and three months after AVF creation patients underwent an echocardiographic examination . Mann-Whitney U-test was used to compare relative increase between the measured cardiac parameters for the two groups . RESULTS Twenty-seven patients participated in the study . The relative increase in left ventricular parameters was not significantly different between the two groups . Only left ventricular end-diastolic diameter tended to be of significance . Mean blood flow through the brachial artery was 1680+/-156 and 1450+/-221 mL/min three months after surgery for the PTFE and the BB-AVF group , respectively . CONCLUSION After three months of follow-up , changes in cardiac structure were comparable between patients with BB and PTFE AVFs . Also access flow was comparable at this time . In general , the effects of creation of a fistula on LV structure were limited . Longer follow up time may be needed to explore the long term effects of different vascular accesses on cardiac function .","answer":"{\\"Intervention\\": [\\"BB-AVF\\", \\"brachial-basilic ( BB ) AVF\\", \\"prosthetic brachial-antecubital forearm loop access\\"], \\"Outcome\\": [\\"changes in cardiac structure\\", \\"cardiac function .\\", \\"left ventricular hypertrophy\\", \\"left ventricular end-diastolic diameter\\", \\"measured cardiac parameters\\", \\"left ventricular parameters\\", \\"cardiac performance .\\", \\"Mean blood flow\\", \\"Mann-Whitney U-test\\", \\"access flow\\"], \\"Participant\\": [\\"Twenty-seven patients participated in the study .\\", \\"AVF creation patients\\", \\"patients with BB and PTFE AVFs .\\", \\"hemodialysis population .\\"]}"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Il-6 trans-signaling induces plasminogen activator inhibitor-1 from vascular endothelial cells in cytokine development syndromeAbstract:Cytokine release syndrome (CRS) is a life-threatening complication induced by systemic inflammatory responses to infections, including bacteria and chimeric antigen receptor T cell therapy.There are currently no immunotherapies with proven clinical efficacy and understanding of the molecular mechanisms of CRS pathogenesis is limited.Here, we found that patients diagnosed with CRS from sepsis, acute respiratory distress syndrome (ARDS), or burns showed common manifestations: strikingly elevated levels of the four proinflammatory cytokines interleukin (IL)-6, IL-8, monocyte chemotactic protein-1 (MCP-1), and IL-10 and the coagulation cascade activator plasminogen activator inhibitor-1 (PAI-1).Our in vitro data indicate that endothelial IL-6 trans-signaling formed an inflammation circuit for robust IL-6, IL-8, and MCP-1 production and promoted PAI-1 production; additionally, an IL-6 signaling blockade by the human monoclonal antibody tocilizumab blunted endothelial cell activation.Plasma from severe COVID-19 patients similarly exhibited increased IL-6, IL-10, and MCP-1 levels, but these levels were not as high as those in patients with CRS from other causes.In contrast, the PAI-1 levels in COVID-19 patients were as highly elevated as those in patients with bacterial sepsis or ARDS.Tocilizumab treatment decreased the PAI-1 levels and alleviated critical illness in severe COVID-19 patients.Our findings suggest that distinct levels of cytokine production are associated with CRS induced by bacterial infection and COVID-19, but both CRS types are accompanied by endotheliopathy through IL-6 trans-signaling.Thus, the present study highlights the crucial role of IL-6 signaling in endothelial dysfunction during bacterial infection and COVID-19.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Our in vitro data indicate that endothelial IL-6 trans-signaling formed an inflammation circuit for robust IL-6, IL-8, and MCP-1 production and promoted PAI-1 production; additionally, an IL-6 signaling blockade by the human monoclonal antibody tocilizumab blunted endothelial cell activation.\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Kinetic and stereochemical studies on novel inactivators of C-terminal amidation. C-terminal amidation, a required post-translational modification for the bioactivation of many neuropeptides, entails sequential enzymic action by peptidylglycine alpha-mono-oxygenase (PAM, EC 1.14.17.3) and peptidylamidoglycolate lyase (PGL, EC 4.3.2.5). Here we introduce novel compounds in which an olefinic functionality is incorporated into peptide analogues as the most potent turnover-dependent inactivators of PAM. Kinetic parameters for PAM inactivation by 4-oxo-5-acetamido-6-phenyl-hex-2-enoic acid and 4-oxo-5-acetamido-6- (2-thienyl) -hex-2-enoic acid were obtained by using both the conventional dilution assay method and the more complex progress curve method. The results obtained from the progress curve method establish that these compounds exhibit the kinetic characteristics of pure competitive inactivators (i.e. no ESI complex forms during inactivation). On the basis of k (inact) /K (i) values, 4-oxo-5-acetamido-6- (2-thienyl) -hex-2-enoic acid is almost two orders of magnitude more potent than benzoylacrylate, a chemically analogous olefinic inactivator that lacks the peptide moiety. Stereochemical studies established that PAM inactivation by 4-oxo-5-acetamido-6- (2-thienyl) -hex-2-enoic acid is stereospecific with respect to the moiety at the P (2) position, which is consistent with previous results with substrates and reversible inhibitors. In contrast, 2, 4-dioxo-5-acetamido-6-phenylhexanoic acid, which is a competitive inhibitor with respect to ascorbate, exhibits a low degree of stereospecificity in binding to the ascorbate sites of both PAM and dopamine-beta-hydroxylase.","answer":"[[\\"4-oxo-5-acetamido-6-phenyl-hex-2-enoic acid and 4-oxo-5-acetamido-6- (2-thienyl) -hex-2-enoic acid\\", \\"INHIBITOR\\", \\"PAM\\"], [\\"4-oxo-5-acetamido-6- (2-thienyl) -hex-2-enoic acid\\", \\"INHIBITOR\\", \\"PAM\\"], [\\"2 \\", \\"4-dioxo-5-acetamido-6-phenylhexanoic acid\\", \\"INHIBITOR\\", \\"PAM\\"], [\\"2 \\", \\"4-dioxo-5-acetamido-6-phenylhexanoic acid\\", \\"INHIBITOR\\", \\"dopamine-beta-hydroxylase\\"]]"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:Figure3","answer":"[]"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Neutralization of sars-cov-2 lineage b.1.1.7 pseudovirus by bnt162b2 vaccine-elicited human sera.Abstract:Recently, a new SARS-CoV-2 lineage called B.1.1.7 has emerged in the United Kingdom that was reported to spread more efficiently than other strains.This variant has an unusually large number of mutations with 10 amino acid changes in the spike protein, raising concerns that its recognition by neutralizing antibodies may be affected.Here, we investigated SARS-CoV-2-S pseudoviruses bearing either the Wuhan reference strain or the B.1.1.7 lineage spike protein with sera of 16 participants in a previously reported trial with the mRNA-based COVID-19 vaccine BNT162b2.The immune sera had equivalent neutralizing titers to both variants.These data, together with the combined immunity involving humoral and cellular effectors induced by this vaccine, make it unlikely that the B.1.1.7 lineage will escape BNT162b2-mediated protection.","answer":"{\\"verdict\\": \\"SUPPORT\\", \\"evidence\\": [\\"Recently, a new SARS-CoV-2 lineage called B.1.1.7 has emerged in the United Kingdom that was reported to spread more efficiently than other strains.\\", \\"Here, we investigated SARS-CoV-2-S pseudoviruses bearing either the Wuhan reference strain or the B.1.1.7 lineage spike protein with sera of 16 participants in a previously reported trial with the mRNA-based COVID-19 vaccine BNT162b2.\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: The LIM protein complex establishes a retinal circuitry of visual adaptation by regulating Pax6 α-enhancer activity}Article:Abstract:The visual responses of vertebrates are sensitive to the overall composition of retinal interneurons including amacrine cells, which tune the activity of the retinal circuitry. The expression of Paired-homeobox 6( PAX6) is regulated by multiple cis-DNA elements including the intronic α-enhancer, which is active in GABAergic amacrine cell subsets. Here, we report that the transforming growth factor ß1-induced transcript 1 protein( Tgfb1i1) interacts with the LIM domain transcription factors Lhx3 and Isl1 to inhibit the α-enhancer in the post-natal mouse retina. Tgfb1i1-/- mice show elevated α-enhancer activity leading to overproduction of Pax6ΔPD isoform that supports the GABAergic amacrine cell fate maintenance. Consequently, the Tgfb1i1-/- mouse retinas show a sustained light response, which becomes more transient in mice with the auto-stimulation-defective Pax6ΔPBS/ΔPBS mutation. Together, we show the antagonistic regulation of the α-enhancer activity by Pax6 and the LIM protein complex is necessary for the establishment of an inner retinal circuitry, which controls visual adaptation.Introduction:The retina is a primary sensory tissue that receives light stimulus and converts it into electrical signals, which are then sent to the brain for further processing. After light detection by rod and cone photoreceptors, the first step in visual processing occurs in bipolar cells that are either stimulated or inhibited by light-absorbed photoreceptors( Masland, 2012). The activities of bipolar cells are then tuned by horizontal cells while they receive visual input from the photoreceptors and by amacrine cells while they deliver the signals to retinal ganglion cells( RGCs)( Hoon et al., 2014; Masland, 2012). The amacrine cells do not simply convey the signals from bipolar cells, but they also invert the signals by releasing inhibitory neurotransmitters such as γ-aminobutyric acid( GABA) and glycine. Therefore, even subtle changes in the composition and connectivity of amacrine cell subsets might alter the output of the retina, modifying the visual information sent to the brain. The neurons of the vertebrate retina develop in an ordered fashion from multipotent retinal progenitor cells( RPCs)( Cepko, 2014). A number of transcription factors with precise temporal and spatial expression patterns control the composition of retinal neurons via the hierarchical and reciprocal regulation of other transcription factor expression( Zagozewski et al., 2014). Thus, the alterations of transcription factors that specify retinal neuron subtypes should modify visual output of mature retina. Those transcription factors include Pax6 in amacrine cells( Marquardt et al., 2001), Vsx2 in bipolar cells( Liu et al., 1994), Otx2 in bipolar cells and photoreceptors( Koike et al., 2007; Nishida et al., 2003), and Lhx2 and Sox2 in Müller glia and certain amacrine subtypes( de Melo et al., 2012; Gordon et al., 2013; Lin et al., 2009). These transcription factors are not only expressed in the earlier optic structures to play critical roles in the eye and brain development( Danno et al., 2008; Glaser et al., 1994; Yun et al., 2009), but also in the mature retinal neurons to support the survival and functions of the neurons( de Melo et al., 2012; Kim et al., 2015). However, the mechanisms underlying the recurrent expression of transcription factors in the retinal lineage are still largely unknown. Pax6 is one of the earliest transcription factors expressed in the eye field, and as such, it is considered as a master regulator of eye development( Ashery-Padan and Gruss, 2001; Hanson and Van Heyningen, 1995). Pax6 contains two DNA-binding domains—a paired domain( PD) and a homeodomain( HD)—linked via a glycine-rich domain, and activates target gene transcription through its C-terminal proline-, serine-, and threonine-rich( PST) domain( Epstein et al., 1994; Xu et al., 1999a). Multiple cis-regulatory elements govern Pax6 expression in various mouse tissues( Kammandel et al., 1999; Xu et al., 1999b). The ‘α-enhancer’, located within intron 4 of the Pax6 gene, is active in the retina from embryo to adult( Kammandel et al., 1999; Marquardt et al., 2001; Plaza et al., 1995). This retina-specific enhancer activity sustains in RPCs in the peripheral retina of the embryos and regulates neuronal differentiation in a context-dependent manner( Marquardt et al., 2001). In the mature eye, the α-enhancer is active in cells of the ciliary body and amacrine cells of the retina( Marquardt et al., 2001). The α-enhancer contains multiple binding sites for transcription factors, including the auto-stimulatory Pax6( Kammandel et al., 1999), the stimulatory Msx1( Kammandel et al., 1999) and Pou4f2( Plaza et al., 1999), and the inhibitory Pax2( Kammandel et al., 1999; Schwarz et al., 2000) and Vax1( Mui et al., 2005). Although the inhibition of α-enhancer activity by Vax1 has been shown to be crucial for the development of the retina-optic stalk border( Mui et al., 2005), the roles the other transcription factors that bind the α-enhancer in the retina remain unclear. In this study, we show that regulation of Pax6 expression through the α-enhancer fine tunes amacrine cell subtype composition, and consequently, the visual output of the retina.Discussion:Transcription factors frequently act in combination, allowing relatively few to generate the tremendous cellular diversity of the nervous system( Jessell, 2000). Especially, the ‘LIM code’ mixes and matches LIM domain-containing transcription factors to direct tissue- and cell-specific gene expression( Gill, 2003; Shirasaki and Pfaff, 2002). Lhx3, for example, specifies motor neuron cell fate in the spinal cord by forming a hetero-hexameric complex with Isl1 and nuclear LIM interactor( NLI) for the binding to the promoter of the Mnx1/Hb9 gene, whereas it specifies V2 interneuron cell fate by forming a hetero-tetrameric complex with NLI at the promoter of the Vsx2/Chx10 gene( Thaler et al., 2002). Given that the various LIM homeodomain transcription factors, including Lhx2, Lhx3, Lhx4, and Lhx9, share a consensus target sequence( Gehring et al., 1994), we speculate Isl1 partners with different LIM homeodomain transcription factors in a cell-context-dependent manner. In contrast to its relationship with Lhx3, Isl1 cooperates with Lhx2 to activate the α-enhancer in cultured cell lines( data not shown). However, this is unlikely to occur in vivo, because Lhx2 and Isl1 are expressed mutually exclusively in RPCs( Lhx2) and post-mitotic RGCs( Isl1) of the embryonic mouse retina, in GABAergic( Lhx2) and cholinergic amacrine cells( Isl1) in the mature retina, as well as in Müller glia( Lhx2) and ON bipolar cells( Isl1)( Balasubramanian et al., 2014; Elshatory et al., 2007; Gordon et al., 2013; Pan et al., 2008). Moreover, Lhx2flox/flox;P6α-Cre retinas, which lack Lhx2 expression in the Cre-active lineages( Gordon et al., 2013), show no change in the number of Pax6 α-enhancer-active cells( data not shown). This suggests Lhx2 may be dispensable for the activation of the Pax6 α-enhancer in the mouse retina. We propose that a Tgfb1i1 dimer links Isl1 and Lhx3 to form a hetero-tetrameric complex that represses the Pax6 α-enhancer( Figures 2 and 3). The effects of Tgfb1i1 on the α-enhancer could be achieved by blocking Pax6’s access the PBS sequence( Figure 3G, H). Alternatively, Tgfb1i1 may also recruit transcriptional co-repressors, such as NCoR( nuclear receptor co-repressor)( Heitzer and DeFranco, 2006), to the Pax6 α-enhancer. These negative effects of Tgfb1i1 on the Pax6 α-enhancer can be antagonized by Lmo4, which is persistently co-expressed with Pax6 in the retina and interferes with the interactions between Tgfb1i1 and Lhx3 and/or Isl1( Duquette et al., 2010)( Figures 2D and 3D). Retinas lacking Lmo4 have fewer GABAergic amacrine cells than controls( Duquette et al., 2010), which suggests Lmo4 may positively affect Pax6 α-enhancer-dependent GABAergic amacrine cell fate determination by inhibiting the formation of the LIM complex. However, the antagonistic regulation of the LIM complex by Tgfb1i1 and Lmo4 could not be applied to OFF bipolar cell fate determination, since OFF bipolar cell numbers are decreased commonly in Tgfb1i1−/− and Lmo4-cko mouse retinas. Our results suggest that Tgfb1i1 and Lmo4 might involve in the development of different OFF bipolar cell subsets. The numbers of Bhlhb5-positive OFF bipolar cell subsets were not altered significantly in Tgfb1i1−/− mouse retinas( Figure 4E, F), in contrast to a significant decrease in Lmo4-cko mouse retinas. In addition to its canonical form, two alternative forms of Pax6, Pax6( 5a) and Pax6ΔPD, are produced by alternative splicing and internal transcription initiation, respectively( Epstein et al., 1994; Mishra et al., 2002). Pax6ΔPD does not affect Pax6 target gene expression via the conserved PBS( data not shown). Instead, as previously reported( Mikkola et al., 2001), Pax6ΔPD may potentiate the expression of Pax6 target genes by interacting with full-length Pax6. This facilitation of Pax6-induced gene transcription by Pax6ΔPD may also occur with the Pax6 α-enhancer, resulting in a feed-forward activation of the α-enhancer. Alternatively, it may bind another promoter element containing the Pax6 homeodomain target DNA sequence( TAATT( /C) NA( /C) ATTA). Therefore, future studies will be needed to identify the targets of Pax6ΔPD in RPCs and post-mitotic retinal neurons. This will provide a full understanding of the distinctive roles Pax6 and Pax6ΔPD play in the retina. Although the mechanisms of light adaptation and re-sensitization in the photoreceptors are fairly well-understood, how the inner retina contributes to these mechanisms is less clear. Acting downstream of rod bipolar cells that deliver visual signals from rod photoreceptors, A17 GABAergic amacrine cells provide a direct feedback inhibition to the rod bipolar cells( Chávez et al., 2010). In parallel, an unidentified subset of GABAergic amacrine cells is also proposed to inhibit rod bipolar cells at the downstream of ON-cone bipolar cells, which can be activated by AII amacrine cells in the rod pathway as well as by daylight( Demb and Singer, 2012; Eggers et al., 2013). GABAergic inhibition to the rod bipolar cells could be reduced in Tgfb1i1−/− mouse retinas, leading to sustained ON responses( Figure 7A). Conversely, the ON pathway in Pax6ΔPBS/ΔPBS mouse retinas is activated more transiently and is also more readily re-activated by subsequent visual stimuli( Figure 7D). Therefore, the P6α amacrine cells might attenuate those GABAergic inhibitions to rod bipolar cells and prevent premature inactivation of rod pathway. However, future studies should identify molecular and electrophysiological identities of the P6α amacrine cells and their pre- and post-synaptic partners to fully understand this visual adaptive circuits in the inner retina.","answer":"The retina is a light-sensitive layer of tissue that lines the inside of the eye . This tissue is highly organized and comprises a variety of different nerve cells , including amacrine cells . Together , these cells process incoming light and then trigger electrical signals that travel to the brain , where they are translated into an image . Changes in the nerve cell composition of the retina , or in how the cells connect to each other , can alter the visual information that travels to the brain . The nerve cells of the retina are formed before a young animal opens its eyes for the first time . Proteins called transcription factors – which regulate the expression of genes – tightly control how the retina develops . For example , a transcription factor called Pax6 drives the development of amacrine cells . Several other transcription factors control the production of Pax6 by binding to a section of DNA known as the “α-enhancer” . However , it is not clear how regulating Pax6 production influences the development of specific sets of amacrine cells . Kim et al . reveal that a protein known as Tgfb1i1 interacts with two transcription factors to form a “complex” that binds to the α-enhancer and blocks the production of a particular form of Pax6 . In experiments performed in mice , the loss of Tgfb1i1 led to increased production of this form of Pax6 , which resulted in the retina containing more of a certain type of amacrine cell that produce a molecule called GABA . Mice lacking Tgfb1i1 show a stronger response to light and are therefore comparable to people who are too sensitive to light . On the other hand , mice with a missing a section of the α-enhancer DNA have fewer amacrine cells releasing GABA and become less sensitive to light and are comparable to people who have difficulty detecting weaker light signals . The findings of Kim et al . suggest that an individual’s sensitivity to light is related , at least in part , to the mixture of amacrine cells found in their retina , which is determined by certain transcription factors that target the α-enhancer ."},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:we are grateful to j. sandweiss for suggesting that we investigate this problem .this work was supported by the u.s .department of energy under grant de - fg02 - 87er40328 .20    see , for example : _ proceedings of quark matter  96 _ , nucl . phys . * a610 * , ( 1996 ) .m. schwartz ( unpublished ) .g. baym , g. friedman , r. j. hughes , and b. v. jacak , phys .d * 48 * , r3957 ( 1993 ) .k. kajantie , j. kapusta , l. mclerran , and a. mekjian , phys .d * 34 * , 2746 ( 1986 ) .j. d. bjorken , phys .d * 27 * , 140 ( 1983 ) .s. jeon and j. kapusta , phys .c * 56 * , 468 ( 1997 ) .the predictions for rhic are contained in : s. jeon , j. kapusta , a. chikanian and j. sandweiss , phys .c * 58 * , 1666 ( 1998 ) .    k. geiger and j. kapusta , phys .d * 47 * , 4905 ( 1993 ) .j. i. kapusta and a. p. vischer , z. phys .c * 75 * , 507 ( 1997 ) .see also reference 12 therein .figure 1 : the transverse momentum distributions for electronic atoms for a central au+au collision at rhic . + figure 2 : the transverse momentum distributions for muonic atoms for a central au+au collision at rhic .+ figure 3 : the number of electronic atoms produced with a transverse momentum greater than the indicated value per unit of rapidity per day at rhic .these assume design luminosity and impact parameters less than 1 fm for au+au collisions .+ figure 4 : the number of muonic atoms produced with a transverse momentum greater than the indicated value per unit of rapidity per day at rhic .these assume design luminosity and impact parameters less than 1 fm for au+au collisions .","answer":"the number of hydrogen - like atoms produced when heavy nuclei collide is estimated for central collisions at the relativistic heavy ion collider using the sudden approximation of baym _  et al_. as first suggested by schwartz , a simultaneous measurement of the hydrogen and hadron spectra will allow an inference of the electron or muon spectra at low momentum where a direct experimental measurement is not feasible .  +    -0.1 cm -1 cm    pacs numbers :  25.75.-q +    @xmath0 kapusta@physics.spa.umn.edu + @xmath1 amocsy@nucth1.spa.umn.edu    the production rate of lepton pairs is a rapidly increasing function of temperature and so has long been considered a good probe of the initial high energy density phase of ultrarelativistic nuclear collisions @xcite .  the experimental detection of such direct leptons is a problem in the sub - gev range of transverse momentum due to the large number of charged hadrons produced and the need to disentangle direct leptons from those arising from hadron decays .  but this is just the kinematic range characterizing a quark - gluon plasma at a temperature of 200 to 500 mev .     schwartz @xcite proposed to measure the distribution of atoms formed by the binding of a directly produced lepton to one of the charged hadrons emerging from the final state of the nuclear collision .  a measurement of the charged hadrons and of the atoms , together with a theoretical calculation relating the distributions of the three particle species , would then imply the spectrum of leptons .  the beauty of the idea lies in the fact that nearly all indirectly produced leptons arise from the decay of hadrons , and these decays occur too long after the collision to allow an atom to be formed . of course  , one still can not tell whether the leptons were produced in quark - gluon plasma or in hadronic matter , but this is another issue .     five years ago baym , friedman , hughes and jacak calculated the relationship among the spectra of the atoms and of the charged hadrons and leptons which comprise them @xcite .  the formula reads : @xmath2 here @xmath3 and @xmath4 is the reduced mass of the hadron and lepton making up the atom .  since the binding energy is so small it is an excellent approximation to evaluate the hadron and lepton rapidities at the same rapidity as that of the atom , and to equate their transverse velocities as well : @xmath5 .  this formula is based on the sudden approximation which simply asks for the overlap of the outgoing wave functions of the hadron and the lepton with their hydrogenic state .  the sudden approximation is valid because these particles are formed in a nuclear volume which is extremely small in comparison to the size of the hydrogen atom and over a time interval which is extremely small in comparison to the bohr period .  the specific focus of baym _  et al_. was on @xmath6-@xmath7 atoms .  here we shall be interested in p - e , p-@xmath7 , @xmath6-e and @xmath6-@xmath7 atoms .  our essential contribution is to estimate @xmath8 for the leptons , protons and pions in the relevant range of transverse momentum , and from these to estimate the number of hydrogenic atoms to be formed in central au+au collisions at the relativistic heavy ion collider ( rhic ) .     first we estimate the number of leptons produced in the quark - gluon plasma phase .  the reaction rate for the process @xmath9 is : @xmath10 where the 12 arises from three colors and four possible spin states of the colliding quarks , @xmath11 is the fermi - dirac distribution , and @xmath12 is the matrix element for the reaction .  approximating @xmath13 the momentum distribution for negatively charged leptons becomes @xcite : @xmath14 sqrt{(1 - 4 m_l^2/s)(1 - 4m_q^2/s ) }  , , end{aligned} ] ] where @xmath15 .  the expression for positively charged leptons is the same .  if the masses of the leptons and the quarks can be neglected this simplifies to @xmath16 for the range of transverse momentum of interest in this context the masses of the muon and strange quark can not be neglected .    to obtain the total number emitted  we integrate over the space - time volume according to bjorken s model @xcite .  for central collisions : @xmath17 sqrt{(1 - 4 m_l^2/s)(1 - 4m_q^2/s ) }  , .end{aligned} ] ] here @xmath18 is the nuclear radius , @xmath19 is the momentum space rapidity , @xmath20 is the position space rapidity , @xmath21 is the temperature when the plasma is first considered to be thermalized , and @xmath22 is the critical or phase transition temperature . in the bjorken model  the temperature drops with proper time @xmath23 according to @xmath24 finally @xmath25 and @xmath26 where the z - axis is the beam axis .    in general  the integrals must be done numerically . however  , if the masses can be neglected then the above simplifies to : @xmath27  , .end{aligned} ] ] if one is interested in hydrogen - like atoms with a transverse momentum of a few gev / c then the transverse momentum of the lepton must have been @xmath28 which is just a few mev / c for electrons and a few hundred mev for muons . for electrons  the above formula simplifies even more since their transverse momentum is always much less than the temperature . @xmath29 ] ] this invariant distribution diverges logarithmically at small transverse momentum  .    our estimates of the lepton distributions also include those coming from the mixed phase as the system goes through a first - order phase transition .  the contribution from the quark - gluon plasma phase at the phase transition temperature @xmath22 is given by the distribution ( [ rate ] ) multiplied by the volume fraction occupied by the plasma , @xmath30 plus the corresponding rate in the hadronic phase multiplied by the hadronic volume fraction @xmath31 . here  r is the ratio of the number of degrees of freedom in the two phases .  the hadronic rate is obtained from the annihilation process @xmath32 .  these calculations are standard and well - known @xcite .     the canonical picture of central collisions of gold nuclei at rhic is that the central rapidity region will be almost baryon free @xcite .  however , central collisions of lead nuclei at the sps @xcite and extrapolations of nucleon collisions such as lexus @xcite suggest that the baryon rapidity distribution may be roughly flat  . furthermore , initial temperatures at rhic may be as high as 500 mev @xcite and this will be reflected in the final transverse mass distribution of the outgoing protons since high temperatures eventually get converted to transverse flow .  indeed , inverse slopes for protons for central lead collisions at the sps already reach 300 mev @xcite .  therefore a not unreasonable estimate for protons at rhic is to assume a flat rapidity distribution times an exponential falloff in transverse mass . @xmath33 ] ] @xmath34 is the charge of a single nucleus , @xmath35 is the rapidity gap between projectile and target nuclei , @xmath36 is the proton s transverse mass , and @xmath37 is the proton effective temperature ( not really a temperature , just an inverse slope ) .  similarly , we assume the charged - pion distribution to be : @xmath38, ] ] with the pion rapidity distribution @xmath39 .    to get a rough idea of  the numbers assume : @xmath40 mev , @xmath41 , @xmath42 fm for a central collision at the maximum rhic energy of 100 gev per nucleon per beam , @xmath43 for three quark flavors and a hadron gas with @xmath44 effective degrees of freedom @xcite .    in figures 1 and 2  we plot the transverse momentum distributions of p - e , @xmath6-e , p-@xmath7 and @xmath6-@xmath7 atoms for a central au+au collision at rhic .  the trends are easily understood on the basis of eq .  ( 1 ) .  the muonic atoms dominate the electronic ones because they have a greater reduced mass , and the pionic ones dominate the protonic ones because charged pions are much more abundant than protons .    in figures 3 and 4 we plot the number of hydrogen - like atoms expected per unit of rapidity per day for transverse momentum bigger than @xmath45 for au+au collisions with an impact parameter of 1 fm or less . a beam luminosity of @xmath46/@xmath47 sec is assumed .  for the most abundant species , @xmath6-@xmath7 atoms , we estimate about 1000 per unit of rapidity per day for transverse momenta larger than 1 gev / c .    in conclusion  , we have reinvestigated the rates for the production of hydrogen - like atoms at rhic .  the results are quite promising for their experimental detection .  it remains to be seen whether an efficient detector can be designed to observe them ."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: There is no approved treatment for covid-19Abstract:We remain largely without effective prophylactic/therapeutic interventions for COVID-19.Although many human clinical trials are ongoing, there remains a deficiency of supportive preclinical drug efficacy studies.Here we assessed the prophylactic/therapeutic efficacy of hydroxychloroquine (HCQ), a drug of interest for COVID-19 management, in two animal models.When used for prophylaxis or treatment neither the standard human malaria dose (6.5 mg/kg) nor a high dose (50 mg/kg) of HCQ had any beneficial effect on clinical disease or SARS-CoV-2 kinetics (replication/shedding) in the Syrian hamster disease model.Similarly, HCQ prophylaxis/treatment (6.5 mg/kg) did not significantly benefit clinical outcome nor reduce SARS-CoV-2 replication/shedding in the upper and lower respiratory tract in the rhesus macaque disease model.In conclusion, our preclinical animal studies do not support the use of HCQ in prophylaxis/treatment of COVID-19.","answer":"{\\"verdict\\": \\"NEI\\", \\"evidence\\": []}"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: We incorporate a Localization Mode which can be useful for lightweight long-term localization in well mapped areas, as long as there are not significant changes in the environment. In this mode the local mapping and loop closing threads are deactivatedand the camera is continuously localized by the tracking using relocalization if needed. In this mode the tracking leverages visual odometry matches and matches to map points.Visual odometry matches are matches between ORB in the current frame and 3D points created in the previous frame from the stereo/depth information. These matches make the localizationrobust to unmapped regions, but drift can be accumulated. Map point matches ensure drift-free localization to the existing map.This mode is demonstrated in the accompanying video.Question: Why are both map point matches and visual odometry matches required?","answer":"map point matches and visual odometry matches are required for Localization Mode which can be useful for lightweight long-term localization in well mapped areas, as long as there are not significant changes in the environment. In this mode the local mapping and loop closing threads are deactivated and the camera is continuously localized by the tracking using relocalization"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Internet-based Mindfulness Meditation for Cognition and Mood in Older Adults : A Pilot Study . CONTEXT Older adults are at risk for greater chronic stress and cognitive decline . Training in mindfulness meditation ( MM ) may help reduce stress and , thus , cognitive decline in older adults , but little research has explored that hypothesis . OBJECTIVE The current study 's primary aim was to evaluate the feasibility and acceptability for use by older adults of the Internet Mindfulness Meditation Intervention ( IMMI ) , a program that had been developed by the research team , as well as of an Internet-based health-and-wellness education program , the control . The secondary aim was to collect preliminary pre- and postintervention data on mood and cognitive function . DESIGN The study was a randomized , controlled trial ( RCT ) , a pilot study , with participants randomized either to the meditation group or the education group . SETTING Participants obtained access to the programs from their homes , and the baseline and endpoint assessments occurred in their homes as well . PARTICIPANTS Older adults aged 65-90 y were recruited from the Portland , OR , metropolitan area . Twenty-one people enrolled in the study . INTERVENTION Participants in both groups took part in a 1-h online session each week for 6 wk , with 30 min of daily home practice . OUTCOME MEASURES Feasibility and acceptability were assessed through measures of adherence to the protocol and a client satisfaction questionnaire . Mood and cognitive outcomes were also evaluated before and after the interventions . RESULTS Sixteen participants completed the study , 8 in each group , and 5 dropped out , for a 76 % completion rate . Participants ' mean age was 76.2 y ; 88 % were Caucasian , and 50 % were female . Acceptability was high for the interventions , based on above-average scores on the client satisfaction questionnaire . The IMMI participants completed ( 1 ) 4.25 ± 2.4 sessions , with a range of 0-6 ; ( 2 ) 604 ± 506 home-practice minutes , with a range 0-1432 ; and ( 3 ) 21.3 ± 15.5 d of practice , with a range of 0-46 . The education group completed ( 1 ) 4.75 ± 1.8 sessions , with a range of 2-6 ; ( 2 ) 873 ± 395 home-practice minutes , with a range of 327-1524 ; and ( 3 ) 25.6 d of practice , with a range of 11-35 . The intervention and control formats were both feasible , and the control group was appropriate . As expected due to the pilot nature of the study , no differences existed between groups for the mood or cognitive outcomes . CONCLUSIONS Administering interventions via the Internet to older adults is feasible . The 2 interventions were acceptable to participants and equal with regard to perceived credibility and acceptability . Future RCTs are planned to evaluate the clinical efficacy of the 2 interventions .","answer":"{\\"Intervention\\": [\\"mindfulness meditation ( MM )\\", \\"education\\", \\"Internet-based Mindfulness Meditation\\", \\"IMMI\\", \\"meditation\\", \\"Internet Mindfulness Meditation Intervention ( IMMI )\\"], \\"Outcome\\": [\\"client satisfaction\\", \\"stress\\", \\"feasibility and acceptability\\", \\"cognitive decline .\\", \\"mood\\", \\"cognitive outcomes\\", \\"chronic stress\\", \\"Acceptability\\", \\"Mood\\", \\"cognitive decline\\", \\"Feasibility and acceptability\\", \\"cognitive function .\\"], \\"Participant\\": []}"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: What is known about natriuretic peptide receptor A?Context: The natriuretic peptide receptor A (NPRA), also known as NPR1 or guanylyl cyclase A, binds ANP and BNP to initiate transmembrane signal transduction by elevating the intracellular levels of cyclic guanosine monophosphate.The results of this study indicated that NPRA may play a role in cardiac metabolism, which could be mediated by circRNA through endogenous competition mechanisms.Atrial natriuretic peptide (ANP) and its natriuretic peptide receptors A (NPR-A) and C (NPR-C) are involved in the regulation of physiological and pathophysiological process of blood pressure.","answer":"Atrial natriuretic peptide (ANP) and its natriuretic peptide receptors A (NPR-A) and C (NPR-C) are involved in the regulation of physiological and pathophysiological process of blood pressure.The natriuretic peptide receptor A (NPRA), also known as NPR1 or guanylyl cyclase A, binds ANP and BNP to initiate transmembrane signal transduction by elevating the intracellular levels of cyclic guanosine monophosphate."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Cardio-vascular pathologies, evoluting and uncontrolled, (severe HTA), cardiac deficiency, severe angor, severe arrhythmia. Infectious pathologies evoluting and requiring antibiotherapy. Patients HIV+. Transplanted patients or patients suffering from severe auto-immune disease. Psychiatric troubles that do not allow the protocol follow-up. Pregnant or breast-feeding women. No contraception.","answer":"{\\"Condition\\": [\\"Cardio-vascular pathologies\\", \\"breast-feeding\\", \\"HTA\\", \\"angor\\", \\"severe auto-immune disease\\", \\"arrhythmia\\", \\"Psychiatric troubles\\", \\"Pregnant\\", \\"cardiac deficiency\\", \\"Infectious pathologies\\", \\"HIV+\\"], \\"Device\\": [], \\"Drug\\": [\\"antibiotherapy\\"], \\"Measurement\\": [\\"HIV\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [\\"No\\"], \\"Observation\\": [], \\"Person\\": [\\"women\\"], \\"Procedure\\": [\\"Transplanted\\", \\"contraception\\"], \\"Qualifier\\": [\\"do not allow the protocol follow-up\\", \\"requiring antibiotherapy\\", \\"severe\\", \\"evoluting\\", \\"uncontrolled\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"evoluting and requiring antibiotherapy\\", \\"evoluting and uncontrolled\\"], \\"Temporal\\": [], \\"Value\\": [\\"+\\"], \\"Visit\\": []}"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: The zinc shock antiviral protein restricts sars-cov-2Abstract:Recent evidence shows that the Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2) is highly sensitive to interferons (IFNs).However, the underlying antiviral effectors remain to be defined.Here, we show that Zinc finger antiviral protein (ZAP) that specifically targets CpG dinucleotides in viral RNA sequences restricts SARS-CoV-2.We demonstrate that ZAP and its cofactors KHNYN and TRIM25 are expressed in human lung cells.Type I, II and III IFNs all strongly inhibited SARS-CoV-2 and further induced ZAP expression.Strikingly, SARS-CoV-2 and its closest relatives from bats show the strongest CpG suppression among all known human and bat coronaviruses, respectively.Nevertheless, knock-down of ZAP significantly increased SARS-CoV-2 production in lung cells, particularly upon treatment with IFN-or IFN-{gamma}. Thus, our results identify ZAP as an effector of the IFN response against SARS-CoV-2, although this pandemic pathogen may be preadapted to the low CpG environment in humans.HighlightsO_LISARS-CoV-2 and its closest bat relatives show strong CpG suppression C_LIO_LIIFN-{beta},-{gamma} and-{lambda} inhibit SARS-CoV-2 with high efficiency C_LIO_LIZAP restricts SARS-CoV-2 and contributes to the antiviral effect of IFNs C_LI","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Here, we show that Zinc finger antiviral protein (ZAP) that specifically targets CpG dinucleotides in viral RNA sequences restricts SARS-CoV-2.\\", \\"Type I, II and III IFNs all strongly inhibited SARS-CoV-2 and further induced ZAP expression.\\", \\"Strikingly, SARS-CoV-2 and its closest relatives from bats show the strongest CpG suppression among all known human and bat coronaviruses, respectively.\\"]}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Deep Journey into Super-resolution: A survey Chapter Title:  EnhanceNet 1. Abstract of Cited Paper (BIB001):  We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results. 2. Abstract of Cited Paper (BIB002):  We present a highly accurate single-image superresolution (SR) method. Our method uses a very deep convolutional network inspired by VGG-net used for ImageNet classification [19]. We find increasing our network depth shows a significant improvement in accuracy. Our final model uses 20 weight layers. By cascading small filters many times in a deep network structure, contextual information over large image regions is exploited in an efficient way. With very deep networks, however, convergence speed becomes a critical issue during training. We propose a simple yet effective training procedure. We learn residuals only and use extremely high learning rates (104 times higher than SRCNN [6]) enabled by adjustable gradient clipping. Our proposed method performs better than existing methods in accuracy and visual improvements in our results are easily noticeable. 3. Abstract of Cited Paper (BIB003):  Single image super-resolution is the task of inferring a high-resolution image from a single low-resolution input. Traditionally, the performance of algorithms for this task is measured using pixel-wise reconstruction measures such as peak signal-to-noise ratio (PSNR) which have been shown to correlate poorly with the human perception of image quality. As a result, algorithms minimizing these metrics tend to produce over-smoothed images that lack high-frequency textures and do not look natural despite yielding high PSNR values. ::: We propose a novel application of automated texture synthesis in combination with a perceptual loss focusing on creating realistic textures rather than optimizing for a pixel-accurate reproduction of ground truth images during training. By using feed-forward fully convolutional neural networks in an adversarial training setting, we achieve a significant boost in image quality at high magnification ratios. Extensive experiments on a number of datasets show the effectiveness of our approach, yielding state-of-the-art results in both quantitative and qualitative benchmarks. 4. Abstract of Cited Paper (BIB004):  The Super-Resolution Generative Adversarial Network (SRGAN) is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN - network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge. The code is available at this https URL .Literature Review:","answer":"This network design focuses on creating faithful texture details in high-resolution super-resolved images BIB004 . A key problem with regular image quality measures such as PSNR is their noncompliance with the perceptual quality of an image. This results in overly smoothed images that do not have sharp textures. To overcome this problem, EnhanceNet used two other loss terms beside the regular pixel-level MSE loss: (a) the perceptual loss function was defined on the intermediate feature representation of a pretrained network BIB002 in the form of 1 distance. (b) the texture matching loss is used to match the texture of low and high resolution images and is quantified as the 1 loss between gram matrices computed from deep features. The whole network architecture is adversarialy trained where the SR network's goal is to fool a discriminator network. The architecture used by EnhanceNet is based on the Fully Convolutional Network BIB001 and residual learning principle BIB003 . Their results showed that although best PSNR is achieved when only a pixel level loss is used, the additional loss terms and an adversarial training mechanism lead to more realistic and perceptually better outputs. On the downside, the proposed adversarial training could create visible artifacts when super-resolving highly textured regions. This limitation was addressed further by the recent work on high perceptual quality SR BIB005 ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"SSX\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Cloning, sequencing and expression of a cDNA encoding mammalian valyl-tRNA synthetase. A fragment of the cDNA encoding a rat valyl-tRNA synthetase (TrsVal)-like protein was cloned from a rat cDNA library in lambda gt11 using an oligodeoxyribonucleotide (oligo) probe. Three independent plaque clones containing the human TrsVal cDNA were then isolated from a lambda gt10 human erythroleukemia cDNA library using the rat cDNA fragment as the hybridization probe. Sequence analyses of the cDNA fragments provided a 3.2-kb sequence with an open reading frame that contained the 'HIGH' synthetase signature sequence and the tRNA 3'-end-binding motif, KMSKS, and putative Val-binding motif, EWCISRQ. The sequence was extended to the 3' end of the cDNA by the polymerase chain reaction using an internal primer and an oligo(dT) adapter. The deduced 1051-amino-acid sequence shares 65% identity with yeast TrsVal, and contains a highly basic N-terminal region, a newly evolved protease-sensitive region in sequence close to the C terminus, and several sites for protein kinase C phosphorylation. A 3-kb cDNA fragment was sub-cloned into plasmid pSVL and expressed in COS-7 cells; up to a sevenfold increase in TrsVal activity was obtained. These results confirm the cloning and sequencing of a human TrsVal-encoding cDNA.","answer":"{\\"Gene\\": [\\"TrsVal\\", \\"evolved protease-sensitive region\\", \\"Val-binding motif\\", \\"synthetase signature sequence\\", \\"valyl-tRNA synthetase\\", \\"N-terminal region\\", \\"tRNA 3u0027-end-binding motif\\", \\"protein kinase C\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:The effectiveness of omeprazole , clarithromycin and tinidazole in eradicating Helicobacter pylori in a community screen and treat programme . Leeds Help Study Group . INTRODUCTION Helicobacter pylori screening and treatment has been proposed as a cost-effective method of preventing gastric cancer . AIM To assess , in a randomized controlled trial , the efficacy of therapy in eradicating H. pylori as part of a screening programme , and to report the adverse events associated with this strategy . METHODS Subjects between the ages of 40-49 years were randomly selected from the lists of 36 primary care centres . Participants attended their local practice and H. pylori status was determined by 13C-urea breath test . Infected subjects were randomized to receive omeprazole 20 mg b.d. , clarithromycin 250 mg b.d . and tinidazole 500 mg b.d . for 7 days ( OCT ) or identical placebos . Eradication was determined by a 13C-urea breath test 6 months and 2 years after the first visit . Successful eradication was defined as two negative 13C-urea breath tests or one negative and one missing test . Adverse events and compliance were assessed at the 6-month visit . RESULTS A total of 32 929 subjects were invited to attend , 8407 were evaluable , and 2329 ( 28 % ) of these were H. pylori-positive . A total of 1161 subjects were randomized to OCT and 1163 to placebo ; over 80 % returned for a repeat 13C-urea breath test on at least one occasion . The eradication rates in those allocated to OCT were as follows : intention-to-treat , 710 out of 1161 ( 61 % ; 95 % confidence interval : 58-64 % ) ; evaluable 710 out of 967 ( 73 % ; 95 % CI : 71-76 % ) ; took all medication 645 out of 769 ( 84 % ; 95 % CI : 81-87 % ) . Adverse events occurred in 45 % of the treatment group and in 18 % of the placebo group ( relative risk 2.5 ; 95 % CI : 2.1-2.9 ) . Compliance , male gender , no antibiotic prescription in the subsequent 2 years and experiencing a bitter taste with the medication were independently associated with treatment success . CONCLUSIONS The OCT regimen has an eradication rate of 61 % in intention-to-treat analysis and is therefore less successful in treating H. pylori as part of a screening programme compared with hospital studies in dyspeptic patients .","answer":"{\\"Intervention\\": [\\"omeprazole 20 mg b.d.\\", \\"tinidazole\\", \\"placebos\\", \\"omeprazole\\", \\"clarithromycin\\", \\"and tinidazole 500 mg b.d .\\", \\"clarithromycin 250 mg b.d\\"], \\"Outcome\\": [\\"eradicating Helicobacter pylori\\", \\"Successful eradication\\", \\"compliance\\", \\"eradication rates\\", \\"pylori-positive\\", \\"one negative and one missing test\\", \\"experiencing a bitter taste\\", \\"Eradication\\", \\"eradication rate\\", \\"negative 13C-urea breath tests\\", \\"Adverse events\\"], \\"Participant\\": [\\"2329\\", \\"32 929\\", \\"dyspeptic\\", \\"H. pylori-positive\\", \\"between the ages of 40-49 years\\", \\"1161\\", \\"8407\\"]}"},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Is Tcf3 associated with the Wnt pathway?Context: TCF3, a novel positive regulator of osteogenesis, plays a crucial role in miR-17 modulating the diverse effect of canonical Wnt signaling in different microenvironmentsFurthermore, the role of miR-17 was because of its target gene TCF3 (transcription factor 3), a key transcription factor of canonical Wnt pathway.Consequently, Tcf3 knockdown in HCT-R cells restores their sensitivity to the effects of butyrate on Wnt activity and clonal cell growth. Interestingly, the effects of overexpressed Tcf3 differ between HCT-116 and HCT-R cellsIn HCT-R cells, however, the overexpression of Tcf3 inhibits Wnt activity, and the cells are still able to proliferate due to the higher expression levels of cell cycle factors, particularly those driving the G(1) to S transition.TCF3 (also known as TCF7L1) is a member of the TCF/LEF transcription factor family that is central in regulating epidermal and embryonic stem cell identity.We found that in contrast to ES cells, where it represses Wnt-pathway target genes, TCF3 promotes the expression of a subset of Wnt-responsive genes in breast cancer cells while repressing another distinct target subset. In the normal mouse mammary gland, Tcf3 is highly expressed in terminal end buds, structures that lead duct developmentTcf3 is essential within the neural ectoderm to maintain anterior character and that its interaction with Hesx1 ensures the repression of Wnt targets in the developing forebrain.We report here that a terminal component of the canonical Wnt pathway in ES cells, the transcription factor T-cell factor-3 (Tcf3), co-occupies promoters throughout the genome in association with the pluripotency regulators Oct4 and Nanog.Our results suggest that the Wnt pathway, through Tcf3, brings developmental signals directly to the core regulatory circuitry of ES cells to influence the balance between pluripotency and differentiation.The wnt pathway regulates the steady state level of beta-catenin, a transcriptional coactivator for the Tcf3/Lef1 family of DNA binding proteins.Along with evidence that a significant amount of Tcf protein is nonnuclear, these findings suggest that CK1epsilon can modulate wnt signaling in vivo by regulating both the beta-catenin-Tcf3 and the GBP-dsh interfaces.RA increases the expression of ligands and receptors of the noncanonical Wnt pathway (Wnt 5a, 7a, Fzd2 and Fzd6), downstream signaling, and Tcf3 expression.The noncanonical Wnt signaling pathway, through actions of Tcf3, can antagonize the canonical pathway.We report here that a terminal component of the canonical Wnt pathway in ES cells, the transcription factor T-cell factor-3 (Tcf3), co-occupies promoters throughout the genome in association with the pluripotency regulators Oct4 and Nanog.Both Tcf3 depletion and Wnt pathway activation cause increased expression of Oct4, Nanog, and other pluripotency factors and produce ES cells that are refractory to differentiation.Here, we show that injection of a hesx1 morpholino into a 'sensitised' zygotic headless (tcf3) mutant background leads to severe forebrain and eye defects, suggesting an interaction between Hesx1 and the Wnt pathway during zebrafish forebrain development.In addition, we reveal that Tcf3 is essential within the neural ectoderm to maintain anterior character and that its interaction with Hesx1 ensures the repression of Wnt targets in the developing forebrain.TCF3, a novel positive regulator of osteogenesis, plays a crucial role in miR-17 modulating the diverse effect of canonical Wnt signaling in different microenvironments.Our studies located the position of Wnts, downstream LEF1 and TCF3 and stem cell marker proteins, which provide new information in understanding the role of the Wnt singaling pathway in whisker follicles' growth.The transcription factor T-cell factor 3 (TCF3), one component of the Wnt pathway, is known as a cell-intrinsic inhibitor of many pluripotency genes in embryonic stem cells (ESCs) that influences the balance between pluripotency and differentiation.Overexpression of TCF3 attenuated the effect of miR-17 on modulating canonical Wnt signaling.We also find that TCF3 phosphorylation is triggered by canonical Wnt ligands, LRP6, and dominant negative mutants for Axin and GSK3, indicating that this process shares the same upstream regulators with β-catenin stabilization.Wnt pathway stimulation also triggers β-catenin association at regulatory elements with classic Lef/Tcf motifs associated with differentiation programs.We show that menin physically interacts with proteins involved in the canonical Wnt signaling pathway, including beta-catenin, TCF3 (TCFL1), and weakly with TCF4 (TCFL2).T-cell factor 3 (Tcf3) is a component of the Wnt signaling and a dominant downstream effector in ESCs.factor 3 (Tcf3) is a component of the Wnt signaling and a dominant downstream effector in ESCs. Despitrt here that a terminal component of the canonical Wnt pathway in ES cells, the transcription factor T-cell factor-3 (Tcf3), co-occupies promoters throughout the genome in association with the pluripotency regulators Oct4 and Nanog. Thus, TcTcf3, is recruited to a palindromic motif enriched in the promoter of cell cycle repressor genes, such as p15Ink4b, p16Ink4a and p19Arf, which mediate the Wnt-dependent anti-proliferative effect in mESCs. Consistently, ablnonical Wnt/β-catenin pathway controls mESC pluripotency via the Wnt-effector Tcf3. Howeg increases the dissociation of Tcf1 and the association of Tcf3 at promoters of genes that regulate stemness (e.g., NR5A2, Lrh-1) or differentiation (e.g. Cyr61, Zic5). Knockdown of Tcf3 increasespport the existence of a regulatory circuit whereby Wnt/β-catenin counteracts Tcf3 repression of Lef1, which subsequently activates target gene expression via Lef1-β-catenin complexes. We propose that the Tcf/with a requirement for Wnt signalling repression, we highlight a synergistic gene dosage-dependent interaction between Hesx1 and Tcf3, a transcriptional repressor of Wnt target genes, to maintain anterior forebrain identity during mouse embryogenesis. In additionexpression of ligands and receptors of the noncanonical Wnt pathway (Wnt 5a, 7a, Fzd2 and Fzd6), downstream signaling, and Tcf3 expression. RA reduces the phospBACKGROUND AND OBJECTIVES: Transcription factor 3 (TCF3) implicates Wnt signaling pathway and regulates E-cadherin expression, which is involved iWe demonstrate that mouse Tcf3 mediates repression of both moderate and high levels of canonical Wnt signaling, by either competing with other members of the Tcf/Lef family for binding to β-catenin, or for binding to DNA.TCF3 is a transcriptional repressor that has been implicated in Wnt signaling and plays key roles in embryonic axis specification and stem cell differentiation.Our data show for the first time that Wnt signaling down-regulates Tcf3 expression, possibly at both the transcriptional and post-transcriptional levels, and thus highlight a novel mechanism through which Wnt signaling inhibits neuro-ectodermal lineage differentiation in mouse embryonic stem cells.We found Tcf3 to be a repressor of Wnt signaling in neocortical NPCs in a reporter gene assay.We found that down-regulation of Tcf3, a member of the Tcf/Lef family and a key player in the control of self-renewal and pluripotency, represents a specific and primary response to Wnt activation in ESCs.Wnt16b also activated the RhoA/Rac1 signaling cascade suggesting the activation of a non-canonical Wnt pathway in TCF3-PBX1 cells.B-cell precursor acute lymphoblastic leukemia (BCP-ALL) with TCF3-PBX1 fusion gene expression has constitutively elevated levels of Wnt16b and ROR1 (receptor tyrosine kinase-like orphan receptor), a ligand and a receptor from the Wnt signaling pathway, respectively.We found that in contrast to ES cells, where it represses Wnt-pathway target genes, TCF3 promotes the expression of a subset of Wnt-responsive genes in breast cancer cells while repressing another distinct target subset.Together, these results suggest that Tcf3 antagonizes Wnt signaling in NPCs, thereby maintaining their undifferentiated state in the neocortex and that Wnt signaling promotes the transition from Tcf3-mediated repression to Tcf1/Lef1-mediated enhancement of Wnt signaling, constituting a positive feedback loop that facilitates neuronal differentiation.We also found that Wnt signal stimulation reduces the level of Tcf3, and increases those of Tcf1 (also known as Tcf7) and Lef1, positive mediators of Wnt signaling, in NPCs.These data suggest that in the absence of Wnt signals, Tcf3 may function in skin SCs to maintain an undifferentiated state and, through Wnt signaling, directs these cells along the hair lineage.","answer":"yes"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:experimentsContext before the citation:This evaluation set-up is an improvement versus the one we previously reported (Gerber and Chai 2010), in which fixed partitions were used for training, development, and testing. Following this, we split the predicate instances evenly into ten folds and used each fold as testing data for a model trained on the instances outside the fold. In order to remove any confounding factors caused by specific documents, we first randomized the annotated predicate instances.Citation Sentence:This evaluation set-up is an improvement versus the one we previously reported ( Gerber and Chai 2010 ) , in which fixed partitions were used for training , development , and testing .Context after the citation:During training, the system was provided with annotated predicate instances. The system identified missing argument positions and generated a set of candidates for each such position. A candidate three-tuple (p, iargn, c') was given a positive label if the candidate implicit argument c (the primary filler) was annotated as filling the missing argument position; otherwise, the candidate three-tuple was given a negative label. During testing, the system was presented with each predicate instance and was required to identify all implicit arguments for the predicate.","answer":"Extends"},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: the addition of zinc to hydroxychloroquine and azithromycin was associated with a decrease in mortality in patients who were not admitted to the intensive care unit.Abstract:Backgrounds.Since COVID-19 outbreak, various agents have been tested but no proven effective therapies have been identified.This has led to a lot of controversies among associated researches.Hence, in order to address the issue of using hydroxychloroquine in treating COVID-19 patients, we conducted a systematic review and meta-analysis.Methods.A thorough search was carried out to find relevant studies in MEDLINE, medRxiv, PubMed, Cochrane Database, China Academic Journals Full-text Database and Web of Science.Two investigators independently reviewed 274 abstracts and 23 articles.The trials which evaluated hydroxychloroquine for treatment of COVID-19 were included for this systematic review.Two investigators assessed quality of the studies and data extraction was done by one reviewer and cross checked by the other.Results.Five trials involving 677 patients were included while conducting the meta-analysis.Compared with the control group, hydroxychloroquine with or without azithromycin showed benefits in positive-to-negative conversion of SARS-CoV-2 (odds ratio [OR], 1.95 [95% CI,0.19 to 19.73] and a reduction in progression rate (OR, 0.89 [95% CI, 0.58 to 1.37]), but without demonstrating any statistical significance.This systematic review has also suggested a possible synergistic effect of the combination therapy which included hydroxychloroquine and azithromycin.However, the use of hydroxychloroquine alone was associated with increased mortality in COVID-19 patients.Conclusion.The use of hydroxychloroquine with or without azithromycin for treatment of COVID-19 patients, seems to be effective.The combination of hydroxychloroquine and azithromycin has shown synergic effects.However, mortality rate was increased when the treatment was conducted with hydroxychloroquine.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"However, the use of hydroxychloroquine alone was associated with increased mortality in COVID-19 patients.\\"]}"},{"question":"You will be shown sections from a scientific research paper, together with a question about the paper. Your task is to answer the question based on the contents of the paper. Your response should be a \`json\` object with two fields:\\"answer\\": An array of strings extracted directly from the paper which, collectively, answer the question.\\"evidence\\": An array of strings. Each should be an excerpt from the paper, in which one or more of the extracted answers can be found.For instance, for the question \\"What baselines did the authors compare against?\\", a sample response might be:{  \\"answer\\": [\\"BERT\\", \\"RoBERTa\\"],  \\"evidence\\": [\\"In our experiments, we compare the performance of our model against BERT and RoBERTa.\\"]}Do not include any text in your response other than the json.If the question is unanswerable given the provided excerpts, respond with the single word \\"null\\".Paper: Brazilian Lyrics-Based Music Genre Classification Using a BLSTM NetworkOrganize songs, albums, and artists in groups with shared similarity could be done with the help of genre labels. In this paper, we present a novel approach for automatic classifying musical genre in Brazilian music using only the song lyrics. This kind of classification remains a challenge in the field of Natural Language Processing. We construct a dataset of 138,368 Brazilian song lyrics distributed in 14 genres. We apply SVM, Random Forest and a Bidirectional Long Short-Term Memory (BLSTM) network combined with different word embeddings techniques to address this classification task. Our experiments show that the BLSTM method outperforms the other models with an F1-score average of 0.48. Some genres like\\"gospel\\",\\"funk-carioca\\"and\\"sertanejo\\", which obtained 0.89, 0.70 and 0.69 of F1-score, respectively, can be defined as the most distinct and easy to classify in the Brazilian musical genres context.IntroductionMusic is part of the day-to-day life of a huge number of people, and many works try to understand the best way to classify, recommend, and identify similarities between songs. Among the tasks that involve music classification, genre classification has been studied widely in recent years BIBREF0 since musical genres are the main top-level descriptors used by music dealers and librarians to organize their music collections BIBREF1.Automatic music genre classification based only on the lyrics is considered a challenging task in the field of Natural Language Processing (NLP). Music genres remain a poorly defined concept, and boundaries between genres still remain fuzzy, which makes the automatic classification problem a nontrivial task BIBREF1.Traditional approaches in text classification have applied algorithms such as Support Vector Machine (SVM) and Naïve Bayes, combined with handcraft features (POS and chunk tags) and word count-based representations, like bag-of-words. More recently, the usage of Deep Learning methods such as Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) has produced great results in text classification tasks.Some works like BIBREF2, BIBREF3 BIBREF4 focus on classification of mood or sentiment of music based on its lyrics or audio content. Other works, like BIBREF1, and BIBREF5, on the other hand, try to automatically classify the music genre; and the work BIBREF6 tries to classify, besides the music genre, the best and the worst songs, and determine the approximate publication time of a song.In this work, we collected a set of about 130 thousand Brazilian songs distributed in 14 genres. We use a Bidirectional Long Short-Term Memory (BLSTM) network to make a lyrics-based music genre classification. We did not apply an elaborate set of handcraft textual features, instead, we represent the lyrics songs with a pre-trained word embeddings model, obtaining an F1 average score of 0.48. Our experiments and results show some real aspects that exist among the Brazilian music genres and also show the usefulness of the dataset we have built for future works.This paper is organized as follows. In the next section, we cite and comment on some related works. Section SECREF3 describes our experiments from data collection to the proposed model, presenting some important concepts. Our experimental results are presented in Section SECREF4, and Section SECREF5 presents our concluding remarks and future work.Related WorksSeveral works have been carried out to add textual information to genre and mood classification. Fell and Sporleder BIBREF6 used several handcraft features, such as vocabulary, style, semantics, orientation towards the world, and song structure to obtain performance gains on three different classification tasks: detecting genre, distinguishing the best and the worst songs, and determining the approximate publication time of a song. The experiments in genre classification focused on eight genres: Blues, Rap, Metal, Folk, R&B, Reggae, Country, and Religious. Only lyrics in English were included and they used an SVM with the default settings for the classification.Ying et al. BIBREF0 used Part-of-Speech (POS) features extracted from lyrics and combined them with three different machine learning techniques – k-Nearest-Neighbor, Naïve Bayes, and Support Vector Machines – to classify a collection of 600 English songs by the genre and mood.Zaanen and Kanters BIBREF7 used the term frequency and inverse document frequency statistical metrics as features to solve music mood classification, obtaining an accuracy of more than 70%.In recent years, deep learning techniques have also been applied to music genre classification. This kind of approach typically does not rely on handcraft features or external data. In BIBREF5, the authors used a hierarchical attention network to perform the task in a large dataset of nearly half a million song lyrics, obtaining an accuracy of more than 45%. Some papers such as BIBREF8 used word embedding techniques to represent words from the lyrics and then classify them by the genre using a 3-layer Deep Learning model.MethodsIn this chapter we present all the major steps we have taken, from obtaining the dataset to the proposed approach to address the automatic music genre classification problem.Methods ::: Data AcquisitionIn order to obtain a large number of Brazilian music lyrics, we created a crawler to navigate into the Vagalume website, extracting, for each musical genre, all the songs by all the listed authors. The implementation of a crawler was necessary because, although the Vagalume site provides an API, it is only for consultation and does not allow obtaining large amounts of data. The crawler was implemented using Scrapy, an open-source and collaborative Python library to extract data from websites.From the Vagalume's music web page, we collect the song title and lyrics, and the artist name. The genre was collected from the page of styles, which lists all the musical genres and, for each one, all the artists. We selected only 14 genres that we consider as representative Brazilian music, shown in Table TABREF8. Figure FIGREF6 presents an example of the Vagalume's music Web page with the song “Como é grande o meu amor por você”, of the Brazilian singer Roberto Carlos. Green boxes indicate information about music that can be extracted directly from the web page. From this information, the language in which the lyrics are available can be obtained by looking at the icon indicating the flag of Brazil preceded by the “Original” word.After extracting data, we obtained a set of 138,368 songs distributed across 14 genres. Table TABREF8 presents the number of songs and artists by genre. In order to use the data to learn how to automatically classify genre, we split the dataset into tree partitions: training (96,857 samples), validation (27,673 samples), and test (13,838 samples). The total dataset and splits are available for download.Methods ::: Word EmbeddingsWord embeddings is a technique to represent words as real vectors, so that these vectors maintain some semantic aspects of the real words. Basically, vectors are computed by calculating probabilities of the context of words, with the intuition that semantically similar words have similar contexts, and must therefore have similar vectors.Word2Vec, by Mikolov et al. BIBREF9, is one of the first and most widely used algorithms to make word embeddings. It has two architectures to compute word vectors: Continuous Bag-Of-Words (CBOW) and Skip-gram. CBOW gets a context as input and predicts the current word, while Skip-gram gets the current word as input and predicts its context.In this work, we use the Python Word2Vec implementation provided by the Gensim library. The Portuguese pre-trained word embeddings created by BIBREF10 and available for download was used to represent words as vectors. We only used models of dimension 300 and, for Word2Vec, Wang2Vec, and FastText, skip-gram architectured models.Methods ::: Bidirectional Long Short-Term MemoryLong Short-Term Memory (LSTM) is a specification of Recurrent Neural Network (RNN) that was proposed by Hochreiter and Schmidhuber BIBREF11. This kind of network is widely used to solve classification of sequential data and is designed to capture time dynamics through graph cycles. Figure FIGREF14 presents an LSTM unity, which receives an input from the previous unit, processes it, and passes it to the next unit.The following equations are used to update C_t and h_t values.where W_f, W_i, W_C, W_o are the weight matrices for h_{t-1} input; U_f, U_i, U_C, U_o are the weight matrices for x_t input; and b_f, b_i, b_C, b_o are the bias vectors.Basically, a Bidirectional LSTM network consists of using two LSTM networks: a forward LSTM and a backward LSTM. The intuition behind it is that, in some types of problems, past and future information captured by forward and backward LSTM layers are useful to predict the current data.Methods ::: Proposed ApproachOur proposed approach consists of three main steps. Firstly, we concatenate the title of the song with its lyrics, put all words in lower case and then we clean up the text by removing line breaks, multiple spaces, and some punctuation (,!.?). Secondly, we represent the text as a vector provided by a pre-trained word embeddings model. For classical learning algorithms like SVM and Random Forest, we generate, for each song, a vectorial representation by calculating the average of the vectors of each word in the song lyrics that can be can be expressed by the equation below:where L is the song lyrics, w is a word in L, and n is the number of words in L. If a word does not have a vector representation in the word embeddings model, it is not considered in the equation. For the BLSTM algorithm, the representation was made in the format of a matrix, as shown in Figure FIGREF16, where each line is a vector representation of a word in the lyrics. In the third step, we use as features the generated representation for the genre classification tasks using SVM, Random Forests, and BLSTM.Experimental ResultsIn this section, we describe our experiments. We used the Linear SVM and Random Forest Scikit-learn implementations and Keras on top of TensorFlow for the BLSTM implementation. In this study, we did not focus on finding the best combination of parameters for the algorithms, so that for SVM we used the default parameters, and for Random Forest we used a number of 100 trees. Our BLSTM model was trained using 4 epochs, with Adam optimizer, and 256 as the size of the hidden layer.As we can see in Table TABREF20, our BLSTM approach outperforms the other models with an F1-score average of 0.48. In addition, we can note that the use of Wang2Vec pre-trained word embeddings made it possible to obtain better F1-score results in BLSTM, which is not necessarily noticed in other cases, since for SVM and Random Forest, Glove and FastText, respectively, were the techniques that obtained better F1-scores.Table TABREF21 shows the BLSTM classification results for each genre. We can see that the genres gospel, funk-carioca and sertanejo have a greater distinction in relation to the other genres, since they were better classified by the model. In particular, funk-carioca obtained a good classification result although it did not have a large number of collected song lyrics.In gospel song lyrics, we can identify some typical words, such as “Deus” (God) , “Senhor” (Lord), and “Jesus” (Jesus); in funk-carioca, songs have the words “bonde” (tram), “chão” (floor) and “baile” (dance ball), all used as slang; in sertanejo, some of the most common words are “amor” (love), “coração” (heart) and “saudade” (longing). The occurrence of these typical words could contribute to the higher performance of F1-scores in these genres.The bossa-nova and jovem-guarda genres, which have few instances in the dataset, are among the most difficult ones to classify using the model. The pop genre, by contrast, has a small distribution between the number of songs and the number of artists, and could not be well classified by our model. This may indicate that our model was unable to identify a pattern due to the low number of songs per artist, or that the song lyrics of this genre cover several subjects that are confused with other genres.Figure FIGREF22 shows the confusion matrix of the results produced by our BLSTM model. We can notice that many instances of class forró are often confused with class sertanejo. Indeed, these two genres are very close. Both Forró and sertanejo have as theme the cultural and daily aspects of the Northeast region of Brazil. Instances of class infantil are often confused with class gospel: in infantil we have music for children for both entertainment and education. In some of the songs, songwriters try to address religious education, which could explain the confusion between those genres. The MPB (Brazilian Popular Music) genre was the most confused of all, which may indicate that song lyrics of this genre cover a wide range of subjects that intersect with other genres.Conclusion and Future WorksIn this work we constructed a dataset of 138,368 Brazilian song lyrics distributed in 14 genres. We applied SVM, Random Forest, and a Bidirectional Long Short-Term Memory (BLSTM) network combined with different word embeddings techniques to address the automatic genre classification task based only on the song lyrics. We compared the results between the different combinations of classifiers and word embedding techniques, concluding that our BLSTM combined with the Wang2Vec pre-trained model obtained the best F1-score classification result. Beside the dataset construction and the comparison of tools, this work also evidences the lack of an absolute superiority between the different techniques of word embeddings, since their use and efficiency in this specific task showed to be very closely related to the classification technique.As future work, it is possible to explore the dataset to identify genre or artist similarities, generating visualizations that may or may not confirm aspects pre-conceived by the consumers of Brazilian music. It is also possible to perform classification tasks by artists of a specific genre.Figure 1: An example of a Vagalume’s song web pageTable 1: The number of songs and artists by genreFigure 2: The Long Short-Term Memory unit.Figure 3: Our BLSTM model architectureTable 2: Classification results for each classifier and word embeddings model combinationTable 3: Detailed result of BLSTMFigure 4: Normalized confusion matrixQuestion: what is the source of the song lyrics?","answer":"{\\"answer\\": [\\"Vagalume website\\"], \\"evidence\\": [\\"In order to obtain a large number of Brazilian music lyrics, we created a crawler to navigate into the Vagalume website, extracting, for each musical genre, all the songs by all the listed authors. The implementation of a crawler was necessary because, although the Vagalume site provides an API, it is only for consultation and does not allow obtaining large amounts of data. The crawler was implemented using Scrapy, an open-source and collaborative Python library to extract data from websites.\\"]}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: This paper proposes a novel architecture for recurrent neural networks (RNNs). The proposed recurrent controllerKeyphrases: sentiment analysis text sentence-levelDataset description:SHREC: The SHREC dataset contains 14 dynamic gestures performed by 28 participants (all participants are right handed) and captured by the Intel RealSense short range depth camera. Each gesture is performed between 1 and 10 times by each participant in two way: using one finger and the whole hand.WHU: Created for MVS tasks and is a large-scale multi-view aerial dataset generated from a highly accurate 3D digital surface model produced from thousands of real aerial images with precise camera parameters.SST: The Stanford Sentiment Treebank is a corpus with fully labeled parse trees that allows for a complete analysis of the compositional effects of sentiment in language. The corpus is based on the dataset introduced by Pang and Lee (2005) and consists of 11,855 single sentences extracted from movie reviews.LOCATA: The LOCATA dataset is a dataset for acoustic source localization. It consists of real-world ambisonic speech recordings with optically tracked azimuth-elevation labels.WikiQA: The WikiQA corpus is a publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering. In order to reflect the true information need of general users, Bing query logs were used as the question source.NVGesture: The NVGesture dataset focuses on touchless driver controlling. It contains 1532 dynamic gestures fallen into 25 classes.Options:- A: SHREC  B: WHU  C: SST  D: LOCATA  E: WikiQA  F: NVGesture","answer":"[\\"SST\\", \\"WikiQA\\"]"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Dissecting molecular architecture of postsynaptic density at excitatory synapsesPaper sections:<p>Synapses are fundamental units with distinct morphology to precisely connect individual neurons in the central nervous system, which require complex molecular machinery for neurotransmitter release and signaling. The mammalian synapses are highly organized as supramolecular protein machines, where mutations have been identified in more than 130 brain diseases (Bayes et al. 2017). The growth and maturation of synapses involve spine growth, protrusion, retraction, and contact with the presynaptic bouton, resulting from temporal and spatial protein-protein interaction, assembly, and regulation (Sin et al. 2002). Proteomic studies have identified more than 1,000 postsynaptic proteins, including trans-synaptic/adhesion proteins, scaffolds/adaptors proteins, neurotransmitter receptors, ion channels, and immediate-early/local translation proteins, which are organized through physical interactions into supercomplexes and networks (Collins et al. 2006, Bayes et al. 2011, Biesemann et al. 2014). Various postsynaptic signaling proteins organize into higher-order supercomplexes with great diversity between different synapses and even within the same synapse at different times. Because of the complexity and heterogeneity of protein complexes at synapses, defining the organization of the myriad synaptic proteins is a major challenge for neuroscientists.</p><p>The postsynaptic density (PSD) can be visualized under electron microscopy as a prominent electron-dense thickening (~30 nm thick) beneath the postsynaptic membrane. PSD95, also known as discs large homologue-4 (DLG4), is the most abundant scaffold protein almost exclusively expressed at excitatory synapses. PSD95 is considered the most crucial organizer of postsynaptic structure and signaling complexes, which includes glutamate receptors, ion channels, signaling enzymes, and adhesion proteins at excitatory synapses. Because PSD95 is involved in anchoring synaptic proteins, it plays an important role in synaptic plasticity and the stabilization of synaptic changes during certain conditions such as long-term potentiation. PSD95 has conserved modular structures consisting of three PDZ domains and one Src homology 3–guanylate kinase-like (SH3–GK) supermodule (Doyle et al. 1996, Long et al. 2003). The N-terminus of PSD95 is located at the membrane with the palmitoylation site, which is necessary for its synaptic localization, clustering of receptors, and stability at the PSD (Won et al. 2016). The synaptic complexes comprising PSD95 and the glutamate N-methyl-D-aspartic acid receptors (NMDARs), two key players involved in synaptic plasticity and cognitive functions, are extensively studied at excitatory synapses. PSD95 directly interacts with NMDARs through the binding between the first two PDZ domains in the tandem of PSD95 and the PDZ-ligands of the subunits GluN2 of NMDARs (Sturgill et al. 2009). GluN2A seems to be not essential for assembly with PSD95 in vivo, and a tripartite mechanism exists for the assembly of PSD95-PSD93-GluN2B (Frank et al. 2016). NMDARs are partitioned within two discrete populations of 0.8 and 1.5 MDa, which were biochemically, genetically, and developmentally separable. By comparison, almost all PSD95 is retained within ~1.5 MDa PSD95 supercomplexes (Frank et al. 2016). However, how NMDARs and others synaptic proteins are organized into PSD95 supercomplexes in vivo remains unclear.</p><p>Synaptic protein copy numbers and their stoichiometric distribution can profoundly affect synaptic integrity and function. The molecular composition and the localization of proteins at PSD have been extensively studied using fluorescence imaging, immunocytochemistry and immunoblotting of proteins isolated from synaptosomes and PSD. However, these methods are often confounded with the uncertain specificity and affinity of the antibodies used, and the acquired data are generally not quantitative. Studies using the traditional subcellular fractionation and protein identification approach have shown specific roles of proteins that are localized to synapses, termed the \\"synaptic proteome\\" or \\"neuro-proteome\\", in determining synaptic function and plasticity (Bayes and Grant 2009). The development of mass spectrometry combined with co-immunoprecipitation (co-IP) has accelerated the identification of PSD components in purified synaptic proteins. The tandem affinity purification and mass spectrometry (TAP-MS) approach has been applied to cells in culture and in transgenic and knock-in mice (Fernandez et al. 2009, Kang et al. 2014). Nevertheless, the major limitation of this approach is that it is insufficient to directly define the size, stoichiometry, and arrangement of proteins in hetero-oligomeric complexes in vivo.</p><p>In this issue of Journal of Neurochemistry, Frank et al. (2017) used an integrative biochemical and genetic approach to dissect the composition and organization of PSD95 postsynaptic supercomplexes in the mouse brain. To measure the molar ratio of GluN1 to PSD95, two knock-in mouse lines in which the PSD95 and GluN1 were inserted an identical 3xFlag tag into the endogenous loci by homologous recombination in embryonic stem cells (Glun1TAP/TAP and Psd95TAP/TAP, respectively) (Figure 1A). Using an identical knock-in tag in two mouse lines is an innovative approach and requires no fractionation or other steps that could introduce sampling bias. A simple readout of blot density was applied to quantify the molar ratio of the corresponding proteins. The immuno-dot blots from Glun1TAP/TAP and Psd95TAP/TAP showed a 1:17 molar ratio of GluN1 to PSD95 in the mouse forebrain, which implies that only a small portion of PSD-95 binds to NMDARs. The authors also used different tags targeted to the gene Psd95 to identify the number of PSD95 protein molecules in each ~1.5 MDa supercomplexes (Figure 1B). They produced a compound heterozygous knock-in line, Psd95TAP/EGFP, from Psd95TAP/TAP and Psd95EGFP/EGFP, which was then used for serial purification of the Flag-tag and GFP to estimate the ratio of co-assembly of PSD95-TAP and PSD95-GFP. The showed that each ~1.5 MDa PSD95 supercomplex contains on average two molecules of PSD95 in forebrain extracts. Together with their recent findings on NMDAR complexes at synapses (Frank et al. 2016), these data suggest that almost all PSD95 proteins are retained within ~1.5 MDa PSD95 supercomplexes as a dimer.</p><p>The analysis using knock-in tagged mouse lines provides a direct readout for the PSD95-NMDAR stoichiometry at native synapses. Interestingly, NMDAR-containing supercomplexes only represent 3% of total proteins of supercomplexes that contain PSD95 (Frank et al. 2017). This finding is somewhat surprising because NMDARs and PSD95 are assumed to co-assemble in the majority of excitatory synapses. The ratio 1:34 of 1.5-NR to 1.5-PSD95 provides important information for future studies on PSD supercomplexes. Furthermore, Frank et al. (2017) investigated the higher-order molecular architecture of constituents identified from the mass spectrometry analysis of TAP-purified NMDARs and PSD95. They screened native protein assemblies of more than 60 brain proteins detected by blue non-denaturing PAGE immunoblot of mouse forebrain extracts. They found 15 constituent proteins with bands co-migrating at ~1.5 MDa molecular weight, indicating that these proteins assemble into supercomplexes (Frank et al. 2016).</p><p>How are the 1.5 MDa constituent supercomplexes organized at the PSD? What specific roles do the synaptic dominating proteins (e.g., PSD95, PSD93, and subunits of NMDARs) play in the assembly of the higher-order molecular architecture? To address these questions, the authors examined four functionally distinct proteins to identify common and distinct genetic requirements for supercomplex assembly in a battery of mutant mice (Psd95−/−, Psd93−/−, Glun2b2A(CTR)/2A(CTR), Glun2a2B(CTR)/2B(CTR), Glun2adel-CTD). These proteins are Kir2.3 (an inward-rectifying potassium channel), IQsec2/Brag1 (an ARF-GEF signaling cofactor), Arc/Arg3.1 (an immediate early gene product), and Adam22 (a trans-synaptic adhesion protein), which were partitioned into multiple distinct assemblies that all included a discrete band migrating with masses that ranged from 1.2 to 3 MDa. The array of direct readouts indicates that the four supercomplexes are differentially assembled and depend on the presence of PSD95, PSD93, and GluN2 (Figure 1C). The authors also extended their findings to different organizations of NMDAR-Kir2.3 ion channel-channel supercomplex in the rostroventral midbrain and caudodorsal forebrain, and they showed that Kir2.3-NMDAR supercomplexes seem to be anatomically restricted to certain brain regions. Their findings shed new light on our understanding of the genetic hierarchy required for the assembly of distinct supercomplex subfamilies at excitatory synapses in the brain.</p><p>The work by Frank et al. (2017) may serve a fine example for future investigations into the molecular mechanisms that govern the assembly of PSD and synaptic diversity. Giving that synaptic plasticity is critically involved in learning and memory and in many neurological disorders such as epilepsy, chronic pain, and drug addiction, understanding the detailed molecular organization of PSD is fundamentally important. There are many new questions emerge from the work by Frank et al. (2017). For example, what are the dynamic changes of the molecular composition and structure of postsynaptic supercomplexes during learning and stress? How are the PSD supercomplexes reorganized in various neurological disease condition? Recent development of new and powerful experimental tools offers an unprecedented opportunity to answer these questions and define the genetic and epigenetic basis and the \\"rules of order\\" for the molecular composition and arrangement of PSD in the mammalian brain.</p>","answer":"The mammalian synapses are highly organized as supramolecular protein machines for precise and efficient neurotransmitter release and signaling. The synaptic complexes comprising PSD95 and the glutamate N-methyl-D-aspartic acid receptors, two key players involved in synaptic plasticity and cognitive functions, are extensively studied at excitatory synapses. Frank and colleagues in this issue of the J. Neurochemistry using gene-tagging knock-in, targeted mutations and quantitative biochemical assays to determine the composition and stoichiometry of endogenous proteins at the postsynaptic density in the mouse brain. They showed that a dimer of PSD95 can organize postsynaptic proteins into multiple distinct ~1.5 MDa PSD95 supercomplexes subfamilies at excitatory synapses. Their findings shed new light on our understanding of the genetic hierarchy required for the assembly of distinct supercomplex subfamilies at excitatory synapses in the brain. The integrative biochemical and genetic approach used in this work may serve as a fine example for future investigations into the molecular mechanisms that govern the assembly of postsynaptic protein complexes and synaptic diversity."},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey on Sensor Coverage and Visual Data Capturing/Processing/Transmission in Wireless Visual Sensor Networks Chapter Title:  Sensor Coverage/Deployment in WVSNs 1. Abstract of Cited Paper (BIB001):  Visual sensor networks (VSNs) merge computer vision, image processing and wireless sensor network disciplines to solve problems in multi-camera applications by providing valuable information through distributed sensing and collaborative in-network processing. Collaboration in sensor networks is necessary not only to compensate for the processing, sensing, energy, and bandwidth limitations of each sensor node but also to improve the accuracy and robustness of the sensor network. Collaborative processing in VSNs is more challenging than in conventional scalar sensor networks (SSNs) because of two unique features of cameras, including the extremely higher data rate compared to that of scalar sensors and the directional sensing characteristics with limited field of view. In this paper, we study a challenging computer vision problem, target detection and counting in VSN environment. Traditionally, the problem is solved by counting the number of intersections of the backprojected 2D cones of each target. However, the existence of visual occlusion among targets would generate many false alarms. In this work, instead of resolving the uncertainty about target existence at the intersections, we identify and study the non-occupied areas in the cone and generate the so-called certainty map of non-existence of targets. This way, after fusing inputs from a set of sensor nodes, the unresolved regions on the certainty map would be the location of target. This paper focuses on the design of a light-weight, energy-efficient, and robust solution where not only each camera node transmits a very limited amount of data but that a limited number of camera nodes is used. We propose a dynamic itinerary for certainty map integration where the entire map is progressively clarified from sensor to sensor. When the confidence of the certainty map is satisfied, a geometric counting algorithm is applied to find the estimated number of targets. In the conducted experiments using real data, the results of the proposed distributed and progressive method shows effectiveness in detection accuracy and energy and bandwidth efficiency. 2. Abstract of Cited Paper (BIB002):  Collaboration in visual sensor networks (VSNs) is essential not only to compensate for the processing, sensing, energy, and bandwidth limitations of each sensor node but also to improve the accuracy and robustness of the network. In this paper, we study target localization in VSNs, a challenging computer vision problem because of two unique features of cameras, including the extremely higher data rate and the directional sensing characteristics with limited field of view. Traditionally, the problem is solved by localizing the targets at the intersections of the back-projected 2D cones of each target. However, the existence of visual occlusion among targets would generate many false alarms. In this work, instead of resolving the uncertainty about target existence at the intersections, we identify and study the non-occupied areas in the cone and generate the so-called certainty map of non-existence of targets. As a result, after fusing inputs from a set of sensor nodes, the unresolved regions on the certainty map would be the location of targets. This paper focuses on the design of a light-weight, energy-efficient, and robust solution where not only each camera node transmits a very limited amount of data but that a limited number of camera nodes is involved. We propose a dynamic itinerary for certainty map integration where the entire map is progressively clarified from sensor to sensor. When the confidence of the certainty map is satisfied, targets are localized at the remaining unresolved regions in the certainty map. Based on results obtained from both simulation and real experiments, the proposed progressive method shows effectiveness in detection accuracy as well as energy and bandwidth efficiency. 3. Abstract of Cited Paper (BIB003):  This paper presents a decentralized control strategy for positioning and orienting multiple robotic cameras to collectively monitor an environment. The cameras may have various degrees of mobility from six degrees of freedom, to one degree of freedom. The control strategy is proven to locally minimize a novel metric representing information loss over the environment. It can accommodate groups of cameras with heterogeneous degrees of mobility (e.g., some that only translate and some that only rotate), and is adaptive to robotic cameras being added or deleted from the group, and to changing environmental conditions. The robotic cameras share information for their controllers over a wireless network using a specially designed multihop networking algorithm. The control strategy is demonstrated in repeated experiments with three flying quadrotor robots indoors, and with five flying quadrotor robots outdoors. Simulation results for more complex scenarios are also presented. 4. Abstract of Cited Paper (BIB004):  Coverage estimation is one of the fundamental problems in sensor networks. Coverage estimation in visual sensor networks (VSNs) is more challenging than in conventional 1-D (omnidirectional) scalar sensor networks (SSNs) because of the directional sensing nature of cameras and the existence of visual occlusion in crowded environments. This article represents a first attempt toward a closed-form solution for the visual coverage estimation problem in the presence of occlusions. We investigate a new target detection model, referred to as the certainty-based target detection (as compared to the traditional uncertainty-based target detection) to facilitate the formulation of the visual coverage problem. We then derive the closed-form solution for the estimation of the visual coverage probability based on this new target detection model that takes visual occlusions into account. According to the coverage estimation model, we further propose an estimate of the minimum sensor density that suffices to ensure a visual K-coverage in a crowded sensing field. Simulation is conducted which shows extreme consistency with results from theoretical formulation, especially when the boundary effect is considered. Thus, the closed-form solution for visual coverage estimation is effective when applied to real scenarios, such as efficient sensor deployment and optimal sleep scheduling. 5. Abstract of Cited Paper (BIB005):  Wireless visual sensor network (VSN) can be said to be a special class of wireless sensor network (WSN) with smart-cameras. Due to its visual sensing capability, it has become an effective tool for applications such as large area surveillance, environmental monitoring and objects tracking. Different from a conventional WSN, VSN typically includes relatively expensive camera sensors, enhanced flash memory and a powerful CPU. While energy consumption is dominated primarily by data transmission and reception, VSN consumes extra power onimage sensing, processing and storing operations. The well-known energy-hole problem of WSNs has a drastic impact on the lifetime of VSN, because of the additional energy consumption of a VSN. Most prior research on VSN energy issues are primarily focusedon a single device or a given specific scenario. In this paper, we propose a novel optimal two-tier deployment strategy for a large scale VSN. Our two-tier VSN architecture includes tier-1 sensing network with visual sensor nodes (VNs) and tier-2 network having only relay nodes (RNs). While sensing network mainly performs image data collection, relay network only for wards image data packets to the central sink node. We use uniform random distribution of VNs to minimize the cost of VSN and RNs are deployed following two dimensional Gaussian distribution so as to avoid energy-hole problem. Algorithms are also introduced that optimizes deployment parameters and are shown to enhance the lifetime of the VSN in a cost effective manner. 6. Abstract of Cited Paper (BIB006):  Traditional Wireless Sensor Networks (WSN) transmits the scalar data (e.g., temperature, irradiation) to the sink node. A new Wireless Visual Sensor Network (WVSN) that can transmit images is a more promising solution than the WSN on sensing, detecting and monitoring the environment to enhance awareness of the cyber, physical, and social contexts of our daily activities. Sensor coverage in WVSN is more challenging than in WSN due to besides the sensing range coverage, the Field of View (FoV) should also be considered in deploying the sensors. In this paper, we study the sensor coverage problem in WVSN. We first propose the mathematical model to formulate the sensor coverage problem in WVSN. We devise a heuristic algorithm (FoVIC) algorithm to tackle this sensor coverage problem in WVSN. The basic idea of FoVIC algorithm is to deploy a sensor one at a time that can cover the largest number of uncovered nodes and then the algorithm checks for any sensor deployed in the earlier stage that could be removed. From the computational experiments, they show that larger span angle could help the sensors to cover more nodes in bigger grid size and fewer sensors will be need in smaller grid size when in fixed sensing range and span angle. 7. Abstract of Cited Paper (BIB007):  Inspired by current challenges in data-intensive and energy-limited sensor networks, we formulate a coverage optimization problem for mobile sensors as a (constrained) repeated multiplayer game. Each sensor tries to optimize its own coverage while minimizing the processing/energy cost. The sensors are subject to the informational restriction that the environmental distribution function is unknown a priori. We present two distributed learning algorithms where each sensor only remembers its own utility values and actions played during the last plays. These algorithms are proven to be convergent in probability to the set of (constrained) Nash equilibria and global optima of a certain coverage performance metric, respectively. Numerical examples are provided to verify the performance of our proposed algorithms.Literature Review:","answer":"In WSNs, the sensors can cover an event if it is within sensing range. However, in WVSNs, besides the sensing range coverage, the event must also fall within the view angle of the camera on the sensor. Because the view angle of the camera equipped on the sensor node is limited, directional coverage instead of omni-directional coverage is applied in WVSNs. As indicated in Figure 2b , only two nodes (i.e., nodes C and E) are inside the coverage area of the camera sensor. Hence, there are two requirements (sensing range coverage and view angle coverage) for sensor coverage in WVSNs. The directional coverage literature in WSNs is surveyed in  . However, besides these two requirements, there is another factor (i.e., the occlusion problem) that needs to be addressed. In the WVSN, the camera on the sensor node could only capture the images of the object without any obstacles. Hence, line-of-sight is required between the camera on the sensor and the object. If there is an obstacle (e.g., a tree) between the sensor and the object, the sensor cannot capture the object image even if the object is within the view angle coverage of the sensor. This is known as occlusion. To be more precise, the FoV coverage in WVSNs should consider the view angle of the camera and the occlusion at the same time. Hence, as compared to the sensor coverage problem in WSNs that only needs to consider the sensing range coverage, in the sensor coverage problem in WVSNs, there are three criteria to be considered (i.e., sensing range coverage, view coverage, occlusion). In Figure 2 , we show the differences between the sensor coverage problems in WSNs and WVSNs. In Figure 2a , the sensor could sense and capture the data from the nodes that are within sensing range. Hence, the sensor could capture the data from five nodes (i.e., nodes A, B, C, D and E). In Figure 2b , besides the sensing range, the view angle from the camera on the sensor nodes pose another constraint on the coverage. The FoV of the sensor covers nodes C and E. In Figure 2c , we could observe that the node C is behind the obstacle so that the FoV of the sensor could only cover node E. Research on sensor coverage problems in WVSNs can be traced back to the art gallery problem. The art gallery problem is to identify how many guards are needed to guard an art gallery and how should they be placed  . There are polynomial algorithms to solve the 2-D art gallery problem. When the view angle of the camera on the sensor is 360° and the sensing range is unlimited, then the sensor coverage problem in WVSN could be reduced to the art gallery problem. However, in most of the cases, the view angle of the camera is less than 360° (e.g., 120°) and sensing range of the sensor is limited. This makes the sensor coverage problem in WVSN more challenging than the art gallery problem. In BIB007 , we consider a WVSN deployment algorithm with consideration of the sensing range coverage and angle coverage constraints. Optimization-based heuristics are proposed to tackle this problem. From the computational experiments, fewer sensors will be needed in a smaller grid size when in fixed sensing range and span angle. In BIB001 , the angle coverage problem in WVSNs is assessed. When sensors are deployed, the objective is to identify a minimum set of sensors that can capture all the angles of view of the object while fulfilling the image resolution requirements. This paper is about an object tracking system capturing the images of moving targets from all angles. In  , a visual sensor deployment algorithm, which minimizes the total deployment cost while guaranteeing full multi-perspective (or multi-angle) coverage of the area (i.e., the coverage needed for video panorama generation) and the minimum required resolution is discussed. This multi-angle coverage problem is the same as the all angle coverage problem described in BIB001 . In both of these works, the occlusion problem is not considered. References  BIB003 BIB005 discuss the sensor deployment problem with consideration of occlusion. In  , by assuming the shape of obstacle to be square block, they derive the expected coverage area of the camera sensors. The mathematical derivation of the coverage area starts from one camera sensor and then generalizes to the multiple sensors. The assumption of square shape obstacle helps to derive the coverage mathematical model but it is not applicable to real WVSNs. This mathematical coverage model is a lower bound on the coverage areas because it fails to consider the possible cooperation between camera sensors to reduce the uncovered areas caused by the obstacle. The method to calculate the -certainty map‖ that are the non-occluded areas for target localization and counting applications is found in BIB003 BIB002 . By cooperatively fusing the certainty map from neighboring sensors, the occluded areas beside the objects and obstacles could be minimized. In BIB005 , based on the idea of certainty map, the authors derive a close form visual coverage mathematical formulation that considers visual occlusions. Then, the minimum sensor density that suffices to ensure a visual K-coverage in a crowded sensing field is estimated. In BIB006 , the two-tier deployment problem in WVSN is considered. Tier-1 consists of visual sensor nodes that can capture the image data and tier-2 consists of relay nodes that can relay the image data back to the sink node. The goal is to minimize the deployment cost and at the same time to prolong the lifetime of the WVSN. However, without considering the FoV angle coverage and visual occlusion makes this work is not applicable to real WVSN networks. In BIB004 , a decentralized control strategy is proposed to position and orient the cameras placed on flying robots so as to cover the targeted area with minimum deployment cost. The control strategy considers heterogeneous degrees of mobility, where some cameras can translate and some cameras can only rotate. They propose an interesting performance metric, -minimum information per pixel‖, to minimize the aggregate information per camera pixel over the environment. With this minimum information per pixel performance metric, the cameras' overlapped FoV could be minimized. This performance metric also minimizes the number of camera sensors that needs to be deployed. In BIB008 , they consider the mobile camera sensor coverage optimization problem as a repeated multi-player game. They propose distributed camera sensor coverage learning algorithms based on game theory to maximize the coverage and in the same time minimize the processing/energy cost. In this constrained exact potential game, each sensor will move and set its camera to optimize its coverage utilizing only the information from its utility values and last play actions. The two proposed algorithms are proven to be convergent in probability to a set of Nash equilibria and global optima of a certain set of coverage performance metrics (tradeoff between coverage and cost). In Table 2 , we summarize the existing works on sensor coverage and the WVSN deployment problem. This table also shows existing works that do not address the four research issues namely, view angle coverage, occlusion, visual data quality aware and energy aware at the same time. Therefore, it is a challenge to consider solutions to these four issues that will meet the application needs in a cost efficient way."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: Masks can lead to pneumonia or other lung infectionsAbstract:Background Protecting Health Care Workers (HCWs) during routine care of suspected or confirmed COVID-19 patients is of paramount importance to halt the SARS-CoV-2 (Severe Acute Respiratory Syndrome-Coronavirus-2) pandemic.The WHO, ECDC and CDC have issued conflicting guidelines on the use of respiratory filters (N95) by HCWs.Methods We searched PubMed, Embase and The Cochrane Library from the inception to March 21, 2020 to identify randomized controlled trials (RCTs) comparing N95 respirators versus surgical masks for prevention of COVID-19 or any other respiratory infection among HCWs.The grading of recommendations, assessment, development, and evaluation (GRADE) was used to evaluate the quality of evidence.Findings Four RCTs involving 8736 HCWs were included.We did not find any trial specifically on prevention of COVID-19.However, wearing N95 respirators can prevent 73 more (95% CI 46-91) clinical respiratory infections per 1000 HCWs compared to surgical masks (2 RCTs; 2594 patients; low quality of evidence).A protective effect of N95 respirators in laboratory-confirmed bacterial colonization (RR= 0.41; 95%CI 0.28-0.61) was also found.A trend in favour of N95 respirators was observed in preventing laboratory-confirmed respiratory viral infections, laboratory-confirmed respiratory infection, and influenza like illness.Interpretation We found no direct high quality evidence on whether N95 respirators are better than surgical masks for HCWs protection from SARS-CoV-2.However, low quality evidence suggests that N95 respirators protect HCWs from clinical respiratory infections.This finding should be contemplated to decide the best strategy to support the resilience of healthcare systems facing the potentially catastrophic SARS-CoV-2 pandemic.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"The WHO, ECDC and CDC have issued conflicting guidelines on the use of respiratory filters (N95) by HCWs.\\", \\"However, wearing N95 respirators can prevent 73 more (95% CI 46-91) clinical respiratory infections per 1000 HCWs compared to surgical masks (2 RCTs; 2594 patients; low quality of evidence).\\", \\"A trend in favour of N95 respirators was observed in preventing laboratory-confirmed respiratory viral infections, laboratory-confirmed respiratory infection, and influenza like illness.\\", \\"Interpretation We found no direct high quality evidence on whether N95 respirators are better than surgical masks for HCWs protection from SARS-CoV-2.\\", \\"However, low quality evidence suggests that N95 respirators protect HCWs from clinical respiratory infections.\\"]}"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:Brn3cmicewerebredaspreviouslydescribed[22].","answer":"[]"},{"question":"You will be shown an abstract from a materials science research paper. Your task is to extract all synthesis operations described in the abstract into a structured JSON format. Your output should be a JSON array. Each entry in the array should be a JSON object describing a single synthesis operation. This object should have the following fields:- \\"trigger\\": A verbal predicate indicating a synthesis operation. This should be a string extracted directly from the abstract.- \\"arguments\\": An array of arguments specifying aspects of the synthesis operation. Each entry in the array should be a length-2 array formatted as [<argument_text>, <argument_type>]. The \`argument_text\` should be a string extracted directly from the abstract. The \`argument_type\` should be one of the following types: [\\"Recipe_Precursor\\", \\"Atmospheric_Material\\", \\"Participant_Material\\", \\"Recipe_Target\\", \\"Solvent_Material\\"].For instance, suppose an excerpt from the abstract reads:Tetraethoxysilane (TEOS, 98%) and cetyltrimethylammonium bromide (CTAB, 98%) were purchased from Fluka. The MTTZ-siloxy derivative (triethoxysilyl-propyl-5-mercapto-1-methyl-tetrazole) was synthesized as previously described [38].This excerpt includes two operations, which could be annotated as follows.[{\\"arguments\\": [[\\"Tetraethoxysilane\\", \\"Recipe_Precursor\\"], [\\"cetyltrimethylammonium bromide\\", \\"Recipe_Precursor\\"]], \\"trigger\\": \\"purchased\\"}, {\\"arguments\\": [[\\"MTTZ-siloxy derivative\\", \\"Recipe_Target\\"]], \\"trigger\\": \\"synthesized\\"}]In your response, please include the JSON and no other text.Abstract:10.1016/j.electacta.2015.01.051A Peanut Shell Inspired Scalable Synthesis of Three-Dimensional Carbon Coated Porous Silicon Particles as an Anode for Lithium-Ion BatteriesThe porous silicon film was treated with a liquid PAN solution (10 wt% dissolved in DMF) and ball milled for 1 h at 200 r min-1. The recipe contained 40 mg porous silicon film and 600 mg of the above liquid PAN solution. Following this, the mixed slurry was spread onto copper foil with a diameter of 14 mm for a current collector and dried for 3 h in a vacuum drying oven at 80 degC. The as-obtained PAN coated PSP electrodes were then heated in an Ar atmosphere at a rate of 5 degC min-1 to 700 degC and held for 1 h. The carbon-coated PSP loaded on per electrode is ~ 0.85 mg.","answer":"[{\\"arguments\\": [[\\"silicon\\", \\"Recipe_Precursor\\"], [\\"PAN\\", \\"Recipe_Precursor\\"]], \\"trigger\\": \\"treated\\"}, {\\"arguments\\": [[\\"DMF\\", \\"Solvent_Material\\"], [\\"PAN\\", \\"Recipe_Precursor\\"]], \\"trigger\\": \\"dissolved\\"}, {\\"arguments\\": [[\\"slurry\\", \\"Participant_Material\\"]], \\"trigger\\": \\"spread\\"}, {\\"arguments\\": [[\\"PSP\\", \\"Participant_Material\\"]], \\"trigger\\": \\"obtained\\"}, {\\"arguments\\": [[\\"Ar\\", \\"Atmospheric_Material\\"], [\\"PSP\\", \\"Participant_Material\\"]], \\"trigger\\": \\"heated\\"}, {\\"arguments\\": [[\\"slurry\\", \\"Participant_Material\\"]], \\"trigger\\": \\"mixed\\"}]"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:star forming galaxies emit most of their light in the far infrared around 100 microns , due to emission from dust heated by the recent stars formed ( e.g. sanders & mirabel 1996 ) . at high redshift ,the peak of the sed ( spectral energy distribution ) of galaxies is moving to the submillimeter range , which is at the origin of the negative k - correction effect : it is as easy to detect the continuum emission from @xmath0 and @xmath1 objects .already at the present sensitivity of submm instruments ( scuba on jcmt , mambo on iram-30 m ) , a few hundreds of galaxies have been detected at high redshift , and many of them are not identified in the visible domain . above a flux of 1mjy , deep surveys detect about 1 source per arcminute ( e.g. greve et al 2004 ) .these smg ( submillimeter galaxies ) are very actively forming stars , as luminous as ulirgs .    at the moment , it is not possible to detect more modest starbursts , and in particular the typical lyman break galaxies at redshift around 3 are not detected . with the 100 times better sensitivity of alma , they will all be detected , and the number of sources in deep surveys is expected to be multiplied by 2 orders of magnitude ( 100 objects per arcminute ) . for very high redshifts objects ( z @xmath2 7 ) , the sensitivity of alma will be larger than in the visible / nir , larger than for the jwst .the star formation history is quite uncertain at high z ( e.g. genzel & cesarsky 2000 ) , due precisely to the ill - known amount of extinction suffered by high - z galaxies .the indication given by the smg pushes towards a high contribution , corresponding to a large fraction of the cosmic infrared background accounted by starbursting enshrouded galaxies ( elbaz et al .2002 ) . in the local universe ,the star formation rate is dominated by normal ( quiescent ) galaxies .it begins to be dominated by lirgs ( with l @xmath2 10@xmath3 l@xmath4 ) at @xmath5 , and it is likely that ulirgs ( l @xmath2 10@xmath6 l@xmath4 ) dominate at very large redshift ( z@xmath2 2.5 ) .the smgs detected until now have a median redshift of @xmath7 , and the dust - corrected uv luminosities can underestimate their bolometric luminosity by 2 orders of magnitude ( chapman et al 2005 ) .in addition to dust continuum emission , alma will detect the co lines , which are much more difficult to detect , due to the absence of negative k - correction ( e.g. combes et al 1999 ) . with the present sensitivity ,it is only possible to detect high - z huge starbursts , and their star formation efficiency ( sfe ) is quite surprising ( greve et al 2005 ) .figure 1 ( left ) shows that their sfe , as traced from the ratio of the infrared luminosity ( heated dust emission ) to the amount of molecular gas present ( co luminosity ) , is higher than for lirgs and ulirgs at lower redshift .since ulirgs are explained by major mergers , smg could be mergers of high - z galaxies with a lower bulge - to - disk mass ratio , for which a merger is more violent in triggering disk instability ( e.g. mihos & hernquist 1996 ) . from a compilation of all smgs detected up to now, a typical sfr of 700 m@xmath4/yr , and a starburst phase of 40 - 200 myr can be deduced for smgs ( greve et al 2005 ) .their typical masses are 0.6 m * , and their number is compatible with hierarchical galaxy formation scenarios ( baugh et al 2005 ) .the co lines at high redshift will allow to determine more reliably than in the visible domain the kinematics of galaxies .they will give information on the dark matter distribution in galaxies , in the absence of the hi line , ( to be obtained later with ska ) .the co tully - fisher relation is even more accurate , since the co line width is less broadened by galaxy interactions than the hi width ( lavezzi & dickey 1998 , tutui & sofue 1997 ) .absorption lines are much more sensitive than emission lines to cold gas along the line of sight , provided that a strong continuum source is detected . with alma , the number of background sources available in the millimeter domain will be multiplied by 2 orders of magnitude , and it will be possible to explore the chemistry as a function of redshift , the cmb temperature versus z , or to check the variations of the fine structure constant , or the ratio of electron to proton mass , etc .. ( e.g. wiklind & combes 1998 ) ./l@xmath8 , as a function of redshift .the smg ( submillimeter galaxies ) are plotted as stars , and compared to lirgs ( full symbols ) and ulirgs ( open symbols ) . from greve et al .( 2005 ) . @xmath9_ * right * _ : predictions from numerical simulations of clusters of the thermal sz effect ( noted tsz ) , and the kinetic sz effect ( noted ksz ) , in the diagram of anisotropy power as a function of scale . the pattern of cmb primary anisotropy is plotted for comparison . from da silva et al ( 2004 ) ., width=207 ]    /l@xmath8 , as a function of redshift .the smg ( submillimeter galaxies ) are plotted as stars , and compared to lirgs ( full symbols ) and ulirgs ( open symbols ) . from greve et al .( 2005 ) . @xmath9_ * right * _ : predictions from numerical simulations of clusters of the thermal sz effect ( noted tsz ) , and the kinetic sz effect ( noted ksz ) , in the diagram of anisotropy power as a function of scale .the pattern of cmb primary anisotropy is plotted for comparison . from da silva et al ( 2004 ) ., width=207 ]since its first detection with the ryle interferometer ( jones et al 1993 ) , the thermal sz has been detected in about 100 clusters ( e.g. reviews by birkinshaw 1999 , carlstrom et al 2002 ) , with interferometers ( bima , ovro ) or single dishes ( diabolo on iram-30 m , scuba on jcmt , bolocam on cso , acbar on viper ) .the sze is a precious tool for cosmology , since the detection rate is almost independent of redshift , it depends only on the mass of the cluster. with more sensitive instruments , the mass limit will decrease , and angular resolution is then needed , to map clusters at high redshift .alma will detect the kinetic sz ( undetected up to now ) , which is expected 2 orders of magnitude lower ( cf figure 1 , right ) , and trace possible cluster rotation .there are two kinds of scientific goals that could be pursued with the sze :    * determine the cosmological parameters : by obtaining a cluster - based hubble diagram , constrain w ( the state equation of dark energy ) , @xmath10 and @xmath11 through cluster counts as a function of redshift , and obtaining the variation of t@xmath12 with ( 1+z ) .* study the physics of clusters , by mapping the hot gas across clusters , and their radial velocity ( through the kinetic sz ) , obtaining the baryon fraction , the mass - to - temperature relation , etc ..    in 2010 , at the start of alma , 5000 clusters will have been observed with planck , but essentially at z@xmath13 0 .a few hundreds will be detected at higher z with the near future experiments like amiba , sza , apex etc . and several dozens with spectral measurements .alma will be able to make detailed maps , with resolution better than a few arcsecs , with much increased sensitivity , reaching the cluster physics ( shocks , cooling flows , cold fronts , map of te ). it will be hard to make blind surveys however , since alma has too small field of view .the future x - ray satellite constellation - x / xeus will be needed to identify the clusters .alma will be able to detect polarisation signals , which are quite weak , and require high angular resolution .the ostriker - vishniac effect can provide a unique probe of the epoch of reionization , and on galaxy formation .large ionized clouds at redshift z between 7 and 10 will produce anisotropies at the arcsec scale ( ostriker & vishniac 1986 ) .estimations of the effect have been computed , with ionized gas sizes of d=2.5 - 30kpc , i.e. angles between 1 and 6 arcsec at @xmath14 ( peebles & juszkiewicz 1998 , jaffe & kamionkowski 1998a ) .the effect is dominated by the kinetic term ( v @xmath13 600km / s ) , and the expected signal is of the order of 30 micro k , detectable with alma .baugh , c.m . , lacey , c. g. , frenk , c. et al .: 2005 mnras 356 , 1191 birkinshaw m. : 1999 , phys . reports 310 , 97 carlstrom , j. e. , holder , g. p. , reese , e. d. : 2002 araa 40 , 643 chapman , s. c. , blain , a. w. , smail , i. , ivison , r. j. : 2005 , apj 622 , 772 combes f. , maoli r. , omont a. : 1999 , a&a 345 , 369 da silva , a. c. , kay , s. t. , liddle , a. r. , thomas , p. a. : 2004 , mnras 348 , 1401 elbaz , d. , cesarsky c. , chanial p. et al : 2002 , a&a 384 , 848 genzel r. , cesarsky c. : 2000 , araa 38 , 761 greve , t. r. , bertoldi , f. , smail , i. et al . : 2005 , apj 359 , 1165 greve , t. r. , ivison , r. j. , bertoldi , f. et al : 2004 mnras 354 , 779 jaffe , a. h. , kamionkowski , m. : 1998 , phrvd 58 , d3001 jones , m. , saunders , r. , alexander , p. et al . : 1993 , nature 365 , 320 lavezzi , t. e. , dickey , j. m. : 1998 , aj 116 , 2672 mihos j.c ., hernquist l. : 1996 , apj 464 , 641 ostriker , j. p. , vishniac , e. t. : 1986 , apj 306 , l51 peebles , p. j. e. , juszkiewicz , r. : 1998 , apj 509 , 483 sanders d. , mirabel i.f . : 1996 , araa 34 , 749 tutui y. , sofue y. : 1997 a&a 326 , 915 wiklind t. , combes f. : 1998 , apj 500 , 129","answer":"alma is a privileged instrument to tackle high redshift galaxies , due to the negative k - correction in the millimeter domain .  many dusty star - forming galaxies , invisible in the optical or nir , will be detected easily through the peak of their emission in the fir redshifted in the submm between z=10 and z=5 .  their mass and dynamics will be determined through the co lines , together with the efficiency of star formation .  normal intervening galaxies at all z will be studied through absorption lines in front of quasars , exploring the dense tail of the column density spectrum .  cmb anisotropies could be detected at the arcsecond scale , the secondary effects ( sz , vishniak - ostriker ) could test the re - ionization and the nature of dark energy .  the detection of the sz effect on a few arcsec scales will allow to map in detail clusters and proto - clusters ."},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Does clinical trial data support the use of minocycline for amyotrophic lateral sclerosis?Context: Two double-blind, randomized, placebo-controlled feasibility trials of minocycline in ALS were conducted.This pilot study shows that minocycline and riluzole can be taken safely together. Further trials are needed to assess efficacy of such treatment.It reduces apoptosis in mouse models of Huntington's disease and familial amyotrophic lateral sclerosis (ALS) and is in clinical trial for sporadic ALS.Efficacy of minocycline in patients with amyotrophic lateral sclerosis: a phase III randomised trial.FINDINGS: ALSFRS-R score deterioration was faster in the minocycline group than in the placebo group (-1.30 vs -1.04 units/month, 95% CI for difference -0.44 to -0.08; p=0.005). Patients on minocycline also had non-significant tendencies towards faster decline in FVC (-3.48 vs -3.01, -1.03 to 0.11; p=0.11) and MMT score (-0.30 vs -0.26, -0.08 to 0.01; p=0.11), and greater mortality during the 9-month treatment phase (hazard ratio=1.32, 95% CI 0.83 to 2.10; p=0.23) than did patients on placebo. Quality-of-life scores did not differ between the treatment groups.INTERPRETATION: Our finding that minocycline has a harmful effect on patients with ALS has implications for trials of minocycline in patients with other neurological disorders, and for how potential neuroprotective agents are screened for use in patients with ALS.A recent publication of the results of a clinical trial of minocycline in 412 ALS patient has aroused considerable controversy in the ALS scientific community. As on previous occasions, the results obtained in the laboratory are not reproduced in clinical practice.A recent publication of the results of a clinical trial of minocycline in 412 ALS patient has aroused considerable controversy in the ALS scientific community.INTERPRETATION  Our finding that minocycline has a harmful effect on patients with ALS has implications for trials of minocycline in patients with other neurological disorders, and for how potential neuroprotective agents are screened for use in patients with ALS.A recent publication of the results of a clinical trial of minocycline in 412 ALS patient has aroused considerable controversy in the ALS scientific communityA recent publication of the results of a clinical trial of minocycline in 412 ALS patient has aroused considerable controversy in the ALS scientific community.Our finding that minocycline has a harmful effect on patients with ALS has implications for trials of minocycline in patients with other neurological disorders, and for how potential neuroprotective agents are screened for use in patients with ALS.Patients on minocycline also had non-significant tendencies towards faster decline in FVC (-3.48 vs -3.01, -1.03 to 0.11; p=0.11) and MMT score (-0.30 vs -0.26, -0.08 to 0.01; p=0.11), and greater mortality during the 9-month treatment phase (hazard ratio=1.32, 95% CI 0.83 to 2.10; p=0.23) than did patients on placebo.","answer":"no"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:As reproduction appears the key trait maximizing fitness (Viblanc et al. 2010), we predicted that greater allocations into reproduction should be made in the presence of greater number of kin, either due to a positive effect of kin numbers on energy income, or if more female kin provide a safer environment for raising the young.","answer":"Background"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: A novel role for Ets4 in axis specification and cell migration in the spider Parasteatoda tepidariorum}Article:Abstract:Organizers play important roles during the embryonic development of many animals. The most famous example is the Spemann organizer that sets up embryonic axes in amphibian embryos. In spiders, a group of BMP secreting mesenchymal cells( the cumulus) functions as an organizer of the dorsoventral axis. Similar to experiments performed with the Spemann organizer, transplantation of the cumulus is able to induce a secondary axis in spiders. Despite the importance of this structure, it is unknown which factors are needed to activate cumulus specific gene expression. To address this question, we performed a transcriptomic analysis of early embryonic development in the spider Parasteatoda tepidariorum. Through this work, we found that the transcription factor Pt-Ets4 is needed for cumulus integrity, dorsoventral patterning and for the activation of Pt-hunchback and Pt-twist expression. Furthermore, ectopic expression of Pt-Ets4 is sufficient to induce cell delamination and migration by inducing a mesoderm-like cell fate.Introduction:The self-regulatory capacities of vertebrate embryos were most famously demonstrated by Spemann and Mangold. They found that by grafting the dorsal-lip of an amphibian embryo( now known as the Spemann Organizer) to the ventral side of the host gastrula embryo it was possible to induce a secondary body axis( Spemann and Mangold, 2001; De Robertis, 2009; Anderson and Stern, 2016). Intriguingly, spider embryos also have high self-regulatory capacities, even to the extent that twinning can occur spontaneously( Napiórkowska et al., 2016; Oda and Akiyama-Oda, 2008). During spider embryogenesis a group of migratory cells( the cumulus) is needed to break the radial symmetry of the early embryo and to induce the dorsoventral body axis( Oda and Akiyama-Oda, 2008; Akiyama-Oda and Oda, 2003, 2006; McGregor et al., 2008; Hilbrant et al., 2012; Mittmann and Wolff, 2012; Schwager et al., 2015). Similar to the vertebrate experiments, Holm showed that transplanting cumulus material was able to induce a secondary axis in spider embryos( Holm, 1952). Modern work has shown that the cumulus signals via BMP signaling( again, similar to vertebrates). The mesenchymal cumulus cells are the source of the BMP receptor ligand Decapentaplegic( Akiyama-Oda and Oda, 2006). Interfering with the BMP signaling pathway by gene knockdown results in the loss of dorsal tissue identity, which in turn leads to completely radially-symmetric and ventralized embryos( Akiyama-Oda and Oda, 2006). The cumulus forms in the center of the so-called germ-disc( the embryonic pole of the embryo) and migrates underneath the ectoderm towards the rim of the disc. Arrival of the cumulus at the rim induces the opening of the germ-disc( Oda and Akiyama-Oda, 2008; Akiyama-Oda and Oda, 2003, 2006; McGregor et al., 2008; Hilbrant et al., 2012; Mittmann and Wolff, 2012; Schwager et al., 2015). Cumulus migration is dependent on the Hh-signaling pathway( Akiyama-Oda and Oda, 2010) and it was shown that the knockdown of components of this signaling pathway results in cumulus migration defects and in the ectopic opening of the germ-disc( Akiyama-Oda and Oda, 2010). How the cumulus is specified and forms is still under debate. During the formation of the germ-disc a small cluster of cells ingress and form an indentation where the future center of the fully formed germ-disc will be located. This cluster of cells appears as a visible spot and is called the primary thickening( Akiyama-Oda and Oda, 2003; Hilbrant et al., 2012). However, it is not clear whether all or only a subset of the cells of the primary thickening give rise to the cumulus, or if cumulus cells arise from subsequent cell invagination at the site of the primary thickening( Oda and Akiyama-Oda, 2008; Akiyama-Oda and Oda, 2003). Cell tracing( Holm, 1952; Edgar et al., 2015), as well as the expression of the endodermal marker forkhead( Oda et al., 2007) within the primary thickening/cumulus cells led to the suggestion that the primary thickening/cumulus cells are central endodermal cells( Hilbrant et al., 2012; Oda et al., 2007). However, these studies could not completely rule out that the labeled cumulus cells develop into cells of the visceral mesoderm( Edgar et al., 2015). During the last 15 years, research focused on candidate genes known to be involved in development in Drosophila melanogaster has revealed several aspects of how spider embryos pattern their main body axis. However, there are many open questions regarding the early regulation of cumulus specific gene expression, cumulus establishment and maintenance. To overcome the limitations of the candidate gene approach, we have carried out transcriptome sequencing of carefully staged embryos to find new genes involved in cumulus and axial patterning in the spider Parasteatoda tepidariorum. From this work, we have identified the transcription factor Pt-Ets4 as a new gene expressed during early development and have found it to be expressed exclusively within the central primary thickening and the cells of the migrating cumulus. Our combined genetic and cellular analyses show that Pt-Ets4 is needed for the integrity of the cumulus. We found that the knockdown of this gene leads to embryos that show axis patterning defects reminiscent of BMP knockdown phenotypes, suggesting that an intact cumulus is needed to induce the formation of the bilaterally symmetric spider embryo. Importantly, Pt-Ets4 is necessary and sufficient for driving the early expression of twist( a gene involved in gastrulation and mesoderm formation in Drosophila) and hunchback, and the ectopic expression of Pt-Ets4 is sufficient to induce cell delamination.Discussion:The cumulus is a fascinating example of a migrating and signaling organizer. Thus far, cumulus-related dorsoventral patterning defects have been observed in spider embryos that either completely lack BMP signaling or are deficient for cumulus migration( Akiyama-Oda and Oda, 2006, Akiyama-Oda and Oda, 2010). Here, we show that the knockdown of the transcription factor Pt-Ets4 generates a novel dorsoventral phenotype that is dependent on cumulus integrity. Our results show that formation of the bilaterally symmetric spider embryo is a precisely timed process that relies on the presence of an intact, migrating and signaling cumulus.","answer":"At the earliest stages of animal development , embryos consisting of only a handful of cells must figure out where each part of their body will come from . The first step in this process is to determine what will be their head versus their tail , and what will be their front versus their back . Many animals use specialized groups of cells , called “organizers” , to make this decision . This occurs in backboned animals – including humans – and also in distantly related animals such as spiders . In spiders , the developing embryo must form an organizer called the “cumulus” or the spiderling will not develop correctly . In order to form and maintain the cumulus , various genes must be turned on in a carefully controlled order in exactly the right cells . Pechmann et al . have now discovered the role of a previously unknown gene ( called Pt-Ets4 ) that marks the spot where the cumulus forms . This gene is required for cumulus maintenance and it also helps to activate a number of other cumulus-specific genes . When this gene is disrupted , the spider embryo does not properly differentiate its front from its back . The findings presented by Pechmann et al . add to a growing foundation of studies aiming to understand how genes ‘talk’ to one another and organize embryos as they develop . In years to come , the unraveling of these gene pathways , where genes sequentially turn other genes on and off , will allow us to more fully understand how a single cell can grow into a complete adult animal ."},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Can fetal aneuploidy be detected with non-invasive prenatal testing?Context: Non-invasive prenatal testing with cell-free DNA: US physician attitudes toward implementation in clinical practice.The aim of this study was to assess awareness, potential adoption, and current utilization of non-invasive prenatal testing (NIPT) analysis for common fetal aneuploidies among obstetriciansCell-free DNA has been used for fetal rhesus factor and sex determination, fetal aneuploidy screening, cancer diagnostics and monitoring, and other applications.The recent release of new, non-invasive prenatal tests for fetal aneuploidy using cell-free fetal DNA (cffDNA) has been hailed as a revolution in prenatal testing and has triggered significant commercial interest in the field.Non-invasive prenatal testing (NIPT) for aneuploidy using cell-free DNA in maternal plasma is revolutionizing prenatal screening and diagnosis.SNP-based non-invasive prenatal testing detects sex chromosome aneuploidies with high accuracy.Non-invasive prenatal testing (NIPT) of cell-free fetal DNA in maternal plasma is a novel approach, designed for detecting common aneuploidies in the fetus.This study aimed to develop a single-nucleotide polymorphism-based and informatics-based non-invasive prenatal test that detects sex chromosome aneuploidies early in pregnancy.RAPIDR: an analysis package for non-invasive prenatal testing of aneuploidy.Non-invasive prenatal testing for aneuploidy: current status and future prospects.Non-invasive prenatal testing of fetal whole chromosome aneuploidy by massively parallel sequencing.Attitudes towards non-invasive prenatal testing for aneuploidy among US adults of reproductive age.[Non-invasive prenatal test in the diagnosis of aneuploidy 13, 18 and 21--theoretical and practical aspects].To track and analyze two false positive cases from non-invasive prenatal testing for potential fetal aneuploidy.Non-invasive prenatal testing (NIPT) of fetal aneuploidy using cell-free fetal DNA is becoming part of routine clinical practice.To report secondary or additional findings arising from introduction of non-invasive prenatal testing (NIPT) for aneuploidy by whole genome sequencing as a clinical service.Israeli Society of Medical Genetics NIPT Committee Opinion 072013: Non-invasive prenatal testing of cell-free DNA in maternal plasma for detection of fetal aneuploidy.In recent years, technical advances in the molecular analysis of fetal DNA (e.g., digital PCR and massively parallel sequencing (MPS)) has enabled the successful implementation of noninvasive testing into clinical practice, such as fetal sex assessment, RhD genotyping, and fetal chromosomal aneuploidy detection.With the ability to decipher the entire fetal genome from maternal plasma DNA, we foresee that an increased number of non-invasive prenatal tests will be available for detecting many single-gene disorders in the near futureFirst identified in 1997, cell-free fetal DNA (cffDNA) has just recently been used to detect fetal aneuploidy of chromosomes 13, 18, and 21, showing its potential to revolutionize prenatal genetic testing as a non-invasive screening toolNon-invasive prenatal testing (NIPT) using cell-free fetal DNA in maternal plasma has been developed for the detection of fetal aneuploidyIsraeli Society of Medical Genetics NIPT Committee Opinion 072013: Non-invasive prenatal testing of cell-free DNA in maternal plasma for detection of fetal aneuploidyNon-invasive prenatal testing for fetal aneuploidies in the first trimester of pregnancyTo explore the value of next-generation sequencing for the non-invasive prenatal testing of fetal chromosomal aneuploidiesSecondary findings from non-invasive prenatal testing for common fetal aneuploidies by whole genome sequencing as a clinical serviceTo report secondary or additional findings arising from introduction of non-invasive prenatal testing (NIPT) for aneuploidy by whole genome sequencing as a clinical serviceSecondary findings from non-invasive prenatal testing for common fetal aneuploidies by whole genome sequencing as a clinical service.Motivations for undertaking DNA sequencing-based non-invasive prenatal testing for fetal aneuploidy: a qualitative study with early adopter patients in Hong Kong.OBJECTIVE: To determine whether non-invasive prenatal testing by maternal plasma DNA sequencing can uncover all fetal chromosome aneuploidies in one simple sequencing event.Non-invasive prenatal diagnosis of fetal aneuploidies using massively parallel sequencing-by-ligation and evidence that cell-free fetal DNA in the maternal plasma originates from cytotrophoblastic cells.Non-invasive prenatal testing (NIPT) using cell-free fetal DNA in maternal plasma has been developed for the detection of fetal aneuploidy.Non-invasive prenatal testing (NIPT) of cell-free fetal DNA in maternal plasma is a novel approach, designed for detecting common aneuploidies in the fetus.non-invasive prenatal tests for fetal aneuploidy using cell-free fetal DNA (cffDNA) has been hailed as a revolution in prenatal testing and has triggered significant commercial interest in the field.Non-invasive prenatal testing (NIPT) of fetal aneuploidy using cell-free fetal DNA is becoming part of routine clinical practice. RAPIDR (Reliable Accurate Prenatal non-Invasive Diagnosis R package) is an easy-to-use open-source R package that implements several published NIPT analysis methods.The clinical data collected thus far indicate that NIPT is highly sensitive in detecting trisomies 21 and 18, and fairly sensitive in detecting trisomy 13 and sex chromosome aneuploidies. Because false-positive results may occur, an abnormal result must be validated by invasive prenatal testing.When non-invasive prenatal screening for aneuploidy is available, maternal age alone should not be an indication for invasive prenatal diagnosis in a twin pregnancy. (II-2A) If non-invasive prenatal screening is not available, invasive prenatal diagnosis in twins should be offered to women aged 35 and over.Therefore, methods with high sensitivity and precision are required to detect and differentiate fetal DNA from the large background of maternal DNA. In recent years, technical advances in the molecular analysis of fetal DNA (e.g., digital PCR and massively parallel sequencing (MPS)) has enabled the successful implementation of noninvasive testing into clinical practice, such as fetal sex assessment, RhD genotyping, and fetal chromosomal aneuploidy detection.With the ability to decipher the entire fetal genome from maternal plasma DNA, we foresee that an increased number of non-invasive prenatal tests will be available for detecting many single-gene disorders in the near future.Non-invasive prenatal testing for fetal aneuploidies in the first trimester of pregnancy.Secondary findings from non-invasive prenatal testing for common fetal aneuploidies by whole genome sequencing as a clinical service.To explore the value of next-generation sequencing for the non-invasive prenatal testing of fetal chromosomal aneuploidies.[Cell-free nucleic acid-based non-invasive prenatal diagnosis of fetal aneuploidies].Maternal age alone is a poor minimum standard for prenatal screening for aneuploidy, and it should not be used a basis for recommending invasive testing when non-invasive prenatal screening for aneuploidy is available.Israeli Society of Medical Genetics NIPT Committee Opinion 072013: Non-invasive prenatal testing of cell-free DNA in maternal plasma for detection of fetal aneuploidy.Attitudes towards non-invasive prenatal testing for aneuploidy among US adults of reproductive age.The recent release of new, non-invasive prenatal tests for fetal aneuploidy using cell-free fetal DNA (cffDNA) has been hailed as a revolution in prenatal testing and has triggered significant commercial interest in the field.Non-invasive prenatal testing (NIPT) of fetal aneuploidy using cell-free fetal DNA is becoming part of routine clinical practice.Non-invasive prenatal testing (NIPT) by massively parallel sequencing is a useful clinical test for the detection of common fetal aneuploidies.The clinical data collected thus far indicate that NIPT is highly sensitive in detecting trisomies 21 and 18, and fairly sensitive in detecting trisomy 13 and sex chromosome aneuploidies.","answer":"yes"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:One major factor impeding more widespread adoption of deep neural networks (DNNs) is their issues with robustness, which is essential for safety critical applications such as autonomous driving. This has motivated much recent work on adversarial attacks for DNNs, which mostly focus on pixel-level perturbations void of semantic meaning. In contrast, we present a general framework for adversarial black-box attacks on trained agents, which covers semantic perturbations to the environment of the agent performing the task as well as pixel-level attacks. To do this, we re-frame the adversarial attack problem as learning a distribution of parameters that always fool the agent. In the semantic case, our proposed adversary (denoted as BBGAN) is trained to sample parameters that describe the environment with which the black-box agent interacts, such that the agent performs its dedicated task poorly in this environment. We apply BBGAN on three different tasks (primarily targeting aspects of autonomous navigation): object detection, self-driving, and autonomous UAV racing. On these tasks, BBGAN can generate failure cases that consistently fool an agent. We also demonstrate the usefulness of our framework as an analysis tool by visualizing systemic failure cases and uncovering semantic insights about the agents themselves.Cited Abstract(s):[1]: State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features—using the recently popular terminology of neural networks with ’attention’ mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3] , our detection system has a frame rate of 5 fps ( including all steps ) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.[2]: It has been well demonstrated that adversarial examples, i.e., natural images with visually imperceptible perturbations added, cause deep networks to fail on image classification. In this paper, we extend adversarial examples to semantic segmentation and object detection which are much more difficult. Our observation is that both segmentation and detection are based on classifying multiple targets on an image (e.g., the target is a pixel or a receptive field in segmentation, and an object proposal in detection). This inspires us to optimize a loss function over a set of targets for generating adversarial perturbations. Based on this, we propose a novel algorithm named Dense Adversary Generation (DAG), which applies to the state-of-the-art networks for segmentation and detection. We find that the adversarial perturbations can be transferred across networks with different training data, based on different architectures, and even for different recognition tasks. In particular, the transfer ability across networks with the same architecture is more significant than in other cases. Besides, we show that summing up heterogeneous perturbations often leads to better transfer performance, which provides an effective method of black-box adversarial attack.[3]: Given the ability to directly manipulate image pixels in the digital input space, an adversary can easily generate imperceptible perturbations to fool a Deep Neural Network (DNN) image classifier, as demonstrated in prior work. In this work, we tackle the more challenging problem of crafting physical adversarial perturbations to fool image-based object detectors like Faster R-CNN. Attacking an object detector is more difficult than attacking an image classifier, as it needs to mislead the classification results in multiple bounding boxes with different scales. Extending the digital attack to the physical world adds another layer of difficulty, because it requires the perturbation to be robust enough to survive real-world distortions due to different viewing distances and angles, lighting conditions, and camera limitations. We show that the Expectation over Transformation technique, which was originally proposed to enhance the robustness of adversarial perturbations in image classification, can be successfully adapted to the object detection setting. Our approach can generate adversarially perturbed stop signs that are consistently mis-detected by Faster R-CNN as other objects, posing a potential threat to autonomous vehicles and other safety-critical computer vision systems.[4]: Machine learning is enabling a myriad innovations, including new algorithms for cancer diagnosis and self-driving cars. The broad use of machine learning makes it important to understand the extent to which machine-learning algorithms are subject to attack, particularly when used in applications where physical security or safety is at risk. In this paper, we focus on facial biometric systems, which are widely used in surveillance and access control. We define and investigate a novel class of attacks: attacks that are physically realizable and inconspicuous, and allow an attacker to evade recognition or impersonate another individual. We develop a systematic method to automatically generate such attacks, which are realized through printing a pair of eyeglass frames. When worn by the attacker whose image is supplied to a state-of-the-art face-recognition algorithm, the eyeglasses allow her to evade being recognized or to impersonate another individual. Our investigation focuses on white-box face-recognition systems, but we also demonstrate how similar techniques can be used in black-box scenarios, as well as to avoid face detection.[5]: We construct targeted audio adversarial examples on automatic speech recognition. Given any audio waveform, we can produce another that is over 99.9 similar, but transcribes as any phrase we choose (at a rate of up to 50 characters per second). We apply our iterative optimization-based attack to Mozilla's implementation DeepSpeech end-to-end, and show it has a 100 success rate. The feasibility of this attack introduce a new domain to study adversarial examples.","answer":"Attacks beyond Classifiers Sharif al [4] demonstrate attacks on other perception networks and attack a face recognition system by painting frames of sunglasses. Calini and Vagner use adversarial attacks to confuse a speech recognition system [5] . Xie al [2] perform adversarial attacks on object detection and segmentation by perturbing image pixels and show the transferability of the perturbation to different networks.Chen al [3] propose expectation over transformation to construct adversarial attacks on faster R-CNN [1] that is robust to perspective and occlusion. However, they only demonstrate how it works on stop-signs."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Arsenic\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Exendin-4 protects hypoxic islets from oxidative stress and improves islet transplantation outcome. Oxidative stress produced during pancreatic islet isolation leads to significant β-cell damage. Homeostatic cytokines secreted subsequently to islet transplantation damage β-cells by generating oxygen free radicals. In this study, exendin-4, a glucagon-like peptide-1 analog improved islet transplantation outcome by increasing the survival of diabetic recipient mice from 58% to 100%. We hypothesized that this beneficial effect was due to the ability of exendin-4 to reduce oxidative stress. Further experiments showed that it significantly reduced the apoptotic rate of cultured β-cells subjected to hypoxia or to IL-1β. Reduction of apoptotic events was confirmed in pancreatic islet grafts of exendin-4-treated mice. Exendin-4 enhanced Akt phosphorylation of β-cells and insulin released from them. It even augmented insulin secretion from islets cultivated at hypoxic conditions. Exposure to hypoxia led to a decrease in the activation of Akt, which was reversed when β-cells were pretreated with exendin-4. Moreover, exendin-4 increased the activity of redox enzymes in a hypoxia-treated β-cell line and reduced reactive oxygen species production in isolated pancreatic islets. Recovery from diabetes in mice transplanted with hypoxic islets was more efficient when they received exendin-4. In conclusion, exendin-4 rescued islets from oxidative stress caused by hypoxia or due to cytokine exposure. It improved the outcome of syngenic and xenogenic islet transplantation.","answer":"{\\"Chemical\\": [\\"oxygen\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:DNA polymerase POLQ and cellular defense against DNA damage. In mammalian cells, POLQ (pol θ) is an unusual specialized DNA polymerase whose in vivo function is under active investigation. POLQ has been implicated by different experiments to play a role in resistance to ionizing radiation and defense against genomic instability, in base excision repair, and in immunological diversification. The protein is formed by an N-terminal helicase-like domain, a C-terminal DNA polymerase domain, and a large central domain that spans between the two. This arrangement is also found in the Drosophila Mus308 protein, which functions in resistance to DNA interstrand crosslinking agents. Homologs of POLQ and Mus308 are found in multicellular eukaryotes, including plants, but a comparison of phenotypes suggests that not all of these genes are functional orthologs. Flies defective in Mus308 are sensitive to DNA interstrand crosslinking agents, while mammalian cells defective in POLQ are primarily sensitive to DNA double-strand breaking agents. Cells from Polq (-/-) mice are hypersensitive to radiation and peripheral blood cells display increased spontaneous and ionizing radiation-induced levels of micronuclei (a hallmark of gross chromosomal aberrations), though mice apparently develop normally. Loss of POLQ in human and mouse cells causes sensitivity to ionizing radiation and other double strand breaking agents and increased DNA damage signaling. Retrospective studies of clinical samples show that higher levels of POLQ gene expression in breast and colorectal cancer are correlated with poorer outcomes for patients. A clear understanding of the mechanism of action and physiologic function of POLQ in the cell is likely to bear clinical relevance.","answer":"[]"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Type 1 diabetes, Secondary diabetes, gestational diabetesOngoing dementia treatment or anti-depressive disorder medicationUncontrolled psychiatric disorderBDI = 30 pointsHeavy alcoholicsUnderlying chronic liver disease (hemochromatosis, liver cell carcinoma, autoimmune liver disease, liver cirrhosis, chronic viral hepatitis)Allergy or hypersensitivity to target medication or any of its componentsRenal failure, moderate or severe renal impairment (estimated glomerular filtration rate < 30 mL/min/1.73 m2), or ongoing dialysisAbnormal liver function (AST/ALT > x3 upper normal limit)History of alcohol or drug abuse in the previous 3 monthsPremenopausal women who are nursing or pregnantHuman immunodeficiency virus (HIV) or human immunodeficiency virus (AIDS)chronic pancreatitis or pancreatic cancer","answer":"{\\"Condition\\": [\\"renal impairment\\", \\"hemochromatosis\\", \\"Premenopausal\\", \\"human immunodeficiency virus (AIDS)\\", \\"hypersensitivity\\", \\"r drug the p\\", \\"liver cell carcinoma\\", \\"alcoholics\\", \\"Renal failure\\", \\"drug abuse\\", \\"nursing\\", \\"chronic liver disease\\", \\"chronic viral hepatitis\\", \\"autoimmune liver disease\\", \\"chronic pancreatitis\\", \\"dementia\\", \\"Allergy\\", \\"liver cirrhosis\\", \\"Human immunodeficiency virus (HIV)\\", \\"Type 1 diabetes\\", \\"gestational diabetes\\", \\"pregnant\\", \\"Secondary diabetes\\", \\"pancreatic cancer\\"], \\"Device\\": [], \\"Drug\\": [\\"anti-depressive disorder medication\\", \\"target medication\\"], \\"Measurement\\": [\\"BDI\\", \\"liver function\\", \\"estimated glomerular filtration rate\\", \\"AST/ALT\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [\\"women\\"], \\"Procedure\\": [\\"treatment\\", \\"dialysis\\"], \\"Qualifier\\": [\\"Heavy\\", \\"Uncontrolled\\", \\"severe\\", \\"moderate\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"AST/ALT u003e x3 upper normal limit\\", \\"estimated glomerular filtration rate u003c 30 mL/min/1.73 m2\\", \\"moderate or severe\\", \\"moderate or severe renal impairment\\", \\"alcohol or drug abuse\\", \\"hemochromatosis, liver cell carcinoma, autoimmune liver disease, liver cirrhosis, chronic viral hepatitis\\", \\"Abnormal liver function\\", \\"Allergy or hypersensitivity\\"], \\"Temporal\\": [\\"in the previous 3 months\\", \\"ongoing\\", \\"Ongoing\\"], \\"Value\\": [\\"Abnormal\\", \\"u003e x3 upper normal limit\\", \\"= 30 points\\", \\"u003c 30 mL/min/1.73 m2\\"], \\"Visit\\": []}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Treatment of severe meconium aspiration syndrome with porcine surfactant: a multicentre, randomized, controlled trial.Abstract 1:A randomized, controlled clinical trial was performed in 19 Chinese neonatal intensive care units to evaluate the safety and efficacy of exogenous surfactant replacement therapy for severe meconium aspiration syndrome (MAS) in term and near-term neonates.                Sixty-one term infants with severe MAS were randomly assigned to either a surfactant or a control group within 36 h after birth. The infants in the surfactant group (n=31) received an initial dose of porcine lung-derived surfactant (Curosurf) at 200 mg/kg, and repeated doses of 200, 100 and 100 mg/kg were given at 6-12 h intervals to a maximum of four doses if oxygenation index (OI) deteriorated by >2 from baseline. The primary outcomes were a reduction of OI to less than 10 and an increase of the pre-treatment a/A PO(2) ratio of 100% over baseline 24 h after surfactant treatment. The secondary outcomes were duration of mechanical ventilation, incidence of complications and survival to discharge from hospital.                The general demographic characteristics of the study subjects were similar. There was a trend for surfactant-treated infants to have an improvement in arterial oxygenation compared to the control group. In comparison with the control group at 24 h, the surfactant group had a lower mean OI (8.1 vs 10.9), more infants with a 100% increase of a/A PO(2) (83% vs 48%, p<0.01) over baseline, and a larger area under the curve for PaO(2)/FiO(2) over baseline (3762+/-1877 vs 2715+/-1644 mmHg(.)h, p<0.05). Repeated measures of these parameters were also in favour of the surfactant group during 24 h to 3 and 7 d compared to the baseline (p<0.05). No differences were found in mean duration of mechanical ventilation, incidence of major complications and number of survivors between the two groups.                Surfactant replacement therapy improved oxygenation in the study subjects, suggesting that surfactant may have a role in the treatment of severe MAS in term and near-term infants.Title 2:Multicenter study of surfactant (beractant) use in the treatment of term infants with severe respiratory failure. Survanta in Term Infants Study Group.Abstract 2:The purpose of this study was to determine whether surfactant (beractant) administration to term newborns in respiratory failure and at risk for requiring extracorporeal membrane oxygenation (ECMO) treatment would significantly reduce the incidence of severe complications through 28 days of age and the need for ECMO.                A multicenter (n = 44), randomized, double-blind, placebo-controlled trial was conducted. Infants weighing 2000 gm or more with gestational ages of 36 weeks or greater were stratified by diagnosis (meconium aspiration syndrome, sepsis, or idiopathic persistent pulmonary hypertension of the newborn) and oxygenation index (15 to 22, 23 to 30, 31 to 39) and then randomly assigned to receive four doses of beractant, 100 mg/kg (n = 167), or air placebo (n = 161) before ECMO treatment and four additional doses during ECMO, if ECMO was required. The incidence of untoward effects (including hemorrhagic, neurologic, pulmonary, renal, cardiovascular, infectious, metabolic, and technical complications) occurring before and after randomization and through 28 days of age or discharge were recorded.                The two treatment groups were comparable in baseline parameters, including birth weight, sex, gestational age, oxygenation index, and primary diagnosis. There was no difference in the incidence of severe complications. The need for ECMO therapy was significantly less in the surfactant group than in the placebo group (p = 0.038); this effect was greatest within the lowest oxygenation index stratum (15 to 22; p = 0.013).                Use of surfactant, particularly in the early phase of respiratory failure, significantly decreases the need for ECMO in the treatment of term newborns with respiratory failure, without increasing the risk of complications.Title 3:Surfactant replacement therapy for meconium aspiration syndrome.Abstract 3:The pathophysiology of meconium aspiration syndrome (MAS) is related not only to mechanical obstruction of the airways and chemical injury to the respiratory epithelium but also to surfactant inactivation by meconium. A randomized, controlled study was performed to determine whether high-dose surfactant therapy improves the pulmonary morbidity of term infants ventilated for MAS.                Forty term infants receiving mechanical ventilation for MAS were enrolled in this trial, in which the infants in the study group (n = 20) received up to four doses of 150 mg (6 mL)/kg beractant (Survanta), instilled every 6 hours by continuous infusion for 20 minutes via a side hole endotracheal tube adapter, and the infants in the control group (n = 20) received 6 mL/kg air placebo.                Mean arterial-to-alveolar PO2 ratio values increased from 0.09 to 0.11 at 1 and 6 hours with a concomitant slight decrease in oxygenation index values from 23.7 to 19.7 at 1 hour and 20.7 at 6 hours after the first dose of surfactant. Oxygenation improved cumulatively after the second and third dose of surfactant, with mean arterial-to-alveolar PO2 ratios and oxygenation indices of 0.18 and 12.1 at 6 hours after the second dose of surfactant and 0.31 and 5.9 at 6 hours after the third dose of surfactant, eliminating the need for a fourth dose in any infant in the study group. After three doses of surfactant, persistent pulmonary hypertension had resolved in all but one of the infants in the study group versus none of the infants in the control group. No air leaks developed in any of the 20 infants in the study group after surfactant therapy, and only 1 infant required extracorporeal membrane oxygenation. Air leaks developed in 5 of the 20 infants in the control group, and 6 underwent extracorporeal membrane oxygenation. The duration of mechanical ventilation, oxygen therapy, and admission was significantly shorter in the surfactant group than in the control group.                Surfactant replacement therapy, if started within 6 hours after birth, improves oxygenation and reduces the incidence of air leaks, severity of pulmonary morbidity, and hospitalization time of term infants with MAS.","answer":"In infants with MAS, surfactant administration may reduce the severity of respiratory illness and decrease the number of infants with progressive respiratory failure requiring support with ECMO. The relative efficacy of surfactant therapy compared to, or in conjunction with, other approaches to treatment including inhaled nitric oxide, liquid ventilation, surfactant lavage and high frequency ventilation remains to be tested."},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:we tested well - defined risk groups for hiv and parenterally transmitted infections to more precisely determine the transmission route of parv4 .autopsy tissue samples used in this project were obtained from the edinburgh medical research council ( mrc ) hiv brain and tissue bank at the western general hospital , edinburgh .consent for use of postmortem tissue was obtained from the lothian research ethics committee ( lrec2002/4/36 ) .study subjects were divided into 4 groups of approximately equal size ( n = 1113 , table 1 ) : 1 ) injection drug users ( idus ) without hiv infection ( all positive for antibodies to hcv when testing was available ) ; 2 ) men who had sex with men ( msm ) with aids without a history of parenteral exposure ( all negative for antibodies to hcv when testing was available ) ; 3 ) idus infected with hiv with aids - defining illnesses ; and 4 ) idus infected with hiv who died of other causes while presymptomatic . *idu , injection drug user ; m , male ; f , female ; y , yes ; n , no ; msm , men who had sex with men ; nd , not done ; na , not applicable . these study groups overlap with the previously analyzed hiv - positive group ( 8) , restricted to those in whom parenteral risk factors for infection have been identified .   previously described in ( 8) .we also tested samples from 2 persons with hemophilia treated with nonvirally inactivated factor viii concentrates from the late 1970s onward , both of whom became infected with hiv and hcv .study subjects showed similar demographic characteristics , with similar age ranges and dates of death largely restricted to the 1990s ( table 1 ) .the idus , msm , and patients with hemophilia with aids showed similar mean cd4 counts before death , indicating profound immunosuppression .samples of lymphoid tissue ( lymph node or spleen ) and bone marrow were assayed for parvovirus b19 and parv4 dna sequences by nested pcr as described ( 8) . in all samples , > 0.5 g of genomic dna was tested , which provided a test sensitivity of 6 copies of target sequence/10 cells .detection of both parvovirus b19 and parv4 sequences was highly reproducible between the 2 tissues analyzed ( table 2 ) , which enabled generally unambiguous categorization of study subjects into infected and uninfected categories .persons in whom b19 or parv4 was detected in 1 of the 2 tissues were considered infected , although the same conclusions for risk group associations would have been reached if the 5 persons with discrepant results had been excluded from analysis or considered uninfected ( data not shown ) .parvovirus b19 infection frequency increased with age of the patients and corresponded closely to frequencies of b19 seropositivity in the general population in the united kingdom recorded previously for different age ranges ( 9 ) .infections were absent in 2 young patients with hemophilia ( 22 and 26 years of age at death ) , ranged from 46% to 67% in idus and msm ( mean ages 3339 years ) , and were found in all 8 low - risk controls ( mean age 54 years ) .these findings provide further evidence for high frequencies of or potentially universal persistence of infection with b19 in those exposed ( 57 ) .in contrast , infections with parv4 were restricted to those with a history of parenteral exposure ( idus and patients with hemophilia ) .frequencies of infection ranged from 8.3% ( 1/12 ) of the hiv - negative idus to 55% and 85% , respectively , in hiv - infected idus before and after aids developed .no parv4 infections were found in the msm group , despite profound immunosuppression associated with aids and histories of frequent past exposure to sexually transmitted infections , such as hiv .the absence of detectable parv4 in the msm group demonstrates that parv4 infections are not specifically associated with hiv co - infection .instead , its specific risk group association with injection drug use and hemophilia ( and absence in msm and low - risk controls ) provides evidence for a predominantly or exclusively parenteral route of transmission .the higher frequency of parv4 detection in hiv - positive persons may be an indirect reflection of the greater degree of parenteral exposure among idus who become infected with hiv . in edinburgh ,hiv infections are much less prevalent in the idu population than are hcv infections , because the transmission of hiv is less efficient through the bloodborne route ( 10 ) .the higher frequency of parv4 infection in the idu - aids group compared with the frequency in the pre - aids group may also have originated through differential parenteral exposure ; aids is more likely to be diagnosed among those exposed early to hiv in their period of injection .it could be argued that the higher frequency of parv4 infection in hiv - infected idus and persons with hemophilia may be the result of greater ease of detection in immunosuppressed persons .parv4 infections may be widespread like b19 infections but may only persist in detectable amounts in persons whose compromised immune system allows viral reactivation .although this hypothesis was difficult to discount in our original study ( 8) , our new observation of an absence of parv4 infection in msm with aids removes the proposed link between immunosuppression and parv4 detection .the findings of our study provide evidence that parv4 is primarily or exclusively transmitted through parenteral routes , a marked contrast to predominantly respiratory routes of transmission of parvoviruses in other genera , including b19 and human bocavirus ( 11 ) .although no information was provided on the specific risk factors for persons at high risk who were enrolled in the options project cohort ( i.e. , whether an idu or msm ) , the finding of a higher prevalence of viremia in this group compared with blood donor controls ( 3 ) is also consistent with evidence obtained in the current study for a predominantly parenteral route of transmission .previous observations of the remarkable sequence homogeneity of parv4 nucleotide sequences between variants detected in the united kingdom and in the united states ( 3,8 ) indicate the recent origin and spread of this virus in this specific risk group .although we currently understand little about its pathogenicity or the clinical outcome of infection , parv4 infection represents a potential newly emerging , additional bloodborne virus in idus .given the resistance of parvoviruses to viral inactivation procedures , recipients of a wide range of plasma - derived therapeutics may also be at risk for parv4 infection .","answer":"transmission routes of parv4 , a newly discovered human parvovirus , were investigated by determining frequencies of persistent infections using autopsy samples from different risk groups .  predominantly parenteral routes of transmission were demonstrated by infection restricted to injection drug users and persons with hemophilia and absence of infection in homosexual men with aids and low - risk controls ."},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Is pregabalin effective for sciatica?Context: CONCLUSIONS: Treatment with pregabalin did not significantly reduce the intensity of leg pain associated with sciatica and did not significantly improve other outcomes, as compared with placebo, over the course of 8 weeks. The incidence of adverse events was significantly higher in the pregabalin group than in the placebo group.Whilst pregabalin (PGB) and gabapentin (GBP) are both used to treat neuropathic pain, their relative role in sciatica is unclear.GBP and PGB appeared to demonstrate comparable efficacy and SE. However, the amount and quality of evidence was low, and only indirect comparisons were available.","answer":"no"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: What was the predominant rotavirus genotype in the pre-vaccine era, in Australia?Context: G1P[8] was the dominant genotype nationally in the prevaccine era (1995-2006).From 1995 to 2015, the Australian Rotavirus Surveillance Program conducted genotypic analysis on 13051 rotavirus-positive samples from children <5 years of age, hospitalized with acute gastroenteritis.In the pre-vaccine era, G1P[8] was most prevalent, ranging from 39% (411/1,057) to 74% (527/709) per year.","answer":"G1P[8]"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Neural networks trained with backpropagation, the standard algorithm of deep learning which uses weight transport, are easily fooled by existing gradient-based adversarial attacks.This class of attacks are based on certain small perturbations of the inputs to make networks misclassify them.We show that less biologically implausible deep neural networks trained with feedback alignment, which do not use weight transport, can be harder to fool, providing actual robustness.Tested on MNIST, deep neural networks trained without weight transport (1) have an adversarial accuracy of 98% compared to 0.03% for neural networks trained with backpropagation and (2) generate non-transferable adversarial examples.However, this gap decreases on CIFAR-10 but is still significant particularly for small perturbation magnitude less than 1 ⁄ 2.Deep neural networks trained with backpropagation (BP) are not robust against certain hardly perceptible perturbation, known as adversarial examples, which are found by slightly altering the network input and nudging it along the gradient of the network's loss function [1] .The feedback-path synaptic weights of these networks use the transpose of the forward-path synaptic weights to run error propagation.This problem is commonly named the weight transport problem.Here we consider more biologically plausible neural networks introduced by Lillicrap et al. [2] to run error propagation using feedbackpath weights that are not the transpose of the forward-path ones i.e. without weight transport.This mechanism was called feedback alignment (FA).The introduction of a separate feedback path in [2] in the form of random fixed synaptic weights makes the feedback gradients a rough approximation of those computed by backpropagation.Since gradient-based adversarial attacks are very sensitive to the quality of gradients to perturb the input and fool the neural network, we suspect that the gradients computed without weight transport cannot be accurate enough to design successful gradient-based attacks.Here we compare the robustness of neural networks trained with either BP or FA on three well-known gradient-based attacks, namely the fast gradient sign method (FGSM) [3] , the basic iterative method (BIM) and the momentum iterative fast gradient sign method (MI-FGSM) [4] .To the best of our knowledge, no prior adversarial attacks have been applied for deep neural networks without weight transport.We perform an empirical evaluation investigating both the robustness of deep neural networks without weight transport and the transferability of adversarial examples generated with gradient-based attacks.The results on MNIST clearly show that (1) FA networks are robust to adversarial examples generated with FA and (2) the adversarial examples generated by FA are not transferable to BP networks.On the other hand, we find that these two conclusions are not true on CIFAR-10 even if FA networks showed a significant robustness to Figure 1b , we denote by \\"BP → F A\\" the generation of adversarial examples using BP to fool the FA network, and \\"F A → BP \\" the generation of adversarial examples using FA to fool the BP network gradient-based attacks.Therefore, one should consider performing more exhaustive analysis on more complex datasets to understand the impact of the approximated gradients provided by feedback alignment on the adversarial accuracy of biologically plausible neural networks attacked with gradient-based methods.","answer":"Less biologically implausible deep neural networks trained without weight transport can be harder to fool."},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Australian National Health and Medical Research Council dietary salt study in mild hypertension.Abstract 1:Two-hundred-and-twelve untreated subjects (mean age 52.3 +/- 0.8 years; 181 males and 31 females) with a diastolic blood pressure between 90 and 100 mmHg were recruited to the study. Subjects were seen fortnightly and, after 4 pre-diet visits, were randomized into a normal diet group (A, 55 subjects), a high-potassium diet group (B, 52 subjects receiving greater than 100 mmol K+/day) a reduced-sodium diet group (C, 52 subjects receiving 50-75 mmol Na+/day) or a high-potassium and low-sodium diet group (D, 53 subjects receiving same Na+ and K+ as groups B and C). Two-hundred subjects completed the diet phase of 12 weeks. Urine sodium fell to 86 +/- 7 mmol/day in group C and 73 +/- 6 mmol/day in group D, while daily potassium excretion rose to 96 +/- 5 mmol in group B and 87 +/- 4 mmol in group C. Systolic and diastolic blood pressure fell by 3.8 +/- 1.0 and 1.6 +/- 0.6 mmHg respectively in the normal diet group. The falls in systolic and diastolic blood pressures (mmHg) in the diet phase were 7.7 +/- 1.1 and 4.7 +/- 0.7 (B), 8.9 +/- 1.0 and 5.8 +/- 0.6 (C) and 7.9 +/- 0.9 and 4.2 +/- 0.7 (D). These falls were all greater than those in the control group on an intention-to-treat analysis (P less than 0.005) but did not differ from each other. Factorial analysis confirmed that the falls in pressure attributable to the low-sodium diet and high-potassium diet were not additive.(ABSTRACT TRUNCATED AT 250 WORDS)Title 2:The influence of oral potassium citrate/bicarbonate on blood pressure in essential hypertension during unrestricted salt intake.Abstract 2:In several trials, a blood pressure lowering effect of potassium chloride could be demonstrated. However, it is not known if other potassium salts are also effective. In a randomized cross-over trial, 12 patients with essential hypertension were treated for 8 weeks with placebo and 120 mmol potassium per day. Potassium was given together with 50% citrate and 50% bicarbonate as anions. Urinary potassium excretion rose from 61.8 +/- 8.1 to 166.7 +/- 21.2 mmol/24 hours during potassium supplementation. However, blood pressure and heart rate remained unchanged when compared to placebo. Non-chloride potassium salts may not be effective in lowering blood pressure in essential hypertension. Since potassium rich foods like fruits and vegetables contain potassium mostly as non-chloride salts, it appears to be premature to recommend a high dietary potassium intake as a mean to treat elevated blood pressure.Title 3:Placebo-controlled trial of potassium supplements in black patients with mild essential hypertension.Abstract 3:Forty-eight black patients with mildly increased blood pressure (BP) that had not yet been subjected to treatment took part in a double-blind clinical trial of the efficacy and tolerability of oral potassium supplements (64 mmol daily) versus a matching placebo (made of starch with coating) in a 16-week study. Potassium supplements produced a significant decrease in mean supine and standing BP within 4 weeks after treatment inception. Urinary potassium excretion increased significantly in the 24 patients who received potassium supplements (p less than 0.001). No significant changes occurred in plasma sodium and potassium concentrations or in urinary excretion of sodium during the study. All patients completed the trial without experiencing any notable untoward effects. These results are consistent with the premise that oral potassium supplements may exert hypotensive effects of clinically significant degree in patients with mild hypertension.Title 4:Controlled trial of long term oral potassium supplements in patients with mild hypertension.Abstract 4:A 15 week randomised double blind placebo controlled trial of oral potassium supplements (48 mmol daily) was conducted in 37 patients who had mildly increased blood pressure and a normal dietary intake of sodium. After a two month run in and a one week baseline period the patients were randomly assigned to receive either potassium supplements (n = 18) or placebo (n = 19). By the third week of treatment blood pressure in the actively treated group had decreased significantly compared with that in the placebo group, though the decrease reached its maximum after 15 weeks. Urinary potassium excretion increased significantly in the group who received potassium supplements, but no significant changes were found in plasma sodium and potassium concentrations or in urinary sodium excretion. In a subgroup of 13 patients who underwent a further nine weeks of treatment with oral potassium supplements at half of the previous dose (24 mmol daily) their blood pressure, at the end of this second study period, was still significantly lower compared with their baseline value but not with that of the placebo group. These results show that moderate oral potassium supplements are associated with a long term reduction in blood pressure in patients who have mild hypertension.Title 5:Double-blind, placebo-controlled trial of potassium chloride in the treatment of mild hypertension.Abstract 5:Epidemiological and experimental data suggest blood pressure-lowering effects of dietary potassium. A randomized, double-blind clinical trial was used to assess blood pressure response to orally administered potassium, 120 mEq/day, and to placebo in 101 adults with mild hypertension. Blood pressure was measured with a random-zero sphygmomanometer every 2 weeks of this 8-week trial. Systolic blood pressure in the potassium-treated group decreased by 6.4 +/- 13.7 (SD) mm Hg (p less than or equal to 0.025) compared with 0.11 +/- 13.0 mm Hg in the placebo-treated group (p = 0.96). Diastolic blood pressure in the potassium-treated group decreased by 4.1 +/- 8.3 mm Hg (p less than or equal to 0.05) compared with a 1.6 +/- 6.5 mm Hg decrease in placebo-treated subjects (p = 0.09). Baseline blood pressure of potassium-treated subjects was unexpectedly higher than that of controls. After correcting for baseline variation, blood pressure still decreased 3.4/1.8 mm Hg more in potassium recipients than in placebo recipients (p = 0.14 and 0.24, respectively). Blood pressure decreased by 19/13 mm Hg in five blacks taking potassium versus a 1/0 mm Hg increase in seven blacks taking placebo. Compliance with the potassium regimen was 91.5% by pill count; only one subject discontinued treatment because of side effects. In conclusion, 120 mEq/day of microencapsulated potassium chloride was well tolerated in adults with mild hypertension. An antihypertensive effect of potassium cannot be ruled out despite the fact that there was no statistically significant difference between potassium-treated and placebo-treated subjects after adjustment for differences in baseline blood pressure.(ABSTRACT TRUNCATED AT 250 WORDS)","answer":"Potassium supplementation has no statistically significant effect on blood pressure. Due to small number of participants in the two high quality trials, the short duration of follow-up, and the unexplained heterogeneity between trials, the evidence about the effect of potassium supplementation on blood pressure is not conclusive. Further high quality RCTs of longer duration are required to clarify whether potassium supplementation can reduce blood pressure and improve health outcomes."},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(OBJECTIVE) In this study we investigated whether the association between measures of fetal growth restriction and intellectual performance was mediated by socioeconomic or familial factors.(METHODS) This was a population-based cohort study of 357,768 Swedish males born as singletons without congenital malformations between 1973 and 1981. The main outcome measure was intellectual performance at military conscription.(RESULTS) Compared with men born with appropriate birth weight for gestational age, men born light for gestational age suffered an increased risk of low intellectual performance after adjustment for maternal and socioeconomic factors. The increase in risk of low intellectual performance related to a decrease in birth weight for gestational age was similar between families and within families. Men born short or with a small head circumference for gestational age were also at increased risk of low intellectual performance, both when adjusting for maternal and socioeconomic factors and within families.Question:Birth characteristics and risk of low intellectual performance in early adulthood: are the associations confounded by socioeconomic factors in adolescence or familial effects?Answer:","answer":"NO"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:This paper proposes a new actor-critic-style algorithm called Dual Actor-Critic or Dual-AC.  It is derived in a principled way from the Lagrangian dual form of the Bellman optimality equation, which can be viewed as a two-player game between the actor and a critic-like function, which is named as dual critic.  Compared to its actor-critic relatives, Dual-AC has the desired property that the actor and dual critic are updated cooperatively to optimize the same objective function, providing a more transparent way for learning the critic that is directly related to the objective function of the actor.We then provide a concrete algorithm that can effectively solve the minimax optimization problem, using techniques of multi-step bootstrapping, path regularization, and stochastic dual ascent algorithm.We demonstrate that the proposed algorithm achieves the state-of-the-art performances across several benchmarks.Reinforcement learning (RL) algorithms aim to learn a policy that maximizes the long-term return by sequentially interacting with an unknown environment.Value-function-based algorithms first approximate the optimal value function, which can then be used to derive a good policy.These methods BID23 BID28 often take advantage of the Bellman equation and use bootstrapping to make learning more sample efficient than Monte Carlo estimation BID25 .However, the relation between the quality of the learned value function and the quality of the derived policy is fairly weak BID6 .Policy-search-based algorithms such as REINFORCE BID29 and others (Kakade, 2002; BID18 , on the other hand, assume a fixed space of parameterized policies and search for the optimal policy parameter based on unbiased Monte Carlo estimates.The parameters are often updated incrementally along stochastic directions that on average are guaranteed to increase the policy quality.Unfortunately, they often have a greater variance that results in a higher sample complexity.Actor-critic methods combine the benefits of these two classes, and have proved successful in a number of challenging problems such as robotics (Deisenroth et al., 2013) , meta-learning BID3 , and games (Mnih et al., 2016 ).An actor-critic algorithm has two components: the actor (policy) and the critic (value function).As in policy-search methods, actor is updated towards the direction of policy improvement.However, the update directions are computed with the help of the critic, which can be more efficiently learned as in value-function-based methods BID24 Konda & Tsitsiklis, 2003; BID13 BID7 BID19 .Although the use of a critic may introduce bias in learning the actor, its reduces variance and thus the sample complexity as well, compared to pure policy-search algorithms.While the use of a critic is important for the efficiency of actor-critic algorithms, it is not entirely clear how the critic should be optimized to facilitate improvement of the actor.For some parametric family of policies, it is known that a certain compatibility condition ensures the actor parameter update is an unbiased estimate of the true policy gradient BID24 .In practice, temporaldifference methods are perhaps the most popular choice to learn the critic, especially when nonlinear function approximation is used (e.g., BID19 ).Inthis paper, we propose a new actor-critic-style algorithm where the actor and the critic-like function, which we named as dual critic, are trained cooperatively to optimize the same objective function. Thealgorithm, called Dual Actor-Critic , is derived in a principled way by solving a dual form of the Bellman equation BID6 . Thealgorithm can be viewed as a two-player game between the actor and the dual critic, and in principle can be solved by standard optimization algorithms like stochastic gradient descent (Section 2). Weemphasize the dual critic is not fitting the value function for current policy, but that of the optimal policy. Wethen show that, when function approximation is used, direct application of standard optimization techniques can result in instability in training, because of the lack of convex-concavity in the objective function (Section 3). Inspiredby the augmented Lagrangian method (Luenberger & Ye, 2015; Boyd et al., 2010) , we propose path regularization for enhanced numerical stability. We alsogeneralize the two-player game formulation to the multi-step case to yield a better bias/variance tradeoff. The fullalgorithm is derived and described in Section 4, and is compared to existing algorithms in Section 5. Finally,our algorithm is evaluated on several locomotion tasks in the MuJoCo benchmark BID27 , and compares favorably to state-of-the-art algorithms across the board.Notation. We denotea discounted MDP by M = (S, A, P, R, γ), where S is the state space, A the action space, P (·|s, a) the transition probability kernel defining the distribution over next-state upon taking action a in state x, R(s, a) the corresponding immediate rewards, and γ ∈ (0, 1) the discount factor. If thereis no ambiguity, we will use a f (a) and f (a)da interchangeably.In this paper, we revisited the linear program formulation of the Bellman optimality equation, whose Lagrangian dual form yields a game-theoretic view for the roles of the actor and the dual critic.Although such a framework for actor and dual critic allows them to be optimized for the same objective function, parametering the actor and dual critic unfortunately induces instablity in optimization.We analyze the sources of instability, which is corroborated by numerical experiments.We then propose Dual Actor-Critic , which exploits stochastic dual ascent algorithm for the path regularized, DISPLAYFORM0 Figure 2: The results of Dual-AC against TRPO and PPO baselines.Each plot shows average reward during training across 5 random seeded runs, with 50% confidence interval.The x-axis is the number of training iterations.The Dual-AC achieves comparable performances comparing with TRPO and PPO in some tasks, but outperforms on more challenging tasks.multi-step bootstrapping two-player game, to bypass these issues.Proof We rewrite the linear programming 3 as DISPLAYFORM1 Recall the T is monotonic, i.e., if DISPLAYFORM2 Theorem 1 (Optimal policy from occupancy) s,a∈S×A ρ * (s, a) = 1, and π DISPLAYFORM3 a∈A ρ * (s,a) .Proof For the optimal occupancy measure, it must satisfy DISPLAYFORM4 where P denotes the transition distribution and I denotes a |S| × |SA| matrix where I ij = 1 if and only if j ∈ [(i − 1) |A| + 1, . . . , i |A|].Multiply both sides with 1, due to µ and P are probabilities, we have 1, ρ * = 1.Without loss of generality, we assume there is only one best action in each state.Therefore, by the KKT complementary conditions of (3), i.e., ρ(s, a) R(s, a) + γE s |s,a [V (s )] − V (s) = 0, which implies ρ * (s, a) = 0 if and only if a = a * , therefore, the π * by normalization.Theorem 2 The optimal policy π * and its corresponding value function V * is the solution to the following saddle problem DISPLAYFORM5 Proof Due to the strong duality of the optimization (3), we have DISPLAYFORM6 Then, plugging the property of the optimum in Theorem 1, we achieve the final optimization (6).","answer":"We propose Dual Actor-Critic algorithm, which is derived in a principled way from the Lagrangian dual form of the Bellman optimality equation. The algorithm achieves the state-of-the-art performances across several benchmarks."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"IGF\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Arabidopsis CP12 mutants have reduced levels of phosphoribulokinase and impaired function of the Calvin-Benson cycle. CP12 is a small, redox-sensitive protein, the most detailed understanding of which is the thioredoxin-mediated regulation of the Calvin-Benson cycle, where it facilitates the formation of a complex between glyceraldehyde-3-phosphate dehydrogenase (GAPDH) and phosphoribulokinase (PRK) in response to changes in light intensity. In most organisms, CP12 proteins are encoded by small multigene families, where the importance of each individual CP12 gene in vivo has not yet been reported. We used Arabidopsis thaliana T-DNA mutants and RNAi transgenic lines with reduced levels of CP12 transcript to determine the relative importance of each of the CP12 genes. We found that single cp12-1, cp12-2, and cp12-3 mutants do not develop a severe photosynthetic or growth phenotype. In contrast, reductions of both CP12-1 and CP12-2 transcripts lead to reductions in photosynthetic capacity and to slower growth and reduced seed yield. No clear phenotype for CP12-3 was evident. Additionally, the levels of PRK protein are reduced in the cp12-1, cp12-1/2, and multiple mutants. Our results suggest that there is functional redundancy between CP12-1 and CP12-2 in Arabidopsis where these proteins have a role in determining the level of PRK in mature leaves and hence photosynthetic capacity.","answer":"{\\"Gene\\": [\\"phosphoribulokinase\\", \\"thioredoxin\\", \\"CP12\\", \\"cp12-2\\", \\"CP12-3\\", \\"cp12-3\\", \\"glyceraldehyde-3-phosphate dehydrogenase\\", \\"CP12-1\\", \\"CP12-2\\", \\"PRK\\", \\"cp12-1/2\\", \\"GAPDH\\", \\"cp12-1\\"]}"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:obesity has reached epidemic proportions in the united states and has become a major health problem estimated to account for approximately 280,000 deaths per year .bariatric surgery has been proven to be the most effective treatment of refractory morbid obesity .roux - en - y gastric bypass ( rygb ) appears to offer the best long - term results , and the demand for this procedure has increased dramatically the last decade .identification of risk factors that predict adverse outcomes after rygb and preoperative risk stratification is an integral part of patient education and selection and ultimately leads to improved patient satisfaction .hypertension , sleep apnea , advanced age , sex , and surgeon 's experience have all been associated with adverse outcome after rygb in recent studies .the main limitation of these studies is that they represent a single institution 's experience .our population - based study includes all patients who underwent rygb in the state of pennsylvania over a 3-year period and aims to determine whether age or sex is predictive of adverse outcomes and mortality .all hospitals in the state of pennsylvania are required to review all in - patient hospital medical records and submit data regarding patients ' age , sex , race , principal and all secondary diagnoses , principal and all secondary procedures , length of stay , illness severity , discharge status , unique hospital and surgeon identifier , and insurance status to the pennsylvania health care cost containment council ( phc4 ) on a quarterly basis .data are abstracted from medical records and collection is made by trained personnel in each hospital and is based on standardized requirements .the principal procedure code for rygb ( 44.31 or 44.39 ) and the principal diagnosis code for obesity ( diagnostic - related group 288 ) were used to search the phc4 database and identify patients who underwent rygb for obesity between january 1 , 1999 and december 31 , 2001 .data regarding age , sex , race , comorbid medical conditions , illness severity , in - hospital mortality , in - hospital adverse outcome , and insurance status for all appropriately selected patients were obtained from the database .prevalences were computed , and subsequent analysis with the mixed procedure ( sas institute inc . , cary , nc ) was used to assess whether advanced age ( > 50 years ) or sex significantly increase mortality or adverse outcomes after rygb for obesity while controlling for any comorbid medical conditions .adverse outcome was defined as a combined variable ( one or more postoperative complications , nonroutine hospital transfer , and in - hospital mortality ) .complications or deaths that occurred after discharge from the original hospitalization for surgery could not be identified based on the collected data and therefore are not reported .the independent variables included patient age , sex , race , comorbid medical conditions , insurance status , and illness severity .co - morbidities included the secondary diagnoses of all the obesity - related medical conditions , such as sleep apnea , hypercholesterolemia , cirrhosis , history of thrombophlebitis , coronary artery disease , diabetes mellitus , hypertension , osteoarthritis , benign intracranial hypertension , esophageal reflux , depression , and congestive heart failure .patient 's preoperative illness severity was categorized as catastrophic , major , moderate , or minor , according to the ohio refined drg grouper , a severitized drg report .ages ranged from 16 to 74 years with a mean and median of 42 years .included were 3076 ( 80% ) patients 50 years or younger ( mean age , 38 years ) and 609 patients older than 50 years ( mean age , 55 years ) .no change occurred in the annual ratios of female / male and younger / older patients between 1999 and 2001 .patient 's preoperative illness severity was categorized as catastrophic in 4.5% , major in 16.3% , moderate in 16.2% , and minor in 63% of cases .seventy - one percent of patients had one or more comorbid medical conditions ( table 1 ) .incidence of comorbid medical conditions the median length of stay was 4 days ( range , 1 to 83 ) .an in - hospital adverse outcome occurred in 813 of 4685 ( 17.4% ) patients who underwent rygb .of the 813 patients with adverse outcomes , 756 ( 93% ) had postoperative complications , 29 ( 3.6% ) required a nonroutine hospital transfer , and 28 ( 3.4% ) died in the immediate postoperative period . the overall complication andrespiratory complications were the most common ( 7.7% ) followed by cardiac events ( 3.4% ) , intestinal obstruction ( 2.7% ) , urinary complications ( 2.6% ) , hemorrhage ( 2.4% ) , sepsis ( 1.9% ) , renal failure ( 0.8% ) , pulmonary embolism ( 0.2% ) , clostridium difficile colitis ( 0.2% ) and fascial dehiscence ( 0.1% ) .patients with major or catastrophic illness severity preoperatively had the highest prevalence ( 71.5% ) of adverse outcome , while patients with medicaid insurance had the highest mortality rate ( 1.6% ) .age > 50 years , male sex , black race , and presence of comorbidities were also associated with an increased prevalence of adverse outcomes and mortality ( table 2 ) .patient characteristics with increased prevalence of adverse outcome and mortality male patients had a significantly higher prevalence of adverse outcomes ( males , 24% vs. females , 16% , p<0.05 ) and mortality ( males , 1.2% vs. females , 0.47% , p<0.05 ) ( figures 1 and 2 ) . the likelihood of an adverse outcome in males was further increased ( p<0.05 ) when the groups were controlled for the presence of comorbid medical conditions ( figure 1 ) .older patients had a significantly higher adverse outcome rate ( > 50 , 23% vs. 50 , 16% , p<0.05 ) as well .adverse outcome rates were higher ( p<0.05 ) in older patients who had no other comorbid medical conditions ( figure 3 ) .the presence of comorbidities had no significant effect on mortality rate in relation to sex or age .prevalence of adverse outcome in relation to age , with , or without comorbidity interaction .cmc = comorbid medical conditions , * p<0.05 . mortality rate in relation to age .statewide data from pennsylvania confirmed the national trend of an increasing demand for bariatric procedures . in this study ,the annual number of patients undergoing rygb almost doubled each year ( 672 in 1999 , 1322 in 2000 , 2691 in 2001 ) . in accordance with the literature , the majority of patients in this study undergoing rygb were females less than 50 years old and of white origin .approximately 2/3 of patients had additional obesity - related comorbidities and 1/5 was considered severely ill preoperatively .in addition , the 16.1% and 0.6% complication and mortality rates reported in this study fall within the range of rates reported in previous open and laparoscopic rygb series . according to our results ,the complication rate in male patients undergoing rygb was further increased when additional comorbid medical conditions were present .mortality rate in male patients however was not related to pre - existing medical conditions .recent studies have also shown that male sex is an independent risk factor for complications and anastomotic leaks .livingston et al showed in his series of 1067 patients that adverse outcomes after rygb occurred more frequently in men ( men , 13.1% vs. women , 6% ) .this study confirmed previous reports that advanced age significantly increased the likelihood of complications after rygb .in addition , as previously reported , the presence of comorbid medical conditions in older patients undergoing rygb did not have a negative impact on the morbidity of the procedure .our finding , however , that mortality rates were similar in younger and older patients , is in contrast with the study by livingston et al that showed that mortality of patients 55 years of age and older was 3.5% compared with 1.1% in patients younger than 55 years ( p=0.05 ) .it is possible that the different cut - off values used in the 2 studies to dichotomize the age variable may have affected the ultimate results of the analysis .contrary to most of the published series that represent a single institution 's experience , this is a large , population - based study including surgeons and institutions from the entire state of pennsylvania .therefore , the applicability of the findings is more likely to be generalizable to all practice settings . the inclusion of nonroutine hospital transfers to the in - hospital adverse outcomes allowed the identification of all patients who experienced a less than routine outcome after elective surgery .furthermore , in this study , the effect of comorbid medical conditions on the relationship of age and sex to the morbidity and mortality of rygb was statistically controlled .previous studies , such as that by nguyen and colleagues , have not done so .body mass index ( bmi ) was not included in the data reported to the phc4 by each hospital .therefore , the effect of the bmi - age , or bmi - sex interaction on the morbidity and mortality rates is not known .nevertheless , bmi was not a significant risk factor for an adverse outcome after rygb in any of the previously published reports .similarly , the anastomotic leak rate was not separately recorded and therefore could not be assessed .in addition , laparoscopic and open rygb could not be distinguished in the state database and could not be analyzed separately . as a result , the effect of type of approach on the increased morbidity and mortality of rygb in patients of advanced age or male sex can not be investigated .a recent study showed that the laparoscopic approach did not ameliorate the increased risk of men for postoperative complications . in his series of 150 laparoscopic rygb ,nguyen et al demonstrated that men had a greater risk of developing complications ( adjusted odds ratio , 5.2 , p=0.03 ) than did women .in contrast , another recent study of 188 laparoscopic rygb by perugini et al showed that of 9 variables examined by univariate and multivariate analysis , including age and sex , only surgeon 's experience , sleep apnea , and hypertension were predictive of complications .further studies on larger patient populations are needed to delineate the effect , if any , of the type of approach on the increased morbidity and mortality of rygb in older men .major complications following revision operations have been more frequent than in primary rygb in most reported series .nevertheless , it is possible that the inclusion of revision operations in this study may have affected the reported morbidity and mortality rate .another limitation of this study is that the complication and mortality rates represent events that occurred within the initial in - hospital course from the day of surgery until the date of discharge .discharge data collection and entry did not allow the identification of events that occurred during the 30-day postoperative period but after the initial discharge .therefore , it is likely that the complication and mortality rates reported herein might have been underestimated .finally , the coding of data for these databases may lead to systematic over- or underreporting .in summary , this study clearly suggests that male patients are at increased risk for complications and death after rygb and should be monitored closely during the immediate postoperative period .careful preoperative patient assessment for any comorbid medical conditions is important for risk stratification purposes , especially for men , because their presence increases the morbidity of the procedure .older patients require close perioperative monitoring as well because advanced age ( > 50 years ) has a negative impact on morbidity rates after rygb . despite the fact that the morbidity and mortality rates after rygb remain within acceptable limits for both subgroups , older patients and men","answer":"objectives : this study aimed to determine whether advanced age or sex was predictive of adverse outcomes after roux - en - y gastric bypass.methods:the pennsylvania state discharge database was searched for records of morbidly obese patients who underwent roux - en - y gastric bypass .  the sass mixed procedure was used to test whether mortality alone or adverse outcomes ( postoperative complications , nonroutine hospital transfer and mortality ) were significantly related to sex or advanced age ( > 50 years ) .  the presence of comorbidities was used as a blocking variable.results:between 1999 and 2001 , 4,685 patients underwent roux - en - y gastric bypass in pennsylvania , of which 82% were female and 20% were older than 50 years of age .  comorbidities were present in 71% of patients .  twenty - eight deaths ( 0.6% ) and 813 adverse outcomes ( 17.4% ) occurred .  mortality was greater in males than in females ( 1.2% vs. 0.47% , p<0.05 ) without comorbid interaction .  mortality did not increase with age .  adverse outcomes were related to both sexes ( 24% male , 16% female , p<0.05 ) and age ( 50 , 16% vs. > 50 , 23% , p<0.05 ) with a small comorbid interaction.conclusion:adverse outcomes are more frequent among males and older patients and are influenced by comorbidities .  male patients have a higher mortality that was not affected by the presence of comorbidities ."},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Use of topical benzydamine in gynecology.Abstract 1:To evaluate the topical anti-inflammatory activity of benzydamine when used as 0.1% solution for vaginal douche, a double blind, parallel group, randomized clinical trial was carried out on 30 patients with vaginitis following internal radiotherapy for carcinoma of the uterus. The patients were divided into 3 groups, one being treated with 0.1% benzydamine plus tricetol as preservative, one with 0.1% benzydamine alone, and one with placebo. Treatment began 12-24 hours after radiotherapy. Benzydamine was found to be significantly superior to placebo in its overall topical anti-inflammatory activity both after 5 and 15 days of treatment. Tricetol did not interfere with the therapeutic effect of benzydamine.Title 2:Prevention of vaginal stenosis in patients following vaginal brachytherapy.Abstract 2:The assessment of patients following intracavitary irradiation administered as part of the treatment of gynaecological malignancy reveals vaginal stenosis in the majority. Vaginal dilators are available for daily insertion in an attempt to prevent the formation of adhesions. However, the design of the dilator neglects the fact that the vagina is the most distensible in the upper third and hence many patients develop stenosis of the upper vagina. Many clinicians have abandoned the use of dilators and instead advise patients to have sexual intercourse to prevent the problem. In 1994, we designed a new vaginal stent, which was given to all patients who had received intracavitary irradiation with full instructions about its use. This stent was designed to suit better the true anatomy of the vagina and hence, with correct use, should prevent vaginal stenosis. A retrospective study was undertaken to look at the incidence of vaginal stenosis and this was compared with the incidence in patients using the new stent. The study revealed that 57% of the patients who were advised to have sexual intercourse had stenosis, whereas 11% of the patients using the stent had evidence of stenosis, which, however, was related to their incorrect use of the stent. In those who used the stent correctly there was no evidence of vaginal stenosis. Details of the design of the stent and the problems relating to those who used the stent incorrectly are presented. The findings of this study strongly support the continued use of this vaginal stent in patients who have undergone intracavitary irradiation as a means of preventing this common complication.Title 3:Topical benzydamine in the treatment of vaginal radiomucositis.Abstract 3:Radiotherapy for invasive cervical cancer involves a high risk of local complications. Classically, the critical structures are the rectum, the bladder and the bony ring of the pelvis. However, endocavitary curietherapy is an important component in the radiological treatment since it delivers the highest dose to the vaginal mucosa. The anti-inflammatory efficacy of benzydamine in gynaecology, already well documented, was investigated in our controlled clinical study (benzydamine vs. placebo) involving 32 consecutive unselected patients treated by endocavitary curietherapy with 137caesium sources, alone, after radical surgery, or in association with megavoltage external irradiation. In the group with topical benzydamine, we have observed a statistically significant improvement of subjective symptomatology and colposcopic view. On the contrary in the placebo group a worsening of all the clinical parameters considered became evident.Title 4:Postirradiation vaginitis. An evaluation of prophylaxis with topical estrogen.Abstract 4:nan","answer":"These findings reflect the quality of published data regarding interventions for this aspect of the management of radiation induced complications. Although there is grade IC evidence, these studies are not recent, the allocation concealment is unclear in the text, and overall there is a variable level of assessment of the response, emphasising the need for more studies to be conducted with improved designs to clarify the investigative process and support the final result."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Generalized Weakness in a Transplant Patient: A Case Presentation Generalized weakness in transplant patients is a major complaint in tertiary rehabilitation hospitals. The diagnosis and management of generalized weakness in this population pose challenges for physicians. We present the case of a transplant patient with generalized weakness who was eventually diagnosed with calciphylaxis using a multidisciplinary diagnostic approach of electrodiagnostics, vascular study, and skin biopsy. Calciphylaxis is a rare cutaneous disorder that mimics other collagen vascular diseases in its presentation and fulminant course. Physiatrists should be cognizant of calciphylaxis, as it signals a poor prognosis if not correctly diagnosed and treated in a timely manner, with high incidence of sepsis, wound pain, and disability. V.","answer":"{\\"AnatomicalStructure\\": [\\"vascular\\"], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"Calciphylaxis\\", \\"cutaneous disorder\\", \\"collagen vascular diseases\\", \\"sepsis\\", \\"calciphylaxis\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"wound pain\\", \\"diagnosed\\", \\"disability\\", \\"Generalized weakness\\", \\"poor prognosis\\", \\"Generalized Weakness\\", \\"diagnosis\\", \\"transplant\\", \\"Transplant\\", \\"generalized weakness\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"study\\", \\"skin biopsy\\", \\"management\\", \\"multidisciplinary diagnostic approach\\", \\"electrodiagnostics\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [\\"Case Presentation\\"], \\"MedicalDevice\\": [], \\"Organization\\": [\\"rehabilitation hospitals\\"], \\"PopulationGroup\\": [\\"population\\"], \\"ProfessionalOrOccupationalGroup\\": [\\"physicians\\", \\"Physiatrists\\"], \\"ResearchActivity\\": [], \\"SpatialConcept\\": [], \\"Virus\\": []}"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Trifluoromethyl Sulfoxides: Reagents for Metal‐Free C−H TrifluoromethylthiolationPaper sections:<p>D. Wang, C. G. Carlton, M. Tayu, J. J. W. McDouall, G. J. P. Perry, D. J. Procter, Angew. Chem. Int. Ed.2020, 59, 15918.</p><p>Incorporating fluorine into organic compounds is a useful tool in drug design and development. The fluoro group is well known to improve the pharmacokinetic properties of a molecule and fluorine‐18 is an important radioisotope in molecular imaging.1, 2 Trifluoromethylthio (SCF3) groups are commonly found in drug molecules and veterinary medicines.3, 4 By combining a fluorinated moiety with a heteroatom, many have turned to the SCF3 group to impart useful properties, such as high lipophilicity, to a compound of interest.5</p><p>An attractive route for incorporating SCF3 groups into organic molecules is through the direct, metal‐free functionalization of C−H bonds.6 Early methods using trifluoromethylsulfenyl chloride have fallen from favor because of concerns over handling and toxicity of the reagent.7 This triggered a push to develop shelf‐stable, easy‐to‐handle trifluoromethylthiolating agents (Scheme 1 A).8 Despite the advantages of these reagents, they are generally limited to the C−H trifluoromethylthiolation of highly electron‐rich (hetero)arenes, such as indoles and phenols, whereas reactions involving less nucleophilic arenes, such as anisole and toluene, are scarce.8a, 8b, 8d, 8o, 8p Furthermore, few reports describe the use of these reagents for the late‐stage trifluoromethylthiolation of complex molecules.8a, 8b, 8j, 8m, 8n</p><p>A) Current methods for transition metal‐free C−H trifluoromethylthiolation. B) This work: C−H trifluoromethylthiolation by an interrupted Pummerer reaction.</p><p>In recent years, our group9 and others10 have explored the so‐called interrupted Pummerer reaction of sulfoxides and its use for the functionalization of C−H bonds.11 For example, we have described the thioarylation of simple arenes using sulfoxides as sulfide precursors.9c Key to these reactions is the in situ formation of a highly electrophilic sulfonium salt, by activation of the sulfoxide with an acid anhydride, which is susceptible to reaction with a range of nucleophiles.</p><p>We were keen to assess whether underutilized trifluoromethyl sulfoxides would engage in C−H trifluoromethylthiolation. We reasoned that trifluoromethylsulfonium salts, generated from trifluoromethyl sulfoxides by an interrupted Pummerer reaction, would prove versatile intermediates en route to the incorporation of SCF3 into nucleophilic arenes. Herein, we present trifluoromethyl sulfoxides as novel, tuneable trifluoromethylthiolating agents (Scheme 1 B). The easy to prepare, bench‐stable and novel trifluoromethyl sulfoxides12 allow SCF3 incorporation into a variety of heteroarenes and arenes, including drug molecules, at the expense of C−H bonds. In contrast to current methods for trifluoromethylthiolation, which involve direct attack of an arene on an electrophilic SCF3 reagent, our unique strategy builds the desired connectivity to give sulfonium salts that are selectively deconstructed in situ to deliver trifluoromethylthiolated products.</p><p>Our first aim was to design and synthesize a sulfoxide suitable for general and selective trifluoromethylthiolation.13 Key to our mechanistic hypothesis for trifluoromethylthiolation is the selective loss of the R group, rather than the CF3 group, from the sulfoxide 1 (Scheme 1 B). As this step likely occurs by nucleophilic substitution in a sulfonium salt intermediate (see below), we identified the benzyl‐substituted trifluoromethyl sulfoxide 1 a as a candidate for enabling trifluoromethylthiolation: the activating effect of the adjacent π‐system, combined with the inhibitory effect of fluoro groups towards incoming nucleophiles,14 would make the benzyl group more susceptible to removal. We developed a new route for the synthesis of 1 a, which was obtained as a free‐flowing, bench‐stable, crystalline solid and has been characterized by X‐ray crystallographic analysis (Scheme 1 B).15</p><p>With a novel sulfoxide in hand, we attempted the trifluoromethylthiolation of indole (2 a; Scheme 2). The sulfoxide was activated using triflic anhydride9 to give the desired trifluoromethylthiolated indole 3 a in 70 % yield. The reaction tolerated substitution at all positions around the indole motif [C4 (3 b, 3 f, 3 h), C5 (3 d, 3 e, 3 i), C6 (3 c, 3 g), C7 (3 j) and C3 (3 k)], including various electron‐withdrawing (3 b–g) and electron‐donating (3 i–k) groups. We were pleased to find that functional groups that can undergo subsequent transformations, such as halides (3 b, 3 c), nitriles (3 d), esters (3 e–3 g), and boronate esters (3 h), were well tolerated. N‐methyl indoles also worked well in the procedure (3 l–n). A range of other heteroaromatic compounds also underwent efficient C−H trifluoromethylthiolation, such as benzothiophene (3 o), thiophenes (3 p, 3 q), benzofuran (3 r) and pyrroles (3 s, 3 t). The reaction was also executed on a gram scale without severe detriment to the yield (3 a).</p><p>Scope[a] of the metal‐free C−H trifluoromethylthiolation of heteroarenes. [a] Procedure A, conditions: i) 2 (0.3 mmol, 1.5 equiv), 1 a (0.2 mmol, 1.0 equiv), Tf2O (0.24 mmol, 1.2 equiv), MeCN (1.0 mL, 0.2 m) at 0 °C for 1 h. ii) Et2NH (0.5 mmol, 2.5 equiv). [b] Reaction run on a gram scale. [c] Numbers within parenthesis indicate ratio of C2 versus C3 trifluoromethylthiolation.</p><p>In comparison to heteroarenes, the trifluoromethylthiolation of arenes has received less attention.8a, 8b, 8d, 8o, 8p Initial results using 1 a gave poor yields of the desired trifluoromethylthiolated arenes, however, a novel ester‐derived trifluoromethyl sulfoxide, 1 b, showed good reactivity (Scheme 3). This outcome suggests that the structure of the sulfoxide can be tuned for optimization with a specific class of substrate.16 With 1 b, anisole, phenol and other alkylated arenes were responsive to trifluoromethylthiolation (5 a–e).17 Unfortunately, free amines were not tolerated in this reaction (5 f).18 A range of 1,2‐ (5 g–j) 1,3‐ (5 k) and 1,4‐disubstituted (5 l, 5 m) arenes, bearing various functionalities, such as halogens and esters, also performed well under our reaction conditions. The reaction was also applicable to trisubstituted arenes (5 n, 5 o) and naphthalenes (5 p, 5 q). Finally, we showcased our method using substrates relevant in catalysis, materials, medicine, and agriculture. We were able to trifluoromethylthiolate a BINOL derivative (5 r), pyrene (5 s), drugs (5 t), pesticides (5 u), and a natural product derivative (5 v).</p><p>Scope[a] of the metal‐free C−H trifluoromethylthiolation of arenes. [a] Procedure B, conditions: i) 4 (0.2 mmol, 1.0 equiv), 1 b (0.24 mmol, 1.2 equiv), Tf2O (0.3 mmol, 1.5 equiv), MeNO2 (1.0 mL, 0.2 m) at −25 °C for 10 min, then at RT for 3 h. ii) Et2NH (0.7 mmol, 3.5 equiv) at RT for 15 h. [b] Numbers within parenthesis indicate ratio of C4 versus C2 trifluoromethylthiolation. The major regioisomer is shown. [c] Procedure A (see Scheme 2). [d] See the Supporting Information for modified reaction stoichiometry. [e] Numbers within parenthesis indicate ratio of C4 versus C2 trifluoromethylthiolation. The major regioisomer is shown. [f] Numbers within parenthesis indicate ratio of C1 versus C2 trifluoromethylthiolation. The major regioisomer is shown.</p><p>A mechanistic proposal for the trifluoromethylthiolation is summarized in Scheme 4. The trifluoromethyl sulfoxides 1 are initially activated through reaction with Tf2O to produce the electrophilic intermediates 6. The intermediates 6 then undergo the so‐called interrupted Pummerer reaction with a (hetero)arene (e.g. 4) to give the sulfonium salts 7. Selective removal of the R group by Et2NH reveals the trifluoromethylthiolated products (e.g. 5). Experimental and computational studies provided support for our proposed mechanism. Firstly, the sulfonium salt 7 m was isolated from the reaction between p‐xylene (4 m) and 1 b.15, 19 We then modelled the dealkylation step using DFT calculations. These results showed that the transition state for attack of the amine (Et2NH) at the ‐CH2CO2Et group lies 40.8 kJ mol−1 lower in energy than the transition state for attack at the ‐CF3 group. In addition, the expected side‐product, Et2NCH2CO2Et (8), was detected by GCMS. It is likely that attack at the ‐CF3 group is disfavored because of unfavorable electrostatic interactions,14 though further studies are required to fully delineate the intricacies of this mechanism. These studies highlight our unique strategy for trifluoromethylthiolation; whereas current methods proceed through direct attack of an arene on an electrophilic SCF3 reagent,8 we have introduced alternative reactivity in which the desired connectivity is built, to give 7, before inducing controlled deconstruction and release of the desired trifluoromethylthiolated products.</p><p>A) Proposed mechanism for the trifluoromethylthiolation of (hetero)arenes using sulfoxides. B) Computational investigation of the chemoselective dealkylation. [a] The process was modelled using the cation of 7 m. See the Supporting Information for further details.</p><p>In summary, we have developed a new strategy for the metal‐free C−H trifluoromethylthiolation of (hetero)arenes. In this process, we utilize the interrupted Pummerer reaction to establish trifluoromethyl sulfoxides as novel trifluoromethylthiolating agents. Our method for incorporating SCF3 components exploits a build‐up/deconstruct strategy and is mechanistically distinct from current processes. A variety of (hetero)aromatic compounds underwent efficient trifluoromethylthiolation, including drug molecules and natural products. We expect trifluoromethyl sulfoxides to find application in other trifluoromethylthiolation reactions in the future.</p>Conflict of interest<p>The authors declare no conflict of interest.</p><p>As a service to our authors and readers, this journal provides supporting information supplied by the authors. Such materials are peer reviewed and may be re‐organized for online delivery, but are not copy‐edited or typeset. Technical support issues arising from supporting information (other than missing files) should be addressed to the authors.</p><p>Supplementary</p><p>Click here for additional data file.</p>","answer":"AbstractTrifluoromethyl sulfoxides are a new class of trifluoromethylthiolating reagent. The sulfoxides engage in metal‐free C−H trifluoromethylthiolation with a range of (hetero)arenes. The method is also applicable to the functionalization of important compound classes, such as ligand derivatives and polyaromatics, and in the late‐stage trifluoromethylthiolation of medicines and agrochemicals. The isolation and characterization of a sulfonium salt intermediate supports an interrupted Pummerer reaction mechanism."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: Hand sanitizer can help protect you from coronavirus, but it should not be considered your first line of defense against COVID-19.Abstract:The coronavirus known as SARS-CoV-2, which causes COVID-19 disease, is presently responsible for a global pandemic wherein more than 3.5 million people have been infected and more than 250,000 killed to-date.There is currently no vaccine for COVID-19, leaving governments and public health agencies with little defense against the virus aside from advising or enforcing best practices for virus transmission prevention, which include hand-washing, physical distancing, use of face covers, and use of effective disinfectants.In this study, a novel iodine complex called CupriDyne® was assessed for its ability to inactivate SARS-CoV-2.CupriDyne was shown to be effective in inactivating the virus in a time-dependent manner, reducing virus titers by 99% (2 logs) after 30 minutes, and reducing virus titers to below the detection limit after 60 minutes.The novel iodine complex tested herein offers a safe and gentle alternative to conventional disinfectants for use on indoor and outdoor surfaces.","answer":"{\\"verdict\\": \\"NEI\\", \\"evidence\\": []}"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Light-Activated Proteomic Labeling via Photocaged Bioorthogonal Non-Canonical Amino AcidsPaper sections:<p>Biological processes are staggeringly dynamic and heterogeneous. Though all cells within an organism share a common genome, differential expression of genes into proteins regulate developmental processes, tissue morphogenesis and function, disease susceptibility and response, and a diverse array of signaling events governed by a wide variety of intra- and extra-cellular cues. While each protein is encoded by a gene, protein quantity and activity cannot be determined through genomic or transcriptomic analysis1,2; such techniques are blind to posttranscriptional phenomena (e.g., translational regulation, modification, protein-biomolecular interactions), necessitating strategies to directly measure protein identity and abundance3.</p><p>Recent advances in mass spectrometry and genomic sequencing have enabled high-throughput proteomic analysis, whereby the abundance, turnover, modification, and interactions of thousands of proteins can be measured in minutes4,5. From this has emerged a growing appreciation of the exceptionally dynamic nature of the proteome, which undergoes large-scale biochemical shifts during cellular proliferation, migration, and differentiation. Efforts to quantify temporal variations of the proteome have focused on the pulsed labeling of cultures with specialty amino acids that can distinguish newly synthesized from pre-existing cellular proteins.</p><p>One particularly powerful method for interrogating proteomic fluctuations in culture is known as bioorthogonal non-canonical amino acid tagging (BONCAT). In BONCAT, pulsing cells with non-canonical amino acid (ncAA) analogs yields newly synthesized proteins that bear bioorthogonal reactive groups (e.g., azides, alkynes)6–8. Metabolically labeled proteins can be covalently modified with an affinity tag that is then exploited for purification9, enabling isolation of proteins synthesized over a short window of time and providing temporally resolved proteomics.</p><p>As protein expression, degradation, translocation, and post-translational modification occur at different rates depending on cellular and subcellular location within tissues10, we sought to control BONCAT within user-defined regions of culture. Recognizing light's unique ability to initiate chemical reactions at a time and place of interest, we developed a light-activated bioorthogonal non-canonical amino acid tagging (laBONCAT) approach (Figure 1). This strategy relies on the introduction of a molecular photocage onto the α-amine of an ncAA, preventing metabolic incorporation into proteins. Upon user-directed light exposure, the ncAA is liberated and made available for incorporation into newly translated proteins. Subsequent labeling and enrichment of these proteins is exploited for proteomic analysis.</p><p>While laBONCAT methodologies can be theoretically applied to any amino acid (including stable isotopes of natural amino acids, ncAAs, and other variants useful for quantitative proteomics), we first sought to demonstrate its utility using L-Azidohomoalanine (Aha). Aha is an azide-bearing ncAA that is metabolically incorporated by endogenous cellular machinery as a methionine (Met) surrogate11–13 whose low-level incorporation does not significantly alter protein expression14,15 (Figure 2a). Aha's azido functionality represents a useful bioorthogonal handle for subsequent labeling reactions, including the strain-promoted azide-alkyne cycloaddition16 (SPAAC) (Figure 2b). We synthesized a photocaged Aha (NPPOC-Aha, Figure 2a) through condensation of the α-amine of Aha17 with the activated ester of 2,5-dioxopyrrolidin-1-yl (2-(2-nitrophenyl)propyl) carbonate18 (NPPOC). As NPPOC-caged amines undergo irreversible β-elimination upon exposure to near-ultraviolet light18 (λ = 365 nm; Figure 2c), Aha can be photochemically generated in situ in response to mild and cytocompatible light exposure18–22. We believe this to be the first example of an amino acid (canonical or otherwise) that has been photocaged at its N-terminus to prevent translation.</p><p>For this system to be effective, the kinetics of NPPOC uncaging should be rapid, such that the liberation of free Aha is not rate limiting compared with the biological processes under study. To determine its photolysis kinetics, NPPOC-Aha (dissolved in H2O:CH3CN, 50:50) was irradiated with collimated UV light18 (λ = 365 nm, 10 mW cm−2, 0 – 600 s exposure). Degradation products were quantitatively analyzed by HPLC, with elution fractions compositionally identified by mass spectrometry. A first-order decay constant of 0.0075 ± 0.0002 s−1 was observed for NPPOC photolysis (Figure 2d); 90% of the NPPOC cleaved after 5 minutes of mild irradiation (10 mW cm−2), a timescale suitable for many biological applications.</p><p>To demonstrate photomediated incorporation of Aha, Met-depleted HeLa cells were incubated with NPPOC-Aha (250 µM). Subsequent irradiation with UV light (λ = 365 nm, 10 mW cm−2, 5 min) yielded photoliberated Aha for metabolic incorporation. Two hours after light exposure, cells were lysed and their proteins were treated with a bicyclononyne-modified fluorescein (FAM-BCN, 100 nM, Figure 2e) to introduce a fluorescent label by SPAAC. Protein fluorescence was then used to quantify the extent of Aha incorporation following protein separation by sodium dodecyl sulfate polyacrylamide gel electrophoresis (SDS-PAGE). Non-irradiated samples and the Met control exhibited a similar lack of fluorescence; the UV-treated NPPOC-Aha and Aha control displayed significant fluorescent enhancement (Figure 3a), indicating successful implementation of laBONCAT.</p><p>To control the extent of ncAA incorporation into newly synthesized proteins, we varied NPPOC-Aha concentration (0 – 250 µM) and the intensity of light irradiation (0 – 10 mW cm−2) employed during photo-uncaging. As expected, Aha incorporation increased with NPPOC-Aha concentration for a given exposure condition; for low NPPOC-Aha concentrations, metabolic labeling increased with light intensity (Figure 3b). When the extent of incorporation was normalized for the expected concentration of liberated Aha, based on values predicted by the photokinetics and assuming no side reactions accompanying photolysis, the result was a smooth, continuous curve that plateaus above ~50 µM free Aha (Figure 3c). To determine the potential effects of UV irradiation on metabolic incorporation, labeled protein fluorescence was compared for samples treated with Aha (50 µM) +/− light (10 mW cm−2, 5 min) (Figure 3d). Finding no statistical difference in protein labeling following UV irradiation, we compared incorporation between Aha and irradiated NPPOC-Aha cultures (each at 100 µM). NPPOC-Aha + light gave rise to slightly less incorporation than Aha alone, which we attribute to incomplete photoconversion of NPPOC-Aha to Aha. This is supported by data that protein labeling does not depend on whether NPPOC-Aha is irradiated separately or during incubation with cells (Figure 3d).</p><p>To assess its in vitro stability, NPPOC-Aha (100 µM) was incubated in media with HeLa cells for 0 – 4 hr prior to light exposure (10 mW cm−2, 5 min) and subsequent metabolic labeling (2 hr). Aha incorporation was observed for all irradiated samples, though its extent decreased over time. This was attributed to unknown cellular processing of NPPOC-Aha; simple hydrolysis yielding free Aha does not explain this behavior, as non-irradiated samples do not show increased incorporation over time. While the >4 hours of working time is likely sufficient for many applications, we anticipate that different photocages and/or ncAAs may exhibit increased long-term stability. Such stability is useful in sampling biological systems, as it decouples media swaps from proteome labeling, allowing researchers to standardize their experimental conditions.</p><p>After demonstrating the ability to label newly synthesized proteins, we sought to extend the laBONCAT methodologies to their affinity purification. After NPPOC-Aha uncaging and metabolic incorporation of the ncAA, proteins were biotinylated via SPAAC with a dibenzocyclooctyne-modified biotin probe. Biotinylated proteins were captured on a streptavidin resin prior to protein elution by streptavidin denaturation. Eluents were subjected to SDS-PAGE and silver stained for visualization (Figure 3f). Results highlight the capability to selectively isolate newly synthesized proteins from irradiated samples.</p><p>Building on the capability to fluorescently tag cellular lysates as well as isolate species of interest via laBONCAT, we turned our efforts towards the technique's unique ability to label newly synthesized proteins in vitro with spatial control; we anticipate that this method could be applied to the isolation of proteins transcribed at user-specified times and locations from heterogeneous features in tissue culture, especially tissue slices. HeLa cells were treated with NPPOC-Aha (100 µM) and exposed to light (λ = 365 nm, 10 mW cm−2, 5 min). Two hours after exposure, cells were fixed, permeabilized, and treated with FAM-BCN (100 nM) to introduce a fluorescent label via SPAAC. The extent of fluorescent labeling of cells treated in this method was similar to free Aha, while NPPOC-Aha in the absence of light exhibited low-level labeling similar to Met (Figure 4).</p><p>Next, we demonstrated the ability to control Aha incorporation spatially within synthetic tissues. Cells were encapsulated in oxime-based poly(ethylene glycol) hydrogels (7 wt%), treated with NPPOC-Aha and selectively irradiated through a slitted photomask. Cells were fixed and fluorescently labeled with FAM-BCN, phalloidin, and Hoechst. The observed cellular FAM signal was localized near exposed regions, corresponding to patterned Aha incorporation. FAM fluorescence decreased exponentially away from exposed regions in a diffusion-predicted manner. Actin and DNA staining lack substantial patterning (Figure 4, Supplementary Figure 6).</p><p>This technique provides an inherent improvement to traditional BONCAT by allowing for precise timing in metabolic incorporation. In addition, the photochemical nature of the system provides a degree of spatial control for the investigation of heterogeneous biological systems. While not the focus of this manuscript, we anticipate that laBONCAT could be readily combined with strategies for pulsed stable isotope labeling by amino acids in cell culture23 (pSILAC) to purify, identify, and quantify proteins expressed at user-defined regions in culture. This newfound ability is expected to prove particularly useful in the investigation of heterogeneous protein-related disease (e.g., Alzheimer's), potentially yielding new diagnostic markers and therapeutic targets.</p><p>In this manuscript, we have demonstrated the ability to control protein translation spatiotemporally through laBONCAT. While the method has been initially validated using NPPOC-Aha responsive to near-UV light, facile extension of the technique to control incorporation of different amino acids using different photocage/light combinations is expected. We believe that this strategy shows unique promise towards the visualization and characterization of newly synthesized proteins at user-defined time and places of interest.</p>METHODS<p>Detailed methods and experimental conditions are described in the Supporting Information.</p><p>          ASSOCIATED CONTENT</p><p>          Supporting Information</p><p>The Supporting Information is available free of charge on the ACS Publications website at DOI: XXX.</p><p>This includes full experimental procedures, synthesis and characterization of all small molecules and functional polymers, control experiments for affinity purification of newly synthesized proteins, and full analysis of spatially labeled synthetic tissues.</p><p>          Author Contributions</p><p>For this manuscript, S.M.A and C.A.D. conceived and designed the experiments; S.M.A, E.R.R., P.E.F., and J.V.W. performed the experiments; S.M.A. and C.A.D. analyzed the data and prepared the figures; S.M.A. and C.A.D. wrote the paper.</p><p>The authors declare no competing financial interest.</p>","answer":"This work introduces light-activated bioorthogonal non-canonical amino acid tagging (laBONCAT) as a method to selectively label, isolate, and identify proteins newly synthesized at user-defined regions in tissue culture. By photocaging L-azidohomoalanine (Aha), metabolic incorporation into proteins is prevented. The caged compound remains stable for many hours in culture, but can be photochemically liberated rapidly and on demand with spatial control. Upon directed light exposure, the uncaged amino acid is available for local translation, enabling downstream proteomic interrogation via bioorthogonal conjugation. Exploiting the reactive azide moiety present on Ahaxe2x80x99s amino acid side chain, we demonstrate that newly synthesized proteins can be purified for quantitative proteomics or visualized in synthetic tissues with a new level of spatiotemporal control. Shedding light on when and where proteins are translated within living samples, we anticipate that laBONCAT will aid in understanding the progression of complex protein-related disorders."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Web-based orthodontic instruction and assessment.Abstract 1:Orthodontic records- study models , panoramic and cephalometric radiographs , and the patient 's facial and intraoral photographs-are used to collect data to establish a diagnosis and to develop problem-solution lists . These records , however , can be damaged or lost when dispensed to students and need to be stored and maintained every year . An orthodontic diagnosis web site , therefore , has been set up using digital records to provide students with an accessible source of complete , good- quality study material s. The web site is also used for clinical examination in orthodontic courses . The effectiveness of the web-based digital records in providing relevant information to students in comparison to the traditional records was evaluated by a r and omized controlled trial involving ninety-nine second-year dental students . One group ( fifty students ) studied two cases from the web site ; the other group ( forty-nine students ) studied the same two cases from traditional orthodontic records .  Effectiveness was assessed by comparing test scores and the time spent on the tests by t-statistics . There were no significant differences between means for the two study groups in test performance or time . Attitudes of students toward the web site , assessed from post-test question naires , were positive . It was concluded that web-based digital orthodontic records were as effective in teaching clinical orthodontic diagnosis as were conventional recordsTitle 2:Teaching periodontal pocket charting to dental students: a comparison of computer assisted learning and traditional tutorialsAbstract 2:Aim The aim of this study was to compare the effectiveness of a computer assisted learning ( CAL ) programme with that of traditional small group tutorials in teaching theoretical and practical aspects of periodontal pocket charting . Method Sixty-one third year undergraduate dental students were r and omized to either receive a tutorial or to work through the CAL programme .  Students using the CAL programme  completed question naires relating to previous computer experience and the ease of use of the programme . All students were assessed immediately after the intervention by means of a confidence log , a practical exercise and a further confidence log . They were assessed again three weeks later by means of a confidence log and a multiple-choice written test . Results There were very few significant differences between groups for any of the assessment s used . However , subjective comments indicated that students occasionally felt disadvantaged if they had not received a tutorial . Conclusion CAL and traditional teaching methods are equally effective in teaching periodontal pocket charting to undergraduate dental studentsTitle 3:Computer-aided learning: an overvalued educational resource?Abstract 3:AIM The aim of this study was to evaluate the place of computer-aided learning in a basic science course in the undergraduate medical curriculum at the University of Adelaide . METHODS A software program was written which would allow students to study the anatomy and physiology of the liver and biliary tree in three different styles . Identical content was produced , matched for each style ( problem-based , didactic and free text response ) and students r and omly allocated to one of four groups ( three computer and one control ) . Students were tested before and after access to the program . RESULTS Ninety second-year students completed the study . Those students who had access to the material in the problem-based and free text response styles did no better in the post- study test than the controls , whilst the group who had studied the didactically presented computer material performed significantly better than the other three groups . All three computer groups accessed the material on a similar number of occasions , but the group who had access to the free text entry program spent significantly less time on computer study . CONCLUSIONS If computer material s are to be provided as a learning re source for the basic medical sciences , provision must be made for the style of teaching of the course and the style of learning of the students attending that courseTitle 4:A Hypertext tutorial for teaching cephalometrics.Abstract 4:Hypertext is a non-linear method of text presentation . It necessitates the use of a computer to store data as a series of nodes that can be called up in any desired sequence and , as such , is a new form of discovery-based learning . This paper describes a Hypertext tutorial in cephalometrics and its subsequent testing on first-year clinical dental students . Students were divided into two groups : the first received a conventional lecture ; the second used the Hypertext tutorial . Testing was by means of conventional multiple choice questions . The results showed that there was no statistically significant difference between the two groups , although the computer tutor was shown more consistently to improve the knowledge of the students than did the conventional lecture . Most students who used the computer program found it enjoyable , but time consuming ; less than half found it easy to follow","answer":"Overall ,  student attitudes were positive towards CAL .No conclusions can be drawn about the time efficiency of CAL ."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Genome-wide integrated analyses of androgen receptor signaling in prostate cancer based on high-throughput technology. The androgen receptor (AR) is a steroid hormone receptor that functions as a ligand-dependent transcriptional factor, which plays a key role in the development and progression of prostate cancer. Recent advancement in high throughput technologies including microarrays and deep-sequencing provides unbiased genome-wide knowledge on the AR signaling including datasets for androgen-regulated gene expression and genomic binding sites for AR. In the present review, we will briefly summarize the main features of the AR signaling as well as the individual AR target genes identified by the integration of multiple datasets in prostate cancer. Cap analysis gene expression (CAGE) is also featured as a unique transcriptome method, which particularly determines the androgen-dependent transcription start points in prostate cancer.","answer":"[]"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Two-Photon Voltmeter for Measuring a Molecular Electric FieldPaper sections:<p>The electronic properties of polar chromophores in solution are dominated by their interactions with the solvent environment. Understanding how the molecular electric dipole moment and polarizability behave in the ground and excited states is critical for optimizing solvent-dependent properties of materials, including absorption and fluorescence spectra as well as photo-initiated charge separation.[1] Furthermore, if the molecular dipoles and polarizabilities in the ground- and excited states could be accurately determined, then spectroscopy would directly probe the intrinsic electric fields acting on the chromophore,[2] thus providing important quantitative insight into solvation, catalysis, and other phenomena.</p><p>Among available experimental methods, standard solvatochromism relies on several assumptions, which are typically valid only for a limited range of rigid systems.[1] Electrochromism and microwave conductivity measurements require strong external electric fields and suffer from reduced fidelity in heterogeneous environments.[3] Spectral hole-burning Stark spectroscopy[2c] offers higher selectivity and fidelity, but requires cooling of the samples to cryogenic temperatures to achieve narrow homogeneous line shapes, thus limiting its versatility, especially regarding biological systems. The vibrational Stark effect and vibrational absorption spectroscopy has been used to probe local electric fields, provided that the vibrational frequency shifts are calibrated with respect to external fields.[4] In addition, currently available techniques suffer from ambiguity regarding the boundary separating the core chromophore from its immediate surrounding solvent thus complicating distinction between the intrinsic electric field versus the externally applied voltage.[2a]</p><p>Here we report an all-optical method that determines the strength of the dielectric reaction field (Ereac), the vacuum molecular electric dipole moment (μvac) and polarizability (α) in both the ground- (S0) and lowest excited (S1) singlet states, and provides quantitative estimate of the effective molecular size (a0) for two benchmark polar chromophores, prodan and C153. Our approach combines solvatochromic one-photon absorption (1PA) and femtosecond two-photon absorption (2PA) experiments, where the latter serves as a versatile alternative to the Stark effect and related techniques.[5]</p><p>Details of the spectroscopic procedures, spectral data analysis, and computational methods are given in the Supporting Information. Figure 1 shows the 1PA and 2PA spectra of prodan (left) and C153 (right) in three representative mixtures of toluene and DMSO. Both prodan and C153 show a systematic red-shift and broadening of the absorption band with increasing ε. Gaussian decomposition of the 1PA spectrum yields the dependence of the peak frequency and the bandwidth of the lowest energy component (dashed-dotted line) on ε. By extrapolating these dependencies to ε=1 we determined the vacuum peak transition frequency (νvac) and the effective \\"vacuum\\" spectral bandwidth (Δνvac; Table 1). Here and in the following, we refer to spectral parameters or band shape of the lowest-energy transition band only.</p><p>1PA spectrum (blue line) and 2PA spectrum (pink symbols) in prodan (left) and C153 (right), each in three representative toluene:DMSO mixtures. Gaussian fit to the lowest energy band of the S0→S1 transition (dash-dotted line); measured Δμ dependence (black symbols, inserted vertical scale); predicted Δμ dependence (thick dotted line).</p><p>Comparison of experimental, calculated, and literature parameter values. Literature computational values are given in italics.</p><p>CAM-B3LYP/6-311++G(d,p)//B3LYP/6-311G(d,p).[8]</p><p>B3LYP/6-311G(d,p)//B3LYP/6-311G(d,p).[8]</p><p>CAM-B3LYP/6-311++G(d,p)//CAM-B3LYP/6-311G++(d,p)[8] (see the Supporting Information).</p><p>A two-level model has been shown to provide quantitative description of 2PA in the lowest-energy (0-0) component of S0→S1 transition of polar chromophores (see the Supporting Information for details), where the 2PA cross section, σ2PA(2λ), is related to the permanent dipole moment change, Δμ=μ(S1)−μ(S0) (in Debye)[6] given in Equation (1),(1)</p><p>where n is the solvent index of refraction, λ is the transition wavelength (nm), εM is the molar extinction coefficient (m−1 cm−1), and σ2PA is the 2PA cross section, expressed in Göppert–Mayer units (1 GM=10−50 cm4 photon−1 s−1). We assume here and in the following that all vector and tensor quantities are aligned with their predominant component pointing along the same coordinate axis. The black symbols in Figure 1 (Δμexp) show the value of Δμ calculated from Equation (1) (inserted vertical axis). In the case of prodan, Δμ shows up to a 15 % increase with increasing wavelength, whereas in C153 the value remains approximately constant.</p><p>The solute static dipole polarizes the surrounding dielectric (solvent), which in turn creates a reaction electric field that shifts the energy levels of the chromophore via Stark effect, which then relates to the observed transition frequency change as given in Equations (2) and (3),(2)(3)</p><p>where h is Planck's constant, c is the velocity of light in vacuum, Δμvac is the vacuum dipole moment change, Δα=α(S1)−α(S0) is the change of polarizability, and Ereac is the solvent field created by μ(S0).</p><p>Figure 2 shows the experimental correlation between the peak transition frequency and the average Δμ. Fitting with Equations (2) and (3) gives the values of Δμvac and Δα (Table 1).</p><p>Dependence of Δμ in prodan (empty squares) and C135 (full squares) on νvac−ν0. Extrapolation of the fits to νvac yields the vacuum dipole moment changes, Δμvac=12.8±0.6 D for prodan (dashed line) and Δμvac=9.4±0.5 D for C153 (solid line). The slopes of the fits then give the values for change in polarizability, Δα=46.8±4.7 Å3 (prodan) and Δα=−6.6±0.7 Å3 (C153).</p><p>In order to obtain the vacuum ground-state dipole moment, μvac(S0), and the ground-state polarizability, α(S0), we invoked a simple phenomenological model that treats the chromophore as a polarizable point dipole embedded in a dielectric continuum in the center of a spherical volume of radius a. The strength of the reaction field acting on the dipole is given as Equation (4)]:[7](4)</p><p>where f represents the dependence on the dielectric constants outside and inside the volume. To account for unknown close-range solute–solvent interaction, while still complying with Maxwell's equations, this function may be written in the form of Equation (5)](5)</p><p>and where the power dependence (0≤p≤1) ensures that the direction of the reaction field energetically stabilizes the system while satisfying the vacuum limit [Eq. (6)].(6)</p><p>According to Equations (2) and (4), the transition frequency varies as given in Equation (7).(7)</p><p>Solvated chromophores experience heterogeneous and fluctuating solvent environments. We can quantify the local environments by a distribution of effective cavity size, P(a), which is related to the distribution of transition frequencies, P(ν), as shown in Equation (8).(8)</p><p>The transition frequencies are assumed to follow a Gaussian distribution [see Eq. (9)],(9)</p><p>where ν0 and Δν are the center frequency and the half-width of the transition band, respectively. Combining Equations (7)–(9), and defining E0=Ereac(a0) and EΔ=Ereac(a0+Δa) as the reaction field values that correspond to the peak (ν0) and half-width (ν0+Δν) of the distribution, respectively, we arrive at the distribution of the cavity size a [Eq. (10)],(10)</p><p>where ΔνStark is defined by Equation (11).(11)</p><p>Inserting our experimental values Δμvac, Δα, νvac, and Δνvac into the model and performing global fitting of the calculated 1PA profiles to the experimental shapes (see the Supporting Information for details), we obtain the remaining parameters, μvac(S0), α(S0), a0, Δa, and p (Table 1). The experimental ground-state values μvac(S0) and α(S0) agree quantitatively with the corresponding calculated values and the literature data, both for prodan and C153. The experimental Δμvac=12.8±0.6 D for prodan and Δμvac=9.4±0.5 D for C153 agree well with previous measurements, however, are about a factor of two above our calculated values. In prodan the experimental polarizability change, Δα, agrees very well with the calculated value, whereas in C153 the value is much smaller, making it effectively close to zero. Despite the fact that we made no a priori assumptions about the size of the molecule, our estimated average cavity size, a0, agrees surprisingly well with the calculated molecular dimensions. For prodan, we calculated a molecular radius of 6.3 Å,[8] which compares well to our experimental value, a0=6.5±0.7 Å. Similarly, for C153 we calculated the effective radius in the direction F=C⋅⋅⋅N=C=H to be 4.9 Å, which is also very close to our experimental value, a0=4.7±0.5 Å.</p><p>As a further independent check, we used Equations (2) and (3) to predict how Δμ changes as a function of ν within the absorption band (thick dotted line in Figure 1). The results are in good agreement with the measured dependence, and demonstrate that Δμ is not necessarily constant, but may vary within the band.</p><p>Figure 3 shows the distribution of Ereac, which appears to vary in a broad range, 0–107 V cm−1, essentially caused by diverse local environments. Fluctuations of dielectric environment were previously used to explain temporal fluctuations of the fluorescence lifetime in single molecules.[18] Both prodan and C153 show increase of average Ereac with increasing ε, with the respective maximum values, Ereac≈5.0×106 and 1.0×107 V cm−1. The larger reaction field in C153 is due to the larger ground-state dipole moment as well as because of smaller a0. Also, C153 lacks the flexibility of prodan's propyl- and dimethylamino groups, which is reflected in its smaller Δa and narrower Ereac distribution.</p><p>Probability density of the reaction field for different ε for a) prodan and b) C153.</p><p>Finally, by equating f to the well-known expression for the field enhancement factor in spherical volume [Eq. (12)],(12)</p><p>we find functional form for the effective interior dielectric constant εin [Eq. (13)],(13)</p><p>which may be viewed as dielectric continuum approximation of the solute–solvent system at close proximity, on the order of the chromophore radius. Figure 4 plots the resulting dependence of εin on ε for the experimental values of p obtained for prodan (filled symbols) and C153 (open symbols). The range of bulk dielectric constant values used in our measurements, ε=2.38–47.6, lies between the dashed vertical lines, whereas the corresponding \\"internal\\" dielectric constant, εin=1.5–2.4 agrees well with the commonly assumed value, εin=nsolute2≈2.[2a,7]</p><p>Functional dependence of εin from Equation (13) for experimental values of p.</p><p>We conclude that this new all-optical method provides an improved quantitative estimation of the average strength and distribution of the dielectric reaction field acting on a dipolar chromophore in different solvents, along with the values of solute dipole moment and polarizability in the ground- and excited electronic states, including the effective molecular radius. The technique is applicable at ambient temperatures, and does not rely on fluorescence emission or externally applied fields, making it a versatile alternative to standard techniques. A simple phenomenological model based on the continuum dielectric solution of Maxwell's equations is in good quantitative agreement with experimental observations. Finally, our results indicate that the effective dielectric constant near the chromophore exhibits a unique functional dependence on the bulk dielectric constant, which may yield valuable insight into local intermolecular interactions in solvated dipolar systems.</p><p>Supporting information for this article is available on the WWW under http://dx.doi.org/10.1002/anie.201502157.</p>","answer":"We present a new approach for determining the strength of the dipolar solute-induced reaction field, along with the ground- and excited-state electrostatic dipole moments and polarizability of a solvated chromophore, using exclusively one-photon and two-photon absorption measurements. We verify the approach on two benchmark chromophores N,N-dimethyl-6-propionyl-2-naphthylamine (prodan) and coumarin 153 (C153) in a series of toluene/dimethyl sulfoxide (DMSO) mixtures and find that the experimental values show good quantitative agreement with literature and our quantum-chemical calculations. Our results indicate that the reaction field varies in a surprisingly broad range, 0–107 V cm−1, and that at close proximity, on the order of the chromophore radius, the effective dielectric constant of the solute–solvent system displays a unique functional dependence on the bulk dielectric constant, offering new insight into the close-range molecular interaction."},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:related workContext before the citation:One common approach is using Machine Translation (MT) to translate the queries to the language of the documents or translate documents to the language of the queries (Gey et al, 1999; Oard, 1998). Many approaches to cross-lingual IR have been published. Our work has focused on cross-lingual retrieval.Citation Sentence:One common approach is using Machine Translation ( MT ) to translate the queries to the language of the documents or translate documents to the language of the queries ( Gey et al , 1999 ; Oard , 1998 ) .Context after the citation:For most languages, there are no MT systems at all. Our focus is on languages where no MT exists, but a bilingual dictionary may exist or may be derived. Another common approach is term translation, e.g., via a bilingual lexicon. (Davis and Ogden, 1997; Ballesteros and Croft, 1997; Hull and (3refenstette, 1996).","answer":"CompareOrContrast"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: The SSD approach is based on a feed-forward convolutional network that produces a fixed-size collection of bounding boxes and scores for the presence of object class instances in those boxes, followed by a non-maximum suppression step to produce the final detections. The early network layers are based on a standard architecture used for high quality image classification (truncated before any classification layers), which we will call the base network222We use the VGG-16 network as a base, but other networks should also produce good results.. We then add auxiliary structure to the network to produce detections with the following key features:Question: How SSD will predict boundary boxes after training as there is no ground truth anymore?","answer":"After training, SSD predicts the boundary box by doing a non-maximum suppression on boundary boxes with the presence of object class instance."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"IGF\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Contribution of upregulated dipeptidyl peptidase 9 (DPP9) in promoting tumoregenicity, metastasis and the prediction of poor prognosis in non-small cell lung cancer (NSCLC). Dipeptidyl peptidase 9 (DPP9) is encoded by DPP9, which belongs to the DPP4 gene family. Proteins encoded by these genes have unique peptidase and extra-enzymatic functions that have been linked to various diseases including cancers. Here, we describe the expression pattern and biological function of DPP9 in non-small-cell lung cancer (NSCLC). The repression of DPP9 expression by small interfering RNA inhibited cell proliferation, migration, and invasion. Moreover, we explored the role of DPP9 in regulating epithelial-mesenchymal transition (EMT). The epithelial markers E-cadherin and MUC1 were significantly increased, while mesenchymal markers vimentin and S100A4 were markedly decreased in DPP9 knockdown cells. The downregulation of DPP9 in the NSCLC cells induced the expression of apoptosis-associated proteins both in vitro and in vivo. We investigated the protein expression levels of DPP9 by tissue microarray immunohistochemical assay (TMA-IHC) (n = 217). Further we found mRNA expression levels of DPP9 in 30 pairs of clinical NSCLC tissues were significantly lower than in the adjacent non-cancerous tissues. Survival analysis showed that the overexpression of DPP9 was a significant independent factor for poor 5-year overall survival in patients with NSCLC (p = 0.003). Taken together, DPP9 expression correlates with poor overall survival in NSCLC.","answer":"{\\"Gene\\": [\\"dipeptidyl peptidase 9\\", \\"E-cadherin\\", \\"Dipeptidyl peptidase 9\\", \\"S100A4\\", \\"DPP9\\", \\"MUC1\\", \\"vimentin\\", \\"DPP4\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: The Transcriptional Activator LdtR from ‘Candidatus Liberibacter asiaticus’ Mediates Osmotic Stress Tolerance}Article:Abstract:The causal agent of Huanglongbing disease, ‘Candidatus Liberibacter asiaticus’, is a non-culturable, gram negative, phloem-limited α-proteobacterium. Current methods to control the spread of this disease are still limited to the removal and destruction of infected trees. In this study, we identified and characterized a regulon from ‘Ca. L. asiaticus’ involved in cell wall remodeling, that contains a member of the MarR family of transcriptional regulators( ldtR), and a predicted L, D-transpeptidase( ldtP). In Sinorhizobium meliloti, mutation of ldtR resulted in morphological changes( shortened rod-type phenotype) and reduced tolerance to osmotic stress. A biochemical approach was taken to identify small molecules that modulate LdtR activity. The LdtR ligands identified by thermal shift assays were validated using DNA binding methods. The biological impact of LdtR inactivation by the small molecules was then examined in Sinorhizobium meliloti and Liberibacter crescens, where a shortened-rod phenotype was induced by growth in presence of the ligands. A new method was also developed to examine the effects of small molecules on the viability of ‘Ca. Liberibacter asiaticus’, using shoots from HLB-infected orange trees. Decreased expression of ldtRLas and ldtPLas was observed in samples taken from HLB-infected shoots after 6 h of incubation with the LdtR ligands. These results provide strong proof of concept for the use of small molecules that target LdtR, as a potential treatment option for Huanglongbing disease.Introduction:The rapid expansion of Huanglongbing( HLB; also known as “citrus greening”) disease caused a crisis in the citrus industry worldwide, with no solution visible in the near future. Experts estimate that without pro-active measures, the citrus industry in affected areas( like Florida) will be significantly reduced within 2–10 years. As such, it is critical to further our understanding of the metabolic and regulatory pathways in the causal agent ‘Candidatus Liberibacter asiaticus’( ‘Ca. L. asiaticus’), to facilitate the discovery of new means of prevention and/or treatment for HLB. Various treatment methods, including large scale field applications of penicillin and streptomycin, have been thoroughly examined and resulted in little success[1]. Although not applicable to field studies, thermotherapy( incubation of living plants in chambers at 40°C for 48 h) has been proposed for use in nurseries[2]. Despite all these efforts, current methods to control the spread of HLB are still limited to the removal and destruction of infected trees. The causal agent of this devastating disease, ‘Ca. L. asiaticus’, is an unculturable bacterium. The inability to culture these species has greatly hindered progress toward the identification of therapeutic targets, and the development of viable treatment options. Furthermore, comparative genome analyses did not identify genes with predicted virulence functions( toxins), or specialized secretion systems( pathogenicity determinants) in the genome of ‘Ca. L. asiaticus’. These analyses did, however, provide valuable insight into the putative mechanisms of gene regulation. Transcription factors, as defined by the Cluster of Orthologous Groups, constitute less than 2% of the ‘Ca. L. asiaticus’ genome, while in S. meliloti, another member of the Rhizobiaceae family, it comprises 6% of the genome. As a consequence, a small number of transcription factors may control several metabolic pathways. Therefore, we hypothesized that inactivation of a single transcription factor could result in pleiotropic effects, including decreased persistence within the host. CLIBASIA_01180( renamed LdtR), is a homolog of the multidrug resistance regulator MarR. This regulator is encoded upstream of CLIBASIA_01175, a predicted L, D transpeptidase( renamed LdtP) involved in cell wall remodeling. Peptidoglycan( PG) modifications have been observed in Gram-positive and Gram-negative bacteria, and often occur in response to environmental changes. The bacterial pathogens Neisseria gonorrhoeae and Listeria monocytogenes modify their PG residues to evade detection by the host immune system, and increase tolerance to stress[3],[4]. The PG structure consists of alternating N-acetylglucosamine( NAG) and β-( 1-4)-N-acetylmuramic acid( NAM) residues. A peptide stem linked to the NAM residue mediates the cross-link to other units in the growing PG, forming a three-dimensional mesh-like architecture that confers structural strength and rigidity to the cell wall[5]. The PG of A. tumefaciens and S. meliloti is highly cross-linked( 64%), with the muropeptide NAM-L-alanine, D-glutamic acid, DL-diaminopimelic acid, D-alanine being the most frequent[6]. The goal of this study was to characterize and assess the biological importance of LdtR and LdtP, and their role in the persistence of ‘Ca. L. asiaticus’ within citrus hosts. We used a biochemical approach to identify small molecules that modulate the expression and activity of the LdtR transcription factor. As ‘Ca. L. asiaticus’ is yet to be cultured, we used two of its closest culturable phylogenetic relatives, Sinorhizobium meliloti and Liberibacter crescens, as models to assess the biological role of LdtR and LdtP. We also developed a model using ‘Ca. L. asiaticus’ infected shoots, to validate LdtR as an effective target for the design of new therapeutics.Discussion:‘Ca. L. asiaticus’ is frequently exposed to changes in osmotic pressure, due to variations in phloem sap composition. Sucrose concentrations in the phloem can vary significantly( between 0. 5 and 30% w/v, corresponding to 15 mM and 880 mM, respectively) depending on plant species, tissue, time of day, and season[15],[16]. Consequently, bacterial pathogens that replicate in the phloem must continuously respond to changes in osmotic pressure. In this context, L, D transpeptidase activity is critical, as these enzymes are directly involved in cell wall biosynthesis and remodeling in response to stress conditions. In this report, we identified and characterized a regulon from the citrus pathogen ‘Ca. L. asiaticus’, involved in peptidoglycan remodeling. These results represent the first regulatory system functionally analyzed for this pathogen. Included in this regulon is ldtR, a member of the MarR family of transcriptional regulators, and ldtP, a predicted L, D-transpeptidase. The genomic context of ldtRLas was conserved among members of the Rhizobiacea family. As such, the two closest phylogenic relatives of ‘Ca. L. asiaticus’, S. meliloti and L. crescens, were used to study the phenotypic effects of L, D-transpeptidase inactivation, and the physiological conditions that contribute to the expression of the ldtR regulon, since ‘Ca. L. asiaticus’ is yet to be cultured. The highly conserved nature of ldtR suggests a similar mechanism of regulation among these members of the Rhizobiacea family; however, the response to ligands may vary due to the different lifestyle of each species. L, D-transpeptidases( E. C. 2. 3. 2. 12) mediate the substitution of 4→3( D-Ala4 to mDAP3) crosslinks, generated by the penicillin binding protein D, D-transpeptidase, to 3→3( mDAP3 to mDAP3) crosslinks. This pattern of L, D-transpeptidation represents 80% of the crosslinks observed in the cell walls of stationary phase M. tuberculosis cells[17]. Similar results were observed in other microorganisms, including E. coli and V. cholerae[8],[18]. These observations suggest that transpeptidation is an active process in stationary phase cells, which may be critical for adaptation and tolerance to environmental stress. In M. tuberculosis, increased cell wall transpeptidation was positively correlated with increased transcription of LdtM1 during nutrient starvation[17],[19]. Interestingly, our results in L. crescens indicate that ldtPLcr and ldtRLcr are expressed throughout the growth phases, when cultured under laboratory conditions. However, a comparative analysis of the ‘Ca. L. asiaticus’ transcriptome revealed that ldtR expression was five times higher in samples obtained from infected trees, when compared to samples collected from infected psyllids( an alternate host and insect vector of ‘Ca. L. asiaticus’)[20]. These results suggest that in ‘Ca. L. asiaticus’, transcription of Ldt-associated genes may be triggered by the high osmotic pressure generated by the phloem sap. These data, in combination with previous reports of the large proportion of 3→3 crosslinks in the muropeptides of Rhizobiales, suggest that LdtP may be involved in both housekeeping activities and stress response. To further explore the LdtR regulatory mechanism, Bacillus subtilis was used as a heterologous host. Interestingly, we found that LdtR acts as a transcriptional activator of the ldtR and ldtP genes. Although the majority of MarR proteins act as transcriptional repressors, several MarR transcriptional activators have been described. In S. meliloti, the MarR family member ExpG binds to the ExpADGE operon to activate expression of the galactoglucan biosynthesis genes[21]. Similarly, PntR and PenR, from Streptomyces arenae and S. exfoliatus, respectively, activate synthesis of the pentalenolactone antibiotic[22]. Interestingly, all of these regulators bind AT-rich sequences similar to the binding sequence identified for LdtR[21]–[23]. This high degree of conservation could represent a common feature among binding sequences for MarR members that act as transcriptional activators. In S. meliloti, changes in cell morphology( short-cell phenotype) were induced by the mutagenesis of ldtR and ldtP. Similar changes in cell morphology have been described for S. meliloti and Rhizobium spp in response to the accumulation of compounds such as glycine, which decreases the extent of crosslinks[24]–[26]. A similar short-cell phenotype was also observed in V. cholerae, following the accumulation of D-amino acids in the media[18]. Analysis of the ‘Ca. L. asiaticus’ genome revealed no homologs of the transpeptidases involved in these activities, however, a glutamate and alanine racemase were identified. These enzymes contribute to fluctuations in the concentration of D-amino acids. The potential involvement of LdtR in the regulation of these genes may explain the phenotypic changes observed in ldtR mutants. The direct or indirect involvement of LdtR in the regulation of these racemases is currently under examination. Based on the biological relevance of the ldtR regulon, we identified small molecules( phloretin, benzbromarone, and hexestrol) that decreased binding of LdtR to its cognate promoters, resulting in decreased expression of ldtP and ldtR. In L. crescens, decreased gene expression in presence of these small molecules was positively correlated with decreased tolerance to osmotic stress. Furthermore, in S. meliloti, the addition of phloretin, benzbromarone, or hexestrol resulted in morphological changes( short-cell phenotype) similar to those observed in ldtR and ldtP mutants. Consequently, we reasoned that chemical manipulation of LdtRLas activity will reduce long term survival and persistence of the pathogen in infected citrus trees. Thus, we designed an in vitro model using sweet orange leaves infected with ‘Ca. L. asiaticus’, to validate the effect of these chemicals. In samples treated with the small molecules, a significant decrease in ldtR and ldtP expression was observed, confirming the specific effect of these chemicals in ‘Ca. L asiaticus’. The use of a specific target is essential for the development of an effective therapeutic treatment. Modulation of cell wall transpeptidation has been used as a therapeutic treatment for recalcitrant microorganisms, such as Mycobacterium tuberculosis[27]. In contrast, current efforts towards the treatment of Huanglongbing disease are focused primarily on the use of “broad spectrum” treatments( i. e. penicillin, streptomycin, and thermotherapy). This study provides strong proof of concept for the use of small molecules that target LdtRLas, as a potential treatment option for Huanglongbing disease.","answer":"The rapid expansion of Huanglongbing disease ( HLB ) has caused a severe crisis in the citrus industry , with no solution visible in the near future . The causative agent , ‘Candidatus Liberibacter asiaticus’ , is an unculturable bacterium under common laboratory conditions , which has made it difficult to gain understanding of this pathogen . Here we used a biochemical approach to identify new chemicals that could be used for the treatment of this devastating disease . These chemicals target a specific transcription factor ( LdtR ) in ‘Ca . Liberibacter asiaticus’ . When bound to LdtR , the chemicals inactivate the protein , which disrupts a cell wall remodeling process that is critical for survival of the pathogen when exposed to osmotic stress ( i . e . within the phloem of a citrus tree ) . Several model strains were used to confirm that the newly identified transcription factor ( LdtR ) and its regulated genes ( ldtR and ldtP ) confer tolerance to osmotic stress . The results presented in this study provide strong proof of concept for the use of small molecules that target LdtR , as a potential treatment option for Huanglongbing disease ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:A physical map and candidate genes in the BRCA1 region on chromosome 17q12-21. We have constructed a physical map of a 4 cM region on chromosome 17q12-21 that contains the hereditary breast and ovarian cancer gene BRCA1. The map comprises a contig of 137 overlapping yeast artificial chromosomes and P1 clones, onto which we have placed 112 PCR markers. We have localized more than 20 genes on this map, ten of which had not been mapped to the region previously, and have isolated 30 cDNA clones representing partial sequences of as yet unidentified genes. Two genes that lie within a narrow region defined by meiotic breakpoints in BRCA1 patients have been sequenced in breast cancer patients without revealing any deleterious mutations. These new reagents should facilitate the identification of BRCA1..","answer":"{\\"Disease\\": [\\"breast cancer\\", \\"hereditary breast and ovarian cancer\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Data collection: CrystalClear (Rigaku/MSC, 2005 >); cell refinement: CrystalClear; data reduction: CrystalClear; program(s) used to solve structure: SHELXS97 (Sheldrick, 2008 >); program(s) used to refine structure: SHELXL97 (Sheldrick, 2008 >); molecular graphics: ORTEPII (Johnson, 1976 >); software used to prepare material for publication: SHELXL97.","answer":"{\\"AnatomicalEntity\\": [\\"cell\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"SSX\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Expression of central and peripheral cannabinoid receptors in human immune tissues and leukocyte subpopulations. Two proteins with seven transmembrane-spanning domains typical of guanosine-nucleotide-binding-protein-coupled receptors have been identified as cannabinoid receptors; the central cannabinoid receptor, CB1, and the peripheral cannabinoid receptor, CB2, initially described in rat brain and spleen, respectively. Here, we report the distribution patterns for both CB1 and CB2 transcripts in human immune cells and in several human tissues, as analysed using a highly sensitive and quantitative PCR-based method. CB1 was mainly expressed in the central nervous system and, to a lower extent, in several peripheral tissues such as adrenal gland, heart, lung, prostate, uterus, ovary, testis, bone marrow, thymus and tonsils. In contrast, the CB2 gene, which is not expressed in the brain, was particularly abundant in immune tissues, with an expression level 10-100-fold higher than that of CB1. Although CB2 mRNA was also detected in some other peripheral tissues, its level remained very low. In spleen and tonsils, the CB2 mRNA content was equivalent to that of CB1 mRNA in the central nervous system. Among the main human blood cell subpopulations, the distribution pattern of the CB2 mRNA displayed important variations. The rank order of CB2 mRNA levels in these cells was B-cells > natural killer cells >> monocytes > polymorphonuclear neutrophil cells > T8 cells > T4 cells. The same rank order was also established in human cell lines belonging to the myeloid, monocytic and lymphoid lineages. The prevailing expression of the CB2 gene in immune tissues was confirmed by Northern-blot analysis. In addition, the expression of the CB2 protein was demonstrated by an immunohistological analysis performed on tonsil sections using specific anti-(human CB2) IgG; this experiment showed that CB2 expression was restricted to B-lymphocyte-enriched areas of the mantle of secondary lymphoid follicles. These results suggest that (a) CB1 and CB2 can be considered as tissue-selective antigens of the central nervous system and immune system, respectively, and (b) cannabinoids may exert specific receptor-mediated actions on the immune system through the CB2 receptor.","answer":"{\\"Gene\\": [\\"transmembrane-spanning domains\\", \\"guanosine-nucleotide-binding-protein-coupled receptors\\", \\"CB1\\", \\"CB2\\", \\"central and peripheral cannabinoid receptors\\", \\"cannabinoid receptors\\", \\"cannabinoid receptor\\"]}"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: Figure 1 shows examples of this type of plot for the mathsf{conv5} layer.The mathsf{conv5} layer has size 256times13times13, which we depict as 256 separate 13times13 grayscale images. Each of the 256 small images contains activations in the same spatial x-y spatial layout as the input data, and the 256 images are simply and arbitrarily tiled into a 16times16 grid in row-major order.Figure 2 shows a zoomed in view of one particular channel, mathsf{conv5_{151}}, that responds to human and animal faces. All layers can be viewed in the software tool, including pooling and normalization layers. Visualizing these layers provides intuitions about their effects and functions.Question: What is meant by \\"row-major\\" order?","answer":"\\"row-major\\" means that consecutive small grayscale images of each row reside next to each other unlike \\"column-major\\" and both are methods of storing elements in memory."},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:…cargo trafficking (Cai et al., 2011; Gallon et al., 2014; Lauffer et al., 2010; Lunn et al., 2007; Steinberg et al., 2013; Temkin et al., 2011; Valdes et al., 2011; Wang et al., 2013), and our results now suggest an additional unique property of this protein with respect to lipid headgroup…","answer":"Background"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: Describe crowned dens syndrome.Context: BACKGROUND: Patients with crowned dens syndrome (CDS), which is pseudogout of the atlantoaxial junction induced by \\"crown-like\\" calcifications around the dens, present with symptoms of severe neck pain, rigidity, and high fever.BACKGROUND CONTEXT: Crowned dens syndrome (CDS) is a rare form of calcium phosphate crystal depositions and often presents with recurrent neck pain, stiffness of neck, increased erythrocyte sedimentation rate, and episodes of fever.A CT scan revealed calcification of the transverse ligament and crown-like calcification around the odontoid process. According to the clinical and radiological findings, she was diagnosed with crowned dens syndrome (CDS).Crystal deposition in the cervical spine around the odontoid process may lead to acute neck pain. This rare condition is called crowned dens syndrome and should be considered in the differential diagnosis of a possible etiology for fever, headache and cervical pain of unknown origin.Crowned dens syndrome (CDS), related to microcrystalline deposition in the periodontoid process, is the main cause of acute or chronic cervical pain.Axial calcium pyrophosphate dihydrate deposition disease (CPDD) is well known for cervical spine involvement with the crowned dens syndrome but other localisations are probably underdiagnosed in sterile spondylodiscitis.We describe a patient with crowned dens syndrome which manifested with clinical (acute occipital headache) and radiographic (calcium deposits in the alar ligament) features.FDG uptake in the immediate vicinity of the odontoid process, with a crownlike calcification, was identified on the CT scan on the posterior side of the dens, thus confirming the diagnosis of crowned dens syndrome.We describe a patient with crowned dens syndrome which manifested with clinical (acute occipital headache) and radiographic (calcium deposits in the alar ligament) featuresCrowned dens syndrome (CDS), related to microcrystalline deposition in the periodontoid process, is the main cause of acute or chronic cervical pain.This report describes the case of an 87-year-old woman who had severe bradykinesia, muscle rigidity, gait disturbance and neck painThe crowned dens syndrome, related to microcrystalline deposition in the peri-odontoid articular and abarticular structures, is mainly responsible for acute or chronic cervical pain.We report eight cases of crowned dens syndrome with atypical presentations mimicking giant cell arteritis, polymyalgia rheumatica, meningitis or discitisThe crowned dens syndrome as a cause of neck pain: clinical and computed tomography study in patients with calcium pyrophosphate dihydrate deposition diseaseComputed tomography of the cervical spine demonstrated linear calcific deposits in the transverse ligament of atlas (crowned dens syndrome) in all patients.Crystals located in the transverse ligament of the atlas give rise to the crowned dens syndrome, usually in patients affected by severe degenerative lesions of the atlantoaxial joint and peripheral chondrocalcinosis.BACKGROUND: Patients with crowned dens syndrome typically present with severe neck pain and have calcium deposits around the odontoid process of the axis on radiographs.We describe a patient with crowned dens syndrome which manifested with clinical (acute occipital headache) and radiographic (calcium deposits in the alar ligament) features.","answer":"Crowned dens syndrome is a rare form of \\"crown-like\\" calcifications around the dens and often presents with recurrent neck pain, stiffness of neck, increased erythrocyte sedimentation rate, and episodes of fever."},{"question":"You will be shown sections from a scientific research paper, together with a question about the paper. Your task is to answer the question based on the contents of the paper. Your response should be a \`json\` object with two fields:\\"answer\\": An array of strings extracted directly from the paper which, collectively, answer the question.\\"evidence\\": An array of strings. Each should be an excerpt from the paper, in which one or more of the extracted answers can be found.For instance, for the question \\"What baselines did the authors compare against?\\", a sample response might be:{  \\"answer\\": [\\"BERT\\", \\"RoBERTa\\"],  \\"evidence\\": [\\"In our experiments, we compare the performance of our model against BERT and RoBERTa.\\"]}Do not include any text in your response other than the json.If the question is unanswerable given the provided excerpts, respond with the single word \\"null\\".Paper: BLiMP: A Benchmark of Linguistic Minimal Pairs for EnglishWe introduce The Benchmark of Linguistic Minimal Pairs (shortened to BLiMP), a challenge set for evaluating what language models (LMs) know about major grammatical phenomena in English. BLiMP consists of 67 sub-datasets, each containing 1000 minimal pairs isolating specific contrasts in syntax, morphology, or semantics. The data is automatically generated according to expert-crafted grammars, and aggregate human agreement with the labels is 96.4%. We use it to evaluate n-gram, LSTM, and Transformer (GPT-2 and Transformer-XL) LMs. We find that state-of-the-art models identify morphological contrasts reliably, but they struggle with semantic restrictions on the distribution of quantifiers and negative polarity items and subtle syntactic phenomena such as extraction islands.Background & Related Work ::: Language ModelsThe objective of a language model is to give a probability distribution over the possible strings of a language. Language models can be built on neural network models or non-neural network models. Due to their unsupervised nature, they can be trained without external annotations. More recently, neural network based language modeling has been shown to be a strong pretraining task for natural language understanding tasks BIBREF6, BIBREF7, BIBREF8, BIBREF9. Some recent models, such as BERT BIBREF9 use closely related tasks such as masked language modeling.In the last decade, we have seen two major paradigm shifts in the state of the art for language modeling. The first major shift for language modeling was the movement from statistical methods based on n-grams BIBREF10 to neural methods such as LSTMs BIBREF11, which directly optimize on the task of predicting the next word. More recently, Transformer-based architectures employing self-attention BIBREF12 have outperformed LSTMs at language modeling BIBREF4. Although it is reasonably clear that these shifts have resulted in stronger language models, the primary metric of performance is perplexity, which cannot give detailed insight into these models' linguistic knowledge. Evaluation on downstream task benchmarks BIBREF13, BIBREF14 is more informative, but might not present a broad enough challenge or represent grammatical distinctions at a sufficiently fine-grained level.Background & Related Work ::: Evaluating Linguistic KnowledgeA large number of recent studies has used acceptability judgments to reveal what neural networks know about grammar. One branch of this literature has focused on using minimal pairs to infer whether LMs learn about specific linguistic phenomena. Table TABREF4 gives a summary of work that has studied linguistic phenomena in this way. For instance, linzen2016assessing look closely at minimal pairs contrasting subject-verb agreement. marvin2018targeted look at a larger set of phenomena, including negative polarity item licensing and reflexive licensing. However, a relatively small set of phenomena is covered by these studies, to the exclusion of well-studied phenomena in linguistics such as control and raising, ellipsis, distributional restrictions on quantifiers, and countless others. This is likely due to the labor-intensive nature of collecting examples that exhibit informative grammatical phenomena and their acceptability judgments.A related line of work evaluates neural networks on acceptability judgments in a more general domain of grammatical phenomena. Corpora of sentences and their grammaticality are collected for this purpose in a number of computational studies on grammaticality judgment BIBREF26, BIBREF27, BIBREF16. The most recent and comprehensive corpus is CoLA BIBREF16, which contains around 10k sentences covering a wide variety of linguistic phenomena from 23 linguistic papers and textbooks. CoLA, which is included in the GLUE benchmark BIBREF13, has been used to track advances in the general grammatical knowledge of reusable sentence understanding models. Current models like BERT BIBREF9 and T5 BIBREF28 can be trained to give acceptability judgments that approach or even exceed individual human agreement with CoLA.While CoLA can also be used to evaluate phenomenon-specific knowledge of models, this method is limited by the need to train a supervised classifier on CoLA data prior to evaluation. BIBREF29 compare the CoLA performance of pretrained sentence understanding models: an LSTM, GPT BIBREF8, and BERT. They find that these models have good performance on sentences involving marked argument structure, and struggle on sentences with long-distance dependencies like those found in questions, though the Transformers have a noticeable advantage. However, evaluating supervised classifiers prevents making strong conclusions about the models themselves, since biases in the training data may affect the results. For instance, relatively strong performance on a phenomenon might be due to a model's implicit knowledge or to frequent occurrence of similar examples in the training data. Evaluating LMs on minimal pairs evades this problem by eschewing supervised training on acceptability judgments. It is possible to use the LM probability of a sentence as a proxy for acceptability because other factors impacting a sentence's probability such as length and lexical content are controlled for.DataThe *X dataset consists of 67 paradigms of 1000 sentence pairs. Each paradigm is annotated for the unique contrast it isolates and the broader category of phenomena it is part of. The data is automatically generated according to expert-crafted grammars, and our automatic labels are validated with crowd-sourced human judgments.Data ::: Data generation procedureTo create minimal pairs exemplifying a wide array of linguistic contrasts, it is necessary to artificially generate all datasets. This ensures both that we have sufficient unacceptable examples, and that the data is fully controlled, allowing for repeated isolation of a single linguistic phenomenon in each paradigm BIBREF30. The data generation scripts use a basic template to create each paradigm, pulling from a vocabulary of over 3000 words annotated for morphological, syntactic, and semantic features needed to create grammatical and semantically felicitous sentences. Examples SECREF6 and SECREF6 show one such template for the \`acceptable' and \`unacceptable' sentences within a pair: the sole difference between them is the underlined word, which differs only in whether the anaphor agrees in number with its antecedent. Our generation codebase and scripts are freely available.. DP1 V1 refl_match .The cats licked themselves .. DP1 V1 refl_mismatch .The cats licked itself .This generation procedure is not without limitations, and despite the very detailed vocabulary we use, implausible sentences are occasionally generated (e.g., \`Sam ran around some glaciers'). In these cases, though, both the acceptable and unacceptable sentences will be equally implausible given world knowledge, so any difference in the probability assigned to them is still due to the intended grammatical contrast.Data ::: Data validationTo verify that the generated sentences represent a real contrast in acceptability, we conduct human validation via Amazon Mechanical Turk. Twenty separate validators rated five pairs from each of the 67 paradigms, for a total of 6700 judgments. We restricted validators to individuals currently located in the US who self-reported as native speakers of English. To assure that our validators made a genuine effort on the task, each HIT included an attention check item and a hidden field question to catch bot-assisted humans. For each minimal pair, 20 different individuals completed a forced-choice task that mirrors the task done by the LMs; the human-determined “acceptable” sentence was calculated via majority vote of annotators. By this metric, we estimate aggregate human agreement with our annotations to be 96.4% overall. As a threshold of inclusion in *X , the majority of validators needed to agree with *X on at least 4/5 examples from each paradigm. Thus, all 67 paradigms in the public version of *X passed this validation, and only two additional paradigms had to be rejected on this criterion. We also estimate individual human agreement to be 88.6% overall using the approximately 100 annotations from each paradigm. Figure TABREF14 reports these individual human results (alongside model results) as a conservative measure of human agreement.whiteModels & Methods ::: Models ::: GPT-2GPT-2 BIBREF3 is a large-scale language model using the Transformer architecture BIBREF12. We use the large version of GPT-2, which contains 24 layers and 345M parameters. The model is pretrained on BIBREF3's custom-built WebText dataset, which contains 40GB of text extracted from web pages and filtered by humans. To our best knowledge, the WebText corpus is not publicly available. Assuming approximately 5-6 bytes/chars per word on average, we estimate WebText contains approximately 8B tokens. The testing code for GPT-2 has been integrated into jiant, a codebase for training and evaluating sentence understanding models BIBREF34.Models & Methods ::: Models ::: 5-gramWe build a 5-gram LM on the English Gigaword corpus BIBREF37, which consists of 3.07B tokens. To efficiently query n-grams we use an implementation based on BIBREF38, which is shown to speed up estimation BIBREF39. We release our n-gram evaluation code.Models & Methods ::: EvaluationWe mainly evaluate the models by measuring whether the LM assigns a higher probability to the grammatical sentence within the minimal pair. This method, used by BIBREF1, is only meaningful for comparing sentences of similar length and lexical content, as overall sentence probability tends to decrease as sentence length increases or word frequencies decrease BIBREF27. However, as discussed in Section SECREF3 we design every paradigm in *X to be compatible with this method.ResultsWe report the 12-category accuracy results for all models and human evaluation in Table TABREF14.Results ::: Overall ResultsAn LM's overall performance on *X can be measured simply by taking the proportion of correct predictions across the 67,000 minimal pairs from all paradigms. GPT-2 achieves the highest score and the n-gram the lowest. Transformer-XL and the LSTM LM perform in the middle, and at roughly the same level as each other. All models perform well below estimated human agreement (as described in Section SECREF11). The n-gram model's poor overall performance confirms *X is not solvable from co-occurrence information alone. Rather, success at *X is driven by the more abstract features learned by neural networks. There are no categories in which the n-gram approaches human performance.Because we evaluate pretrained models that differ in architecture and training data quantity/domain, we can only speculate about what drives these differences (though see Section SECREF37 for a controlled ablation study on the LSTM LM). Nonetheless, the results seem to indicate that access to training data is the main driver of performance on *X for the neural models we evaluate. On purely architectural grounds, the similar performance of Transformer-XL and the LSTM is surprising since Transformer-XL is the state of the art on several LM training sets. However, they are both trained 100pm 10M tokens of Wikipedia text. Relatedly, GPT-2's advantage may come from the fact that it is trained on roughly two orders of magnitude more data. While it is unclear whether LSTMs trained on larger datasets could rival GPT-2, such experiments are impractical due to the difficulty of scaling LSTMs to this size.Results ::: Shallow Predictors of PerformanceWe also ask what factors aside from linguistic phenomena make a minimal pair harder or easier for an LM to distinguish. We test whether shallow features like sentence length or overall sentence likelihood are predictors of whether the LM will have the right preference. The results are shown in Figure FIGREF31. While sentence length, perplexity and the probability of the good sentence all seem to predict model performance to a certain extent, the predictive power is not strong, especially for GPT-2, which is much less influenced by greater perplexity of the good sentence than the other models.Additional Experiments ::: Regular vs. Irregular AgreementIn the determiner-noun agreement and subject-verb agreement categories, we generate separate datasets for nouns with regular and irregular number marking, as in Example SECREF34. All else being equal, only models with access to sub-word-level information should make any distinction between regular and irregular morphology.. Ṙon saw that nice kid/*kids. (regular) Ron saw that nice man/*men. (irregular)Contrary to this prediction, the results in Figure FIGREF36 show that the sub-word-level models GPT-2 and Transformer-XL show little effect of irregular morphology: they perform less than 0.013 worse on irregulars than regulars. Given their high performance overall, this suggests they robustly encode number features without relying on segmental cues.Additional Experiments ::: Alternate Evaluation Methods ::: ResultsThe results in Figure FIGREF42 show that models have generally comparable accuracies overall in prefix methods and the simple whole-sentence LM method. However, A deeper examination of the differences between these methods in each paradigm reveals some cases where a models' performance fluctuates more between these methods. For example, Transformer-XL performs much worse at binding, determiner-noun agreement, and subject-verb agreement in the simple LM method, suggesting that the probabilities Transformer-XL assigns to the irrelevant part at the end of the sentence very often overturn the \`judgment' based on probability up to the critical word. On the other hand, GPT-2 benefits from reading the whole sentence for binding phenomena, as its performance is better in the simple LM method than in the prefix method. Overall, we observe that Transformer-XL and GPT-2 are more affected by evaluation methods than LSTM and n-gram when we compare the simple LM method and the two-prefix method.AcknowledgmentsThis material is based upon work supported by the National Science Foundation under Grant No. 1850208. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. This project has also benefited from support to SB by Eric and Wendy Schmidt (made by recommendation of the Schmidt Futures program), by Samsung Research (under the project Improving Deep Learning using Latent Structure), by Intuit, Inc., and by NVIDIA Corporation (with the donation of a Titan V GPU).Question: Which of the model yields the best performance?","answer":"{\\"answer\\": [\\"GPT-2\\"], \\"evidence\\": [\\"An LMu0027s overall performance on *X can be measured simply by taking the proportion of correct predictions across the 67,000 minimal pairs from all paradigms. GPT-2 achieves the highest score and the n-gram the lowest. Transformer-XL and the LSTM LM perform in the middle, and at roughly the same level as each other. All models perform well below estimated human agreement (as described in Section SECREF11). The n-gram modelu0027s poor overall performance confirms *X is not solvable from co-occurrence information alone. Rather, success at *X is driven by the more abstract features learned by neural networks. There are no categories in which the n-gram approaches human performance.\\"]}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: A model that takes a paragraph and a question as input, and outputs an answer as a sequence ofKeyphrases: question answering text paragraph-levelDataset description:ProPara: The ProPara dataset is designed to train and test comprehension of simple paragraphs describing processes (e.g., photosynthesis), designed for the task of predicting, tracking, and answering questions about how entities change during the process. ProPara aims to promote the research in natural language understanding in the context of procedural text.TweetQA: With social media becoming increasingly popular on which lots of news and real-time events are reported, developing automated question answering systems is critical to the effectiveness of many applications that rely on real-time knowledge. While previous question answering (QA) datasets have concentrated on formal text like news and Wikipedia, the first large-scale dataset for QA over social media data is presented.SearchQA: SearchQA was built using an in-production, commercial search engine. It closely reflects the full pipeline of a (hypothetical) general question-answering system, which consists of information retrieval and answer synthesis.QNLI: The QNLI (Question-answering NLI) dataset is a Natural Language Inference dataset automatically derived from the Stanford Question Answering Dataset v1.1 (SQuAD). SQuAD v1.1 consists of question-paragraph pairs, where one of the sentences in the paragraph (drawn from Wikipedia) contains the answer to the corresponding question (written by an annotator).DROP: Discrete Reasoning Over Paragraphs DROP is a crowdsourced, adversarially-created, 96k-question benchmark, in which a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs than what was necessary for prior datasets.Quoref: Quoref is a QA dataset which tests the coreferential reasoning capability of reading comprehension systems. In this span-selection benchmark containing 24K questions over 4.7K paragraphs from Wikipedia, a system must resolve hard coreferences before selecting the appropriate span(s) in the paragraphs for answering questions.NewsQA: The NewsQA dataset is a crowd-sourced machine reading comprehension dataset of 120,000 question-answer pairs. Documents are CNN news articles.Options:- A: ProPara  B: TweetQA  C: SearchQA  D: QNLI  E: DROP  F: Quoref  G: NewsQA","answer":"[\\"SearchQA\\", \\"NewsQA\\"]"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey of Wireless Security Chapter Title:  RSN connection is performed in three phases [21, 22, 23]: 1. Abstract of Cited Paper (BIB001):  Current IEEE 802.11 wireless networks are vulnerable to session hijacking attacks as the existing standards fail to address the lack of authentication of management frames and network card addresses, and rely on loosely coupled state machines. Even the new WLAN security standard - IEEE 802.11i does not address these issues. In our previous work, we proposed two new techniques for improving detection of session hijacking attacks that are passive, computationally inexpensive, reliable, and have minimal impact on network performance. These techniques utilise unspoofable characteristics from the MAC protocol and the physical layer to enhance confidence in the intrusion detection process. This paper extends our earlier work and explores usability, robustness and accuracy of these intrusion detection techniques by applying them to eight distinct test scenarios. A correlation engine has also been introduced to maintain the false positives and false negatives at a manageable level. We also explore the process of selecting optimum thresholds for both detection techniques. For the purposes of our experiments, Snort-Wireless open source wireless intrusion detection system was extended to implement these new techniques and the correlation engine. Absence of any false negatives and low number of false positives in all eight test scenarios successfully demonstrated the effectiveness of the correlation engine and the accuracy of the detection techniques.Literature Review:","answer":"Phase 1: Request, authentication and association. The station looks for the AP with appropriate SSID. All APs in the range answer with the Probe Request framework, as shown in Figure  4 . When the station identifies with which AP it is connected and accepts its parameters, authentication is performed as well as connection to the AP. At the end of phase 1 the workstation and the AP establish security rules and 802.1x authentication port is locked. 802.1x network port remains locked as long as the authentication procedure has been completed. Figure 5 . If the mutual authentication is successful, the authentication server generates Master Session key (MSK) and forwards it to the authenticator and to the station. PMK (Pair-Wise Master Key) is then generated by the station and authenticator based on the MSK. Phase 3: 4-Way Handshake. The station and the authenticator have to mutually confirm the current PMK in order to complete successfully RSNA (as shown in Figure 5 ). After successful confirmation a PTK (Pair -Wise Transient Key) is generated to be used for a secure transfer of session data. Now 802.1x port is unlocked. 802.1x authentication has several advantages: -Administrators can define users' responsibilities in the network, they do not have to pair manually users' names with MAC addresses, and can easily find mistakes and supervise the network, -Administrators allow access to the network according to the manufacturer standards, -An authorized port cannot be compromised by a non-802.1x client, -The authenticator waits for a certain period of time for a client to re-authenticate before the port is locked, -A continuity of authentication procedure is allowed in case the client was temporarily unable to respond to authenticator's request, -It is allowed for more devices to access the network by a shared mediator (such as hub), and -Protection is imposed to all users of the access point. -In addition to the advantages mentioned before, 802.1x authentication has also some deficiencies. These deficiencies result from the mistakes in 802.1x and EAP protocols BIB002  that the attackers have used for attacks. to be converted in 128 bits blocks before encryption. This is done by CCMP by adding random data in blocks to become 128 bit blocks. When decryption is completed, CCMP removes added data that are not a part of the original message. CCMP in AES-CCMP is a combination of two AES counter mode encryption and CBC-MAC (Cipher Block Chaining -Message Authentication Code protocol) techniques BIB001 . The first technique adds nonce and counter on AES temporal key and encrypts a message by XOR. Nonce is MAC address of the sender and frame ordinal number. MAC address is used in order to use the same increment in different communications directions, thus providing different encryption streams. Packet ordinal number has a purpose to detect for the receiver injection of old packets. Receiver remembers the ordinal number of the last packet and accepts all packets with bigger ordinal number. A counter is changed for each of data encrypted blocks, as shown in Figure 6 . An attacker can find out a starting value of the counter, but cannot know which block applies to which increment. For message security it is not enough only to encrypt the message, but to preserve the integrity, too. CBC-MAC mechanism guarantees that the message will not be modified during the transmission between two devices. CBC-MAC is based on CBC algorithm of encryption. This algorithm operates in a way that it calculates XOR between unencrypted and previously encrypted blocks, then it is encrypted by AES key and XOR for that block is calculated by next unencrypted block, as it is shown in Figure 6 . The procedure is repeated until the final 128 bit CBC-MAC block is generated. It is obvious that CBC-MAC block value depends on the value of all previous blocks and since all these blocks are encrypted, it is also obvious that CBC-MAC depends on the key. If a receiver finds some irregularities with a CBC-MAC, it means that there was message modification (message integrity is ruined) or that the message was encrypted with a different key. This section describes differences between WPA and WPA2/802.11i safety improvements. Table 1 gives a comparison of these safety improvements in comparison to WEP as a first solution to achieve safety goals in WLAN networks."},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:The precise editing of surface sites on a molecular-like gold catalyst for modulating regioselectivityPaper sections:Introduction<p>The identication of catalytically active sites in particle catalysts has long been an important task in catalytic chemistry. [1][2][3] In the sub-nanometer size regime, each site of a catalyst may be directly or indirectly involved in a reaction process. [4][5][6] Hence, it is highly desirable to explicitly conclude the extents to which individual sites of a catalyst contribute to its overall catalytic performance. However, due to the complexity of conventional investigations, it remains an open challenge to directly observe the catalytic performance of each site in a typical catalyst; microscopy and spectroscopy techniques usually provide statistically averaged or sample-averaged information. 7 Enlightened by organic chemists who can deliberately remove or replace any group in an organic molecule without changing other parts, tailoring a specic site without changing the other parts of a solid catalyst would allow us to unveil the contribution of the specic site to a given chemical reaction.</p><p>Atomically precise metal clusters constitute a new generation of metal catalysts in catalysis science and exhibit unexpected catalytic properties. [8][9][10][11][12][13] These metal clusters provide the potential to precisely correlate intricate structural information (such as aesthetic structural pattern, ligand effect, metal-metal bonding, metal-ligand interfacial bonding, and metal charge) with the catalytic properties, which can shed light on current mysteries in the eld of catalysis. [14][15][16][17][18][19][20][21] By solving their atomic structures, we can determine the active site structure and establish denitive structure-property relationships, which have previously been elusive. 22 Such advances in these clusters inspire us to use them as proof-of-concept catalysts to pursue a fundamental understanding of how a specic site in a catalyst controls the catalytic properties.</p><p>In this work, the cycloaddition reaction of alkyne and azide by means of click chemistry, which has been widely applied to generate high-value organic compounds, was chosen as a probe reaction. 23 A series of ligand-protected Au n (n ¼ gold atom number) clusters with different atomic structures and surface motifs (see ESI for structural details, Fig. S1 †) were screened to catalyze the click reaction. As shown in Fig. 1, these Au n clusters failed to provide regioselectivity for the 1,4-or 1,5-triazole products of the click reaction of phenylacetylene and benzyl azide. The above Au n clusters could not selectively drive the reaction process toward either of the two products. We thus questioned whether a purposeful editing on the surface motifs of the clusters might be used to manipulate the regioselectivity toward one product. If successful, this promising strategy could be developed to precisely modulate the surface active sites of catalysts to obtain an exclusive product through an operative process.</p>Results and discussion<p>Given the complexity of the geometric structures and surface structures of the Au n clusters, it is difficult to rapidly identify the key structures in inducing high regioselectivity toward an exclusive product. Therefore, we analyzed the relationships between the structural information of the Au n clusters with the reaction activity and selectivity using existing reaction data (Fig. 1) to aid in establishing the structure-property relationship. Fig. 2a shows the effect of the surface gold atoms on the catalytic activity. In general, more surface gold atoms resulted in higher catalytic activity (more details of surface Au atoms are shown in Fig. S2 †). It is interesting to consider the steric hindrance effect of the ligands on the regioselectivity of these Au n clusters protected by thiolates (Fig. 2b). Steric hindrance was qualitatively expressed by the surface area occupied by each ligand (i.e., the ratio of the total van der Waals surface area to the number of ligands of a cluster, referred to as the surface area per ligand). The steric hindrance effect of the ligands can also be illustrated by the electrostatic potentials of the Au n clusters determined by density functional theory (DFT) calculations, 24 as shown in Fig. 2b and c (more details can be found in Fig. S3 and Table S1 †). On the other hand, in the systems of the Au n clusters capped by PPh 3 ligands, the steric hindrance is larger than in the thiolate-protected clusters. The Au n clusters capped by PPh 3 ligands show larger surface areas per ligand and much narrower pockets for reactant docking (compared Fig. 2b  and c). More interestingly, the steric hindrance from PPh 3 ligands is strongly correlated to the regioselectivity of the 1,4product (Fig. 2c). Thus, the results suggest that the Au n clusters capped by phosphine ligands relative to thiolates are prone to driving the click reaction pathway toward the 1,4-product compared to Au n clusters capped by thiolates.</p><p>Inspired by the workable molecular tailoring of the Au 23 (SR) 16 cluster, 25 the specic surface site containing phosphine ligands (Au-Ph 2 P-CH 2 -PPh 2 -Au) was selected to enable    16 (Fig. 4a), which may be attributed to the stronger chemical adsorption capability of the former catalyst, as deduced from in situ time-resolved infrared Fourier transform infrared (FTIR) spectroscopic analysis of CO molecules adsorbed onto the two catalysts (Fig. S5 †). The two clusters seemed robust during the reactions (Fig. S6 and S7 †). Furthermore, the relationship between regioselectivity and steric hindrance in the Au 21 (SC 6 H 11 ) 12 (Ph 2 PCH 2 PPh 2 ) 2 and Au 23 (SC 6 H 11 ) 16 systems was corroborated by the analysis of the surface area/ligand ratio. The steric hindrance from the organic ligands can be signicantly increased by the site-specic replacement of SR-Au-SR with Ph 2 P-CH 2 -PPh 2 (Fig. 4b), favoring an increase in regioselectivity toward 1,4-products.</p><p>We now rationalize how Au 21 (SC 6 H 11 ) 12 (Ph 2 PCH 2 PPh 2 ) 2 can achieve regioselectivity while Au 23 (SC 6 H 11 ) 16 cannot. First, the distinct selectivity cannot be attributed to the electronic structures of the two clusters because the exchange of surface motifs had little inuence on the electronic properties of the clusters. As presented in Fig. 5a, the binding energies of the Au 4f X-ray photoelectron spectroscopy (XPS) peaks of Au 21 (SC 6 H 11 ) 12 (-Ph 2 PCH 2 PPh 2 ) 2 were not noticeably difference from those of Au 23 (SC 6 H 11 ) 16 . The gold charge states were also monitored by X-ray absorption near-edge structure (XANES) studies, indicating that the gold charge state of Au 21 was similar to that of Au 23 based on liner combination ts (Fig. 5b and S8 †). This means that tailoring the specic motifs did not cause a signicant perturbation in the electronic structures of the two gold clusters.</p><p>Going further, the Au-acetylide intermediates on the Au 21 (-SC 6 H 11 ) 12 (Ph 2 PCH 2 PPh 2 ) 2 and Au 23 (SC 6 H 11 ) 16 clusters were studied by 1 H nuclear magnetic resonance (NMR) spectroscopy. Free phenylacetylene showed a singlet proton peak (d ¼ 3.1 ppm) and two sets of peaks (d ¼ 7.3 and 7.5 ppm) for the aromatic hydrogen atoms (Fig. 5c). 27 Of note, the acetylenic proton peak of phenylacetylene adsorbed on the Au 21 (SC 6 -H 11 ) 12 (Ph 2 PCH 2 PPh 2 ) 2 cluster was nearly absent, excluding the  binding mode of phenylacetylene in the intact form (C^C-H) and supporting its binding mode in the dehydrogenated form (C^C) (Fig. S9 †). In the Au 23 (SC 6 H 11 ) 16 system, the peak of the ^C-H proton is observed (Fig. 5c), although the peak intensity is weak, implying that the deprotonation-induced activation process of phenylacetylene was more difficult for Au 23 (SC 6 H 11 ) 16 than for Au 21 (SC 6 H 11 ) 12 (Ph 2 PCH 2 PPh 2 ) 2 . Taken together, the results imply that two binding modes of alkyne on Au 23 (SC 6 H 11 ) 16 were obtained: terminal binding and internal binding (Fig. S9 †).</p><p>To further understand the distinct catalytic regioselectivity of the Au 21 (SC 6 H 11 ) 12 (Ph 2 PCH 2 PPh 2 ) 2 and Au 23 (SC 6 H 11 ) 16 clusters for the click reaction of phenylacetylene and benzyl azide, we performed DFT calculations to explore the possible reaction pathways of 1,4-and 1,5-product formation on the two clusters. The overall pathways may include the adsorption, coupling, and reductive elimination of azide and phenylacetylene.  S11 †). The click reaction occurs preferably on the Au-Au P -P-P-Au P -Au (Au P denotes the Au atom attached to the phosphine ligand) and Au-S-Au sites of the Au 21 catalyst. In contrast, for the A-Au 23 catalyst (Fig. 6 and S10 †), the energy difference between the 1,4-product and 1,5-product is relatively small (DDG ¼ 8.6 kcal mol À1 ), leading to comparable selectivity for the formation of the 1,4-and 1,5-triazoles. This rationalizes the non-regioselectivity of the Au 23 cluster. Similar trends were observed for simplied models of Au 21 and Au 23 (S-Au 21 and S-Au 23 ; Fig. S12 and S13 †), for which the energy differences between the pathways toward the 1,4-product and the 1,5-product over the S-Au 21 and S-Au 23 catalysts were 19.2 and 3.1 kcal mol À1 (Fig. S14 †), respectively, in good agreement with the experimental results.</p>Conclusions<p>In summary, we have demonstrated that site-specic editing on an Au 23 (SC 6 H 11 ) 16 cluster via the exchange of the surface RS-Au-SR motifs with Ph 2 P-CH 2 -PPh 2 staples can achieve a transformation from non-regioselectivity to regioselectivity for the click reaction of azide and alkyne. The editing strategy for surface motifs offers an exciting opportunity to elucidate how a surface site of a catalyst can precisely control the reaction pathway. This work not only improves the understanding of the contribution of a single site in a solid catalyst to the overall catalytic performance, but it can also guide the development of a feasible strategy to enable highly efficient chemical processes based on the editing of surface sites of catalysts with atomic precision.</p>Conflicts of interest<p>There are no conicts to declare.</p>","answer":"It is extremely difficult to precisely edit a surface site on a typical nanoparticle catalyst without changing other parts of the catalyst. This precludes a full understanding of which site primarily determines the catalytic properties. Here, we couple experimental data collection with theoretical analysis to correlate rich structural information relating to atomically precise gold clusters with the catalytic performance for the click reaction of phenylacetylene and benzyl azide. We also identify a specific surface site that is capable of achieving high regioselectivity. We further conduct site-specific editing on a thiolateprotected gold cluster by peeling off two monomeric RS-Au-SR motifs and replacing them with two Ph 2 P-CH 2 -PPh 2 staples. We demonstrate that the surface Au-Ph 2 P-CH 2 -PPh 2 -Au motifs enable extraordinary regioselectivity for the click reaction of alkyne and azide. The editing strategy for the surface motifs allows us to exploit previously inaccessible individual active sites and elucidate which site can explicitly govern the reaction outcome."},{"question":"Given a short query with keyphrases about a research idea in 2018 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: We propose a simple and effective algorithm for subsampling and reconstruction of signals residing on the verticesKeyphrases: signal reconstructionDataset description:NuCLS: The NuCLS dataset contains over 220,000 labeled nuclei from breast cancer images from TCGA. These nuclei were annotated through the collaborative effort of pathologists, pathology residents, and medical students using the Digital Slide Archive.SBU Captions Dataset: A collection that allows researchers to approach the extremely challenging problem of description generation using relatively simple non-parametric methods and produces surprisingly effective results.MovieLens: The MovieLens datasets, first released in 1998, describe people’s expressed preferences for movies. These preferences take the form of tuples, each the result of a person expressing a preference (a 0-5 star rating) for a movie at a particular time.DocBank: A benchmark dataset that contains 500K document pages with fine-grained token-level annotations for document layout analysis. DocBank is constructed using a simple yet effective way with weak supervision from the LaTeX{} documents available on the arXiv.com.Options:- A: NuCLS  B: SBU Captions Dataset  C: MovieLens  D: DocBank","answer":"MovieLens"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Causal empirical estimates suggest covid-19 transmission rates are constant seasonalAbstract:Nearly every country is now combating the 2019 novel coronavirus (COVID-19).It has been hypothesized that if COVID-19 exhibits seasonality, changing temperatures in the coming months will shift transmission patterns around the world.Such projections, however, require an estimate of the relationship between COVID-19 and temperature at a global scale, and one that isolates the role of temperature from confounding factors, such as public health capacity.This paper provides the first plausibly causal estimates of the relationship between COVID-19 transmission and local temperature using a global sample comprising of 166,686 confirmed new COVID-19 cases from 134 countries from January 22, 2020 to March 15, 2020.We find robust statistical evidence that a 1°C increase in local temperature reduces transmission by 13% [-21%,-4%, 95%CI].In contrast, we do not find that specific humidity or precipitation influence transmission.Our statistical approach separates effects of climate variation on COVID-19 transmission from other potentially correlated factors, such as differences in public health responses across countries and heterogeneous population densities.Using constructions of expected seasonal temperatures, we project that changing temperatures between March 2020 and July 2020 will cause COVID-19 transmission to fall by 43% on average for Northern Hemisphere countries and to rise by 71% on average for Southern Hemisphere countries.However, these patterns reverse as the boreal winter approaches, with seasonal temperatures in January 2021 increasing average COVID-19 transmission by 59% relative to March 2020 in northern countries and lowering transmission by 2% in southern countries.These findings suggest that Southern Hemisphere countries should expect greater transmission in the coming months.Moreover, Northern Hemisphere countries face a crucial window of opportunity: if contagion-containing policy interventions can dramatically reduce COVID-19 cases with the aid of the approaching warmer months, it may be possible to avoid a second wave of COVID-19 next winter.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Using constructions of expected seasonal temperatures, we project that changing temperatures between March 2020 and July 2020 will cause COVID-19 transmission to fall by 43% on average for Northern Hemisphere countries and to rise by 71% on average for Southern Hemisphere countries.\\", \\"Moreover, Northern Hemisphere countries face a crucial window of opportunity: if contagion-containing policy interventions can dramatically reduce COVID-19 cases with the aid of the approaching warmer months, it may be possible to avoid a second wave of COVID-19 next winter.\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Structure and dynamics underlying elementary ligand binding events in human pacemaking channels}Article:Abstract:Although molecular recognition is crucial for cellular signaling, mechanistic studies have relied primarily on ensemble measures that average over and thereby obscure underlying steps. Single-molecule observations that resolve these steps are lacking due to diffraction-limited resolution of single fluorophores at relevant concentrations. Here, we combined zero-mode waveguides with fluorescence resonance energy transfer( FRET) to directly observe binding at individual cyclic nucleotide-binding domains( CNBDs) from human pacemaker ion channels critical for heart and brain function. Our observations resolve the dynamics of multiple distinct steps underlying cyclic nucleotide regulation: a slow initial binding step that must select a 'receptive' conformation followed by a ligand-induced isomerization of the CNBD. X-ray structure of the apo CNBD and atomistic simulations reveal that the isomerization involves both local and global transitions. Our approach reveals fundamental mechanisms underpinning ligand regulation of pacemaker channels, and is generally applicable to weak-binding interactions governing a broad spectrum of signaling processes.Introduction:Most cellular signaling pathways require or are modulated by the binding of small molecules to integral proteins. However, our understanding of the dynamic events involved in these molecular recognition processes comes primarily from inferences based on downstream activity initiated by binding, or ensemble measures that average over and thereby obscure the underlying mechanistic steps. In contrast, single-molecule observations reveal dynamics and heterogeneity of conformational transitions that are otherwise averaged over in ensemble measurements, and thus are a means to probe specific molecular transitions providing important clues to the physical basis for binding( Joo et al., 2008; Csermely et al., 2010; Greives and Zhou, 2014; Guo and Zhou, 2016; Ruiz and Karpen, 1997; Miller, 1997). Single-molecule approaches have provided mechanistic insight in many areas: for example, patch-clamp recordings from single ion channels reveal the network of states that underlie gating of the central pore( Lape et al., 2008; Mukhtasimova et al., 2009; Colquhoun and Lape, 2012; Purohit et al., 2014), whereas optical techniques such as single-molecule FRET( smFRET) allow tracking of conformations and structural movements of individual domains( Akyuz et al., 2015; Cooper et al., 2015; Wang et al., 2014; Vafabakhsh et al., 2015; Landes et al., 2011; Wang et al., 2016). However, similar resolution of the fundamental mechanisms underlying individual ligand binding events that initiate or modulate downstream domain movements and pore gating are lacking, primarily due to technical challenges in imaging with both sufficient temporal resolution and at concentrations necessary to drive many physiologically relevant recognition processes. For fluorescence based approaches( Funatsu et al., 1995), a major challenge hampering resolution of single binding events with low affinity is the diffraction limit of light microscopy. At the high concentrations necessary to drive these binding reactions, the number of fluorescent ligands within the diffraction-limited excitation volume becomes appreciable, thereby obscuring resolution of individual fluorophores. Unfortunately, many physiologically relevant recognition processes have affinities in the micromolar range, which precludes single-molecule resolution with traditional microscopy techniques including total internal reflection( TIRF) or confocal microscopy. To observe micromolar affinity binding events at single molecules, we used zero-mode waveguide( ZMW) nanofabricated devices( Levene et al., 2003; Zhu and Craighead, 2012). ZMWs limit optical excitation to a sub-diffraction-limited volume such that even at micromolar concentrations there are sufficiently few ligands excited that binding of a single fluorophore in the excitation volume can be resolved. As a notable exception to the overall lack of single-molecule binding observations for physiological processes, ZMWs have been used to great effect to study translation events at individual ribosomes and single-molecule electrochemistry, and have enabled single-molecule genomic sequencing( Uemura et al., 2010; Korlach et al., 2010; Zhao et al., 2013). Here, we combined ZMWs with smFRET to resolve individual specific binding events of a fluorescent cyclic nucleotide derivative( fcAMP)( Kusch et al., 2010) with micromolar affinity for its receptor CNBD from hyperpolarization-activated cyclic nucleotide-gated( HCN) channels critical for oscillatory neuronal activity in the brain and pacemaking in the heart. Although binding of cyclic nucleotides is known to enhance HCN voltage-dependent activation, the mechanisms that underlie this regulation remain unclear. Previous studies of cyclic nucleotide( e. g. cAMP) regulation have relied primarily on ensemble channel currents( Chen et al., 2007), or more recently on ensemble fluorescence from fcAMP( Kusch et al., 2012; Benndorf et al., 2012; Thon et al., 2015), to deduce the dynamics of cyclic nucleotide association. Although fcAMP provides a more direct measure of binding than does downstream pore current, both measurements reflect ensemble-averaged data that obscures resolution of the individual steps involved in the binding process. Resolving the dynamics of these steps is important because it provides a rationale for assigning the effect of specific perturbations to distinct mechanistic steps – an invaluable tool for deconstructing the pathway by which binding is transduced to functional changes elsewhere such as at the pore gate. To resolve ambiguity in current ensemble-based models of cyclic nucleotide association, we dissected the intrinsic binding dynamics at single molecules to reveal that cAMP binding involves multiple conformational transitions: an initial binding step that is appreciably slower than expected for a diffusion-limited encounter complex, partly due to selection of the ‘receptive’ conformation, and a subsequent ligand-induced isomerization of the CNBD. Our single-molecule observations in both monomeric and tetrameric CNBD complexes, in conjunction with the first unique X-ray structure of the unliganded CNBD and molecular dynamics( MD) simulations, resolve the dynamic mechanisms underlying cyclic nucleotide association at HCN channels to a level of unprecedented detail.Discussion:Typical optical approaches utilizing fluorescent ligands are incapable of resolving low affinity binding events at the single-molecule level due to the large background fluorescence from the high ligand concentrations necessary to drive association. Here, we show that ZMW’s in conjunction with smFRET can resolve individual specific binding events in the presence of concentrations of at least 10 µM fluorescent species, extending single-molecule approaches to more physiologically relevant lower affinity binding events than previously possible while eliminating the influence of non-specific binding( e. g. Figure 2—figure supplement 1)( Zhu and Craighead, 2012). Our observations resolve the dynamics of the distinct events that underlie cyclic nucleotide association in HCN channels, and reveal that cAMP selectively binds to the ‘receptive’ state of the CNBD, and thereafter induces an isomerization between two distinct bound conformations. As expected given its modular nature( e. g. isolated CNBDs retain similar binding affinities to full length channels and form cAMP-induced tetramers in solution[Lolicato et al., 2011]), we show that this isomerization occurs in both monomeric and tetrameric CNBD complexes, and thus is likely to reflect inherent properties of the CNBD in channels. We also successfully crystallized the HCN2 CNBD in a unique unliganded state, which provides a high resolution counterpart to previous ligand-bound structures to aid in structural interpretation of the binding mechanism. The single-molecule binding data combined with the structural information suggest a model where the initial binding step reflects selective cAMP association to the apo form of the CNBD, and the subsequent isomerization involves a coordinated rotation of the N- and C-terminal α-helices about the rigid β-roll whereby the C-helix caps the bound ligand as in the holo structure( Figure 6). HMM modeling suggests that binding occurs selectively from one of two unbound states, which implies that the interchange between these states involves an occlusion of the binding site in the apo form, likely by the C-helix. The slow dynamics for this process imply a relatively large energy barrier that is reduced upon binding cAMP, consistent with EPR observations that the C-helix adopts a cAMP-dependent equilibrium between apo and holo positions( Puljung et al., 2014; Deberg et al., 2016). Based on both the model predictions that transitions between U2 and B2 states occur either infrequently or not at all, and the structural observation that the C-helix occludes access to the binding site in the holo form, we rule out cyclic models that allow binding to the isomerized state( e. g. model 6 in Figure 3E). Our observations provide the first direct evidence that the binding rate is relatively slow, which suggests that fcAMP binding to the ‘receptive’ state of the CNBD is rate-limited by additional processes other than simple diffusion, such as ligand reorientation, desolvation and structural rearrangements in the binding site including the P-helix 310 to α-helix transition. Thus, the initial encounter complex is either relatively unstable, such that brief encounters shorter than our frame rate were not observed, or it sees a significant barrier to its formation. Regardless, following formation of the initial bound complex the CNBD undergoes a reversible isomerization between two bound forms. Comparison of apo and holo X-ray structures shows that the N- and C-terminal helices are rotated in the isomerized state where the C-helix caps the binding site( Figure 4). Thus, the observed isomerization may reflect dynamic movement of the C-helix between apo and holo positions( Figure 6). However, we cannot rule out the possibility that the C-helix also moves during the initial binding step; indeed, by perturbing the ligation state of the CNBD in holo and apo structures in otherwise unbiased molecular dynamics simulations at the microsecond scale, we observe that the cyclic nucleotide has a direct impact on the structure of the P-helix and orientation of the B, C helices in the C-terminal region( Figure 5). In this case, the subsequent isomerization may involve rearrangements in the N-terminal C-linker, a region that was truncated in order to obtain the apo structure, and therefore for which we have incomplete structural information regarding its unliganded form. Nonetheless, these data establish the dynamics of the distinct events that underlie both selective binding and cAMP-induced conformational changes that regulate the channel pore. We note, however, that although it is highly plausible that fcAMP and cAMP bind with similar dynamics given their similar affinities and functional effects, we cannot rule out the possibility that cAMP association dynamics differ from those observed here for fcAMP. The large-scale conformational change of the HCN2 CNBD induced by cAMP binding can be viewed as a rotation of the N- and C-terminal helices, taken as a single domain, in relation to the rigid β-roll. Crucially, the C-helix that caps the bound ligand moves in conjunction with the N-terminal helices connected to the tetramerization module( C-linker) and channel pore. Thus, a reciprocal relationship between ligand binding and tetramerization inevitably follows: ligand binding is expected to shift the equilibrium toward tetramerization and, in turn, anything that promotes tetramerization would be expected to enhance ligand binding. This idea is schematically illustrated in Figure 4h, and provides a facile explanation for cAMP-induced tetramerization of monomeric CNBDs in bulk solution and lower affinity for cAMP of CNBDs lacking a C-linker( Lolicato et al., 2011). The notion that ligand activation involves isomerization of a ligand-bound receptor to a ‘flipped’ or ‘primed’ configuration has been predicted primarily on the basis of analysis of downstream current recordings( Lape et al., 2008; Mukhtasimova et al., 2009; Colquhoun and Lape, 2012; Purohit et al., 2014; Thon et al., 2015; Goldschen-ohm et al., 2014; Gielen et al., 2012). However, these various bound states have previously never been directly observed. Our studies here provide direct evidence for such a binding process, and also shed new light on a long-standing debate about the transition pathways that define the binding mechanism–conformational selection versus induced fit. We find that the initial step involves selective binding to the ‘receptive’ state( U1), which thereafter undergoes a conformational change that traps the ligand in the bound conformation( B2). Our observations reveal the dynamics and structural detail of the distinct steps that underlie cyclic nucleotide regulation of HCN pacemaker channels, and lay the necessary foundation to probe the molecular details involved in each separate step of multi-subunit complexes. The combination of dynamic and structural observations provide a general approach for revealing the molecular details governing signaling based on weak-binding, a critical and previously inaccessible class of molecular recognition processes.","answer":"Certain cells in the heart and brain show rhythmic bursts of electrical activity . Such electrical activity is a caused by ions moving in or out of the cells though a number of ion channel proteins in the cell surface membrane . The voltage across this cell membrane regulates the activity of these so-called pacemaking channels , and so do small molecules like cAMP . Nevertheless , it remained poorly understood how cAMP binding altered how the channels work . This was because researchers had been unable to unambiguously resolve the early binding events , because the available techniques were too limited . Goldschen-Ohm , Klenchin et al . have now overcome these technical limitations and observed individual molecules of cAMP ( which had been first labeled with a fluorescent tag ) binding to the relevant parts of a pacemaking channel from humans . This approach revealed that the binding process happens via a sequence of discrete steps . First , cAMP selectively binds when the binding site of the ion channel adopts a specific shape , called its “receptive” state . Second , part of the protein rotates which changes the shape of the binding site and traps the bound cAMP in place . The trapped molecule is not released until the binding site reverts to its previous shape . These new findings provide the groundwork for future studies to dissect how different parts of pacemaking channels change shape and interact to control these channels’ activities ."},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:an iterated function system ( ifs ) can be used to construct a fractal interpolating function for a given set of data @xcite .the simplest such system defines an ifs @xmath1 with coefficients @xmath2 , and @xmath3 determined from discrete data points ( @xmath4 ) , @xmath5 .such an ifs interpolates the data set in the sense that , under certain assumptions on the coefficients @xcite , the attractor of the ifs is a graph that passes through the data points . in this particular case, the ifs can be written as @xmath6 which shows that a linear ( in @xmath7 ) interpolating function between the points ( @xmath8 ) and ( @xmath9 ) is used .various generalizations of fractal interpolating functions have been given , including those for higher dimensional functions , the use of hidden variables , and extensions to certain non  linear distortions @xcite .in this note we describe a generalization whereby the transformation incorporates a @xmath0order polynomial interpolation between adjacent points .we also discuss certain classes of non  linear functions that can arise in such interpolating functions , and show how such functions can , with the use of a particular escape  time algorithm , be used to generate certain fractal images .the paper is organized as follows . in section [ lin ]we describe simple linear fractal interpolating functions , and discuss how particular non  linear functions can arise .section [ quadratic ] generalizes these considerations to @xmath0order interpolating functions .section [ escape ] describes a certain escape  time algorithm which may be used for these systems to generate fractal images like those associated with mandelbrot or julia sets .section [ end ] contains some brief conclusions .we first describe how a standard linear fractal interpolating function is constructed .suppose we have data points ( @xmath4 ) , @xmath10 , describing a function @xmath11 .consider the ifs @xmath12 imposing the conditions , for @xmath13 , @xmath14 leads to determination of the coefficients as @xmath15 the transformation can then be written as @xmath16 thus , @xmath17 is determined by a linear ( in @xmath7 ) interpolating function constructed between the points ( @xmath8 ) and ( @xmath9 ) .a generalization of this type of fractal interpolating function can be found by considering an ifs of the form @xmath18 where @xmath19 is , at this stage , an arbitrary function .imposing the conditions ( [ lincond ] ) leads to determination of the coefficients as @xmath20 the transformation can then be written as @xmath21 where @xmath22 and the identity @xmath23 for arbitrary @xmath24 has been used .the interpolating function of the last section used a linear ( in @xmath7 ) approximation between adjacent points . in this sectionwe indicate how a quadratic approximation may be constructed ; the generalization to an arbitrary @xmath0order polynomial approximation will be straightforward .let us consider a transformation of the form @xmath25 and impose the conditions , for @xmath26 , @xmath27 the point @xmath28 is determined as @xmath29 with corresponding point @xmath30 .the coefficients of the ifs are determined as @xmath31 with this , the transformation can be written as @xmath32 which thus uses a quadratic ( in @xmath24 ) interpolating function between the points ( @xmath9 ) , ( @xmath8 ) , and ( @xmath33 ) .as in the previous section , including an arbitrary function @xmath19 in the ifs transformation via @xmath34 is straightforward . the conditions ( [ quadcond ] ) leads to determination of the point @xmath28 of eq .( [ tm ] ) as before , together with the accompanying point @xmath30 .the transformation itself can be written as @xmath35 where @xmath36 and the identity @xmath37 for arbitrary @xmath24 has been used .    from these considerations ,the pattern to constructing a @xmath0order fractal interpolating function is apparent .start with a transformation of the form @xmath38 and impose the conditions , for @xmath39 , @xmath40 the @xmath41 intermediate points @xmath42 , with @xmath43 , are determined as @xmath44 along with the corresponding @xmath45 points .the resulting transformation will be of the form given by lagrange s formula for a @xmath0order polynomial interpolating function constructed from @xmath46 points : @xmath47 the inclusion of an arbitrary function @xmath19 in the transformation @xmath48 of eq .( [ arb ] ) , as was done for the linear and quadratic transformations of eqs .( [ ling ] ) and ( [ quadg ] ) respectively , is straightforward .as might be expected , the use of these higher  order interpolating functions can increase the accuracy of the interpolation significantly , at least for smooth functions some informal tests on known functions suggest an improvement of almost an order of magnitude in general in using a quadratic interpolating function over a linear one . of course , as for polynomial interpolation, there is a limit to the net gain in employing a higher  order interpolating function .assuming that the corresponding ifs transformation is contractive , so that the distance @xmath49 between any two points in the range of interest satisfies @xmath50 where @xmath51 is the contractivity factor , graphs of the functions represented by fractal interpolating functions can be made by applying the standard random iteration algorithm to the ifs :    * initialize ( @xmath52 ) to a point in the interval of interest * for a set number of iterations * * randomly select a transformation @xmath53 * * plot ( @xmath54 ) @xmath55 * * set ( @xmath52 ) @xmath56 ( @xmath54 ) * end for    alternatively , one can relate an ifs @xmath53 to a shift dynamical system @xmath57 , and on this system perform an escape time algorithm to generate an image @xcite . in this sectionwe describe an algorithm for generating fractal images like those for julia or mandelbrot sets from ifs interpolating functions .suppose we have an ifs transformation @xmath53 , generated by some data points ( @xmath58 ) , @xmath5 , which includes a non  linear function @xmath19 , as was done for the linear and quadratic transformations of eqs .( [ ling ] ) and ( [ quadg ] ) respectively .we now continue the real variable @xmath59 of this transformation to complex values : @xmath60 ( @xmath61 ) , so that the transformation @xmath62 is defined on the complex plane .we can then , in analogy with the algorithm used for julia sets , define the following escape  time algorithm to generate a fractal pattern :    * for each pixel in a region of interest * * initialize @xmath7 * * initialize @xmath63 ( @xmath61 ) to the pixel coordinates * * for @xmath64 * * * calculate ( @xmath65 ) @xmath66 * * * break if @xmath67 exceeds a maximum * * * set ( @xmath68 ) @xmath56 ( @xmath65 ) * * end for * * plot the pixel * end for    where the pixel is plotted using a coloring algorithm based upon , amongst perhaps other factors , the number of iterations attained when the break condition was met @xcite .the preceding can be interpreted as follows .a general @xmath0order fractal interpolating ifs @xmath69 with the coefficients @xmath70 determined from the data ( @xmath4 ) , @xmath5 , can be viewed , with the continuation @xmath71 , as defining a complex map @xmath72 for @xmath64 .the escape  time algorithm described above is then just the standard one used for julia sets of complex maps .the arbitrariness of the function @xmath19 and the data set ( @xmath4 ) used to fix the ifs leads to a wide variety of possible fractal images generated in this way .an interesting class of functions @xmath19 to consider in this context are those for which , when continued to the complex plane @xmath60 ( @xmath61 ) , lead to a map having a fixed point @xmath73 : @xmath74 in such a case one could augment the usual condition of the escape  time algorithm to cease iteration : @xmath75 , where @xmath76 is some suitably large value , to also cease iteration when @xmath77 , where @xmath78 is a suitably small value .the coloring algorithm used to plot a pixel , which depends on the number of iterations attained when this break  out condition was met ( if at all ) , will then lead to structure in the region where the break  out condition on the magnitude of @xmath79 is not met .we give two examples of fractal images generated this way for the choice @xmath80 , with the data generated from the logistic map @xmath81 , with @xmath82 .the first one , appearing in fig .[ ifs1 ] , corresponds to the generalization ( [ ling ] ) of a linear ( in @xmath7 ) fractal interpolating function , while the second image of fig .[ ifs2 ] corresponds to the generalization ( [ quadg ] ) of a quadratic ( in @xmath7 ) interpolating function .a coloring algorithm that simply mapped a color to the number of iterations attained when the break  out condition became satisfied was used in both cases .linear interpolating function ]    quadratic interpolating function ]    these figures illustrate , in the interior of the fractal object , the richer structure arising from the quadratic over the linear interpolation function . in this regionthe break  out condition @xmath83 is satisfied , which numerically for @xmath84 is attained after a relatively small number ( 1030 ) of iterations .we have considered two non  linear generalizations of fractal interpolating functions constructed from iterated function systems .one  using a @xmath0order interpolating polynomial  can potentially improve the accuracy of fractal interpolating functions .the other generalization  the use of certain arbitrary functions in the ifs  can , together with an appropriate escape  time algorithm , generate fractal images .this last point is of interest as , first of all , there is a rich variety of such images possible due to the arbitrariness of the functions used , and secondly , it shows how fractal images as normally associated with julia or mandelbrot sets can also be associated with discrete data sets .this work was supported by the natural sciences and engineering research council of canada .99 m.  f.  barnsley , _ fractals everywhere _ ( academic press , san diego , ca , 1993 ) h.  o.  peitgen , h.  jrgens , and d.  saupe , _ chaos and fractals  new frontiers of science _ ( springer , new york , 1992 ). m.  f.  barnsley , j.  elton , d.  hardin , and p.  massopust , _ hidden variable fractal interpolation functions _, siam j. math .20 * ( 1989 ) , 1218 - 1242 .r.  massopust , _ fractal functions , fractal surfaces and wavelets _ ( academic press , san diego , ca , 1994 ) . l.  m.  kocic and a.  c.  simoncelli , _ fractal interpolation in creating prefractal images _ , visual mathematics * 2 * , no .  2 ( 2000 ) .h.  o.  peitgen and d.  saupe , _ the science of fractal images _ ( springer , new york , 1988 ) .e.  grller , _ modeling and rendering of nonlinear iterated function systems _ , institute of computer graphics , technical university of vienna report tr-186 - 2 - 94 - 12 ( 1994 ) .j.  barrallo and d.  m.  jones , _ coloring algorithms for dynamical systems in the complex plane _ , visual mathematics * 1 * , no .  4 ( 1999 ) .","answer":"we consider two non  linear generalizations of fractal interpolating functions generated from iterated function systems .  the first corresponds to fitting data using a @xmath0order polynomial , while the second relates to the freedom of adding certain arbitrary functions .  an escape  time algorithm that can be used for such systems to generate fractal images like those associated with julia or mandelbrot sets is also described ."},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:Therefore, ScvO2 has become a metabolic monitoring parameter with extraordinary value in the resuscitation of septic shock patients and a cornerstone of an outcome-oriented algorithm such as early goal-directed therapy [3-5].","answer":"Background"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Toxicity patterns following stepwise combinations of cyclophosphamide , methotrexate and fluorouracil . The contribution of the agents used in the CMF regimen, i.e., cyclophosphamide (CY), methotrexate (MTX) and fluorouracil (FUra), to the development of toxicity was determined in tumor-bearing WAG/Rij rats. Data from untreated (U) rats were compared with data from rats treated with single-agent therapy (C-, M- and F-treatment groups), with data from double-agent therapy (CM-, MF- and CF-treatment groups) and with data from the triple combination: the CMF-treatment group. Doses of agents of interest were the same in all treatment groups. The sequence of administration was (1) CY; (2) MTX and (3) FUra which is similar to clinical treatment with CMF. Systemic levels of CY, MTX and FUra were comparable to those found in patients treated according to the CMF regimen. Toxicity was evaluated by body-weight changes, water and food consumption, white blood cell (WBC) and platelet cell (Pts) counts. With the exception of WBC and Pts nadirs, estimated toxicity parameters reflected toxicity over the whole treatment period of 14 days. The toxicity was generally mild and well tolerated, with one fatality in the M-treatment group. CY was the main contributor to toxicity; it caused both myelotoxicity and gastro-intestinal toxicity. The contribution of FUra was judged to be negligible. MTX + FUra did not increase host toxicity in a synergistic or even an additional fashion. The absence of addition or synergism of toxic side-effects can be explained both by site-specific interactions at the pharmacodynamic level and by interactions at the pharmacokinetic level.sentence: Toxicity patterns following stepwise combinations of cyclophosphamide , methotrexate and fluorouracil .","answer":"[[\\"cyclophosphamide\\", \\"methotrexate\\", \\"fluorouracil\\", \\"POS\\"]]"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:The regularization method introduced in [16] and our present regularized method were conceived with quite different purposes.","answer":"Method"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:NoneContext before the citation:and Yang et al. (2003), as described below. positional features that have been employed by highwe can see, the baseline achieves an F-measure of performing resolvers such as Ng and Cardie (2002) 57.0 and a resolution accuracy of 48.4. Each instance is represented by 33 lexical, grammatical, semantic, andCitation Sentence:and Yang et al. ( 2003 ) , as described below .Context after the citation:To get a better sense of how strong our baseline Lexical features. Nine features allow different is, we re-implement the Soon et al. (2001) corefertypes of string matching operations to be performed ence resolver. This simply amounts to replacing the on the given pair of NPs, NP,, and NPy10, including 33 features in the baseline resolver with the 12 fea(1) exact string match for pronouns, proper nouns, tures employed by Soon et al.âs system. Results of and non-pronominal NPs (both before and after deour Duplicated Soon et al. system are shown in row terminers are removed); (2) substring match for 2 of Tables 6 and 7.","answer":"CompareOrContrast"},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(BACKGROUND) Hypertension is one of the important contributing factors linked with both causation and development of kidney disease. It is a multifactorial, polygenic, and complex disorder due to interaction of several risk genes with environmental factors. The present study was aimed to explore genetic polymorphism in ACE-1 gene as a risk factor for CKD among hypertensive patients.(METHODS) Three hundred patients were enrolled in the study. Ninety were hypertensive patients with CKD taken as cases, whereas 210 hypertensive patients without CKD were taken as controls. Demographic data including age, sex, Body mass index (BMI), and other risk factors were also recorded. DNA was extracted from blood by salting out method. Genotyping of ACE gene was done by PCR technique. All the statistical analysis was done by using Epi Info and SPSS version 16 software (SPSS Inc., Chicago, IL).(RESULTS) Mean age was higher in the control group (p < 0.05). Variables among two groups were compared out of which age, BMI, hemoglobin (Hb) was found to be statistically significant whereas other variables like systolic blood pressure, triglyceride and low-density lipoprotein were not. Blood urea and serum creatinine levels were statistically significant in the two genotypes (p < 0.05). Total and HDL cholesterol were statistically significant for DD genotype of ACE gene (OR = 1.42, 95% CI = 0.72-2.81). Similarly, the risk for CKD among hypertensive patients was also associated with D allele of ACE gene (OR = 1.25, 95% CI = 0.86-1.79).Question:Does angiotensin-converting enzyme-1 (ACE-1) gene polymorphism lead to chronic kidney disease among hypertensive patients?Answer:","answer":"YES"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Fludarabine and cladribine induce changes in surface proteins on human B-lymphoid cell lines involved with apoptosis, cell survival, and antitumor immunity. fludarabine and cladribine are purine analogues used to treat hematological malignancies. Alone or in combination with therapeutic antibodies, they are effective in treating patients with chronic lymphocytic leukemia and non-Hodgkin's lymphoma. However, the mechanisms of action of these drugs are not well understood. Plasma membrane proteins perform a variety of essential functions that can be affected by malignancy and perturbed by chemotherapy. Analysis of surface proteins may contribute to an understanding of the mechanisms of action of purine analogues and identify biomarkers for targeted therapy. The surface of human cells is rich in N-linked glycoproteins, enabling use of a hydrazide-coupling technique to enrich for glycoproteins, with iTRAQ labeling for quantitative comparison. A number of plasma membrane proteins on human leukemia and lymphoma cells were affected by treatment with a purine analogue, including decreases in CD22 (an adhesion and signaling molecule) and increases in CD205 (a \\"damaged cell marker\\") and CD80 and CD50 (T-cell interaction molecules). Purine analogues may affect B-cell receptor (BCR) signaling and costimulatory molecules, leading to multiple signals for apoptosis and cell clearance. fludarabine and cladribine induce differential effects, with some cell survival proteins (ECE-1 and CD100) more abundant after fludarabine treatment. Cell surface proteins induced by fludarabine and cladribine may be targets for therapeutic antibodies .sentence: Cell surface proteins induced by fludarabine and cladribine may be targets for therapeutic antibodies .","answer":"[]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Tissue-type plasminogen activator acts as a cytokine that triggers intracellular signal transduction and induces matrix metalloproteinase-9 gene expression.Tissue-type plasminogen activator (tPA), a serine protease well known for generating plasmin, has been demonstrated to induce matrix metalloproteinase-9 (MMP-9) gene expression and protein secretion in renal interstitial fibroblasts. However, exactly how tPA transduces its signal into the nucleus to control gene expression is unknown. This study investigated the mechanism by which tPA induces MMP-9 gene expression. Both wild-type and non-enzymatic mutant tPA were found to induce MMP-9 expression in rat kidney interstitial fibroblasts (NRK-49F), indicating that the actions of tPA are independent of its proteolytic activity. tPA bound to the low density lipoprotein receptor-related protein-1 (LRP-1) in NRK-49F cells, and this binding was competitively abrogated by the LRP-1 antagonist, the receptor-associated protein. In mouse embryonic fibroblasts (PEA-13) lacking LRP-1, tPA failed to induce MMP-9 expression. Furthermore, tPA induced rapid tyrosine phosphorylation on the beta subunit of LRP-1, which was followed by the activation of Mek1 and its downstream Erk-1 and -2. Blockade of Erk-1/2 activation by the Mek1 inhibitor abolished MMP-9 induction by tPA in NRK-49F cells. Conversely, overexpression of constitutively activated Mek1 induced Erk-1/2 phosphorylation and MMP-9 expression. In mouse obstructed kidney, tPA, LRP-1, and MMP-9 were concomitantly induced in the renal interstitium. Collectively, these results suggest that besides its classical proteolytic activity, tPA acts as a cytokine that binds to the cell membrane receptor LRP-1, induces its tyrosine phosphorylation, and triggers intracellular signal transduction, thereby inducing specific gene expression in renal interstitial fibroblasts.","answer":"{\\"Chemical\\": [\\"tyrosine\\", \\"serine\\"], \\"Protein\\": [\\"Mek1\\", \\"tPA\\", \\"plasmin\\", \\"Erk-1 and -2\\", \\"constitutively activated Mek1\\", \\"serine protease\\", \\"MMP-9\\", \\"Tissue-type plasminogen activator\\", \\"cytokine\\", \\"low density lipoprotein receptor-related protein-1\\", \\"matrix metalloproteinase-9\\", \\"LRP-1\\", \\"Erk-1/2\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Uneven X inactivation in a female monozygotic twin pair with Fabry disease and discordant expression of a novel mutation in the alpha-galactosidase A gene. We describe two female monozygotic (MZ) twins heterozygous for Fabry disease, an X linked disorder resulting from the deficient activity of alpha-galactosidase A. While one of the twins was clinically affected, the other was asymptomatic. Enzymatic assay of alpha-galactosidase in blood leucocytes, skin fibroblasts, Epstein-Barr virus transformed lymphoid cell lines, and hair follicles of the twins and their parents confirmed the heterozygous status of the twins and indicated that Fabry disease had occurred as a result of a de novo mutation. The son of the unaffected twin sister was shown to be hemizygous. Molecular analysis of the alpha-galactosidase A gene permitted the identification of an as yet undescribed point mutation at position 10182 of exon 5 which causes an Asp to Asn substitution at codon 231. Single strand conformation polymorphism (SSCP) analysis again showed the heterozygous status of the twins and a normal pattern in their parents. The basis for the discordant expression of this d novo mutation in the twins was investigated by studying their X inactivation status. Analysis of the inactive X specific methylation at the androgen receptor gene showed unbalanced inactivation in the twins ' fibroblasts and in opposite directions. While the maternally derived X chromosome was preferentially active in the asymptomatic twin, the paternal X chromosome was active in the other, affected twin and was found in her hemizygotic nephew. These data suggest that the paternal X chromosome carries the de novo alpha-galactosidase A mutation and that uneven X inactivation is the underlying mechanism for disease expression in this novel female MZ twin pair. This is the first documented case of female twins discordant for Fabry disease.","answer":"{\\"CellLine\\": [\\"Epstein - Barr virus transformed lymphoid cell lines\\"], \\"CellType\\": [\\"blood leucocytes\\", \\"skin fibroblasts\\"], \\"DNA\\": [\\"maternally derived X chromosome\\", \\"alpha - galactosidase A gene\\", \\"position 10182\\", \\"position 10182 of exon 5\\", \\"codon 231\\", \\"exon 5\\", \\"androgen receptor gene\\", \\"paternal X chromosome\\", \\"X chromosome\\", \\"X\\", \\"inactive X\\"], \\"Protein\\": [\\"alpha - galactosidase A\\", \\"alpha - galactosidase\\"], \\"RNA\\": []}"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Serotonin syndrome due to co-administration of linezolid and methadone. Serotonin syndrome (SS), a potentially life-threatening adverse drug reaction caused by excessive serotonergic agonism in central and peripheral nervous system serotonergic receptors, may be caused by a single drug or a combination of drugs with serotonergic activity. The syndrome results in a variety of mental, autonomic and neuromuscular changes, which can range in severity from mild to life-threatening. To our knowledge , we present the first reported case of SS associated with linezolid and methadone with a brief review of the literature .sentence: To our knowledge , we present the first reported case of SS associated with linezolid and methadone with a brief review of the literature .","answer":"[[\\"linezolid\\", \\"methadone\\", \\"NEG\\"]]"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Generalization error (also known as the out-of-sample error) measures how well the hypothesis learned from training data generalizes to previously unseen data.Proving tight generalization error bounds is a central question in statistical learning  theory.   In  this  paper,  we  obtain  generalization  error  bounds  for  learning general  non-convex  objectives,  which  has  attracted  significant  attention  in  recent years.   We develop a new framework,  termed Bayes-Stability,  for proving algorithm-dependent generalization error bounds.  The new framework combines ideas from both the PAC-Bayesian theory and the notion of algorithmic stability.  Applying the Bayes-Stability method, we obtain new data-dependent generalization bounds for stochastic gradient Langevin dynamics (SGLD) and several other noisy gradient methods (e.g., with momentum, mini-batch and acceleration, Entropy-SGD).Our result recovers (and is typically tighter than) a recent result in Mou et al. (2018) and improves upon the results in Pensia et al. (2018).  Our experiments demonstrate that our data-dependent bounds can distinguish randomly labelled data from normal data, which provides an explanation to the intriguing phenomena observed in Zhang et al. (2017a).We also study the setting where the total loss is the sum of a bounded loss and an additiona l\`2 regularization term.We obtain new generalization bounds for the continuous Langevin dynamic in this setting by developing a new Log-Sobolev inequality for the parameter distribution at any time.Our new bounds are more desirable when the noise level of the processis not very small, and do not become vacuous even when T tends to infinity.Non-convex stochastic optimization is the major workhorse of modern machine learning.For instance, the standard supervised learning on a model class parametrized by R d can be formulated as the following optimization problem:where w denotes the model parameter, D is an unknown data distribution over the instance space Z, and F : R d × Z → R is a given objective function which may be non-convex.A learning algorithm takes as input a sequence S = (z 1 , z 2 , . . . , z n ) of n data points sampled i.i.d. from D, and outputs a (possibly randomized) parameter configurationŵ ∈ R d .A fundamental problem in learning theory is to understand the generalization performance of learning algorithms-is the algorithm guaranteed to output a model that generalizes well to the data distribution D?Specifically, we aim to prove upper bounds on the generalization error err gen (S) = L(ŵ, D) − L(ŵ, S), where L(ŵ, D) = Ez∼D[L(ŵ, z)] and L(ŵ, S) = 1 n n i=1 L(ŵ, z i ) are the population and empirical losses, respectively.We note that the loss function L (e.g., the 0/1 loss) could be different from the objective function F (e.g., the cross-entropy loss) used in the training process (which serves as a surrogate for the loss L).Classical learning theory relates the generalization error to various complexity measures (e.g., the VC-dimension and Rademacher complexity) of the model class.Directly applying these classical complexity measures, however, often fails to explain the recent success of over-parametrized neural networks, where the model complexity significantly exceeds the amount of available training data (see e.g., Zhang et al. (2017a) ).By incorporating certain data-dependent quantities such as margin and compressibility into the classical framework, some recent work (e.g., Bartlett et al. (2017) ; Arora et al. (2018) ; Wei & Ma (2019) ) obtains more meaningful generalization bounds in the deep learning context.An alternative approach to generalization is to prove algorithm-dependent bounds.One celebrated example along this line is the algorithmic stability framework initiated by Bousquet & Elisseeff (2002) .Roughly speaking, the generalization error can be bounded by the stability of the algorithm (see Section 2 for the details).Using this framework, Hardt et al. (2016) study the stability (hence the generalization) of stochastic gradient descent (SGD) for both convex and non-convex functions.Their work motivates recent study of the generalization performance of several other gradient-based optimization methods: Kuzborskij & Lampert (2018) ; London (2016); Chaudhari et al. (2017) ; Raginsky et al. (2017) ; Mou et al. (2018) ; Pensia et al. (2018) ; Chen et al. (2018) .In this paper, we study the algorithmic stability and generalization performance of various iterative gradient-based method, with certain continuous noise injected in each iteration, in a non-convex setting.As a concrete example, we consider the stochastic gradient Langevin dynamics (SGLD) (see Raginsky et al. (2017) ; Mou et al. (2018) ; Pensia et al. (2018) ).Viewed as a variant of SGD, SGLD adds an isotropic Gaussian noise at every update step:where g t (W t−1 ) denotes either the full gradient or the gradient over a mini-batch sampled from training dataset.We also study a continuous version of (1), which is the dynamic defined by the following stochastic differential equation (SDE):where B t is the standard Brownian motion.","answer":"We give some generalization error bounds of noisy gradient methods such as SGLD, Langevin dynamics, noisy momentum and so forth."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"SSX\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Loss of corneodesmosin leads to severe skin barrier defect, pruritus, and atopy: unraveling the peeling skin disease. Generalized peeling skin disease is an autosomal-recessive ichthyosiform erythroderma characterized by lifelong patchy peeling of the skin. After genome-wide linkage analysis, we have identified a homozygous nonsense mutation in CDSN in a large consanguineous family with generalized peeling skin, pruritus, and food allergies, which leads to a complete loss of corneodesmosin. In contrast to hypotrichosis simplex, which can be associated with specific dominant CDSN mutations, peeling skin disease is characterized by a complete loss of CDSN expression. The skin phenotype is consistent with a recent murine Cdsn knockout model. Using three-dimensional human skin models, we demonstrate that lack of corneodesmosin causes an epidermal barrier defect supposed to account for the predisposition to atopic diseases, and we confirm the role of corneodesmosin as a decisive epidermal adhesion molecule. Therefore, peeling skin disease will represent a new model disorder for atopic diseases, similarly to Netherton syndrome and ichthyosis vulgaris in the recent past.","answer":"{\\"Gene\\": [\\"Cdsn\\", \\"corneodesmosin\\", \\"CDSN\\"]}"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Deep generative models such as Variational AutoEncoder (VAE) and Generative Adversarial Network (GAN) play an increasingly important role in machine learning and computer vision.However, there are two fundamental issues hindering their real-world applications: the difficulty of conducting variational inference in VAE and the functional absence of encoding real-world samples in GAN.In this paper, we propose a novel algorithm named Latently Invertible Autoencoder (LIA) to address the above two issues in one framework.An invertible network and its inverse mapping are symmetrically embedded in the latent space of VAE.Thus the partial encoder first transforms the input into feature vectors and then the distribution of these feature vectors is reshaped to fit a prior by the invertible network.The decoder proceeds in the reverse order of the encoder's composite mappings.A two-stage stochasticity-free training scheme is designed to train LIA via adversarial learning, in the sense that the decoder of LIA is first trained as a standard GAN with the invertible network and then the partial encoder is learned from an autoencoder by detaching the invertible network from LIA.  Experiments conducted on the FFHQ face dataset and three LSUN datasets validate the effectiveness of LIA for inference and generation.Deep generative models play a more and more important role in cracking challenges in computer vision as well as in other disciplines, such as high-quality image generation Karras et al., 2018a; Brock et al., 2018 ), text-to-speech transformation (van den Oord et al., 2016a; , information retrieval (Wang et al., 2017) , 3D rendering (Wu et al., 2016; Eslami et al., 2018) , and signal-to-image acquisition (Zhu et al., 2018) .Overall, the generative models fall into four categories: autoencoder and its most important variant of Variational AutoEncoder (VAE) (Kingma & Welling, 2013) , auto-regressive models (van den Oord et al., 2016b; a) , Generative Adversarial Network (GAN) (Goodfellow et al., 2014) , and normalizing flows (NF) (Tabak & Vanden-Eijnden, 2010; Tabak & Turner, 2013; Rezende & Mohamed, 2015) .Here we compare these models through the perspective of data dimensionality reduction and reconstruction.To be formal, let x be a data point in the d x -dimensional observable space R dx and y be its corresponding low-dimensional representation in the feature space R dy .The general formulation of dimensionality reduction iswhere f (·) is the mapping function and d y d x .The manifold learning aims at requiring f under various constraints on y (Tenenbaum1 et al., 2000; Roweis & Saul, 2000) .However, the sparsity of data points in high-dimensional space often leads to model overfitting, thus necessitating research on opposite mapping from y to x, i.e.where g(·) is the opposite mapping function with respect to f (·), to reconstruct the data.In general, the role of g(·) is a regularizer to f (·) or a generator to produce more data.The autoencoder is of mapping x f → y g →x.A common assumption in autoencoder is that the variables in lowdimensional space are usually sampled from a prior distribution P(z; θ) such as uniform or Gaussian.To differentiate from y, we let z represent the low-dimensional vector following the prior distribution.Thus we can write g : R dz → R dx , z → x = g(z), z ∼ P(z; θ).It is crucial to establish such dual maps z = f (x) and x = g(z).In the parlance of probability, the process of x → z = f (x) is called inference, and the other procedure of z → x = g(z) is called sampling or generation.VAE is capable of carrying out inference and generation in one framework by two collaborative functional modules.However, it is known that in many cases VAEs are only able to generate blurry images due to the imprecise variational inference.To see this, we write the approximation of the marginal log-likelihoodwhere KL[q(z|x)||p(z)] is the Kullback-Leibler divergence with respect to posterior probability q(z|x) and prior p(z).This lower-bound log-likelihood usually produces imprecise inference.Furthermore, the posterior collapse frequently occurs when using more sophisticated decoder models (Bowman et al., 2015; Kingma et al., 2016 ).These two issues greatly limit the generation capability of the VAE.On the other hand, GAN is able to achieve photo-realistic generation results (Karras et al., 2018a; .However, its critical limitation is the absence of the encoder f (x) for carrying inference on real images.Effort has been made on learning an encoder for GAN under the framework of VAE, however the previous two issues of learning VAE still exist.Normalizing flows can perform the exact inference and generation with one architecture by virtue of invertible networks (Kingma & Dhariwal, 2018) .But it requires the dimension d x of the data space to be identical to the dimension d z of the latent space, thus posing computational issues due to high complexity of learning deep flows and computing the Jacobian matrices.Inspired by recent success of GANs (Karras et al., 2018a; and normalizing flows (Kingma et al., 2016; Kingma & Dhariwal, 2018) , we develop a new model called Latently Invertible Autoencoder (LIA).LIA utilizes an invertible network to bridge the encoder and the decoder of VAE in a symmetric manner.We summarize its key advantages as follows:• The symmetric design of the invertible network brings two benefits.The prior distribution can be exactly fitted from an unfolded feature space, thus significantly easing the inference problem.Besides, since the latent space is detached, the autoencoder can be trained without variational optimization thus there is no approximation here.• The two-stage adversarial learning decomposes the LIA framework into a Wasserstein GAN (only a prior needed) and a standard autoencoder without stochastic variables.Therefore the training is deterministic 2 , implying that the model will be not affected by the posterior collapse when the decoder is more complex or followed by additional losses such as the adversarial loss and the perceptual loss.• We compare LIA with state-of-the-art generative models on inference and generation/reconstruction.The experimental results on FFHQ and LSUN datasets show the LIA achieves superior performance on inference and generation.A new generative model, named Latently Invertible Autoencoder (LIA), has been proposed for generating image sample from a probability prior and simultaneously inferring accurate latent code for a given sample.The core idea of LIA is to symmetrically embed an invertible network in an autoencoder.Then the neural architecture is trained with adversarial learning as two decomposed modules.With the design of two-stage training, the decoder can be replaced with any GAN generator for high-resolution image generation.The role of the invertible network is to remove any probability optimization and bridge the prior with unfolded feature vectors.The effectiveness of LIA is validated with experiments of reconstruction (inference and generation) on FFHQ and LSUN datasets.It is still challenging to faithfully recover all the image content especially when the objects or scenes have unusual parts.For example, LIA fails to recover the hand appeared at the top of the little girl (the second row in Figure 3) .Besides, the Bombay cat's necklace (the second row in Figure 5 ) is missed in the reconstructed image.These features belong to multiple unique parts of the objects or scenes, which are difficult for the generative model to capture.One possible solution is to raise the dimension of latent variables (e.g. using multiple latent vectors) or employ the attention mechanism to highlight such unusual structures in the decoder, which is left for future work.","answer":"A new model Latently Invertible Autoencoder is proposed to solve the problem of variational inference in VAE using the invertible network and two-stage adversarial training."},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:The 2020 SARS-CoV-2 pandemic is caused by a zoonotic coronavirus transmitted to humans, similar to earlier events. Whether the other, seasonally circulating coronaviruses induce cross-reactive, potentially even cross-neutralizing, antibodies to the new species in humans is unclear. The question is particularly relevant for people with immune deficiencies, as their health depends on treatment with immunoglobulin preparations that need to contain neutralizing antibodies against the pathogens in their environment. Testing 54 intravenous immunoglobulin preparations, produced from plasma collected in Europe and the United States, confirmed highly potent neutralization of a seasonal coronavirus; however, no cross-neutralization of the new SARS-CoV-2 was seen.","answer":"[\\"Treatment\\"]"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:This translocation event is independent of the HBV nucleocapsid and can be subsequently detected on secreted virions and SVP (5, 24).","answer":"Background"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:BACKGROUND: Children are at risk for multisystem inflammatory syndrome in children (MIS-C) after infection with severe acute respiratory syndrome coronavirus 2. Cardiovascular complications, including ventricular dysfunction and coronary dilation, are frequent, but there are limited data on arrhythmic complications. METHODS: Retrospective cohort study of children and young adults aged </=21 years admitted with MIS-C. Demographic characteristics, electrocardiogram (ECG) and echocardiogram findings, and hospital course were described. RESULTS: Among 25 patients admitted with MIS-C (60% male; median age 9.7 [interquartile range 2.7-15.0] years), ECG anomalies were found in 14 (56%). First-degree atrioventricular block (AVB) was seen in 5 (20%) patients a median of 6 (interquartile range 5-8) days after onset of fever and progressed to second- or third-degree AVB in 4 patients. No patient required intervention for AVB. All patients with AVB were admitted to the ICU (before onset of AVB) and had ventricular dysfunction on echocardiograms. All patients with second- or third-degree AVB had elevated brain natriuretic peptide levels, whereas the patient with first-degree AVB had a normal brain natriuretic peptide level. No patient with AVB had an elevated troponin level. QTc prolongation was seen in 7 patients (28%), and nonspecific ST segment changes were seen in 14 patients (56%). Ectopic atrial tachycardia was observed in 1 patient, and none developed ventricular arrhythmias. CONCLUSIONS: Children with MIS-C are at risk for atrioventricular conduction disease, especially those who require ICU admission and have ventricular dysfunction. ECGs should be monitored for evidence of PR prolongation. Continuous telemetry may be required in patients with evidence of first-degree AVB because of risk of progression to high-grade AVB.","answer":"[\\"Treatment\\", \\"Diagnosis\\"]"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:vaginal reconstruction due to agenesis , trauma , or after surgical exenteration , has undergone significant evolution since the introduction of split thickness skin graft to cover the vagina canal by abbe in 19th century 1 .the ideal reconstructive procedure should be reliable and provide normal function with no subsequent needs for dilatation .variety of procedures and techniques have been performed to achieve the mentioned goals including using different parts of gastrointestinal tract as either a graft , pedicle flap or free flap 2 , 3 .we describe our case , a 55yearold lady , who was referred to us with a narrow vagina caused by a progressive fibrosis of unknown origin over 2 years which affected her relationship . given the physical and psychological effects on the patient and after ruling out malignancy , decision has been made in multidisciplinary meeting ( mdt ) to reconstruct the vagina .hence , we decided to create the neovagina with a free jejunum flap in view to enlarge the canal , improve the lubrication along with preservation of sensation to clitoris .a 55yearold lady referred to our unit from gynecology department with a progressive vaginal fibrosis over 2 years .imaging was inconclusive and histology revealed epithelial atrophy , chronic inflammatory infiltrates , and intense focal submucosal edema with no evidence of malignancy .vaginal wall thickness reduced from 4.4 to 2.7 mm in further biopsies without showing any change in the cervix or parametrium .cervical biopsy and endocervical curettage indicated reactive benign cellular changes associated with atrophy . storage disease was then ruled out by measuring relevant immunoglobulins and antibodies in the blood . after considering all findings and patients complaint, we decided to perform the reconstruction without visible scars around perineal and thighs ( fig .mri t2wi in the sagittal plane after intravaginal gel administration depicts a lack of vaginal distention , and an abnormal homogenous diffuse high signal intensity in the vaginal walls , secondary to vaginal stenosis and fibrosis .our approach to abdomen was through the midline infraumbilical laparotomy incision from the previous cesarean section .the cesarean was done 20 years before , most probably for fetal distress . that median incision was the approach of choice for a more rapid fetal extraction in those years .we noticed an intense fibrosis of the uterosacral and parametrial ligaments as well as an atrophic uterus .after performing total hysterectomy and double adnexectomy , the fibrotic vagina wall resected via vaginal approach .hysterectomy and bilateral oophorectomy was performed because they precluded the completion of correct cervical cancer screening , due to stenosis of the introitus , to the vaginal fibrosis and to the obliteration and fusion of the vaginal sack with the cervix .segment was approximately 70 cm from the treitz ligament supplied by the third branch of the superior mesenteric artery .after transferring the segment to the pelvis , microsurgical anastomosis performed to the right inferior epigastric vessels and satisfactory flow was confirmed with an intraoperative doppler ( fig .inferior part of the jejunum sutured to the remnant of the vagina without tension with 3.0 braided sutures and then , the posterior wall of the vagina was created with the flap ( fig .flap molded as desired right after anastomosis to the deep inferior epigastric artery and vein and before insetting to reconstruct the new vagina .notice the particular design of the flap which allowed us to reconstruct the posterior wall of the vagina and at the same timernelongate it .finally , surgical wound was closed over a drain and patient was transferred to the recovery with a dilator in situ which was kept for 2 weeks .patient was discharged on day 15 with a satisfactory computed tomography scan ( ctscan ) .she was reviewed in the clinic 2 months postoperatively with an aesthetically acceptable vagina measuring 4 cm in width and 14.5 cm in length ( fig .she started her sexual intercourse 3 months postoperatively and by the fourth month , secretions lessened significantly . ct in the sagittal plane after administration of iodinated contrast medium in the neovagina shows the size , shape , location , and intestinal pattern of the walls , as well as the excellent distention .our approach to abdomen was through the midline infraumbilical laparotomy incision from the previous cesarean section .the cesarean was done 20 years before , most probably for fetal distress . that median incision was the approach of choice for a more rapid fetal extraction in those years .we noticed an intense fibrosis of the uterosacral and parametrial ligaments as well as an atrophic uterus . after performing total hysterectomy and double adnexectomy ,hysterectomy and bilateral oophorectomy was performed because they precluded the completion of correct cervical cancer screening , due to stenosis of the introitus , to the vaginal fibrosis and to the obliteration and fusion of the vaginal sack with the cervix .segment was approximately 70 cm from the treitz ligament supplied by the third branch of the superior mesenteric artery .after transferring the segment to the pelvis , microsurgical anastomosis performed to the right inferior epigastric vessels and satisfactory flow was confirmed with an intraoperative doppler ( fig .inferior part of the jejunum sutured to the remnant of the vagina without tension with 3.0 braided sutures and then , the posterior wall of the vagina was created with the flap ( fig .flap molded as desired right after anastomosis to the deep inferior epigastric artery and vein and before insetting to reconstruct the new vagina .notice the particular design of the flap which allowed us to reconstruct the posterior wall of the vagina and at the same timernelongate it .finally , surgical wound was closed over a drain and patient was transferred to the recovery with a dilator in situ which was kept for 2 weeks .patient was discharged on day 15 with a satisfactory computed tomography scan ( ctscan ) .she was reviewed in the clinic 2 months postoperatively with an aesthetically acceptable vagina measuring 4 cm in width and 14.5 cm in length ( fig .she started her sexual intercourse 3 months postoperatively and by the fourth month , secretions lessened significantly . ct in the sagittal plane after administration of iodinated contrast medium in the neovagina shows the size , shape , location , and intestinal pattern of the walls , as well as the excellent distention .vaginal reconstruction is a complex and controversial process as it affects individuals both physically and psychologically .most frequent indication is congenital agenesis followed by neoplasm , stenosis due to radiotherapy or transsexuality problems 4 , 5 .although a wide spectrum of surgical and nonsurgical techniques being performed , from a simple graft to regional and free flaps 6 , many patients present with postoperative complications such as hypertrophic or unsightly scars , absent or excess of lubrication , receding grafts , and stenosis 7 , 8 . nonsurgical techniques like  frank  are based on progressive introitus dilatation without satisfactory results 6 .mclndoe procedure may offer good result few months postoperatively , but dyspareunia and scarring can be the limiting factors , on the other hand , different types of regional flaps mainly based on perforators of internal pudendal artery can restore shape , volume , and function of the vagina , but lacks lubrication 5 , 9 .amniotic graft can mimic characteristics of the vagina , however , fistula formation , stenosis , inadequate length , and poor lubrication can complicate the postoperative period 10 , 11 .baldwin introduced intestinal interposition , subsequently pedicled and free gastrointestinal segments such as jejunum , cecum , and colon have been employed for the reconstruction .the advantages of using intestinal segments are lowering the risk of stenosis , no molds required to ensure permeability , resistant to repetitive trauma , present natural lubrication , and prevent dyspareunia 12 . on the contrary , the presence of two surgical teams and lengthy procedure are the two limiting factors , and potential donor site morbidities can also be debilitating 13 .the other postoperative concern is hypersecretion which progressively diminishes , thus patients can usually resume their sexual relationship after 3 months 14 .numerous techniques have been described in vaginal reconstruction . vaginal fibrosis is an uncommon condition and treatmentgastrointestinal ( gi ) tract flaps can be ideal as they enlarge and lengthen the vagina , provided natural lubrication , and maintain sensitivity .","answer":"key clinical messagevaginal reconstruction represents a very difficult challenge .  free jejunal flaps can be easily molded and adapted to solve complex cases restoring the width , length , and consistency of the  new  vagina without compromising the external genitalia and improving the lubrication while preserving sensation to clitoris ."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:previous brain surgery;cognitive impairment (< 120 points on the Mattis Dementia Rating Scale)moderate-to-severe depression (> 25 points on the Beck Depression Inventory)marked brain atrophy as detected by magnetic resonance imagingother medical or psychiatric coexisting disorders that could increase the surgical risk or interfere with completion of the trial","answer":"{\\"Condition\\": [\\"depression\\", \\"cognitive impairment\\", \\"brain atrophy\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [\\"Mattis Dementia Rating Scale\\", \\"Beck Depression Inventory\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [], \\"Procedure\\": [\\"magnetic resonance imaging\\", \\"brain surgery\\"], \\"Qualifier\\": [\\"moderate-to-severe\\"], \\"ReferencePoint\\": [], \\"Scope\\": [], \\"Temporal\\": [\\"previous\\"], \\"Value\\": [\\"u003e 25 points\\", \\"u003c 120 points\\"], \\"Visit\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"SSX\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Human liver serine dehydratase. cDNA cloning and sequence homology with hydroxyamino acid dehydratases from other sources. Rat liver serine dehydratase cDNA was used to screen a human liver cDNA library in lambda gt11. One positive clone occurred in every 5,000 clones. Fifteen positive clones were plaque purified. The largest cDNA obtained contained an open reading frame of 987 base pairs, and 5' and 3' noncoding regions of 89 and 317 base pairs, respectively. The deduced amino acid sequence, with a calculated Mr of 34,615, was similar to that of rat liver serine dehydratase except for the absence of a segment consisting of 36 amino acid residues. In vitro transcription/translation with the cDNA resulted in the formation of a polypeptide with an Mr of approximately 35,000, which cross-reacted with the anti-rat serine dehydratase antibody. These results suggest that the human serine dehydratase is structurally cognate with the rat enzyme. Moreover, portions of the sequence postulated to be essential for activity in microbial threonine dehydratases are found in the mammalian serine dehydratases, suggesting that hydroxyamino and dehydratases may have originated from a common ancestor.","answer":"{\\"Gene\\": [\\"serine dehydratase\\", \\"serine dehydratases\\", \\"hydroxyamino acid dehydratases\\"]}"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Past history of hypersensitivity to aripiprazolePrimary diagnosis of MDD with psychotic feature, bipolar disorder, schizophrenia, schizoaffective disorder, other psychotic disorder or anxiety disorder, a history of alcohol/ drug abuse within the past 12 months, or a diagnosis of dementiaClinically significant current Axis II (DSM-IV-TR) diagnosisA significant risk of suicide corroborated by a score of =5 on item 10(suicidal thoughts) on the MADRS scale or by clinical judgment of the investigatorPregnancy or in breast-feedingPresence of a serious medical illness including cardiac, hepatic, renal, respiratory, endocrinologic, neurologic, or hematologic disease or physical disorder judged to significantly affect central nervous system functionPatients taking antipsychotics, mood stabilizer or any psychotropic medications besides antidepressants, except benzodiazepines or beta blockers or hypnoticsPatients with past treatment failures of aripiprazole","answer":"{\\"Condition\\": [\\"schizoaffective disorder\\", \\"bipolar disorder\\", \\"diagnosis\\", \\"neurologic\\", \\"MDD\\", \\"psychotic disorder\\", \\"hepatic\\", \\"hypersensitivity\\", \\"renal\\", \\"lcohol/ buse\\", \\"anxiety disorder,\\", \\"drug abuse\\", \\"cardiac\\", \\"hematologic disease\\", \\"medical illness\\", \\"dementia\\", \\"psychotic feature\\", \\"schizophrenia\\", \\"physical disorder\\", \\"endocrinologic\\", \\"respiratory\\"], \\"Device\\": [], \\"Drug\\": [\\"benzodiazepines\\", \\"hypnotics\\", \\"antipsychotics\\", \\"aripiprazole\\", \\"beta blockers\\", \\"mood stabilizer\\", \\"psychotropic medications\\", \\"antidepressants\\"], \\"Measurement\\": [\\"MADRS scale\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [\\"besides\\", \\"except\\"], \\"Observation\\": [\\"risk of suicide\\", \\"treatment failures\\"], \\"Person\\": [], \\"Procedure\\": [], \\"Qualifier\\": [\\"Axis II\\", \\"significant\\", \\"serious\\", \\"other\\", \\"DSM-IV-TR\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"psychotropic medications besides antidepressants\\", \\"benzodiazepines or beta blockers or hypnotics\\", \\"psychotic feature, bipolar disorder, schizophrenia, schizoaffective disorder, other psychotic disorder or anxiety disorder\\", \\"alcohol/ drug abuse\\"], \\"Temporal\\": [\\"within the past 12 months\\"], \\"Value\\": [\\"score of =5 on item 10\\"], \\"Visit\\": []}"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: What is the physiological role of LKB1 involved in Peutz-Jeghers syndrome?Context: Recent functional genetic studies have pointed out that LKB1 plays a physiological role in controlling the Wnt-signaling pathway and activation of the pathway as a consequence of LKB1 haploinsufficiency might be responsible for the development of harmatomatous polyps.PJS polyps from all patients showed generalized membrane and cytoplasmic localizations of beta-catenin along the mucosal endothelium.","answer":"LKB1 plays a physiological role in controlling the Wnt-signaling."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: The virus survives better in coldAbstract:The undefendable outbreak of novel coronavirus (SARS-COV-2) lead to a global health emergency due to its higher transmission rate and longer symptomatic duration, created a health surge in a short time.Since Nov 2019 the outbreak in China, the virus is spreading exponentially everywhere.The current study focuses on the relationship between environmental parameters and the growth rate of COVID-19.The statistical analysis suggests that the temperature changes retarded the growth rate and found that -6.28{degrees}C and +14.51{degrees}C temperature is the favorable range for COVID-19 growth.Gutenberg- Richter's relationship is used to estimate the mean daily rate of exceedance of confirmed cases concerning the change in temperature.Temperature is the most influential parameter that reduces the growth at the rate of 13-16 cases/day with a 1{degrees}C rise in temperature.","answer":"{\\"verdict\\": \\"SUPPORT\\", \\"evidence\\": [\\"The statistical analysis suggests that the temperature changes retarded the growth rate and found that -6.28{degrees}C and +14.51{degrees}C temperature is the favorable range for COVID-19 growth.\\", \\"Temperature is the most influential parameter that reduces the growth at the rate of 13-16 cases/day with a 1{degrees}C rise in temperature.\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Mucosal effects of tenofovir 1% gel}Article:Abstract:Tenofovir gel is being evaluated for vaginal and rectal pre-exposure prophylaxis against HIV transmission. Because this is a new prevention strategy, we broadly assessed its effects on the mucosa. In MTN-007, a phase-1, randomized, double-blinded rectal microbicide trial, we used systems genomics/proteomics to determine the effect of tenofovir 1% gel, nonoxynol-9 2% gel, placebo gel or no treatment on rectal biopsies( 15 subjects/arm). We also treated primary vaginal epithelial cells from four healthy women with tenofovir in vitro. After seven days of administration, tenofovir 1% gel had broad-ranging effects on the rectal mucosa, which were more pronounced than, but different from, those of the detergent nonoxynol-9. Tenofovir suppressed anti-inflammatory mediators, increased T cell densities, caused mitochondrial dysfunction, altered regulatory pathways of cell differentiation and survival, and stimulated epithelial cell proliferation. The breadth of mucosal changes induced by tenofovir indicates that its safety over longer-term topical use should be carefully monitored. Clinical trial registration: NCT01232803.Introduction:The HIV prevention field has invested considerable resources in testing the phosphonated nucleoside reverse transcriptase inhibitor( NRTI) tenofovir as a mucosally applied topical microbicide to prevent sexual HIV transmission. In a phase 2B trial, CAPRISA 004, pericoital tenofovir 1% gel was 39% efficacious in preventing vaginal HIV acquisition( Abdool Karim et al., 2010). However, in another phase 2B trial, the VOICE study( MTN-003), the daily vaginal tenofovir 1% gel arm was discontinued for futility( Marrazzo et al., 2015). Adherence to product use was low in VOICE, likely explaining the differences in findings between the two studies. Currently, the CAPRISA 004 study is being repeated in a phase 3 trial( FACTS 001 study). A reduced glycerin formulation of the vaginal tenofovir 1% gel for use as a rectal microbicide appears safe when evaluated by epithelial sloughing, fecal calprotectin, inflammatory cytokine mRNA/protein levels, and cellular immune activation markers( McGowan et al., 2013). However, because topical application of an antiretroviral drug to the mucosa is a novel prevention strategy without clinical precedent, we conducted a comprehensive systems biology assessment of tenofovir gel's effects on the mucosa.Discussion:Our findings indicate that reduced glycerin rectal tenofovir 1% gel affects expression of a different and much broader range of genes than N-9 2% gel, potentially affecting mucosal immune homeostasis, mitochondrial function, and regulation of epithelial cell differentiation and survival. These results make biological sense given that tenofovir is a DNA chain terminator, with possible off-target effects in human cells( Lewis et al., 2003), and that topical application achieves at least 100-fold higher active drug concentrations in the mucosa than oral administration of 300 mg tenofovir disoproxil fumarate( Anton et al., 2012; Hendrix et al., 2013). Moreover, tenofovir caused similar changes in primary vaginal epithelial cells cultured from several healthy women. We did not find evidence that tenofovir directly causes inflammation, which is in keeping with our prior report that rectal tenofovir gel did not cause overt histological inflammation or increased mRNA/protein levels of a select panel of pro-inflammatory cytokines( McGowan et al., 2013). Rather, tenofovir dampened anti-inflammatory factors. Most prominently, it strongly inhibited IL-10 gene and protein expression, likely via blocking of CREB1 and its coactivator CREBBP( Martin et al., 2005; Woodgett and Ohashi, 2005; Gee et al., 2006; Alvarez et al., 2009). In addition, it suppressed signaling pathways downstream of TGF-β, a central anti-inflammatory mediator in the gut( Konkel and Chen, 2011; Surh and Sprent, 2012). Consequently, a number of chemokines were induced, such as the B lymphocyte chemoattractant CXCL13( Ansel et al., 2002), and CCL19 and CCL21, both ligands of CCR7 on T lymphocytes and dendritic cells( Forster et al., 2008). Correspondingly, CCR7, the B cell marker CD19, and the T cell markers CD2, CD3D and CD7 increased. In keeping with this, we observed higher densities of CD3+ and CD7+ T lymphocytes in the rectal mucosa following 7 days of tenofovir 1% gel use. In concert, these changes suggest that tenofovir creates a state of potential hyper-responsiveness to external inflammatory stimuli but does not itself cause inflammation. In populations who, unlike our MTN-007 study cohort, have a high incidence of mucosal infections and associated immune activation, this could potentially diminish the anti-viral protective effect of topical tenofovir prophylaxis( Naranbhai et al., 2012). Mitochondrial toxicity of nucleotide/nucleoside reverse transcriptase inhibitors such as tenofovir is well described but the mechanism remains unclear( Lewis et al., 2003). We found that tenofovir consistently inhibited expression of PNPT1, which encodes polynucleotide phosphorylase( PNPASE). PNPASE regulates nucleus-encoded RNA import into mitochondria( Wang et al., 2010). In PNPT1 knock-out mice, mitochondrial morphology and respiratory capacity are disrupted in a manner quite similar to the disruption in renal proximal tubular cells in patients with tenofovir-induced nephrotoxicity( Perazella, 2010; Wang et al., 2010). In our study, just 1 week of daily tenofovir 1% gel application lowered transcription of mitochondrial ATP6 by sixfold and caused visible ultrastructural mitochondrial changes. These findings suggest that tenofovir's suppression of PNPT1 expression may underlie its reported, but heretofore unexplained, mitochondrial toxicity. A number of changes in rectal biopsies and primary vaginal epithelial cells also suggested that tenofovir can cause increased epithelial proliferation. Furthermore, tenofovir's negative effect on mitochondrial function could lead to impairment of tumor progenitor cell apoptosis( Modica-Napolitano et al., 2007; Ni Chonghaile et al., 2011), as has been specifically reported for loss-of-function mutations of mtATP6, a mitochondrial gene strongly suppressed by tenofovir in our study( Shidara et al., 2005). Neoplastic pressure could also arise from the strong induction of KIAA0101 and UBD( ubiquitin D). KIAA0101 is important for regulation of DNA repair( Simpson et al., 2006), is increased in tumor tissues( Yu et al., 2001), and enhances cancer cell growth( Jain et al., 2011; Hosokawa et al., 2007). UBD appears to increase mitotic non-disjunction and chromosome instability( Ren et al., 2006, 2011) and is highly up-regulated in gastrointestinal cancers( Lee et al., 2003; Ren et al., 2006, 2011). Notably, though, these findings remain circumstantial, as there is no actual clinical evidence for carcinogenicity. Nevertheless, they raise the question of whether the relatively high concentrations of tenofovir achieved in the mucosa during topical use could potentially lead to neoplastic lesions with continuous and long-term use. According to Viread's Product Monograph, gastrointestinal tumorigenicity has been observed in mice after high oral dosing of tenofovir disoproxil fumarate. Vaginal tumorigenicity has been documented for azido-thymidine, an NRTI and DNA chain terminator like tenofovir, which induced vaginal hyperplasia and carcinomas when delivered to mice intravaginally as a 2% solution( ∼25% carcinoma rate)( Ayers et al., 1996). This is the first time that a systems biology approach has been applied to a clinical trial of mucosal pre-exposure prophylaxis, and our study shows the value of using these technologies for comprehensive mucosal safety assessment. Our findings raise concerns regarding the safety of topical tenofovir 1% gel in the rectum with long-term use. Tenofovir's effects on vaginal epithelial cells suggest similar activities in the vagina, which we are currently verifying in MTN-014, a phase I clinical trial comparing vaginal and rectal tenofovir 1% gel in a cross-over format. Further studies are required to gauge whether tenofovir, which has become a valuable cornerstone drug in treating HIV infection, can also be safely and effectively used as a vaginal or rectal microbicide.","answer":"Tenofovir is a drug that can stop some viruses—including HIV—from multiplying . It is commonly used in multidrug therapies to control HIV infection . Clinical trials are underway to find out whether using the drug in the form of a gel applied to the vagina or rectum could be an effective way to prevent HIV transmission during sex . Some of the clinical trials carried out so far have produced promising results . However , since the use of gels containing anti-viral drugs is a new strategy for HIV prevention , there are limited data available about the safety of these products . Previous studies have shown that the concentration of tenofovir in the vagina is much higher in individuals using the gel than in those taking the tablet form of the drug . These high concentrations could lead to unexpected effects on the health of the cells exposed to the gel . Here , Hladik , Burgener , Ballweber et al . used a systems biology approach to look at the broad effects of tenofovir gel on tissue from the rectum . Tissue samples taken from the rectums of 15 patients who used tenofovir gel for seven days were compared with tissue samples taken from individuals who used a control gel that did not contain the drug or who did not use any gel . Genes that regulate inflammation were suppressed in the rectal tissue from patients who used tenofovir , as were genes that help these tissues regenerate and produce energy . The tissue from these patients also contained more immune cells , suggesting that their local immune systems were more active . Additionally , Hladik , Burgener , Ballweber et al . observed changes that could potentially lead to the increased growth of cells . Similar differences were also observed in vaginal cells that had been treated with tenofovir in the laboratory . These findings suggest that tenofovir delivered directly to the vagina or rectum may have unintentional local side effects . However , it is important to acknowledge that tenofovir gel has been evaluated in multiple studies that have not observed overt clinical adverse effects . Therefore , the implication of these findings is currently unclear and warrants further study ."},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: Which organ express and secretes the hormone FGF21?Context: We have previously shown that Fibroblast growth factor 21 (Fgf21) is expressed in the thymus as well as in the liver.Fibroblast growth factor 21 (FGF21) is an important endocrine metabolic regulator expressed in multiple tissues including liver and adipose tissue. Although highest levels of expression are in pancreas, little is known about the function of FGF21 in this tissue.","answer":"Fibroblast growth factor 21 (FGF21) is an important endocrine metabolic regulator expressed in multiple tissues including liver and adipose tissue. Although highest levels of expression are in pancreas, little is known about the function of FGF21 in this tissue."},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:helicobacter pylori ( h. pylori ) infection is known to cause several types of gastrointestinal diseases , such as gastritis , peptic ulcers and gastric cancer , thus eradication therapy is widely recommended to prevent their occurrence . as a result , it is very important to accurately diagnose h. pylori infection in clinical situations , with several different invasive and non - invasive methods available . among the available methods , a serologic test for h. pylori infectionis easily performed using obtained serum samples for both epidemiologic studies involving large numbers of subjects as well as in clinical practice for individual patients .it has been reported that the sensitivity and specificity of serological methods for detection of h. pylori infection range from 80% to 90% .on the other hand , the diagnostic accuracy of serological methods for diagnosis of h. pylori infection has been shown to vary based on the duration of exposure to h. pylori , cross - antigenicity with other prevalent antigenically related bacteria such as campylobacter , the diversity of h. pylori strains in different regions , host immune response , the grade of histological gastritis , and the density of h. pylori .the diagnostic accuracy of serological tests for h. pylori in japanese subjects has been repeatedly demonstrated to increase when using kits derived from antigens of h. pylori strains obtained from japanese patients .pylori igg antibody detection kit , was developed using antigens from h. pylori strains derived from japanese patients .this kit has been shown to have a high efficacy for diagnosis of infection , and the serum titer of this test is nearly equal to that of another anti - h .pylori igg antibody test ( eiken chemical co. , ltd . , tokyo ) ( unpublished data ) .in order to increase the sensitivity of diagnosis for h. pylori infection , an antibody titer of 4.0  u / ml is defined as positive in the spherelight h. pylori antibody j test , while the cut - off value in the eiken anti - h .pylori igg antibody test is set at 10  u / ml . we have found that some patients without past - history of eradication therapy for h. pylori also show a negative result in the spherelight h. pylori antibody j test , even though they have endoscopic evidence of gastric mucosal atrophy , which is mainly caused by long - term h. pylori infection .therefore , we performed the present retrospective study to elucidate factors related to a negative result in the spherelight h. pylori antibody j test in cases with gastric mucosal atrophy by analyzing the presence of post - eradication  endoscopic findings , based on several recent studies .the subjects were individuals who visited the health center of shimane environment and health public corporation for a detailed medical checkup examination between april 2014 and march 2015 .the majority were socially active and productive , and considered to be socioeconomically middle class .those with a history of gastric surgery and eradication therapy for h. pylori infection , carefully confirmed by a public health nurse , were excluded .those who had taken such medications as proton pump inhibitors and h2 receptor antagonists were also excluded . finally , 859 subjects ( 545 males , 314 females ; mean age 52.4 years ) who underwent upper gi endoscopic examinations and serum anti - h .pylori igg antibody detection was performed using spherelight h. pylori antibody j. the antibody titer was automatically measured using a chemiluminescent enzyme immunoassay method . an antibody titer 4.0  u / ml was defined as positive , according to the manufacturer s instruction sheet ., s.t . ) using an eg-530nw or eg-530np endoscope ( fujifilm , tokyo , japan ) . when gastric mucosal atrophy was endoscopically observed , its degree was evaluated using the classification of kimura and takemoto , in which gastric mucosal atrophy is classified into 6 groups ( c1 , c2 , c3 , o1 , o2 , o3 ) . the cases without gastric mucosal atrophy was diagnosed as c0 in this study .the presence of gastric mucosal atrophy was carefully determined by the presence or absence of regular arrangement of collecting venules at angular portion and atrophic border in the cases with thin gastric mucosa . when cases with endoscopic evidence of gastric mucosal atrophy showed a negative result in the anti - h .pylori igg antibody test , we investigated the existence of endoscopic evidence of post - eradication by examining for the presence of characteristic endoscopic findings in the stomach .for this study , we defined suspected post - eradication cases based on the presence of map - like redness or depressed patchy redness , as well as absence of diffuse redness , mucosal swelling , sticky mucous , and enlarged folds in endoscopic images .the degree of endoscopically evident gastric mucosal atrophy and presence of suspected post - eradication findings in each study subject were simultaneously reviewed and determined by the same 3 licensed endoscopists .statistical analyses were performed using chi - squared , kruskal - wallis , and mann - whitney u tests .all calculations were done using the stat view 5.0 software program ( abacus concepts inc . ,berkeley , ca ) for macintosh and differences of p<0.05 were considered to be statistically significant .this study was performed in accordance with the declaration of helsinki , and the protocol was approved by the ethics committee of the shimane environment and health public corporation . written informed consent indicating that clinical data would be used for a clinical study without release of individual information was obtained from all subjects before performing the medical checkup examinations .we found that 468 subjects were positive and 391 were negative for the anti - h .pylori igg antibody in subjects with and without gastric mucosal atrophy were 85.6% and 0.9% , respectively ( table  1 ) .the characteristics of our subjects without as well as with several degrees of gastric mucosal atrophy are shown in table  2 .cases with higher grades of gastric mucosal atrophy were older as compared to those with lower grades or no atrophy . when the positive rate and serum titer of the anti - h .pylori igg antibody were analyzed as variables , the subjects with c2 and o3 of gastric mucosal atrophy had a low positive rate .in addition , the serum titer was low in subjects with c1 , c2 and o3 gastric mucosal atrophy , and the number of cases with serum titer of 40.0 u / ml was relatively small in these subjects .the serum titers of all cases without gastric mucosal atrophy ( c0 ) were less than 10  u / ml ( table  2 ) . when the positive rate and serum titer of the anti - h .pylori igg antibody were analyzed separately in male and female subjects , male subjects with o3 gastric mucosal atrophy and female subjects with c2 gastric mucosal atrophy had a low positive rate .in addition , low serum titer was observed in both males and females with mild gastric mucosal atrophy . when endoscopic post - eradication findings were investigated in 78 cases with gastricpylori igg antibody test , 52 cases had suspected post - eradication findings endoscopically . in 24 among these 52 cases , previous other diagnostic methods in our institute orother medical centers also showed negative results for h. pylori infection by their medical records .interestingly , suspected post - eradication findings were more frequently observed in both females and males with c2 gastric mucosal atrophy ( table  3 ) .in this study , we investigated the factors causing a negative result in the spherelight h. pylori antibody j test in cases with gastric mucosal atrophy .continuous h. pylori infection is a main cause of gastric mucosal atrophy , and nearly all japanese individuals with gastric mucosal atrophy and without a past history of h. pylori eradication therapy are considered to be infected .however , 78 of the present 543 study subjects with evidence of gastric mucosal atrophy were not positive in results of anti - h .male subjects with o3 grade of gastric mucosal atrophy showed a lower positive rate in antibody test , and subjects with with c2 gastric mucosal atrophy showed a low positive rate and titer of the antibody in this study .there are several possibilities to explain why our subjects with gastric mucosal atrophy had negative results in the anti - h .pylori igg antibody test , including the antigens used to produce the anti - h .however , the kit employed for this study was produced using antigens from h. pylori strains derived from japanese patients and its good accuracy has been demonstrated .pylori igg antibody test , although the cut off value for the spherelight h. pylori antibody j test is set at 4.0  u / ml to increase sensitivity for diagnosis of h. pylori infection .the disappearance of h. pylori in the stomach is well known to occur due to intestinal metaplasia after long - term infection , while several investigators have also reported that a lower serum titer of the antibody is correlated with the progression of gastric mucosal atrophy .indeed , a relatively low positive rate in antibody test was observed in subjects with o3 gastric mucosal atrophy in the present study , especially in male . on the other hand, we could not clearly explain the lower positive rate and titer of the antibody in subjects with mild gastric mucosal atrophy .the titer of the antibody has been shown to vary based on the duration of exposure to h. pylori , the grade of histological gastritis and the density of h. pylori .a majority of our study subjects were middle - aged , and the subjects with h. pylori infection are considered to have long exposure duration to h. pylori , since h. pylori infection generally occurs during childhood .therefore , the lower titer of the antibody in subjects with mild gastric mucosal atrophy may be caused by the low grade immune response to h. pylori , low grade of histological gastritis and low density of h. pylori .in addition , unplanned natural eradication is considered to correlate with low positive rate and titer of the antibody in subjects with c2 gastric mucosal atrophy , since suspected post - eradication was more frequently observed in cases with c2 atrophy .when serum antibody test  is negative in middle - aged cases with mild gastric mucosal atrophy in clinical practice , we should carefully examine the presence of h. pylori infection by other diagnostic methods , since low titer of antibody test could cause the negative results .pylori igg antibody test to evaluate the status of h. pylori infection and did not employ other diagnostic methods , as the study was a retrospective examination of individuals who visited a medical center for a detailed medical checkup .in addition , a majority of our subjects were socially active , productive , and socioeconomically middle class , thus young and elderly individuals were relatively few .pylori igg antibody tests are needed to clarify the present observations , including our findings that subjects , especially females , with a mild degree of gastric mucosal atrophy had a low positive rate and serum titer in the anti - h .we found that the middle - aged subjects with a mild degree of gastric mucosal atrophy had a low positive rate and titer in serum , and endoscopic suspected post - eradication findings was more frequently observed in these cases .","answer":"the purpose is to elucidate factors related to negative results of anti - h .  pylori antibody test in cases with gastric mucosal atrophy .  a total of 859 individuals without past history of eradication therapy for h. pylori ( 545 males , 314 females ; mean age 52.4 years ) who underwent an upper gi endoscopy examination and serological test were enrolled as subjects .  serological testing was performed using spherelight h. pylori antibody j , and endoscopic findings of gastric mucosal atrophy by the classification of kimura and takemoto and post - eradication findings were analyzed .  the positive rates for the anti - h .  pylori antibody test in subjects with and without gastric mucosal atrophy were 85.6% and 0.9% , respectively . in analysis of subjects with gastric  mucosal atrophy , a low positive rate and serum titer was observed in subjects with c1 , c2 and o3 atrophy .  when the analysis was performed separately in male and female subjects , low positive rate was observed in males with o3 atrophy and females with c2 atrophy .  suspected post - eradication endoscopic findings were more frequently observed in cases with c2 atrophy . in conclusion ,  negative result of anti - h .  pylori antibody test was frequently observed in middle - aged subjects with c1 , c2 and o3 gastric mucosal atrophy ."},{"question":"You will be shown sections from a scientific research paper, together with a question about the paper. Your task is to answer the question based on the contents of the paper. Your response should be a \`json\` object with two fields:\\"answer\\": An array of strings extracted directly from the paper which, collectively, answer the question.\\"evidence\\": An array of strings. Each should be an excerpt from the paper, in which one or more of the extracted answers can be found.For instance, for the question \\"What baselines did the authors compare against?\\", a sample response might be:{  \\"answer\\": [\\"BERT\\", \\"RoBERTa\\"],  \\"evidence\\": [\\"In our experiments, we compare the performance of our model against BERT and RoBERTa.\\"]}Do not include any text in your response other than the json.If the question is unanswerable given the provided excerpts, respond with the single word \\"null\\".Paper: Short-Text Classification Using Unsupervised Keyword ExpansionShort-text classification, like all data science, struggles to achieve high performance using limited data. As a solution, a short sentence may be expanded with new and relevant feature words to form an artificially enlarged dataset, and add new features to testing data. This paper applies a novel approach to text expansion by generating new words directly for each input sentence, thus requiring no additional datasets or previous training. In this unsupervised approach, new keywords are formed within the hidden states of a pre-trained language model and then used to create extended pseudo documents. The word generation process was assessed by examining how well the predicted words matched to topics of the input sentence. It was found that this method could produce 3-10 relevant new words for each target topic, while generating just 1 word related to each non-target topic. Generated words were then added to short news headlines to create extended pseudo headlines. Experimental results have shown that models trained using the pseudo headlines can improve classification accuracy when limiting the number of training examples.IntroductionThe web has provided researchers with vast amounts of unlabeled text data, and enabled the development of increasingly sophisticated language models which can achieve state of the art performance despite having no task specific training BIBREF0, BIBREF1, BIBREF2. It is desirable to adapt these models for bespoke tasks such as short text classification.Short-text is nuanced, difficult to model statistically, and sparse in features, hindering traditional analysis BIBREF3. These difficulties become further compounded when training is limited, as is the case for many practical applications.This paper provides a method to expand short-text with additional keywords, generated using a pre-trained language model. The method takes advantage of general language understanding to suggest contextually relevant new words, without necessitating additional domain data. The method can form both derivatives of the input vocabulary, and entirely new words arising from contextualised word interactions and is ideally suited for applications where data volume is limited.figureBinary Classification of short headlines into 'WorldPost' or 'Crime' categories, shows improved performance with extended pseudo headlines when the training set is small. Using: Random forest classifier, 1000 test examples, 10-fold cross validation.Procedures ::: DatasetThe News Category Dataset BIBREF11 is a collection of headlines published by HuffPost BIBREF12 between 2012 and 2018, and was obtained online from Kaggle BIBREF13. The full dataset contains 200k news headlines with category labels, publication dates, and short text descriptions. For this analysis, a sample of roughly 33k headlines spanning 23 categories was used. Further analysis can be found in table SECREF12 in the appendix.Procedures ::: Word GenerationWords were generated using the BERT pre-trained model developed and trained by Google AI Language BIBREF0. BERT creates contextualized word embedding by passing a list of word tokens through 12 hidden transformer layers and generating encoded word vectors. To generate extended text, an original short-text document was passed to pre-trained BERT. At each transformer layer a new word embedding was formed and saved. BERT's vector decoder was then used to convert hidden word vectors to candidate words, the top three candidate words at each encoder layer were kept.Each input word produced 48 candidate words, however many were duplicates. Examples of generated words per layer can be found in table SECREF12 and SECREF12 in the appendix. The generated words were sorted based on frequency, duplicate words from the original input were removed, as were stop-words, punctuation, and incomplete words. The generated words were then appended to the original document to create extended pseudo documents, the extended document was limited to 120 words in order to normalize each feature set. Further analysis can be found in table SECREF12 in the appendix.figureThe proposed method uses the BERT pre-trained word embedding model to generate new words which are appended to the orignal text creating extended pseudo documents.Procedures ::: Topic EvaluationTo test the proposed methods ability to generate unsupervised words, it was necessary to devise a method of measuring word relevance. Topic modeling was used based on the assumption that words found in the same topic are more relevant to one another then words from different topics BIBREF14. The complete 200k headline dataset BIBREF11 was modeled using a Naïve Bayes Algorithm BIBREF15 to create a word-category co-occurrence model. The top 200 most relevant words were then found for each category and used to create the topic table SECREF12. It was assumed that each category represented its own unique topic.The number of relevant output words as a function of the headline’s category label were measured, and can be found in figure SECREF4. The results demonstrate that the proposed method could correctly identify new words relevant to the input topic at a signal to noise ratio of 4 to 1.figureThe number of generated words within each topic was counted, topics which matched the original headline label were considered 'on target'. Results indicate that the unsupervised generation method produced far more words relating to the label category then to other topics. Tested on 7600 examples spanning 23 topics.Procedures ::: Binary and Multi-class Classification ExperimentsThree datasets were formed by taking equal length samples from each category label. The new datastes are ‘Worldpost vs Crime’, ‘Politics vs Entertainment’, and ‘Sports vs Comedy’, a fourth multiclass dataset was formed by combining the three above sets.For each example three feature options were created by extending every headline by 0, 15 and 120 words. Before every run, a test set was removed and held aside. The remaining data was sampled based on the desired training size. Each feature option was one-hot encoded using a unique tfidf-vectorizer BIBREF16 and used to train a random-forest classifier BIBREF17 with 300-estimators for binary predictions and 900-estimators for multiclass.Random forest was chosen since it performs well on small datasets and is resistant to overfitting BIBREF18. Each feature option was evaluated against its corresponding test set. 10 runs were completed for each dataset.Results and Analysis ::: Evaluating word relevanceIt is desirable to generate new words which are relevant to the target topics and increase predictive signal, while avoiding words which are irrelevant, add noise, and mislead predictions.The strategy, described in section SECREF4, was created to measure word relevance and quantify the unsupervised model performance. It can be seen from fig SECREF4 and SECREF12 in the appendix that the proposed expansion method is effective at generating words which relate to topics of the input sentence, even from very little data. From the context of just a single word, the method can generate 3 new relevant words, and can generate as many as 10 new relevant words from sentences which contain 5 topic related words SECREF12. While the method is susceptible to noise, producing on average 1 word related to each irrelevant topic, the number of correct predictions statistically exceed the noise.Furthermore, because the proposed method does not have any prior knowledge of its target topics, it remains completely domain agnostic, and can be applied generally for short text of any topic.Results and Analysis ::: Evaluating word relevance ::: Binary ClassificationComparing the performance of extended pseudo documents on three separate binary classification datasets shows significant improvement from baseline in the sparse data region of 100 to 1000 training examples.The ‘Worldpost vs Crime’ dataset showed the most improvement as seen in figure SECREF1. Within the sparse data region the extended pseudo documents could achieve similar performance as original headlines with only half the data, and improve F1 score between 13.9% and 1.7%The ‘Comedy vs Sports’ dataset, seen in figure SECREF11, showed an average improvement of 2% within the sparse region.The ‘Politics vs Entertainment’ dataset, figure SECREF11, was unique. It is the only dataset for which a 15-word extended feature set surpassed the 120-words feature set. It demonstrates that the length of the extended pseudo documents can behave like a hyper parameter for certain datasets, and should be tuned according to the train-size.Results and Analysis ::: Evaluating word relevance ::: Multiclass ClassificationThe Extended pseudo documents improved multiclass performance by 4.6% on average, in the region of 100 to 3000 training examples, as seen in figure SECREF11. The results indicate the effectiveness of the proposed method at suggesting relevant words within a narrow topic domain, even without any previous domain knowledge.In each instance it was found that the extended pseudo documents only improved performance on small training sizes. This demonstrates that while the extended pseudo docs are effective at generating artificial data, they also produce a lot of noise. Once the training size exceeds a certain threshold, it becomes no longer necessary to create additional data, and using extended documents simply adds noise to an otherwise well trained model.figureBinary Classification of 'Politics' or 'Entertainment' demonstrates that the number of added words can behave like a hyper paremeter and should be tuned based on training size. Tested on 1000 examples with 10-fold cross validationfigureBinary Classification of 'Politics' vs 'Sports' has less improvement compared to other datasets which indicates that the proposed method, while constructed to be domain agnostic, shows better performance towards certain topics. Tested on 1000 examples with 10-fold cross validation.figureAdded Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into 'World-Post', 'Crime', 'Politics', 'Entertainment', 'Sports' or 'Comedy'. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.2DiscussionGenerating new words based solely on ultra small prompts of 10 words or fewer is a major challenge. A short sentence is often characterized by a just a single keyword, and modeling topics from such little data is difficult. Any method of keyword generation that overly relies on the individual words will lack context and fail to add new information, while attempting to freely form new words without any prior domain knowledge is uncertain and leads to misleading suggestions.This method attempts to find balance between synonym and free-form word generation, by constraining words to fit the original sentence while still allowing for word-word and word-sentence interactions to create novel outputs.The word vectors must move through the transformer layers together and therefore maintain the same token order and semantic meaning, however they also receive new input from the surrounding words at each layer. The result, as can be seen from table SECREF12 and SECREF12 in the appendix, is that the first few transformer layers are mostly synonyms of the input sentence since the word vectors have not been greatly modified. The central transformer layers are relevant and novel, since they are still slightly constrained but also have been greatly influenced by sentence context. And the final transformer layers are mostly non-sensical, since they have been completely altered from their original state and lost their ability to retrieve real words.This method is unique since it avoids needing a prior dataset by using the information found within the weights of a general language model. Word embedding models, and BERT in particular, contain vast amounts of information collected through the course of their training. BERT Base for instance, has 110 Million parameters and was trained on both Wikipedea Corpus and BooksCorpus BIBREF0, a combined collection of over 3 Billion words. The full potential of such vastly trained general language models is still unfolding. This paper demonstrates that by carefully prompting and analysing these models, it is possible to extract new information from them, and extend short-text analysis beyond the limitations posed by word count.Appendix ::: Additional Tables and FiguresfigureA Topic table, created from the category labels of the complete headline dataset, can be used to measure the relevance of generated words.An original headline was analyzed by counting the number of words which related to each topic. The generated words were then analyzed in the same way. The change in word count between input topics and output topics was measured and plotted as seen in figure SECREF12.figureBox plot of the number of generated words within a topic as a function of the number of input words within the same topic. Results indicate that additional related words can be generated by increasing the signal of the input prompt. Tested on 7600 examples spanning 23 topics.figureInformation regarding the original headlines, and generated words used to create extended pseudo headlines.figureTop 3 guesses for each token position at each later of a BERT pretrained embedding model. Given the input sentence '2 peoplpe injured in Indiana school shooting', the full list of generated words can be obtainedfrom the values in the table.figureTop 3 guesses for each token position at each later of a BERT pretrained embedding model.Figure 1: Binary Classification of short headlines into ’WorldPost’ or ’Crime’ categories, shows improved performance with extended pseudo headlines when the training set is small. Using: Random forest classifier, 1000 test examples, 10-fold cross validation.Figure 2: The proposed method uses the BERT pre-trained word embedding model to generate new words which are appended to the orignal text creating extended pseudo documents.Figure 3: The number of generated words within each topic was counted, topics which matched the original headline label were considered ’on target’. Results indicate that the unsupervised generation method produced far more words relating to the label category then to other topics. Tested on 7600 examples spanning 23 topics.Figure 4: Binary Classification of ’Politics’ or ’Entertainment’ demonstrates that the number of added words can behave like a hyper paremeter and should be tuned based on training size. Tested on 1000 examples with 10-fold cross validationFigure 5: Binary Classification of ’Politics’ vs ’Sports’ has less improvement compared to other datasets which indicates that the proposed method, while constructed to be domain agnostic, shows better performance towards certain topics. Tested on 1000 examples with 10-fold cross validation.Figure 6: Added Words improve Multiclass Classification between 1.5% and 13% in the range of 150 to 2000 training examples. Tests were conducted using equal size samples of Headlines categorized into ’World-Post’, ’Crime’, ’Politics’, ’Entertainment’, ’Sports’ or ’Comedy’. A 900 Estimator Random Forest classifier was trained for each each data point, tested using 2000 examples, and averaged using 10-fold cross validation.Figure 7: A Topic table, created from the category labels of the complete headline dataset, can be used to measure the relevance of generated words.Figure 8: Box plot of the number of generated words within a topic as a function of the number of input words within the same topic. Results indicate that additional related words can be generated by increasing the signal of the input prompt. Tested on 7600 examples spanning 23 topics.Figure 11: Top 3 guesses for each token position at each later of a BERT pretrained embedding model.Question: What is the language model pre-trained on?","answer":"{\\"answer\\": [\\"Wikipedea Corpus and BooksCorpus\\"], \\"evidence\\": [\\"This method is unique since it avoids needing a prior dataset by using the information found within the weights of a general language model. Word embedding models, and BERT in particular, contain vast amounts of information collected through the course of their training. BERT Base for instance, has 110 Million parameters and was trained on both Wikipedea Corpus and BooksCorpus BIBREF0, a combined collection of over 3 Billion words. The full potential of such vastly trained general language models is still unfolding. This paper demonstrates that by carefully prompting and analysing these models, it is possible to extract new information from them, and extend short-text analysis beyond the limitations posed by word count.\\"]}"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Genetically Encoded Cyclopropene Directs Rapid, Photoclick Chemistry-Mediated Protein Labeling in Mammalian CellsPaper sections:<p>The introduction of bioorthogonal organic reporters into proteins site-selectively through genetic,[1] metabolic,[2] or enzyme-catalyzed ligation method,[3] in conjunction with a growing repertoire of bioorthogonal reactions,[4] has allowed the visualization of proteins and their regulations in their native environment.[5] Numerous small organic groups such as ketone,[6] azides,[7] terminal alkynes,[8] and terminal alkenes,[9] as well as larger reactive bioorthogonal groups such as cyclooctyne,[10] norbornene,[11] transcyclooctene,[10b, 11b] tetrazole,[12] and tetrazine[13] have been genetically encoded for site-selective protein labeling in vivo. To track fast protein dynamics in vivo, it is imperative that these genetically encoded bioorthogonal reporters direct fast and selective bioorthogonal labeling with the cognate biophysical probes, preferably with a spatiotemporal control.</p><p>In our continued effort to genetically encode substrates suitable for the photoclick chemistry,[14] we envisioned that nonnatural amino acids carrying the strained alkenes may show higher rate of cycloaddition without the liability of being Michael acceptors, i.e. electron-deficient alkenes. While we reported recently that norbornene exhibited robust reactivity in the cycloaddition reaction with the macrocyclic tetrazoles,[15] norbornene is relatively bulky and may perturb the structure of the encoded protein. Therefore, we set out to explore the genetic encoding of cyclopropene because of its small size and inherent large ring strain (54.1 kcal/mol[16] vs. 21.6 kcal/mol for norbornene[17]), much of which is released after the cycloaddition reaction (ring strain of cyclopropane = 28.7 kcal/mol).[18] Here, we report the synthesis of a stable cyclopropene amino acid, the characterization of its reactivity in the photoinduced cycloaddition reaction with two tetrazoles, its site-specific incorporation into proteins both in E. coli and in mammalian cells, and its utility in directing bioorthogonal labeling of proteins both in vitro and in vivo.</p><p>To design a cyclopropene-containing amino acid suitable for genetic incorporation, we decided to focus on pyrrolysyl-tRNA synthetase (PylRS)/tRNACUA pair from Methanosarcina barkeri (Mb) because: (i) this pair is orthogonal to all the endogenous tRNAs and aminoacyl-tRNA synthetases in E. coli and eukaryotic cells;[19] and (ii) many nonnatural lysine-derived amino acids have been efficiently incorporated into proteins based on this pair.[20] In our preliminary studies, we found that 3,3-disubstituted cyclopropenes such as 1c exhibited excellent chemical stability at room temperature. 1-Methylcycloprop-2-enecarboxylic acid (1c) can be expediently prepared from the commercially available starting materials ethyl 2-methylacetoacetate through a three-step procedure with an overall yield of 21% (Scheme 1). The cyclopropene carboxylic acid 1c was then coupled with the ε-amino group of Fmoc-lysine, which upon removal of the protecting group afforded Nε-(1-methylcycloprop-2-enecarboxamido)-lysine (CpK, 1) in 74% yield over three steps. To our delight, crystal structure of 1c was obtained in which a hydrogen-bonded dimer of 1c was observed (Scheme 1; see Table S1 in Supporting Information for crystal data and structure refinement). As expected, a bond angle of mere 50° at C1-C2-C1A provides a very high angle strain in the ring structure. Importantly, the carbonyl group in 1c is essentially perpendicular to cyclopropene double bond, preventing the conjugation between these two π systems. Perhaps as a result of this geometry, CpK was found to be very stable towards glutathione—abundant biological nucleophile inside cells: greater than 95% remained after CpK was incubated with 10 mM glutathione for more than 60 hours (Figure S1 in Supporting Information).</p><p>Using ethyl 1-methylcycloprop-2-enecarboxylate (2) as a model substrate, we examined the reactivity of cyclopropene with two representative tetrazoles: a 302-nm photoreactive tetrazole 3[21] and a water-soluble 365-nm photoreactive 4,[22] in acetonitrile/PBS (1:1) mixture, and compared it to those of acrylamide and norbornene (Table 1 and Figures S2-S7). In the cycloaddition reactions with tetrazole 3, cyclopropene 2 showed a k2 value of 58 ± 16 M−1 s−1, similar to acrylamide (entry 1 vs. 3) but significantly faster than norbornene (entry 1 vs. 5). In the cycloaddition reactions with tetrazole 4, however, cyclopropene 2 showed more than 10-fold drop in k2 value, which is also 50% slower than that of acrylamide (entry 2 vs. 4) but similar to norbornene (entry 2 vs. 6). The decrease in reaction kinetics at long wavelength is likely due to the filtering effect associated with the formation of fluorescent pyrazoline adducts.[23] Compared to other bioorthogonal reactions involving the genetically encoded alkenes, the cycloaddition of cyclopropene with tetrazole 3 is about 60 times faster than with the cycloaddition of O-allyltyrosine under the same conditions (k2 = 0.95 M−1 s−1),[21] at least 6 times faster than the ligation between 5-norbornene-2-ol and a pyrimidine-substituted tetrazine (k2 = 9 M−1 s−1 in 95:5 H2O/MeOH),[11a] but three orders of magnitude slower than tetrazine ligation with transcyclooctene (k2 = 35000 ± 3000 M−1 s1 in biological buffer).[11b]</p><p>To evolve an orthogonal tRNA/aminoacyl-tRNA synthetase pair that selectively charges CpK in response to TAG amber codon in proteins in E. coli, an MbPylRS library was constructed in which five residues (L266, L270, Y271, L274, and C313) were randomized through overlapping extension PCR using the synthetic oligonucleotide primers (Table S2). After three rounds of positive and two rounds of negative selections, a CpK-specific aminoacyl-tRNA synthetase, termed CpKRS, was identified. Sequencing of this clone revealed the following five mutations: L266M, L270I, Y271L, L274A, and C313I. To test whether CpKRS/MbtRNACUA pair allows for efficient and selective CpK incorporation in E. coli, the expression of sperm whale myoglobin carrying an amber codon at position-4 and a C-terminal His tag was carried out in E. coli cells transformed with CpKRS/MbtRNACUA pair and grown in LB medium supplemented with 1 mM CpK. The CpK-encoded mutant myoglobin proteins (Myo-CpK) were obtained at a yield of 3.0 mg/L. Importantly, Myo-CpK was produced only when CpK was added (Figure 1a), indicating that CpK incorporation is highly specific. ESI-TOF mass spectrometry showed an intact mass of 18476.0 Da for Myo-CpK (Figure S8), matching the theoretic mass of 18476.3 Da. Subsequent tryptic digestion and tandem mass spectrometry analysis confirmed the presence of CpK at position-4 (Figure 1b).</p><p>To assess whether CpK can serve as a bioorthogonal reporter for protein labeling, we incubated Myo-CpK with tetrazole 3 in PBS buffer and subjected the mixture to 302-nm photoirradiation with a handheld UV lamp for a period of 1–12 min. In-gel fluorescence analysis revealed a time-dependent appearance of a fluorescent band at the Myo-CpK spot with highest intensity reached at 10 min (Figure 2a), consistent with the formation of fluorescent pyrazoline adduct (Figure 2a).[24] As a control, photoirradiation of a mixture of wild-type myoglobin and tetrazole 3 did not yield fluorescent bands on the SDS-PAGE gel (Figure S9), confirming that the labeling was mediated through the cyclopropene moiety. Furthermore, ESI-TOF mass spectrometry analysis of the product mixture revealed a greater than 85% conversion with a new mass peak at 18701.87 Da, matching the theoretic mass of the pyrazoline-labeled myoglobin, 18701.56 (Figure S10). Tryptic digestion and tandem mass spectrometry analysis confirmed the presence of the pyrazoline-modified lysine at position-4 by the appearance of expected masses of three fragment ions b92+, b162+, and y143+ (Figure 2b). For comparison, the same photoclick reaction with a mutant myoglobin encoding the recently reported norbornene-modified lysine (NorK)[11a] at position-4[25] showed a time-dependent, weakly fluorescent cycloadduct formation (Figure S12), affording the pyrazoline cycloadduct in 60% yield based on mass spectrometry analysis after 10-min photoirradiation (Figure S13). The slightly higher reactivity of CpK relative to NorK in the protein context is consistent with the kinetics data described in Table 1.</p><p>To examine whether CpK can direct the bioorthogonal labeling in mammalian cells, we co-transfected human embryonic kidney (HEK) 293 cells with pCMV-CpKRS plasmid in which the transcription of CpKRS is under the control of CMV promoter and the transcription of MbtRNACUA is under the control of human U6 promoter,[20c] together with pSwan-EGFP37TAG reporter.[20d] The cells were allowed to grow in the presence 4 mM CpK for 36 hours, treated with 40 μM tetrazole 4 for 1.5 hours followed by a brief 365-nm photoirradiation for 2 min, and finally proceeded to microscopic imaging. In the EGFP channel (ex 488 nm, em 499-578), green fluorescent cells were detected only in plates where CpK was included in the culture medium (compare panels b & e to h in Figure 3), indicating that CpKRS/MbtRNACUA pair supports site-specific incorporation of CpK into EGFP37TAG in HEK293 cells. In the pyrazoline channel (ex 405 nm, em 410–498 nm), only the tetrazole 4-treated cells expressing CpK-encoded EGFP showed the cyan fluorescence (panel a vs. d & g; see Figure S14 for fluorescence spectrum of the pyrazoline adduct). It is important to note that fluorescent images were acquired in two separate tracks with a single laser source exciting at one wavelength a time to avoid any possible fluorescence leakage to the unintended channel. As seen in the overlaid images, the cyan fluorescent cells coincided with the cells that showed high green fluorescence (indicated by white arrows in panel c), suggesting that the labeling reaction was indeed directed by the cyclopropene moiety. However, not all green fluorescent cells were labelled, indicating some variability in tetrazole reagent penetration into the highly confluent HEK293 cells. Notably, repeated attempts to incorporate NorK in HEK293 cells using wild-type MbPylRS and identical transfection conditions were not successful (Figures S15 and S16), precluding the comparison of the reactivity of these two strained alkenes in photoclick chemistry in vivo.</p><p>In conclusion, we have demonstrated the genetic incorporation of a cyclopropene-containing amino acid, CpK, into target proteins site-specifically, and the use of CpK as a bioorthogonal reporter for directing rapid (~ 2 min) fluorescent labeling of the target protein in mammalian cells. Compared to other genetically encoded, bioorthogonal labeling reactions reported recently,[10–13] the main advantage of the cyclopropene-directed photoclick chemistry lies in its potential in the spatiotemporally controlled protein labeling in mammalian cells, which requires the development of highly reactive laser-activatable tetrazole reagents using either single photon (e.g. 405 nm) or two-photon laser source; work along this line is currently in progress. Because of its small size, cyclopropene moiety such as 1c can also be readily incorporated into small-molecule substrates and inhibitors for the study of proteomes[26] and lipids.[27]</p>","answer":"Genetic incorporation of a cyclopropene amino acid, Nxcexb5-(1-methylcycloprop-2-enecarboxamido)-lysine (CpK), into sperm whale myoglobin site-specifically in E. coli as well as enhanced green fluorescent protein in mammalian cells was achieved through amber codon suppression employing an orthogonal aminoacyl-tRNA synthetase/tRNACUA pair. Because of its high ring strain, cyclopropene exhibited fast reaction kinetics (up to 58 xc2xb1 16 Mxe2x88x921 sxe2x88x921) in the photoclick reaction and allowed rapid (~ 2 min) bioorthogonal labeling of proteins in mammalian cells."},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Erlotinib induces cell cycle arrest and apoptosis in hepatocellular cancer cells and enhances chemosensitivity towards cytostatics. Hepatocellular carcinoma (HCC) is one of the most common cancer-related causes of death worldwide. In light of the very poor 5-year-survival new therapeutic approaches are urgently needed. Recently, evidence has been accumulated that the epidermal growth factor receptor (EGFR) is a promising target for cancer therapy. Several reports indicate that EGFRs are expressed frequently in HCC, most likely contributing to the aggressive growth characteristics of these tumors.  methods erlotinib, an inhibitor of EGFR-tyrosine kinase, potently suppresses the growth of various tumors, but its effect on HCC remains to be explored. We therefore studied the antineoplastic potency of erlotinib in human HCC cells (Huh-7 and HepG2 cell lines).  results We show that erlotinib inhibited HCC growth in a time- and dose-dependent manner. Moreover erlotinib treatment induced apoptosis and resulted in a dose-dependent arrest at the G1/S checkpoint of the cell cycle. Combining erlotinib with doxorubicin or docetaxel or SN-38 resulted in additive or even synergistic antiproliferative effects .  conclusions Our data demonstrate that in human HCC cells the inhibition of EGFR-tyrosine kinase by erlotinib induces growth inhibition, apoptosis and cell cycle arrest. Additionally, erlotinib enhances the antineoplastic activity of conventional cytostatic drugs. Thus, inhibiting EGFR-tyrosine kinase appears to be a promising treatment strategy in HCC.sentence: Combining erlotinib with doxorubicin or docetaxel or SN-38 resulted in additive or even synergistic antiproliferative effects .","answer":"[[\\"erlotinib\\", \\"doxorubicin\\", \\"POS\\"], [\\"erlotinib\\", \\"docetaxel\\", \\"POS\\"], [\\"erlotinib\\", \\"SN-38\\", \\"POS\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:An intrachromosomal insertion causing 5q22 deletion and familial adenomatous polyposis coli in two generations. We report familial adenomatous polyposis coli (FAPC) with epidermoid cysts, osteomata, and areas of congenital hypertrophy of the retinal pigment epithelium (CHRPEs) in a male patient and his maternal aunt, both of whom suffered a mild to moderate degree of mental handicap. Both had an interstitial deletion of the long arm of chromosome 5 (del (5) (q22q23. 2)). Two other normal family members had the underlying direct insertion of chromosome 5 (dir ins (5) (q31. 3q22q23 3q22q23. 2)). Molecular genetic and fluorescent hybridisation studies have shown that loci D5S37 and D5S98 are outside the deletion whereas loci detected by probes EF5. 44 and YN5. 48 are lost. As expected, the molecular analyses indicate loss of one allele at the MCC and APC loci. The APC gene is located within band 5q22. Familial direct insertions should be considered as a cause of recurrent microdeletion syndromes.","answer":"{\\"Disease\\": [\\"mental handicap\\", \\"osteomata\\", \\"APC\\", \\"congenital hypertrophy of the retinal pigment epithelium\\", \\"familial adenomatous polyposis coli\\", \\"CHRPEs\\", \\"FAPC\\", \\"epidermoid cysts\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Autocatalytic microtubule nucleation determines the size and mass of Xenopus laevis egg extract spindles}Article:Abstract:Regulation of size and growth is a fundamental problem in biology. A prominent example is the formation of the mitotic spindle, where protein concentration gradients around chromosomes are thought to regulate spindle growth by controlling microtubule nucleation. Previous evidence suggests that microtubules nucleate throughout the spindle structure. However, the mechanisms underlying microtubule nucleation and its spatial regulation are still unclear. Here, we developed an assay based on laser ablation to directly probe microtubule nucleation events in Xenopus laevis egg extracts. Combining this method with theory and quantitative microscopy, we show that the size of a spindle is controlled by autocatalytic growth of microtubules, driven by microtubule-stimulated microtubule nucleation. The autocatalytic activity of this nucleation system is spatially regulated by the limiting amounts of active microtubule nucleators, which decrease with distance from the chromosomes. This mechanism provides an upper limit to spindle size even when resources are not limiting.Introduction:A general class of problems in biology is related to the emergence of size and shape in cells and tissues. Reaction diffusion mechanisms have been broadly successful in explaining spatial patterns in developmental biology as well as some instances of intracellular structures( Turing, 1952; Howard et al., 2011). The mitotic spindle, a macromolecular machine responsible for segregating chromosomes during cell division, is thought to be a classic example of such reaction diffusion processes. A diffusible gradient of the small GTPase Ran emanating from chromosomes has been shown to trigger a cascade of events that result in the nucleation of microtubules, the main building blocks of the spindle( Kaláb et al., 2006; Caudron et al., 2005). The spatial distribution of microtubule nucleation is key for understanding size and architecture of large spindles. This is because microtubules in these spindles are short and turnover rapidly in comparison to the entire structure( Redemann et al., 2017; Brugués et al., 2012; Needleman et al., 2010). The mechanisms underlying the spatial regulation of microtubule nucleation, however, are still unclear( Prosser and Pelletier, 2017; Petry, 2016). One possibility is that the interplay between Ran-mediated nucleation and microtubule turnover governs spindle assembly( Kaláb et al., 2006; Caudron et al., 2005). However, the role of the Ran gradient in determining spindle size is still controversial. For instance, in cell culture systems, the length scale of the Ran gradient does not correlate with spindle size( Oh et al., 2016). A second possibility is that autocatalytic growth accounts for spindle assembly via microtubule-stimulated microtubule nucleation( Petry et al., 2013; Goshima et al., 2008; Loughlin et al., 2010; Ishihara et al., 2016). However, autocatalytic mechanisms suffer from the fact that their growth is hard to control. Although autocatalytic growth can be regulated by limiting the catalyst, such mechanisms are unlikely to function in the large cells of developing eggs such as Xenopus, where resources are not limiting( Crowder et al., 2015). Understanding the role of microtubule nucleation in setting the size of spindles is limited by the fact that little is known about the rate, distribution, and regulation of microtubule nucleation in spindles( Prosser and Pelletier, 2017; Petry, 2016). This is partly because of the lack of methods to measure microtubule nucleation in spindles. Here, we measured microtubule nucleation in spindles assembled in Xenopus laevis egg extract using laser ablation. We show that microtubule nucleation is spatially dependent and requires physical proximity to pre-existing microtubules. Our findings are consistent with a theoretical model in which autocatalytic microtubule nucleation is regulated by the amount of the active form of spindle assembly factors. This mechanism provides a finite size for spindles even when resources are not limiting.Discussion:Our data and model are consistent with an autocatalytic mechanism in which microtubule-stimulated microtubule nucleation controls growth in Xenopus laevis egg extract spindles. This process is spatially regulated by a gradient of active nucleators that is established by the interplay between the Ran gradient and microtubule dynamics. Microtubules regulate the nucleator activity because they act as the substrate where active nucleators need to bind to nucleate microtubules. Chromatin acts as a trigger for an autocatalytic wave of microtubule nucleation, and at the same time limits spindle size by controlling the amount of active nucleators through RanGTP. This suggests that the amount of active Ran can tune spindle length, and resolves its controversial relation to spindle length regulation: while a diffusion and inactivation process has a characteristic length scale independent of the amplitude of the gradient – set by the ratio of the squared root of the diffusion and inactivation rate – here we show that both the length scale and amplitude of the gradient of nucleators are involved in regulating the size and mass of spindles. Since the length scale of the gradient is amplified by microtubule-stimulated nucleation, the relevant length scale for setting the size is the distance at which a microtubule generates one or fewer microtubules. Our proposed mechanism therefore allows regulation of spindle size and mass by two means, although microtubule nucleation is the principal control parameter, microtubule dynamics can still fine tune the spindle length( Reber et al., 2013). Although our results are restricted to Xenopus laevis spindles, we hypothesize that a similar mechanism may also apply to other spindles with a large number of microtubules. This would be consistent with the fact that components involved in microtubule branching have been identified in many eukaryotic systems( Dasso, 2002; Hsia et al., 2014; Sánchez-Huertas and Lüders, 2015). However, further experiments are needed to test this hypothesis. An autocatalytic nucleation process implies that microtubule structures are capable of richer dynamical behaviors than those arising from the classic view of random nucleation in the cytoplasm via a diffusible gradient. Beyond producing finite-sized structures like spindles and ensuring that new microtubules keep the same polarity as the pre-existing ones, it also allows for a rapid switch into unbounded wave-like growth if nucleators become active throughout the cytoplasm. Indeed, the growth of large interphase asters has been hypothesized as a chemical wave upon Cdk1 activation( Chang and Ferrell, 2013; Ishihara et al., 2014b). These properties, characteristic of excitable media, provide a unified view for the formation of spindles and large interphase asters in embryos( Ishihara et al., 2014a) within a common nucleation mechanism. However, microtubule nucleation differs from regular autocatalytic processes in reaction-diffusion systems such as Fisher-waves and Turing mechanisms( Turing, 1952; Fisher, 1937) in that its growth does not rely on diffusion or advection. Instead, the process of branching displaces the center of mass of the structure. Thus, it emerges as consequence of the finite extension and dynamics of the reactant( microtubules). The interplay between autocatalytic growth and fluxes driven by motors could lead to general principles of pattern formation and cytoskeletal organization in cells.","answer":"When cells divide , they first need to create a copy of their genetic material , which they then evenly distribute between their daughter cells . This is done by a complex of proteins known as the mitotic spindle , which divides the chromosomes that carry the genetic material in the form of genes . The mitotic spindle is mainly made of tubulin proteins that are arranged to form hollow cable-like filaments , called the microtubules . Microtubules are dynamic structures that can grow or shrink by adding or removing tubulin proteins . Unlike the spindle , which can ‘live’ up to hours , the microtubules only live for about 20 seconds and need to be constantly renewed to maintain the structure . To successfully distribute the genetic material , spindles need to have the right length . Previous research has shown that the length of a spindle adapts to the size of a cell – the larger the cells , the larger the spindles . However , in very large cells , such as the cells of an embryo when they first divide , spindles have an upper size limit . It is thought that specific proteins produced by the chromosomes help to regulate the formation of new microtubules and thereby also influence the size of the spindle . However , until now it was not clear how exactly they do so and if this also sets the upper size limit . To further investigate microtubule renewal and its relation to spindle size , Decker et al . used spindles assembled in cell extracts from the eggs of the African clawed frog . The results showed that the new microtubules grow off the existing ones , like new branches of a tree . The branching happens when the established microtubules interact with specific molecules emitted by the chromosomes , and the concentration of these molecules decreases with distance from the chromosomes . This concentration gradient regulates how many microtubules grow at different distances from the chromosomes and so sets the size of spindles . These findings help us to understand how biological structures are built out of dynamic and short-lived components . Moreover , a better understanding of how mitotic spindles grow might eventually help to develop new treatments for cancer and other diseases ."},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: What is the function of the Mis18 protein?Context: Mis16 and Mis18 are required for CENP-A loading and histone deacetylation at centromeresHere we report identification of five fission yeast centromere proteins, Mis14-18. Mis14 is recruited to kinetochores independently of CENP-A, and, conversely, CENP-A does not require Mis14 to associate with centromeres.In contrast, Mis15, Mis16 (strong similarity with human RbAp48 and RbAp46), Mis17, and Mis18 are all part of the CENP-A recruitment pathway.Mis16 and Mis18 form a complex and maintain the deacetylated state of histones specifically in the central core of centromeres. Mis16 and Mis18 are the most upstream factors in kinetochore assembly as they can associate with kinetochores in all kinetochore mutants except for mis18 and mis16, respectively.The Mis18 complex, and, in particular, its member M18BP1 was shown to be essential for both incorporation and maintenance of CENP-A.CENP-A nucleosome assembly requires the Mis18 complex and the CENP-A chaperone HJURP.Roles of Mis18α in epigenetic regulation of centromeric chromatin and CENP-A loadingThe Mis18 complex has been identified as a critical factor for the centromeric localization of a histone H3 variant, centromeric protein A (CENP-A), which is responsible for the specification of centromere identity in the chromosome.Here, we generated Mis18α conditional knockout mice and found that Mis18α deficiency resulted in lethality at early embryonic stage with severe defects in chromosome segregation caused by mislocalization of CENP-A.Further, we demonstrate Mis18α's crucial role for epigenetic regulation of centromeric chromatin by reinforcing centromeric localization of DNMT3A/3BMis18α interacts with DNMT3A/3B, and this interaction is critical for maintaining DNA methylation and hence regulating epigenetic states of centromeric chromatinMis18α deficiency led to reduced DNA methylation, altered histone modifications, and uncontrolled noncoding transcripts in centromere region by decreased DNMT3A/3B enrichmentTogether, our findings uncover the functional mechanism of Mis18α and its pivotal role in mammalian cell cycle.Centromere licensing: Mis18 is required to Polo-verThe Mis18 complex is a critical player in determining when and where centromeres are builtIts nearest relatives are yippee, a highly conserved eukaryotic protein of unknown function, and Mis18, a protein involved in the priming of centromeres for recruitment of CENP-A.Mis16 and Mis18 are subunits of a protein complex required for incorporation of the histone H3 variant CenH3 (Cnp1/CENP-A) into centromeric chromatin in Schizosaccharomyces pombe and mammals.The Mis18 proteins (Mis18α, Mis18β, and M18BP1) are pivotal to the deposition of CENP-A at the centromere during cell cycle progression and are indispensable for embryonic development.Although Mis18α and Mis18β are highly homologous proteins, we find that their conserved YIPPEE domains mediate distinct interactions that are essential to link new CENP-A deposition to existing centromeres.Its nearest relatives are yippee, a highly conserved eukaryotic protein of unknown function, and Mis18, a protein involved in the priming of centromeres for recruitment of CENP-A.Ectopically targeted CENP-A chromatin at the LacO array was sufficient to direct the assembly of a functional centromere as indicated by the recruitment of the constitutive centromere-associated network proteins, the microtubule-binding protein NDC80, and the formation of stable kinetochore-microtubule attachments.Replication-independent incorporation of CENP-A at centromeres depends on its chaperone HJURP(Scm3), and Mis18 in vertebrates and fission yeast.Our findings suggest that Eic1 serves a function analogous to that of Mis18BP1(KNL2), thus representing the functional counterpart of Mis18BP1(KNL2) in fission yeast that connects with a module within the CCAN/Mis6/Ctf19 complex to allow the temporally regulated recruitment of the Mis18/Scm3(HJURP) Cnp1(CENP-A) loading factors.Here, we show that Mis18â, a component of Mis18 complex governing CENP-A localization, is a new substrate of âTrCP-containing SCF complex.Schizosaccharomyces pombe centromere protein Mis19 links Mis16 and Mis18 to recruit CENP-A through interacting with NMD factors and the SWI/SNF complex.The fission yeast Schizosaccharomyces pombe and mammalian Mis16 and Mis18 form a complex essential for CENP-A recruitment to centromeres.Its nearest relatives are yippee, a highly conserved eukaryotic protein of unknown function, and Mis18, a protein involved in the priming of centromeres for recruitment of CENP-A. Searches for distant homologs point to an evolutionary relationship of CULT, yippee, and Mis18 to proteins sharing a common fold, which consists of two four-stranded β-meanders packing at a roughly right angle and coordinating a zinc ion at their apexSchizosaccharomyces pombe centromere protein Mis19 links Mis16 and Mis18 to recruit CENP-A through interacting with NMD factors and the SWI/SNF complexIn contrast, Mis15, Mis16 (strong similarity with human RbAp48 and RbAp46), Mis17, and Mis18 are all part of the CENP-A recruitment pathwayEic1 links Mis18 with the CCAN/Mis6/Ctf19 complex to promote CENP-A assembly.Mis16 and Mis18 are required for CENP-A loading and histone deacetylation at centromeres.No Mis18BP1(KNL2) orthologue has been identified in fission yeast, consequently it remains unknown how the key Cnp1(CENP-A) loading factor Mis18 is recruited.In contrast, Mis15, Mis16 (strong similarity with human RbAp48 and RbAp46), Mis17, and Mis18 are all part of the CENP-A recruitment pathway.In fission yeast, Scm3sp and the Mis18 complex, composed of Mis16, Eic1, and Mis18, function as a CENP-A(Cnp1)-specific chaperone and a recruiting factor, respectively, and together ensure accurate delivery of CENP-A(Cnp1) to centromeres.Its nearest relatives are yippee, a highly conserved eukaryotic protein of unknown function, and Mis18, a protein involved in the priming of centromeres for recruitment of CENP-A. Searches for distant homologs point to an evolutionary relationship of CULT, yippee, and Mis18 to proteins sharing a common fold, which consists of two four-stranded β-meanders packing at a roughly right angle and coordinating a zinc ion at their apex.No Mis18BP1(KNL2) orthologue has been identified in fission yeast, consequently it remains unknown how the key Cnp1(CENP-A) loading factor Mis18 is recruited.CENP-A nucleosome assembly requires the Mis18 complex and the CENP-A chaperone HJURP.We find that Mis18α directly interacts with the N terminus of Mis18BP1, whereas Mis18β directly interacts with CENP-C during G1 phase, revealing that these proteins have evolved to serve distinct functions in centromeres of higher eukaryotes.","answer":"Kinetochores assemble on a specialized chromosomal locus termed the centromere, which is characterized by the replacement of histone H3 in centromeric nucleosomes with the essential histone H3 variant CENP-A (centromere protein A). The Mis18 complex has been identified as a critical factor for the centromeric localization of a histone H3 variant, centromeric protein A (CENP-A), which is responsible for the specification of centromere identity in the chromosome. Further, we demonstrate Mis18Î±'s crucial role for epigenetic regulation of centromeric chromatin by reinforcing centromeric localization of DNMT3A/3B. Mis18Î± interacts with DNMT3A/3B, and this interaction is critical for maintaining DNA methylation and hence regulating epigenetic states of centromeric chromatin. Together, our findings uncover the functional mechanism of Mis18Î± and its pivotal role in mammalian cell cycle. The Mis18 complex is a critical player in determining when and where centromeres are built. Mis16 and Mis18 are required for CENP-A loading and histone deacetylation at centromeres Here we report identification of five fission yeast centromere proteins, Mis14-18. Mis14 is recruited to kinetochores independently of CENP-A, and, conversely, CENP-A does not require Mis14 to associate with centromeres. In contrast, Mis15, Mis16 (strong similarity with human RbAp48 and RbAp46), Mis17, and Mis18 are all part of the CENP-A recruitment pathway. Mis16 and Mis18 form a complex and maintain the deacetylated state of histones specifically in the central core of centromeres. Mis16 and Mis18 are the most upstream factors in kinetochore assembly as they can associate with kinetochores in all kinetochore mutants except for mis18 and mis16, respectively. The Mis18 complex has been identified as a critical factor for the centromeric localization of a histone H3 variant, centromeric protein A (CENP-A), which is responsible for the specification of centromere identity in the chromosome. Mis16 and Mis18 form a complex and maintain the deacetylated state of histones specifically in the central core of centromeres. A fundamental process in centromere establishment is the incorporation of the histone variant CENP-A into centromeric chromatin, which provides a binding platform for the other centromeric proteins. CENP-A nucleosome assembly requires the Mis18 complex and the CENP-A chaperone HJURP. Thus, CENP-C provides a link between existing CENP-A chromatin and the proteins required for new CENP-A nucleosome assembly. The Mis18 complex has been identified as a critical factor for the centromeric localization of a histone H3 variant, centromeric protein A (CENP-A), which is responsible for the specification of centromere identity in the chromosome. This is a critical step that is essential for proper centromere function and maintaining the integrity of the genome. The Mis18 complex is a critical player in determining when and where centromeres are built. The Mis18 complex has been identified as a critical factor for the centromeric localization of a histone H3 variant, centromeric protein A (CENP-A), which is responsible for the specification of centromere identity in the chromosome. Eukaryotic chromosomes segregate by attaching to microtubules of the mitotic spindle through a chromosomal microtubule binding site called the kinetochore. Centromeres are important structural constituents of chromosomes that ensure proper chromosome segregation during mitosis by providing defined sites for kinetochore attachment. Centromeres contain specialized chromatin that includes the centromere-specific histone H3 variant, spCENP-A/Cnp1. Together, our findings uncover the functional mechanism of Mis18α and its pivotal role in mammalian cell cycle. The Mis18 complex has been identified as a critical factor for the centromeric localization of a histone H3 variant, centromeric protein A (CENP-A), which is responsible for the specification of centromere identity in the chromosome. the mis18 complex has been identified as a critical factor for the centromeric localization of a histone h3 variant, centromeric protein a (cenp-a), which is responsible for the specification of centromere identity in the chromosome."},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Brief Survey of Deep Reinforcement Learning Chapter Title:  D. Planning and Learning 1. Abstract of Cited Paper (BIB001):  We survey some recent research directions within the field of approximate dynamic programming, with a particular emphasis on rollout algorithms and model predictive control (MPC). We argue that while they are motivated by different concerns, these two methodologies are closely connected, and the mathematical essence of their desirable properties (cost improvement and stability, respectively) is couched on the central dynamic programming idea of policy iteration. In particular, among other things, we show that the most common MPC schemes can be viewed as rollout algorithms and are related to policy iteration methods. Furthermore, we embed rollout and MPC within a new unifying suboptimal control framework, based on a concept of restricted or constrained structure policies, which contains these schemes as special cases. 2. Abstract of Cited Paper (BIB002):  Motivated by vision-based reinforcement learning (RL) problems, in particular Atari games from the recent benchmark Aracade Learning Environment (ALE), we consider spatio-temporal prediction problems where future (image-)frames are dependent on control variables or actions as well as previous frames. While not composed of natural scenes, frames in Atari games are high-dimensional in size, can involve tens of objects with one or more objects being controlled by the actions directly and many other objects being influenced indirectly, can involve entry and departure of objects, and can involve deep partial observability. We propose and evaluate two deep neural network architectures that consist of encoding, action-conditional transformation, and decoding layers based on convolutional neural networks and recurrent neural networks. Experimental results show that the proposed architectures are able to generate visually-realistic frames that are also useful for control over approximately 100-step action-conditional futures in some games. To the best of our knowledge, this paper is the first to make and evaluate long-term predictions on high-dimensional video conditioned by control inputs. 3. Abstract of Cited Paper (BIB003):  Achieving efficient and scalable exploration in complex domains poses a major challenge in reinforcement learning. While Bayesian and PAC-MDP approaches to the exploration problem offer strong formal guarantees, they are often impractical in higher dimensions due to their reliance on enumerating the state-action space. Hence, exploration in complex domains is often performed with simple epsilon-greedy methods. In this paper, we consider the challenging Atari games domain, which requires processing raw pixel inputs and delayed rewards. We evaluate several more sophisticated exploration strategies, including Thompson sampling and Boltzman exploration, and propose a new exploration method based on assigning exploration bonuses from a concurrently learned model of the system dynamics. By parameterizing our learned model with a neural network, we are able to develop a scalable and efficient approach to exploration bonuses that can be applied to tasks with complex, high-dimensional state spaces. In the Atari domain, our method provides the most consistent improvement across a range of games that pose a major challenge for prior methods. In addition to raw game-scores, we also develop an AUC-100 metric for the Atari Learning domain to evaluate the impact of exploration on this benchmark. 4. Abstract of Cited Paper (BIB004):  Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. ::: Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time. 5. Abstract of Cited Paper (BIB005):  The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of stateof-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away. 6. Abstract of Cited Paper (BIB006):  Reinforcement learning provides a powerful and flexible framework for automated acquisition of robotic motion skills. However, applying reinforcement learning requires a sufficiently detailed representation of the state, including the configuration of task-relevant objects. We present an approach that automates state-space construction by learning a state representation directly from camera images. Our method uses a deep spatial autoencoder to acquire a set of feature points that describe the environment for the current task, such as the positions of objects, and then learns a motion skill with these feature points using an efficient reinforcement learning method based on local linear models. The resulting controller reacts continuously to the learned feature points, allowing the robot to dynamically manipulate objects in the world with closed-loop control. We demonstrate our method with a PR2 robot on tasks that include pushing a free-standing toy block, picking up a bag of rice using a spatula, and hanging a loop of rope on a hook at various positions. In each task, our method automatically learns to track task-relevant objects and manipulate their configuration with the robot's arm. 7. Abstract of Cited Paper (BIB007):  Model-free reinforcement learning has been successfully applied to a range of challenging problems, and has recently been extended to handle large neural network policies and value functions. However, the sample complexity of modelfree algorithms, particularly when using high-dimensional function approximators, tends to limit their applicability to physical systems. In this paper, we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks. We propose two complementary techniques for improving the efficiency of such algorithms. First, we derive a continuous variant of the Q-learning algorithm, which we call normalized advantage functions (NAF), as an alternative to the more commonly used policy gradient and actor-critic methods. NAF representation allows us to apply Q-learning with experience replay to continuous tasks, and substantially improves performance on a set of simulated robotic control tasks. To further improve the efficiency of our approach, we explore the use of learned models for accelerating model-free reinforcement learning. We show that iteratively refitted local linear models are especially effective for this, and demonstrate substantially faster learning on domains where such models are applicable.Literature Review:","answer":"Given a model of the environment, it is possible to use dynamic programming over all possible actions (Figure 3 (a)), sample trajectories for heuristic search (as was done by AlphaGo BIB006 ), or even perform an exhaustive search ( Figure  3 (b) ). Sutton and Barto BIB001 define planning as any method which utilises a model to produce or improve a policy. This includes distribution models, which include T and R, and sample models, from which only samples of transitions can be drawn. In RL, we focus on learning without access to the underlying model of the environment. However, interactions with the environment could be used to learn value functions, policies, and also a model. Model-free RL methods learn directly from interactions with the environment, but model-based RL methods can simulate transitions using the learned model, resulting in increased sample efficiency. This is particularly important in domains where each interaction with the environment is expensive. However, learning a model introduces extra complexities, and there is always the danger of suffering from model errors, which in turn affects the learned policy; a common but partial solution in this latter scenario is to use model predictive control, where planning is repeated after small sequences of actions in the real environment BIB002 . Although deep neural networks can potentially produce very complex and rich models BIB003 BIB004 BIB007 , sometimes simpler, more dataefficient methods are preferable BIB008 . These considerations also play a role in actor-critic methods with learned value functions [63, BIB005 ."},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: We begin by demonstrating our ability to capture and recreate variations of an object using a single pseudo-word. In Figure 3 we compare our method to two baselines: LDM guided by a human caption and DALLE-2 guided by either a human caption or an image prompt. Captions were collected using Mechanical Turk. Annotators were provided with four images of a concept and asked to describe it in a manner that could allow an artist to recreate it. We asked for both a short (leq 12 words) and a long (leq 30 words) caption. In total, we collected 10 captions per concept — five short and five long. Figure 3 shows multiple results generated with a randomly chosen caption for each setup. Additional large-scale galleries showing our uncurated reconstructions are provided in the supplementary. To provide intuition for the scale of the results, we add two reference baselines.First, we consider the expected behavior from a model that always produces copies of the training set, regardless of the prompt. For that, we simply use the training set itself as the “generated sample”.Second, we consider a model that always aligns with the text prompt but ignores the personalized concept. We do so by synthesizing images using the evaluation prompts but without the pseudo-word.We denote these setups as “Image Only” and “Prompt Only”, respectively. Our evaluation results are summarized in Figure 10(a).We highlight four observations of particular interest:First, the semantic reconstruction quality of our method and many of the baselines is comparable to simply sampling random images from the training set.Second, the single-word method achieves comparable reconstruction quality, and considerably improved editability over all multi-word baselines. These points outline the impressive flexibility of the textual embedding space, showing that it can serve to capture new concepts with a high degree of accuracy while using only a single pseudo-word. Third, we observe that our baselines outline a distortion-editability trade-off curve, where embeddings that lie closer to the true word distribution (e.g. due to regularization, fewer pseudo-words, or a lower learning rate) can be more easily modified, but fail to capture the details of the target. In contrast, deviating far from the word distribution enables improved reconstruction at the cost of severely diminished editing capabilities. Notably, our single-embedding model can be moved along this curve by simply changing the learning rate, offering a user a degree of control over this trade-off.Question: What existing baselines are there? Thought this was the first work.","answer":"To benchmark their single-word embedding approach, the authors create a bunch of reference baselines to gauge the relative improvement their method offers. One reference baseline they create merely spews out images from the train set itself, while ignoring the new prompt. The second reference baseline that they create is a model which uses the text prompt only, while ignoring the personalization aspect of their task. In addition, they also compare the ability of their model to generate variations of an existing image to two existing approaches: namely, DALLE-2 and LDM."},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: What is the indication for SLCO1B1 genotyping?Context: including the well-known genetic variant associated with statin-associated muscle symptoms-solute carrier organic anion transporter family, member 1B1 (SLCO1B1) rs4149056-also increase the risk of statin-associated muscle symptoms in FH patientsStatin-associated muscle symptoms and SLCO1B1 rs4149056 genotype in patients with familial hypercholesterolemia.Similarly, HMG Co-A reductase inhibitors, commonly known as statins, also display wide interindividual variability in plasma concentration, response and toxicity due in part to polymorphisms in transporter genes, including SLCO1B1 and ABCG2.Association of SLCO1B1 gene polymorphisms with toxicity response of high dose methotrexate chemotherapy in childhood acute lymphoblastic leukemia.development of SLCO1B1 genotyping to avoid statin induced adverse drug reactions is discussed as a model case for transporter pharmacogenetics clinical development.Statin adherence is often limited by side effects. The SLCO1B1*5 variant is a risk factor for statin side effects and exhibits statin-specific effects: highest with simvastatin/atorvastatin and lowest with pravastatin/rosuvastatin. The effects of SLCO1B1*5 genotype guided statin therapy (GGST) are unknown","answer":"Statin treatment"},{"question":"Given a short query with keyphrases about a research idea in 2017 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: I want to train a DDPG agent for continuous control.Keyphrases: continuous control simulationDataset description:Obstacle Tower: Obstacle Tower is a high fidelity, 3D, 3rd person, procedurally generated environment for reinforcement learning. An agent playing Obstacle Tower must learn to solve both low-level control and high-level planning problems in tandem while learning from pixels and a sparse reward signal.TORCS: TORCS (The Open Racing Car Simulator) is a driving simulator. It is capable of simulating the essential elements of vehicular dynamics such as mass, rotational inertia, collision, mechanics of suspensions, links and differentials, friction and aerodynamics.Lani: LANI is a 3D navigation environment and corpus, where an agent navigates between landmarks. Lani contains 27,965 crowd-sourced instructions for navigation in an open environment.MuJoCo: MuJoCo (multi-joint dynamics with contact) is a physics engine used to implement environments to benchmark Reinforcement Learning methods.Options:- A: Obstacle Tower  B: TORCS  C: Lani  D: MuJoCo","answer":"MuJoCo"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:OBJECTIVE: To report our initial experience of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2)/acute coronary syndrome (ACS) patients undergoing standard of care invasive management. BACKGROUND: The rapid diffusion of the SARS-CoV-2 together with the need for isolation for infected patients might be responsible for a suboptimal treatment for SARS-CoV-2 ACS patients. Recently, the group of Sichuan published a protocol for COVID/ACS infected patients that see the thrombolysis as the gold standard of care. METHODS: We enrolled 31 consecutive patients affected by SARS-COV-2 admitted to our emergencies room for suspected ACS. RESULTS: All patients underwent urgent coronary angiography and percutaneous coronary intervention (PCI) when required except two patients with severe hypoxemia and unstable hemodynamic condition that were conservatively treated. Twenty-one cases presented diffuse ST-segment depression while in the remaining cases anterior and inferior ST-elevation was present in four and six cases, respectively. PCI was performed in all cases expect two that were diagnosed as suspected myocarditis because of the absence of severe coronary disease and three with apical ballooning at ventriculography diagnostic for Tako-Tsubo syndromes. Two patients conservatively treated died. The remaining patients undergoing PCI survived except one that required endotracheal intubation (ETI) and died at Day 6. ETI was required in five more patients while in the remaining cases CPAP was used for respiratory support. CONCLUSIONS: Urgent PCI for ACS is often required in SARS-CoV-2 patients improving the prognosis in all but the most advanced patients. Complete patient history and examination, routine ECG monitoring, echocardiography, and careful evaluation of changes in cardiac enzymes should be part of the regular assessment procedures also in dedicated COVID positive units.","answer":"[\\"Diagnosis\\", \\"Treatment\\"]"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:We present a novel approach to train a natural media painting using reinforcement learning.Given a reference image,  our formulation is based on stroke-based rendering that  imitates human drawing and can be learned from scratch without supervision.Our painting agent computes a sequence of actions that represent the primitive painting strokes.In order to ensure that the generated policy is predictable and controllable, we use a constrained learning method and train the painting agent  using the environment model and follows the commands encoded in an observation.We have applied our approach on many benchmarks and our results demonstrate that our constrained agent can handle different painting media and different constraints in the action space to collaborate with humans or other agents.Throughout human history, painting has been an essential element of artistic creation.There are many diverse and complex artistic domains with various styles such as watercolor, oil painting, sketching, and so on.As image processing and computer graphics have advanced, there has been a considerable effort to simulate these styles using non-photorealistic rendering (NPR) techniques (Kumar et al. (2019) ).Hertzmann (1998) ; Winkenbach & Salesin (1996) generate compelling results using stroke-based rendering.However, most prior methods in NPR are engineered for a specific application or task, and cannot easily adapt to new styles or medium.Recent developments in machine learning have resulted in significant advancements in computer vision and computer graphics, including computer-based painting systems.Many visual generative methods based on generative adversarial networks (Goodfellow et al. (2014) ) as Zhu et al. (2017) ; Zhou et al. (2018) ; ; Karras et al. (2017) ; Sangkloy et al. (2017) have demonstrated promising results.Many of these machine learning methods have also been applied to stroke-based rendering tasks, including modeling the brush (Xie et al. (2012) ; Zheng et al. (2019) ), generating brushstroke paintings in an artist's style (Xie et al. (2015) ), reconstructing drawings for specific paintings styles (Tang et al. (2018) ), and constructing stroke-based drawings (Ha & Eck (2017a) ; Zhou et al. (2018) ; ; Jia et al. (2019a) ).In this paper, we focus on a more general and challenging problem of training a natural media painting agent for interactive applications.Given a reference image, our goal is to develop a stroke-based rendering approach that can imitate the human drawing or strokes used in generating the image.A key challenge is to develop a method that can learn from scratch without any supervision.In this regard, we present a technique that can handle all inputs and train an agent to manipulate natural painting media such as charcoal, pencil, watercolor, and so on.We build a model-based natural media environment using deep CNN and train a natural media painting agent using model-based reinforcement learning.In order to introduce controls to the agents for interactive applications, we use a constraint representation along with a different framework for training and use the constrained painting agent.These constraints enable the agent to interact with a human or other agents and generate various styles without retraining the model.The novel contributions of our work include:• A method to train an agent that produces a stream of actions subject to constraint for each action.These constraints can include restricting the start location, stroke width, color, and other stroke parameters.• A method to roll out constrained agents so the user can produce new stylistic effects interactively or automatically, as the agent is painting by modulating the action stream.• By incorporate coarse-to-fine strategy, our painting agents can generate high-resolution stylized images using various constraints and paintbrush configurations.We evaluate our algorithm on different paintbrush configurations and datasets to highlights its benefits over prior reinforcement learning based methods.We also employ differing constraint settings to validate our constrained agents and produce new stylistic effects with a single trained model.In this paper, we train natural media painting agents that can generate artistic paintings using various natural media, and collaborate with humans and other agents to get different visual effects.We build a model of natural media environment using deep CNN and train a natural media painting agent using model-based reinforcement learning.To introduce controls to the agents for interactive purposes, we propose constraint representation, a framework for training a constrained painting agent, and various roll-out schemes to apply the agent.We demonstrate our algorithm by applying the trained model using various paintbrushes from MyPaint and constraints set up.The experimental results show that our algorithm can reproduce reference images in multiple artistic styles.For future work, we aim to extend the proposed algorithm by building a unified model for differing paintbrush configuration.In addition, we will train a hierarchical agent that uses a constrained agent as the low-level policy.We would like to apply our approach on other reference images and use for interactive painting systems.A APPENDIX Figure 9 : Roll-out results using Various PaintbrushesWe roll out our natural media painting agents trained with various brushes in MyPaint.To increase the resolutions of the generated images, we incorporate the coarse-to-fine strategy.We use 8 × 8 patches for first row and 4 × 4 for second row.Figure 10: Reproduction of Starry Night using Charcoal We roll out our natural media painting agent trained with charcoal brush in MyPaint to reproduce Van Gogh's starry night.We incorporate the coarse-to-fine strategy by dividing the reference image and canvas into 16 × 16 patches.Figure 11 : Reproduction of Starry Night using Watercolor We roll out our natural media painting agent trained with watercolor brush in MyPaint to reproduce Van Gogh's starry night.We incorporate the coarse-to-fine strategy by dividing the reference image and canvas into 16 × 16 patches.","answer":"We train a natural media painting agent using environment model. Based on our painting agent, we present a novel approach to train a constrained painting agent that follows the command encoded in the observation."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Mouse retinal cell behaviour in space and time using light sheet fluorescence microscopy}Article:Abstract:As the general population ages, more people are affected by eye diseases, such as retinopathies. It is therefore critical to improve imaging of eye disease mouse models. Here, we demonstrate that 1) rapid, quantitative 3D and 4D( time lapse) imaging of cellular and subcellular processes in the mouse eye is feasible, with and without tissue clearing, using light-sheet fluorescent microscopy( LSFM); 2) flat-mounting retinas for confocal microscopy significantly distorts tissue morphology, confirmed by quantitative correlative LSFM-Confocal imaging of vessels; 3) LSFM readily reveals new features of even well-studied eye disease mouse models, such as the oxygen-induced retinopathy( OIR) model, including a previously unappreciated ‘knotted’ morphology to pathological vascular tufts, abnormal cell motility and altered filopodia dynamics when live-imaged. We conclude that quantitative 3D/4D LSFM imaging and analysis has the potential to advance our understanding of the eye, in particular pathological, neurovascular, degenerative processes.Introduction:Eye diseases, such as diabetic retinopathy, age-related macular degeneration, cataracts, and glaucoma are becoming increasingly common with the increased age of the general population. Although advances in understanding and treating eye diseases have been made, the cellular and molecular mechanisms involved are still not fully understood. We believe that is partially due to the inadequate ability to image eye tissue in its natural, spherical state, to reveal the many distinct layers with interacting cell types oriented differentially within or between the layers. Optical coherence tomography( OCT) is an established medical imaging diagnostic tool that uses light to capture micrometre-resolution, three-dimensional images, non-invasively( Srinivasan et al., 2006; Huber et al., 2009). Its main strength lies in revealing information on tissue depth preserving the eyes natural state. However, its limitation lies in not being able to provide a wide field of view, cellular or molecular information. Furthermore, being a non-fluorescent method, specific proteins cannot be labelled and tracked to investigate mechanisms. Currently, only confocal microscopy can deliver this detailed fluorescently labelled information( del Toro et al., 2010), but the 3D nature of the tissue is likely distorted during flat-mounting and it is currently not known to what extent this might impact the obtained results. For instance, the vascular biology field is one clear example where these limitations can have a substantial impact. The mouse retina is a common model used to study vascular development and disease; confocal imaging approaches have been used to measure vessel morphology, vascular malformations, junctional organisation, and pathological tuft formation( Gerhardt et al., 2003; Bentley et al., 2014; Stahl et al., 2010). Moreover, vessel diameters are now being used to predict blood flow( Bernabeu et al., 2014; Baeyens et al., 2016). Distortions arising from confocal flat-mounting could therefore have important ramifications for the overall conclusions of several studies. Changes in cellular and tissue morphology are a hallmark of many eye diseases. For instance, retinopathy of prematurity and diabetic retinopathy are characterised by excessive, bulbous and leaky blood vessels that protrude out of their usual layered locations. These malformed vessels cause many problems including the generation of abnormal mechanical traction, which pulls on the different layers, eventually leading to detachment of the retina( Nentwich and Ulbig, 2015; Hartnett, 2015). Yet, very limited information has arisen on the conformation and morphogenesis mechanisms of these vascular tuft malformations, despite a wealth of confocal studies of the related oxygen- induced retinopathy( OIR) mouse model( Connor et al., 2009). Another limitation of confocal microscopy for imaging of mouse retinal angiogenesis is the inability to perform live imaging of endothelial cell dynamics. Endothelial cells move and connect in highly dynamic, complex ways to generate the extensive vascular networks required to perfuse the retina over time( angiogenesis). Live, in vivo imaging of murine intraocular vasculature has been reported using confocal microscopy( Ritter et al., 2005) and holds great promise for dynamic longitudinal studies of the growth/regression of large vessel such as hyaloid vessels. However, it does not as yet suit studies of smaller more dynamic cell and subcellular structures as being reliant on confocal currently limits such studies to slow frame rates( 5–10 min intervals), limited z stack resolution with photobleaching issues and an apparent limited field of view. There are a small number of reports on ex vivo live-imaging of the retinal vasculature with confocal microscopy, but which clearly entails challenges as dissection of the retina for culture is time consuming, and moreover, the flatmounting is likely to disturb local tissue arrangement and mechanics( Sawamiphak et al., 2010; Rezzola et al., 2013). Furthermore, photobleaching, phototoxicity and long acquisition times continue to remain an issue. A growing number of reports show that neurovascular interactions in the eye are important during development and disease progression( Akula et al., 2007; Narayanan et al., 2014; Nentwich and Ulbig, 2015; Usui et al., 2015; Verheyen et al., 2012). Neurons and vessels are however currently imaged with physical sectioning of paraffin or cryo-embedded retinas, which precludes concurrent visualisation of the vasculature, due to the orthogonal arrangement of neurons and vessels within or between retinal layers respectively. Likewise, current methods have limited potential for quantitative 3D and live imaging of fluorescently labelled neurons in neurodegenerative mouse models. Recent advances in light-sheet fluorescence microscopy( LSFM) have demonstrated its strength for allowing the rapid acquisition of optical sections through thick tissue samples such as mouse brains( Stelzer, 2015). Instead of illuminating or scanning the whole sample through the imaging objective, as in wide-field or confocal microscopy, the sample is illuminated from the side with a thin sheet of light. Thus, in principle LSFM would require little interference with the original spherical eye tissue structure, avoiding distortion of the tissue with flat-mounting. Moreover, LSFM is becoming a gold-standard technique to perform live-imaging in whole organs/organisms because it permits imaging of thick tissue sections without disturbing the local environment, while also reducing photobleaching and phototoxicity( Stelzer, 2015; Reynaud et al., 2015). Thus, here we investigate the feasibility, advantages and disadvantages of LSFM for imaging the mouse eye for development or disease studies. We present an optimised LSFM protocol to rapidly image neurovascular structures, across scales from the entire eye to subcellular components in mouse retinas. We investigate the pros and cons of LSFM imaging of vessels over standard confocal imaging techniques in early mouse pup retinas. Importantly, we also demonstrate the benefits of LSFM using the OIR mouse model, where we discover previously unappreciated new spatial arrangements of endothelial cells in the onset of vascular tuft malformations due to the improved undistorted, 3D and 4D imaging capabilities of LSFM. We conclude that LSFM quantitative 3D/4D imaging and analysis has the potential to advance our understanding of healthy and pathological processes in the eye, with a particular relevance for the vascular and neurovascular biology fields, as well as ophthalmology.Discussion:The OIR model is a commonly used to study retinopathies. The three-dimensional nature of vascular tufts makes them ideal for LFSM and though this is a widely studied mouse model, the improved three-dimensional imaging allowed us to identify several new features of the important pathological vessels it generates. Our observations of small, medium and large tuft classes with distinct properties and the observation of more complex knotted, swirling and looping morphologies than previously reported, suggest a new mechanistic explanation is required to understand how and why vessels twist and turn on themselves and why it appears that medium tufts reach a critical size then stop twisting and instead coalesce into larger more stable structures, akin to the development of blood islands in retinal development( Goldie et al., 2008). Nuclei with unusual shapes have previously been identified in abnormally growing tissues, such as cancer( Hida et al., 2004; Kondoh et al., 2013; Versaevel et al., 2012), and to reflect mitotic instability( Gisselsson et al., 2001). It is remarkable that we observed the dramatically curved shape of EC nuclei in tufts. Although it remains unclear whether their unusual shape has consequences for EC function in the tuft, it is tempting to speculate that it would have some bearing on, or is at least be an indicator of abnormal cell behavior. Overall, the ability to rotate the tufts in 3D and view from the side, not just the top, gave a much clearer view of their structure potentiating a detailed analysis of their complex knotted structure in the future. It was particularly interesting that tufts in the Everolimus-treated OIR retinas appeared to conform to a specific swirl structure with many filopodia, suggesting that LSFM imaging could help reveal much greater information of the mechanism of action of many drugs targeting these or other complex 3D structures in the eye. LSFM therefore could greatly improve our understanding of these abnormal vascular formations, already opening up avenues for future studies. Current retinal studies must infer dynamics from static images by hypothesising what might have happened in real-time to generate the retina’s phenotype. For example, CollagenIV-positive and IsolectinB4-negative vessels are considered to be empty membrane sleeves where the vasculature has regressed. It is therefore important to establish reproducible live-imaging methods. It will be interesting to investigate in future live-imaging studies how pervasive the kiss and run behaviors are across the plexus and under different conditions, in order to fully elucidate their functional role. We furthermore demonstrated the potential to quantify diverse subcellular level movements in the cells and altered cell movements in the OIR disease model as proof of concept. Previously undirected vascular movements have been indicated as due to the loss of the underlying astrocyte template( Dorrell et al., 2010), LSFM now permits mechanisms involving multiple cell types to be investigated and confirmed live with fluorescent co-labelling studies of neurons/glial cells with vessels in the same retina. The LSFM live imaging protocol is sturdy as indicated from the testing in three different laboratories in three different countries( US, Sweden and Portugal) with different scientists performing the dissections and imaging, on different instruments. As such we can confirm that though challenging, the live imaging protocol has been optimised and is reproducible in different hands.","answer":"Eye diseases affect millions of people worldwide and can have devasting effects on people’s lives . To find new treatments , scientists need to understand more about how these diseases arise and how they progress . This is challenging and progress has been held back by limitations in current techniques for looking at the eye . Currently , the most commonly used method is called confocal imaging , which is slow and distorts the tissue . Distortion happens because confocal imaging requires that thin slices of eye tissue from mice used in experiments are flattened on slides; this makes it hard to accurately visualize three-dimensional structures in the eye . New methods are emerging that may help . One promising method is called light-sheet fluorescent microscopy ( or LSFM for short ) . This method captures three-dimensional images of the blood vessels and cells in the eye . It is much faster than confocal imaging and allows scientists to image tissues without slicing or flattening them . This could lead to more accurate three-dimensional images of eye disease . Now , Prahst et al . show that LSFM can quickly produce highly detailed , three-dimensional images of mouse retinas , from the smallest parts of cells to the entire eye . The technique also identified new features in a well-studied model of retina damage caused by excessive oxygen exposure in young mice . Previous studies of this model suggested the disease caused blood vessels in the eye to balloon , hinting that drugs that shrink blood vessels would help . But using LSFM , Prahst et al . revealed that these blood vessels actually take on a twisted and knotted shape . This suggests that treatments that untangle the vessels rather than shrink them are needed . The experiments show that LSFM is a valuable tool for studying eye diseases , that may help scientists learn more about how these diseases arise and develop . These new insights may one day lead to better tests and treatments for eye diseases ."},{"question":"You will be shown the full-text from a biomedical research paper. Given this text, your task is to extract all unique entities of the following types: [\\"Species\\"].Please return the output as a JSON object of the format: {\\"Species\\": [\\"rat\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Document text:Piezoelectric osteotomy in hand surgery: first experiences with a new techniqueAbstractBackgroundIn hand and spinal surgery nerve lesions are feared complications with the use of standard oscillating saws. Oral surgeons have started using a newly developed ultrasound bone scalpel when performing precise osteotomies. By using a frequency of 25–29 kHz only mineralized tissue is cut, sparing the soft tissue. This reduces the risk of nerve lesions. As there is a lack of experience with this technique in the field of orthopaedic bone surgery, we performed the first ultrasound osteotomy in hand surgery.MethodWhile performing a correctional osteotomy of the 5th metacarpal bone we used the Piezosurgery® Device from Mectron [Italy] instead of the usual oscillating saw. We will report on our experience with one case, with a follow up time of one year.ResultsThe cut was highly precise and there were no vibrations of the bone. The time needed for the operation was slightly longer than the time needed while using the usual saw. Bone healing was good and at no point were there any neurovascular disturbances.ConclusionThe Piezosurgery® Device is useful for small long bone osteotomies. Using the fine tip enables curved cutting and provides an opportunity for new osteotomy techniques. As the device selectively cuts bone we feel that this device has great potential in the field of hand- and spinal surgery.BackgroundFor osteotomies of the hand oscillating saws are usually used [1]. Even though they are varied in size, they are not very precise for use in the vicinity of nerves and arteries. They also pose problems while being used in conjunction with magnification, as one's range of sight and focus is restricted when wearing magnifying glasses. For that reason oral surgeons have moved to using the newly developed piezoelectrical bone scalpel when operating in the near vicinity of nerves or arteries. The tip of this instrument oscillates in the frequency of ultrasound [2]. The mechanism of this device is based on the so called Piezo – Effect. French Physicists Jean and Marie Curie first mentioned the direct Piezo-Effect 1880, whereby certain crystals produce electrical current while under mechanical pressure. The reciprocal effect, by which the crystals are deformed when under electrical current, was then discovered a while later. This is the effect being used by the Piezosurgery Device®. In this device, the electrical field is located in the handle of the saw [3]. Due to the deformation caused by the electrical current, a cutting – hammering movement is produced at the tip of the instrument. These micro movements are in the frequency range of 25 to 29 kHz and, depending on the insert, with an amplitude of 60 to 210 μm. This way only mineralized tissue is selectively cut. Neurovascular tissue and other soft tissue would only be cut by a frequency of above 50 kHz [3-5]. Depending on the strength of the bone and the blade geometry, the efficiency of the cutting can be regulated by the frequency modulator and the power level. For cooling there is an integrated pump with five different working levels. This pump automatically washes physiological solution to the area being cut. The cost of the device is about 7.000 USD. Additional costs per operation are for the cooling liquid and are in the range of a few dollars. We have used the Piezosurgery Device® by Mectron [Italy] [3] for the first time in osteotomies of the long bone in the field of hand surgery. We will report on our experience with one case, with a follow up time of one year.MethodThe correctional osteotomy was performed on a 23 year old worker who suffered a malunited metacarpal bone fracture of the fifth finger on his dominant hand. The X-ray revealed a 45 degree angular deformity of the fifth metacarpal neck with internal rotation. (Figure 1). The operation was performed under regional anesthesia. A longitudinal incision was made over the fifth metacarpal. The tendon of the extensor digiti minimi was found and on its radial side the periosteum of metacarpal five was reached. The periosteum was opened longitudinally over the defect as usual. For the correction of the defect of 45 degrees, a bone wedge was excised. Instead of using the traditional oscillating saw, the Piezosurgery Device® [3] was used (Figure 2). We used a sharp hardened saw coated with titannitrid (Figure 3). For most of the surgery the highest power level, the boosted burst c, was used. We set the automatic cooling of the area with water to its highest level. The angulation and rotation was corrected and fixed with a 1.5 mm titanium five-hole plate and four screws. Closure of the wound was done in layers. Mobilization was started on the 10th postoperative day. The overall time of observation was one year.Results and discussionThe Piezosurgery® Device is ideally sized for hand surgery. The cutting was very precise. The edges of the osteotomy were all sharp to the edge, there was no need to split the bone with a chisel, nor was there the danger of a break out. During the osteotomy there were no disturbing vibrations in the area of operation. This absence of vibration is very practical for operations using a magnifier. Vercellotti mentions that to overcome any problems during surgery, instead of increasing pressure on the hand piece, as in traditional techniques, it is necessary to find the correct pressure to achieve the desired result. With piezoelectric surgery, increasing the working pressure above a certain limit impedes the vibrations of the insert [4]. We have also experienced this in our study. The instrument can be moved in all directions comparable to a pen. The tip of the instrument is exchangeable. Using the fine tip enables multiplanar as well as curved cutting. Because of the automatic water cooling during the whole procedure, there is always a clear view onto the object. This is something oral surgeons found especially useful [6]. The authors mention that the downside of the device is the relative slow sawing process. We needed about 30 seconds for one cut of the relatively small bone. This is about 20 seconds longer than the time needed for cutting with the usual saw. Although the power can be regulated with the power box and the use of different scalpels, we agree with other authors that the optimal use of this device is in surgeries of small bones where precise and soft tissue friendly cutting is required [7]. As other literature has shown, the device selectively cuts bone while sparing nerves and other soft tissue [2,3]. This allows for minimal invasive surgeries with limited retraction of soft tissue and minimal stripping of the periosteum, saves time and might have a positive effect on the healing process. Our aim of the first time use of the Piezosurgery® Device in hand surgery was to check its usability in osteotomies of tubular bones. The preparation of the bone was done in the usual manner as is done when cutting with an oscillating saw. The reason for this was to fully visualize the cutting process using this new device, although in the future, it should be possible to minimize the bony exposure. In our patient the postoperative healing of the wound and the bone consolidation (Figure 4) were smooth. The duration of postoperative sick leave was four weeks which is more rapid than the usual recovery period. The patient regained full use of his finger according to the state before the fracture. At no point was there any loss of sensitivity. The patient as well as the surgeons were fully satisfied with the result.ConclusionThe Piezosurgery® Device is a useful device for small long bone osteotomies. We feel that this device has great potential in the field of hand- and spinal surgery. As the device selectively cuts bone, considerable nerve lesions can be avoided and minimal invasive surgeries are possible. Using the fine tip enables curved cutting and provides an opportunity for new osteotomy techniques.Competing interestsThe author(s) declare that they have no competing interests.Authors' contributionsDJH initiated and coordinated the new application of Piezosurgery® device and wrote the publication.StSt lead the osteotomy as he was experienced with this tool from oral surgery. He played a major part in writing the technical aspects.OVK was the treating surgeon, performed the operation and evaluated the new tool.SS performed a literature review and wrote part of the publication.PH was the treating chief surgeon, evaluated the new tool and lead the treatment in all aspects.ConsentWe obtained oral consent from the patient but could not obtain written consent.Pre-publication historyThe pre-publication history for this paper can be accessed here:","answer":"{\\"Species\\": [\\"patient\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Personalized Medicine applied to Forensic Sciences: new advances and perspectives for a tailored forensic approach Personalized medicine (PM), included in P5 medicine (Personalized, Predictive, Preventive, Participative and Precision medicine) is an innovative approach to the patient, emerging from the need to tailor and to fit the profile of each individual. PM promises to dramatically impact also on forensic sciences and justice system in ways we are only beginning to understand. The application of omics (genomic, transcriptomics, epigenetics/imprintomics, proteomic and metabolomics) is ever more fundamental in the so called \\" molecular autopsy \\". Emerging fields of interest in forensic pathology are represented by diagnosis and detection of predisposing conditions to fatal thromboembolic and hypertensive events, determination of genetic variants related to sudden death, such as congenital long QT syndromes, demonstration of lesions vitality, identification of biological matrices and species diagnosis of a forensic trace on crime scenes without destruction of the DNA. The aim of this paper is to describe the state-of-art in the application of personalized medicine in forensic sciences, to understand the possibilities of integration in routine investigation of these procedures with classical post-mortem studies and to underline the importance of these new updates in medical examiners' armamentarium in determining cause of death or contributing factors to death.","answer":"{\\"AnatomicalStructure\\": [], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"death\\", \\"congenital long QT syndromes\\", \\"destruction of the DNA\\", \\"thromboembolic\\", \\"hypertensive events\\"], \\"BiomedicalOccupationOrDiscipline\\": [\\"epigenetics/imprintomics\\", \\"proteomic\\", \\"metabolomics\\", \\"genomic\\", \\"forensic pathology\\", \\"transcriptomics\\"], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [\\"P5 medicine\\", \\"medicine\\"], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"vitality\\", \\"diagnosis\\", \\"lesions\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"PM\\", \\"molecular autopsy\\", \\"innovative approach\\", \\"Personalized medicine\\", \\"post-mortem studies\\", \\"detection\\", \\"investigation\\", \\"Personalized Medicine\\", \\"personalized medicine\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [\\"individual\\"], \\"ProfessionalOrOccupationalGroup\\": [\\"medical examinersu0027\\"], \\"ResearchActivity\\": [], \\"SpatialConcept\\": [\\"matrices\\"], \\"Virus\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Glucose-6-phosphate dehydrogenase variants from Italian subjects associated with severe neonatal jaundice. Screening for the G6PD deficiency was carried out at the Maternity Division of the Galliera Hospital in Genoa, Italy. Two groups of subjects with hyperbilirubinaemia of non-immunological origin were examined  (a) 302 newborn babies of Sardinian extraction (on cord blood) and (b) 201 newborn babies of south Italian ancestry (on peripheral blood). Among 503 subjects, 43 showed an enzyme deficiency; in 39 the defect was of the Mediterranean type. In one case, previously described, the enzyme was of the A- type. In the remaining cases three different variants were identified. In the present work these three cases, each with severe neonatal jaundice, are reported. Their parents originated from Calabria, from Sardinia and from Sicily. The abnormal enzymes are respectively designated as GdDcbrousse-like, GdGallura and GdAgrigento..","answer":"{\\"Disease\\": [\\"severe neonatal jaundice\\", \\"hyperbilirubinaemia\\", \\"G6PD deficiency\\"]}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: We propose a novel method, Class-Conditional Domain Adaptation, to address the domain adaptation problem inKeyphrases: unsupervised domain adaptation videoDataset description:Cityscapes: Cityscapes is a large-scale database which focuses on semantic understanding of urban street scenes. It provides semantic, instance-wise, and dense pixel annotations for 30 classes grouped into 8 categories (flat surfaces, humans, vehicles, constructions, objects, nature, sky, and void).VisDA-2017: VisDA-2017 is a simulation-to-real dataset for domain adaptation with over 280,000 images across 12 categories in the training, validation and testing domains. The training images are generated from the same object under different circumstances, while the validation images are collected from MSCOCO..Syn2Real: Syn2Real, a synthetic-to-real visual domain adaptation benchmark meant to encourage further development of robust domain transfer methods. The goal is to train a model on a synthetic \\"source\\" domain and then update it so that its performance improves on a real \\"target\\" domain, without using any target annotations.GTA5: The GTA5 dataset contains 24966 synthetic images with pixel level semantic annotation. The images have been rendered using the open-world video game Grand Theft Auto 5 and are all from the car perspective in the streets of American-style virtual cities.ImageCLEF-DA: The ImageCLEF-DA dataset is a benchmark dataset for ImageCLEF 2014 domain adaptation challenge, which contains three domains: Caltech-256 (C), ImageNet ILSVRC 2012 (I) and Pascal VOC 2012 (P). For each domain, there are 12 categories and 50 images in each category.Office-Home: Office-Home is a benchmark dataset for domain adaptation which contains 4 domains where each domain consists of 65 categories. The four domains are: Art – artistic images in the form of sketches, paintings, ornamentation, etc.Options:- A: Cityscapes  B: VisDA-2017  C: Syn2Real  D: GTA5  E: ImageCLEF-DA  F: Office-Home","answer":"[\\"Cityscapes\\", \\"GTA5\\"]"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:various disease states and medications can alter iron levels in the body , and hence affect ga-67 binding .we report a case of pyrexia of unknown origin where abnormal biodistribution of ga-67 in the skeleton was observed .a 23-year - old young male , with pyrexia of unknown origin , was referred to our department for a whole body gallium scan , in order to detect the primary disease focus .the patient had a history of high - grade continuous fever for the past month and no other complaints .this resulted in increased hemoglobin level of 9.2 gram percent on the day of the gallium scan .gallium scan was acquired at 24 hours after an intravenous injection of 5 mci of ga-67 citrate .simultaneous anterior and posterior images were acquired on a dual head ge infinia hawkeye single photon emission computed tomogaphy / computed tomography ( spect / ct ) scanner , using a medium energy collimator using 20% energy windows set at 93 , 184 , 297 kev photopeaks .these images [ figures 1a and 1b ] revealed diffuse tracer uptake in the skeleton with no uptake at normal physiological sites .there was a focus of uptake in the region of left kidney [ figure 1a -arrow ] .this was identical to a whole body 99 m tc methylene diphosphonate ( mdp ) bone scan . however , transaxial spect ct images of the abdomen [ figure 1c - axial ct , 1d - fused images ] revealed that the focus corresponded to bowel activity .a detailed review of history and mechanism of distribution of ga-67 , suggested that the skeletal uptake of gallium was due to iron overload following blood transfusions .whole body gallium scintigraphy ( a ) anterior and ( b ) posterior images show diffuse skeletal tracer uptake .focal tracer uptake seen in the region of left kidney on anterior images ( arrow ) .( c ) axial ct image shows focal tracer uptake corresponding to bowel uptake of gallium , better appreciated on ( d ) fused spect ct image .the primary uptake mechanism involves a carrier - mediated transport system , with ga-67 binding to transferrin , to cross - cell membranes . following entry into the cell , ga-67 binds to other iron binding complexes , mainly lactoferrin and transferrin .normal biodistribution of gallium is seen in liver ( highest uptake ) , spleen , salivary glands , nasopharynx , lacrimal glands , breast ( in pregnant and lactating women ) , lungs ( diffuse uptake upto 24 hours ) , kidneys and bladder ( route of excretion in first 24 hours ) and colon ( route of excretion after 24 hours ) . in the given scenario ,multiple blood transfusions led to an iron - overload state , thereby resulting in saturation of binding capacity of serum transferrin . as a resultthis results in increased bone uptake of tracer resulting in a gallium scan mimicking a whole body bone scan .similar situation is encountered in patients post chemotherapy or post - g  csf ( granulocyte - colony stimulating factor ) administration ; however , the diffuse uptake is due to marrow hyperstimulation .there are similar reports in literature highlighting the diffuse uptake of ga-67 in the bones .moreover , it once again highlights the importance of knowing the detailed history of the patient and adequate patient preparation , prior to any diagnostic procedure .detailed history is important in scintigraphic procedures , since a lot of drugs and biological products interfere with the binding of the tracer due to saturation of the receptor sites , thereby reducing the tracer uptake or altering the normal pathway of biodistribution , as seen in our case .","answer":"gallium-67 localization is based on the fact that it binds to plasma proteins like transferrin and lactoferrin , which have iron - binding sites .  abnormal biodistribution of gallium-67 citrate can occur in iron - overload states .  we report one such case of gallium scan mimicking a bone scan due to skeletal uptake of gallium ."},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: As mentioned, given an input mathbf{x}, we prompt the model to generate an output mathbf{y} and a sentence mathbf{u} expressing its understanding of the task.Thus, the in-context examples for oursare of the form mathbf{x}rightarrowmathbf{u},mathbf{y}.In addition to the input mathbf{x}, oursretrieves a mathbf{fb} if a question similar to mathbf{x} has been asked before.To enable the model to react to such feedback, we also include examples of the form (mathbf{x},mathbf{fb}rightarrowmathbf{u},mathbf{y}) in the prompt, which are aimed to teach the model to react to mathbf{fb} (Appendix D). Our approach, ours, pairs gpt-3 with a growing memory of cases where the model misunderstood user’s intent and was provided with corrective feedback.This feedback is question dependent, and thus the prompt for each sample is edited to adapt to the input.In this sense, our work can be seen as an instance of prompt engineering Liu et al. (2021b) which involves editing the prompts. Our work adds interactivity to prompt engineering as it involves dynamically updating the prompt for every instance. Once the feedback is received from the user, can the model successfully utilize it? By adding a few examples of the form mathbf{x},mathbf{fb}rightarrowmathbf{u},mathbf{y} in the prompt and setting mathbf{fb}=mathbf{u}, we force the model to use the task understanding present in the input when generating the output (Figure 4).Recently, it has been shown that such repetition plays a crucial role in the success of few-shot prompting models (Madaan and Yazdanbakhsh, 2022). Further, it is desirable to have a system that can leverage past feedback on new, unseen examples for prompt-editing. We maintain a memory mathcal{M} of such feedback as a set of key-value pairs, where thekey is a misunderstood question, and the value is the user’s feedback to correct that misunderstanding. Given a new question, we check if the model has made a mistakeon a similar question earlier, by querying the memory for a similar question. If found,append the corresponding feedback to the question prompt. This mechanism aims toprevent the model from making the same type of mistake twice. This failure-driven remindingmechanism draws inspiration from the theory of recursive reminding in psychology Jacoby and Wahlheim (2013),which suggests humans index error corrections in the context in which those errors occurred. In Tandon et al. (2022), we show that using a memory of user feedback can be used to repair erroneous model in a supervised setting.In this work, we build upon the recent advances in few-shot prompting to modify gpt-3’s behavior by adding user feedback to the query (prompt).Like others, we use gpt-3 with few-shot prompting, where the prompt consistsof a prefix prefix containing a few input-output “training” examples of the task, followed by the input x, e.g., a question,to operate on. However, while prior work has focused on constructing better prefixes, e.g., dynamically selecting good “training” examplesbased on the question Le Scao and Rush (2021); Liu et al. (2021a), or even representing the prefix latently Li and Liang (2021),our work elaborates the input x itself to clarify the intended task, by adding user feedback fb from previous misunderstandings.Question: With \\"memory of cases\\" here, do they simply mean a prompt that contains all of these cases as examples?","answer":"Yes, \\"memory of cases\\" in this context does mean a prompt with all of these relevant cases as examples listed out. However, the MemPrompt model's input size is limited to 2048-tokens, so adding all possible matches to the prompt would not be possible, which is why the authors' proposed approach specifically focuses on selecting which prompts to include."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Glucagon receptor antagonism improves islet function in mice with insulin resistance induced by a high-fat diet.AIMS/HYPOTHESIS: Increased glucagon secretion predicts deterioration of glucose tolerance, and high glucagon levels contribute to hyperglycaemia in type 2 diabetes. Inhibition of glucagon action may therefore be a potential novel target to reduce hyperglycaemia. Here, we investigated whether chronic treatment with a glucagon receptor antagonist (GRA) improves islet dysfunction in female mice on a high-fat diet (HFD). MATERIALS AND METHODS: After 8 weeks of HFD, mice were treated with a small molecule GRA (300 mg/kg, gavage once daily) for up to 30 days. Insulin secretion was studied after oral and intravenous administration of glucose and glucagon secretion after intravenous arginine. Islet morphology was examined and insulin secretion and glucose oxidation were measured in isolated islets. RESULTS: Fasting plasma glucose levels were reduced by GRA (6.0 +/- 0.2 vs 7.4 +/- 0.5 mmol/l; p = 0.017). The acute insulin response to intravenous glucose was augmented (1,300 +/- 110 vs 790 +/- 64 pmol/l; p < 0.001). The early insulin response to oral glucose was reduced in mice on HFD + GRA (1,890 +/- 160 vs 3,040 +/- 420 pmol/l; p = 0.012), but glucose excursions were improved. Intravenous arginine significantly increased the acute glucagon response (129 +/- 12 vs 36 +/- 6 ng/l in controls; p < 0.01), notably without affecting plasma glucose. GRA caused a modest increase in alpha cell mass, while beta cell mass was similar to that in mice on HFD + vehicle. Isolated islets displayed improved glucose-stimulated insulin secretion after GRA treatment (0.061 +/- 0.007 vs 0.030 +/- 0.004 pmol islet(-1) h(-1) at 16.7 mmol/l glucose; p < 0.001), without affecting islet glucose oxidation. CONCLUSIONS/INTERPRETATION: Chronic glucagon receptor antagonism in HFD-fed mice improves islet sensitivity to glucose and increases insulin secretion, suggesting improvement of key defects underlying impaired glucose tolerance and type 2 diabetes.","answer":"{\\"Chemical\\": [\\"arginine\\", \\"glucose\\"], \\"Protein\\": [\\"Insulin\\", \\"glucagon receptor\\", \\"Glucagon receptor\\", \\"glucagon\\", \\"insulin\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:An overview on the marine neurotoxin, saxitoxin: genetics, molecular targets, methods of detection and ecological functions.Marine neurotoxins are natural products produced by phytoplankton and select species of invertebrates and fish. These compounds interact with voltage-gated sodium, potassium and calcium channels and modulate the flux of these ions into various cell types. This review provides a summary of marine neurotoxins, including their structures, molecular targets and pharmacologies. Saxitoxin and its derivatives, collectively referred to as paralytic shellfish toxins (PSTs), are unique among neurotoxins in that they are found in both marine and freshwater environments by organisms inhabiting two kingdoms of life. Prokaryotic cyanobacteria are responsible for PST production in freshwater systems, while eukaryotic dinoflagellates are the main producers in marine waters. Bioaccumulation by filter-feeding bivalves and fish and subsequent transfer through the food web results in the potentially fatal human illnesses, paralytic shellfish poisoning and saxitoxin pufferfish poisoning. These illnesses are a result of saxitoxin's ability to bind to the voltage-gated sodium channel, blocking the passage of nerve impulses and leading to death via respiratory paralysis. Recent advances in saxitoxin research are discussed, including the molecular biology of toxin synthesis, new protein targets, association with metal-binding motifs and methods of detection. The eco-evolutionary role(s) PSTs may serve for phytoplankton species that produce them are also discussed.","answer":"{\\"Chemical\\": [\\"sodium\\", \\"calcium\\", \\"Saxitoxin\\", \\"potassium\\", \\"saxitoxin\\"], \\"Protein\\": [\\"voltage-gated sodium, potassium and calcium channels\\", \\"voltage-gated sodium channel\\", \\"metal-binding motifs\\"]}"},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: It is Unlikely That Influenza Viruses Will Cause a Pandemic Again Like What Happened in 1918 and 1919https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4019839/Song, Liting2014-05-07DOI:10.3389/fpubh.2014.00039License:cc-byAbstract: nanText: Influenza and influenza viruses are wellknown popular topics to medical professionals and the general public. Influenza viruses had caused a pandemic globally during 1918 and 1919, and that influenza pandemic had taken away more than 20 million people's lives in the world. However, in my opinion, it is unlikely that influenza viruses will again cause a pandemic on a level (both of the morbidity rate and the mortality rate) comparable to what happened in 1918 and 1919. Influenza viruses very easily reassort, recombine, and point mutate in nature due to their segmented RNA genome structures, however, unlike highly pathogenic (virulent) viruses like rabies virus, Lassa fever virus, smallpox virus, eastern equine encephalitis virus, Ebola virus, Marburg virus, and human immunodeficiency virus 1 (HIV-1); most influenza viruses (wild types and mutants) are moderately pathogenic. The case fatality rates of some highly virulent viruses and related references are listed in Table 1 . On November 11, 1918 , the fighting of World War I was stopped, and World War I was officially ended on June 28, 1919 with the signing of the Versailles Treaty. It is estimated that around 8.5-10 million soldiers lost their lives in World War I due to battle. The war also directly caused more than 6 million civilian deaths. Millions of people suffered from hunger and malnutrition during the war. Malnutrition weakened the human immune system and made a person more vulnerable to infectious diseases like tuberculosis and influenza, therefore, hunger and malnutrition were indirectly responsible for millions of deaths in the world in that period of time.  For example, about 700,000 Germans died from malnutrition-related diseases in the years of 1914-1918. During the 1918-1919 influenza pandemic, between 21 and 25 million people died of influenza worldwide. Those people were killed both directly and indirectly by influenza virus infections. Many families were too poor to buy food and coal, and to afford health care expenses when their family members were ill. Influenza virus could infect all members of a family, and this could result in no one left to feed the fires, and to prepare food for the whole family, even if they had firewood, coal, and food left in their homes. Sadly, a large number of people died of influenza virus infections along with starvation, cold, and poor living conditions (8) . In recent years, while hunger and malnutrition are not major and serious problems in some developed countries anymore, they are still very difficult to overcome in many developing countries. In these less-developed countries, there were approximately 925 million people who suffered from hunger; 125 million children were underweight; and 195 million children were stunted each year (9) . Nevertheless, in comparison to 1918 and 1919, currently, we have much better social and economic conditions and public health systems globally; and generally speaking, the majority of people in the world have better nutritional and educational statuses; better living and working conditions; therefore, better general health and immunity. Furthermore, in 1918 and 1919, physicians and nurses almost had nothing in their hands to help individuals who were infected by influenza viruses. Today, although we still do not have very effective, powerful, and practical anti-influenza drugs available, we at least have some improved, useful, and helpful anti-viral drugs like zanamivir, and effective, convenient anti-cold medicines like Tylenol or Advil. We do not have a universal vaccine to prevent all influenza virus infections, but we can make effective vaccines to a specific influenza virus strain in a short time. Actually, in the United States of America, the influenza classed mortality rate declined from 10.2/100,000 in the 1940s to 0.56/100,000 in the 1990s; and the classed mortality rates of 1957-1958 and 1968-1969 influenza pandemics were not remarkably different from the non-pandemic seasons (10) . Because of the above reasons, we can optimistically assume that even the same strain of influenza virus, which caused pandemic in 1918 and 1919, would not be able to kill millions of people and cause a pandemic comparable to the 1918-1919 pandemic again in the future. Additionally, a significant number of viruses can cause influenza-like syndromes, such as rhinovirus, parainfluenza virus, adenovirus, coronavirus, respiratory syncytial virus, Coxsackie B virus, echovirus, and metapneumovirus (11, 12) . Some of the above-mentioned viruses like adenovirus and mutated coronavirus could cause problems that are comparable to influenza viruses (13, 14) . The World Health Organization (WHO) mistakenly raised the level of influenza pandemic alert from phase 5 to the highest phase 6 on June 11, 2009 (15) . However, the truth was that most cases of H1N1 influenza A virus infections were mild, the symptomatic case fatality rate was only 0.005% in New Zealand (16) ; and in New York City, the case fatality rate was 0.0094-0.0147% for persons ≥65 years old, and for those of 0-17 years old, the case fatality rate was 0.0008-0.0012% (17) . Some researchers argued that it should not have been called an influenza pandemic in the first place if the clinical severity was considered (15, (18) (19) (20) . I believe it was unwise that we had paid too much www.frontiersin.org 23) . Not surprisingly, every year there would be some influenza patients and a few of them would die from the infections, as it is almost impossible to eliminate influenza viruses from the natural environment in many years. The severity of a viral infection is determined by both of the viral virulence (pathogenicity) and the host immunity. Some researchers' opinions on H7N9 avian influenza virus were incorrect and/or inadequate. They mainly focused on influenza viruses and worried about viral mutations, viral pathogenicity, viral adaptation, and transmission. They overestimated the negative part of socio-economic factors of the present east China: overcrowded population in the epidemic region; very busy national and international transportation and travel; a large number of live poultry markets . . . but they underestimated the currently changed, developed, and improved positive part of socio-economic factors in China. The following factors might be used to explain why that H7N9 influenza A virus epidemic was limited and controlled in China, and only a few immunocompromised patients were killed by H7N9 influenza A virus. First, China has a relatively organized and effective public health system, there are four levels of (national, provincial, prefectural-level city, and county) centers for disease control and prevention all over China (24) . Second, physicians and nurses in China were prepared and knowledgeable of influenza virus infections. Third, samples from patients with suspected influenza virus infections were collected and sent to the local and national centers for disease control and prevention promptly. H7N9 influenza A viruses were isolated and identified very quickly. Thereby, they were able to diagnose, confirm, and report three cases of H7N9 influenza patients in the early stage of the epidemic (24, 25) . Fourth, health care and public health workers were protected properly. Consequently, none of the health professionals was infected by H7N9 influenza A virus in 2013. However, a surgeon died of H7N9 influenza in Shanghai, China in January of 2014 (26) . Fifth, they detected H7N9 influenza A viruses from the samples of chickens, pigeons, and the environment of live poultry markets in Shanghai (27) ; and closed the live poultry markets of the involved epidemic region quickly. Sixth, patients were isolated and treated timely in hospitals, 74% (1251/1689) of those close contacts of H7N9 influenza patients were monitored and observed. Thus, H7N9 influenza A virus could not spread to a bigger population (24) . Last but not least, we are connected to the Internet now, and it seems that our planet is much smaller today than the earlier days when we did not have the Internet, because communication and information exchange have become so fast, easy, and convenient presently. During that avian influenza epidemic, some influenza experts in the world shared/exchanged H7N9 influenza A virus information and provided professional consultations and suggestions efficiently and rapidly. All these public health routine practices and measures resulted in that H7N9 influenza epidemic being controlled and stopped in China (24) . I have to point out that the cases of diagnosed H7N9 avian influenza A virus infection might only be the tip of the iceberg. Aside from one laboratory confirmed asymptotic case of H7N9 influenza A virus infection in Beijing (22), there were probably many undetected mild or asymptotic cases of influenza A H7N9 infection. The reason is that most people usually think a common cold is a very common and normal occurrence, and they don't take flu-like illnesses seriously. In most situations, they would just stay home and take some medicines. Only those who have very severe flu-like symptoms would see doctors, and thereby be detected and diagnosed, accordingly the real case fatality rate should be much lower than the detected 32.14% (45/140, one case from Taiwan, and one case from Hong Kong) (22, 23). Nowadays, we travel faster, and we travel more frequently and globally, and we have more complicated social activities and lifestyles, thereby increasing the chances of viral mutation; and we realize that influenza viruses are even easier to reassort, recombine, and mutate in nature than many other RNA viruses. However, we are now living in a technologically, economically, and socially much better and advanced society. I believe influenza virus infections are controllable and preventable, with the increased population health and immunity, with the WHO Global Influenza Surveillance and Response System, and with standard/routine epidemiological practices, and with new effective anti-viral agents and vaccines in production in the future. Now, I first predict that influenza viruses will unlikely again cause a pandemic on a level comparable to what happened in 1918 and 1919. Hopefully, one day we could consider a strategy to produce a universal vaccine that can prevent people from infections of all influenza virus strains, or we could produce some very effective anti-influenza virus drugs; then influenza would not be a problem anymore. We should learn lessons from the mistakes we made in the past. It is reasonable and necessary to be cautious about influenza viruses, but overreactions or catastrophic reactions should be avoided in the future. My opinion is anti-traditional; the purpose of this article is to influence public health policy, and to save some of the limited resources and money for more important diseases like heart diseases, cancer, diabetes, AIDS, hepatitises, and tuberculosis (15) . Liting Song: conception of manuscript, drafting of manuscript, critical revision of manuscript, and final approval of manuscript. The author would like to recognize the contributions of the reviewers and editors of this manuscript for their corrections and editing, and Dr. Emanuel Goldman for correcting errors related to grammar and syntax of the final manuscript.Question: What social and economic factors  contributed to the large fatality rate in the 1918 influenza pandemic?","answer":"Malnutrition weakened the human immune system and made a person more vulnerable to infectious diseases like tuberculosis and influenza, therefore, hunger and malnutrition were indirectly responsible for millions of deaths in the world in that period of time."},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:For nocodazole treatment of embryos, L4 worms were grown on perm-1(RNAi) feeding plates at 20¬∞C for 16-18 hr, then dissected in an open imaging chamber filled with osmotic support medium (Carvalho et al., 2011; Wueseke et al., 2016) and 20 ¬µg/ml nocodazole (Sigma).","answer":"Method"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:Distributed storage plays a crucial role in the current cloud computing framework. After the theoretical bound for distributed storage was derived by the pioneer work of the regenerating code, Reed-Solomon code based regenerating codes were developed. The RS code based minimum storage regeneration code (RS-MSR) and the minimum bandwidth regeneration code (RS-MBR) can achieve theoretical bounds on the MSR point and the MBR point respectively in code regeneration. They can also maintain the MDS property in code reconstruction. However, in the hostile network where the storage nodes can be compromised and the packets can be tampered with, the storage capacity of the network can be significantly affected. In this paper, we propose a Hermitian code based minimum storage regenerating (H-MSR) code and a minimum bandwidth regenerating (H-MBR) code. We first prove that our proposed Hermitian code based regenerating codes can achieve the theoretical bounds for MSR point and MBR point respectively. We then propose data regeneration and reconstruction algorithms for the H-MSR code and the H-MBR code in both error-free network and hostile network. Theoretical evaluation shows that our proposed schemes can detect the erroneous decodings and correct more errors in hostile network than the RS-MSR code and the RS-MBR code with the same code rate. Our analysis also demonstrates that the proposed H-MSR and H-MBR codes have lower computational complexity than the RS-MSR RS-MBR codes in both code regeneration and code reconstruction.Cited Abstract(s):[1]: Explores mechanisms for storage-level management in OceanStore, a global-scale distributed storage utility infrastructure, designed to scale to billions of users and exabytes of data. OceanStore automatically recovers from server and network failures, incorporates new resources and adjusts to usage patterns. It provides its storage platform through adaptation, fault tolerance and repair. The only role of human administrators in the system is to physically attach or remove server hardware. Of course, an open question is how to scale a research prototype in such a way to demonstrate the basic thesis of this article - that OceanStore is self-maintaining. The allure of connecting millions or billions of components together is the hope that aggregate systems can provide scalability and predictable behavior under a wide variety of failures. The OceanStore architecture is a step towards this goal.[2]: Distributed storage systems provide reliable access to data through redundancy spread over individually unreliable nodes. Application scenarios include data centers, peer-to-peer storage systems, and storage in wireless networks. Storing data using an erasure code, in fragments spread across nodes, requires less redundancy than simple replication for the same level of reliability. However, since fragments must be periodically replaced as nodes fail, a key question is how to generate encoded fragments in a distributed way while transferring as little data as possible across the network. For an erasure coded system, a common practice to repair from a single node failure is for a new node to reconstruct the whole encoded data object to generate just one encoded block. We show that this procedure is sub-optimal. We introduce the notion of regenerating codes, which allow a new node to communicate functions of the stored data from the surviving nodes. We show that regenerating codes can significantly reduce the repair bandwidth. Further, we show that there is a fundamental tradeoff between storage and repair bandwidth which we theoretically characterize using flow arguments on an appropriately constructed graph. By invoking constructive results in network coding, we introduce regenerating codes that can achieve any point in this optimal tradeoff.[3]:","answer":"When a storage node in the distributed storage network that employing the conventional @math RS code (such as OceanStore [1] and Total Recall [3] ) fails, the replacement node connects to @math nodes and downloads the whole file to recover the symbols stored in the failed node. This approach is a waste of bandwidth because the whole file has to be downloaded to recover a fraction of it. To overcome this drawback, Dimakis [2] introduced the concept of @math regenerating code. In the context of regenerating code, the replacement node can regenerate the contents stored in a failed node by downloading @math help symbols from @math helper nodes. The bandwidth consumption to regenerate a failed node could be far less than the whole file. A data collector (DC) can reconstruct the original file stored in the network by downloading @math symbols from each of the @math storage nodes. [2] , the authors proved that there is a tradeoff between bandwidth @math and per node storage @math . They find two optimal points: minimum storage regeneration (MSR) and minimum bandwidth regeneration (MBR) points."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: Blood clotting a significant cause of death in patients with COVID-19Abstract:The mortality rate of coronavirus disease-19 (COVID-19) has been reported as 1-6% in most studies.The cause of most deaths has been acute pneumonia.Nevertheless, it has been noted that cardiovascular failure can also lead to death.Three COVID-19 patients were diagnosed based on reverse transcriptase-polymerase chain reaction of a nasopharyngeal swab test and radiological examinations in our hospital.The patients received medications at the discretion of the treating physician.In this case series, chest computed tomography scans and electrocardiograms, along with other diagnostic tests were used to evaluate these individuals.Sudden cardiac death in COVID-19 patients is not common, but it is a major concern.So, it is recommended to monitor cardiac condition in selected patients with COVID-19.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"The cause of most deaths has been acute pneumonia.\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Results:All fractures united. Individual movement of dorsiflexion, palmar flexion, supination, pronation and radial-ulnar deviation were all significantly better in the dorsiflexed-immobilized group as compared with the palmar flexed immobilized group. Grip strength recovery with subjective assessment was better in the dorsiflexed group (77%) as compared to the palmar flexed group (23%). Radiological parameters were markedly better in the dorsiflexed group. Ninety-one per cent of patients in the dorsiflexed group had excellent to good results as compared to 66% in the palmar flexed group.","answer":"{\\"AnatomicalEntity\\": [\\"radial\\", \\"ulnar\\", \\"palmar\\"]}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:An investigation of patients with pulmonary tuberculosis in Kuwait in preparation for studies of immunotherapy with Mycobacterium vaccae.Abstract 1:Sixty-five patients, many of them immigrant to Kuwait, with bacteriologically proven, adult type, pulmonary tuberculosis were studied by many parameters over the 4 months following diagnosis. Twelve were infected with tubercle bacilli resistant to at least one anti-tuberculosis drug. Preliminary evidence suggested that this was frequently primary resistance in patients infected in their countries of origin. The Kuwaiti environment results in very high skin test and lymphocyte proliferative responses (LTT) to shared and species specific antigens of mycobacteria in healthy persons. In comparison, patients with tuberculosis lacked cellular responses to group i and group ii antigens, but had increased IgG and IgA binding to mycobacterial antigens in general. LTT responses to added interleukin 2, and production of alpha interferon, were normal in our patients, but induction of gamma interferon in response to phytohaemagglutinin was reduced initially, rising towards normal during treatment. Biochemical and haematological abnormalities present at the time of diagnosis rapidly corrected. The disease differed from that reported in most previous studies in that fever was uncommon, the disease was never fatal, and most tuberculin tests were not necrotising. This implied that a detrimental immunopathological component is less pronounced in those exposed to the Kuwaiti environment, and a hypothesis is put forward to explain this.Title 2:Immunotherapy with Mycobacterium vaccae in patients with newly diagnosed pulmonary tuberculosis: a randomised controlled trial. Durban Immunotherapy Trial Group.Abstract 2:Mycobacterium vaccae, an environmental saprophyte, has immunogenic properties that enhance the host immune response. Immunotherapy with M. vaccae has been suggested to shorten short-course antituberculosis chemotherapy. We tested the hypothesis that the addition of M. vaccae to standard short-course antituberculosis chemotherapy would decrease the time to achieve a negative sputum culture.                Patients with newly diagnosed tuberculosis were randomly assigned an injection of saline (placebo) or M. vaccae on day 8. All patients received antituberculosis chemotherapy with rifampicin, isoniazid, pyrazinamide, and ethambutol. Sputum samples were checked by microscopy and culture every week for the first 8 weeks and monthly until the end of chemotherapy at 6 months. The primary outcome was the time to a negative sputum culture in the first 8 weeks. Intention-to-treat analysis was used and time to sputum clearance was assessed by log-rank test and Cox's proportional-hazards regression.                172 patients received M. vaccae and 175 patients received placebo. At 8 weeks, 70 patients in the M. vaccae group and 65 patients in the placebo group had a negative culture; there was no difference between groups in the time to a negative culture (p=0.83). There was no interaction between HIV status and treatment.                M. vaccae immunotherapy has no benefit when added to standard antituberculosis chemotherapy.Title 3:Immunotherapy with Mycobacterium vaccae in the treatment of tuberculosis in Romania. 1. Newly-diagnosed pulmonary disease.Abstract 3:In this study, 206 previously untreated patients with sputum culture positive pulmonary tuberculosis were randomized to receive an injection of killed Mycobacterium vaccae as immunotherapy, or of saline as placebo, after 1 month of a 6-month chemotherapeutic regime. Not surprisingly in a disease for which there is good chemotherapy, the difference in numbers which were culture negative at the end of treatment was small, and the final outcome at the latest post-treatment follow-up did not reach statistical significance between the two arms of the study. Nonetheless, those receiving immunotherapy showed better progression in every parameter measured, suggesting faster and more complete cure. Whereas seven of 97 patients receiving immunotherapy required a course of re-treatment and five still had active disease after a mean follow-up of 2 yr, 13 of 109 placebo recipients required re-treatment and nine still had active disease at the end of the study. Only one patient receiving M. vaccae plus chemotherapy died of tuberculosis, compared with four of those receiving chemotherapy alone. A degree of drug resistance was shown by the bacilli cultured from 25 of 175 (14%) patients, and seven of them (4.0%) were multi-drug resistant. Fourteen patients received immunotherapy of whom 13 were cured, including all three of those showing multi-drug resistance. Of the 11 patients with drug resistance in the control group, eight were cured, and one patient with multi-drug-resistant disease died of tuberculosis during re-treatment.Title 4:Immunotherapy with Mycobacterium vaccae in the treatment of tuberculosis in Romania. 2. Chronic or relapsed disease.Abstract 4:In this study of 102 patients with culture-positive chronic treatment failure or repeatedly relapsed pulmonary tuberculosis receiving chemotherapy, 56 received an injection of killed Mycobacterium vaccae as immunotherapy after 1 month of treatment. At the start of treatment, there was little difference between those receiving immunotherapy and the 46 patients in the control group receiving chemotherapy alone. Thereafter, the two groups diverged so that 1 yr later, 43 of 56 (77%) patients receiving M. vaccae had a successful outcome, in comparison with 24 of 46 (52%) patients receiving chemotherapy alone (P < 0.02). Successful results were obtained from patients infected with drug-resistant bacilli, 20 of 32 (63%) patients compared with 11 of 25 (44%) patients, respectively, as well as from fully drug-sensitive cases (23 of 24 compared with 12 of 21 patients; P = 0.004). At the final follow-up after 22 months, 13 of 56 patients receiving immunotherapy had an unfavourable outcome compared with 26 of 46 members of the control group (P = 0.0006). During the study, 16 patients died of tuberculosis (six after immunotherapy), and 12 were lost to follow-up. Not only was bacteriological success improved by immunotherapy, chest X-ray showed markedly better resolution of cavities and other radiological lesions, recovery of body weight was improved, and the mean erythrocyte sedimentation rate returned almost to normal (P < 0.001) in comparison with those receiving chemotherapy alone. These changes were seen even in those failing bacteriological cure, suggesting that the immunotherapy had been effective, but that bacilli were replicating in an extracellular situation, protecting them from its effects.Title 5:Mycobacterium vaccae: a study of safety and outcome measures.Abstract 5:nanTitle 6:Randomized controlled trial of Mycobacterium vaccae immunotherapy in non-human immunodeficiency virus-infected ugandan adults with newly diagnosed pulmonary tuberculosis. The Uganda-Case Western Reserve University Research Collaboration.Abstract 6:Adjunctive immunotherapy with heat-killed Mycobacterium vaccae was studied in a randomized, placebo-controlled trial of 120 non-human immunodeficiency virus-infected adults with newly diagnosed pulmonary tuberculosis. Patients were randomized to a single dose of M. vaccae or placebo 1 week after beginning chemotherapy and were followed up for 1 year. M. vaccae was safe and well tolerated. The rate of sputum culture conversion after 1 month of tuberculosis treatment was 35% in the M. vaccae group and only 14% in the placebo group (P=.01) but was comparable at 2 months and thereafter. Patients receiving M. vaccae had greater improvement on chest radiography at 6 months (91% vs. 77% for placebo recipients; P=.04) and 12 months (94% vs. 80%; P=.04) after initiation of tuberculosis treatment. These data provide evidence of an early increase in sputum culture conversion and greater radiographic improvement among patients who received M. vaccae. Further studies are warranted.Title 7:Mycobacterium vaccae (SRL172) immunotherapy as an adjunct to standard antituberculosis treatment in HIV-infected adults with pulmonary tuberculosis: a randomised placebo-controlled trial.Abstract 7:Mortality rates of HIV-infected patients treated for tuberculosis remain high. This study aimed to assess the effect on mortality of immunotherapy with single-dose SRL172 added to standard antituberculosis chemotherapy in such patients.                The double-blind trial enrolled 1229 patients aged 18-60 years, who had never received antiretroviral treatment and who presented with newly diagnosed, sputum-smear-positive pulmonary tuberculosis to referral centres in Lusaka, Zambia, and Karonga, Malawi. Both HIV-positive and HIV-negative patients were enrolled, to avoid stigmatisation. Participants were randomly assigned a single injection of SRL172 or matching placebo within 2 weeks of starting 8 months of antituberculosis chemotherapy and followed up for at least 12 months. The primary endpoint was time to death in the HIV-infected population. Analyses were based on 760 HIV-positive patients after exclusion of 84 patients with errors in storage of the injection, no bacteriological confirmation, or no HIV result.                Of 760 HIV-infected patients, 374 received SRL172 and 386 received placebo. SRL172 did not cause any serious adverse events. The follow-up rate was 88% at 12 months in both groups. Of the HIV-positive patients, 109 (19.5 per 100 person-years) of 372 assigned SRL172 and 107 (19.3 per 100 person-years) of 386 assigned placebo died. In the Cox's regression analysis, stratified by centre, the hazard ratio of deaths (SRL172/placebo) was 1.03 (95% CI 0.79-1.35). There was no evidence of benefit to the group assigned SRL172.                Immunotherapy with single-dose SRL172 as an adjunct to standard antituberculosis treatment in HIV-positive adults with pulmonary tuberculosis had no significant effect on survival or bacteriological outcome, though the treatment was safe and well tolerated.","answer":"M. vaccae immunotherapy does not benefit people with tuberculosis. No further trials are warranted and, as a result, the authors do not intend to update this review."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Leukotriene D4 induces cognitive impairment through enhancement of CysLT₁ R-mediated amyloid-β generation in mice. Amyloid plaques in the extracellular parenchyma mainly consist of amyloid-β peptides (Aβ), one of the pathological hallmarks in Alzheimer 's disease (AD). In the present study, we examined neuroinflammation, amyloidogenesis, and memory performance following intracerebral infusions of leukotriene D4 (LTD4) in mice. The results demonstrated that intracerebral infusions of LTD4 (1 ng/mouse) produced memory impairment as determined by Morris water maze test and Y-maze test in mice, and caused the accumulation of Aβ1-40 and Aβ1-42 in the hippocampus and cortex through increased activity of β- and γ-secretases accompanied with increased expression of amyloid precursor protein (APP). LTD4 also induced expression of cysteinyl leukotriene receptor 1 (CysLT (1) R) and NF-κB p65 in the hippocampus and cortex. Pretreatment with pranlukast (1.5 ng/mouse, intracerebroventricularly), a CysLT (1) R antagonist, blocked LTD4-induced amyloidogenesis, memory deficits. Pranlukast (0.6 μM) also prevented LTD4 (20 nM) -induced amyloidogenesis in the cultured neurons in vitro. Moreover, LTD4-induced increases in CysLT (1) R and NF-κB p65 in the brain were also attenuated by pranlukast. These results suggest that LTD4 increases Aβ peptide burden via activation of CysLT (1) R, which further affects APP levels and activity of β- and γ-secretases via the NF-κB pathway. Our findings identify CysLT (1) R signaling as a novel proinflammatory and proamyloidogenic pathway, and suggest a rationale for development of therapeutics targeting the CysLT (1) R in neuroinflammatory diseases such as AD.","answer":"[[\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"APP\\"], [\\"pranlukast\\", \\"INDIRECT-DOWNREGULATOR\\", \\"p65\\"], [\\"Leukotriene D4\\", \\"INDIRECT-UPREGULATOR\\", \\"amyloid-u03b2\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"p65\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"amyloid precursor protein\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"CysLT (1) R\\"], [\\"pranlukast\\", \\"INDIRECT-DOWNREGULATOR\\", \\"CysLT (1) R\\"], [\\"LTD4\\", \\"REGULATOR\\", \\"NF-u03baB\\"], [\\"pranlukast\\", \\"INDIRECT-DOWNREGULATOR\\", \\"NF-u03baB\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"Au03b2 peptide\\"], [\\"LTD4\\", \\"ACTIVATOR\\", \\"CysLT (1) R\\"], [\\"pranlukast\\", \\"ANTAGONIST\\", \\"CysLT (1) R\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"Au03b21 - 40\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"Au03b21 - 42\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"cysteinyl leukotriene receptor 1\\"], [\\"LTD4\\", \\"INDIRECT-UPREGULATOR\\", \\"NF-u03baB\\"], [\\"LTD4\\", \\"INDIRECT-REGULATOR\\", \\"APP\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"IGF\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:NK1.1(-) CD4(+) NKG2D(+) T cells suppress DSS-induced colitis in mice through production of TGF-β. CD4(+) NKG2D(+) T cells are associated with tumour, infection and autoimmune diseases. Some CD4(+) NKG2D(+) T cells secrete IFN-γ and TNF-α to promote inflammation, but others produce TGF-β and FasL to facilitate tumour evasion. Here, murine CD4(+) NKG2D(+) T cells were further classified into NK1.1(-) CD4(+) NKG2D(+) and NK1.1(+) CD4(+) NKG2D(+) subpopulations. The frequency of NK1.1(-) CD4(+) NKG2D(+) cells decreased in inflamed colons, whereas more NK1.1(+) CD4(+) NKG2D(+) cells infiltrated into colons of mice with DSS-induced colitis. NK1.1(-) CD4(+) NKG2D(+) cells expressed TGF-β and FasL without secreting IFN-γ, IL-21 and IL-17 and displayed no cytotoxicity. The adoptive transfer of NK1.1(-) CD4(+) NKG2D(+) cells suppressed DSS-induced colitis largely dependent on TGF-β. NK1.1(-) CD4(+) NKG2D(+) cells did not expressed Foxp3, CD223 (LAG-3) and GITR. The subpopulation was distinct from NK1.1(+) CD4(+) NKG2D(+) cells in terms of surface markers and RNA transcription. NK1.1(-) CD4(+) NKG2D(+) cells also differed from Th2 or Th17 cells because the former did not express GATA-3 and ROR-γt. Thus, NK1.1(-) CD4(+) NKG2D(+) cells exhibited immune regulatory functions, and this T cell subset could be developed to suppress inflammation in clinics.","answer":"{\\"Gene\\": [\\"NK1.1\\", \\"NKG2D\\", \\"TNF-u03b1\\", \\"CD223\\", \\"ROR-u03b3t\\", \\"Foxp3\\", \\"FasL\\", \\"GITR\\", \\"IL-17\\", \\"IFN-u03b3\\", \\"CD4\\", \\"IL-21\\", \\"LAG-3\\", \\"TGF-u03b2\\", \\"GATA-3\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Serum amyloid A and P protein genes in familial Mediterranean fever. Two recent studies have suggested the involvement of serum amyloid A (SAA) and P (APCS) genes in familial Mediterranean fever (MEF). To test the role of SAA and APCS in MEF and MEF-amyloidosis, we studied 17 informative families (15 Armenians, 2 non-Ashkenazi Jews) and 8 MEF patients with amyloidosis using a candidate gene approach. No evidence for any MEF-associated polymorphism was found in any of the 41 Armenian and Jewish MEF patients tested. Our family studies allowed us to rule out tight linkage between SAA and MEF (lod score = -2. 16, theta less than or equal to 0. 06). For APCS we found that the allele frequency in the MEF-amyloidosis patients was similar to that in 18 unrelated MEF patients without amyloidosis and their 33 healthy parents.","answer":"{\\"Disease\\": [\\"amyloidosis\\", \\"MEF\\", \\"familial Mediterranean fever\\", \\"MEF-amyloidosis\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:A prospective study on the clinical performance of polysiloxane soft liners : one-year results . OBJECTIVE The aim of the present study was to evaluate the clinical performance of four denture soft liners up to 12 months . MATERIALS AND METHODS Thirty-three edentulous patients who experienced difficulties when using hard denture bases because of changes in denture-supporting tissues were accepted for the study and randomly received Molloplast B , GC Reline Soft , Silagum Comfort , or Mollosil Plus relines . Performance of the materials was evaluated using nine criteria at 3 , 6 , and 12 months : physical integrity , surface detail , adhesion , color , odor , plaque accumulation , resilience , hygiene , and mucosal condition . A four-point categorized scale ( 1=poor , 2=fair , 3=good , 4=excellent ) was used . Unscheduled maintenance events and the presence of fungal colonization were also recorded . RESULTS The percentage of patients available at 3 , 6 , and 12 months were 91 % , 91 % , and 66 % . Main reasons for dropouts and discontinuation were fractured dentures and patient dissatisfaction . At 6 months , 96 % of the performance scores were good or excellent and the largest changes were observed for physical integrity , surface detail , color , and fungal colonization . Fungal colonization was the most commonly observed problem and was the only reason of failure at 12 months . CONCLUSIONS The clinical performance of all soft liners was slightly impaired over the 12-month observation . Except for cases showing extensive fungal colonization , the observed changes in clinical performance did not necessitate remaking of the dentures . Mollosil Plus showed a performance comparable to that of Molloplast B , and the other materials had slightly lower performance especially in terms of fungal colonization .","answer":"{\\"Intervention\\": [\\"Mollosil Plus\\", \\"Molloplast B\\", \\"denture soft liners\\", \\"Molloplast B , GC Reline Soft , Silagum Comfort , or Mollosil Plus relines\\", \\"polysiloxane soft liners\\"], \\"Outcome\\": [\\"performance scores\\", \\"fungal colonization\\", \\"Unscheduled maintenance events\\", \\"presence of fungal colonization\\", \\"patient dissatisfaction\\", \\"physical integrity , surface detail , adhesion , color , odor , plaque accumulation , resilience , hygiene , and mucosal condition\\", \\"fractured dentures\\", \\"physical integrity , surface detail , color ,\\", \\"Fungal colonization\\"], \\"Participant\\": []}"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Music relies heavily on repetition to build structure and meaning.  Self-reference occurs on multiple timescales, from motifs to phrases to reusing of entire sections of music, such as in pieces with ABA structure.  The Transformer (Vaswani et al., 2017), a sequence model based on self-attention, has achieved compelling results in many generation tasks that require maintaining long-range coherence.This suggests that self-attention might also be well-suited to modeling music.In musical composition and performance, however, relative timing is critically important.  Existing approaches for representing relative positional information in the Transformer modulate attention based on pairwise distance (Shaw et al., 2018).  This is impractical for long sequences such as musical compositions since their memory complexity is quadratic in the sequence length.  We propose an algorithm that reduces the intermediate memory requirements to linear in the sequence length.This enables us to demonstrate that a Transformer with our modified relative attention mechanism can generate minute-long (thousands of steps) compositions with compelling structure, generate continuations that coherently elaborate on a given motif, and in a seq2seq setup generate accompaniments conditioned on melodies.   We evaluate the Transformer with our relative attention mechanism on two datasets, JSB Chorales and Piano-e-competition, and obtain state-of-the-art results on the latter.A musical piece often consists of recurring elements at various levels, from motifs to phrases to sections such as verse-chorus.To generate a coherent piece, a model needs to reference elements that came before, sometimes in the distant past, and then repeat, vary, and further develop them to create contrast and surprise.Intuitively, self-attention (Parikh et al., 2016) could be a good match for this task.Self-attention over its own previous outputs allows an autoregressive model to access any part of the previously generated output at every step of generation.By contrast, recurrent neural networks have to learn to proactively store elements to be referenced in a fixed size state or memory, making training potentially much more difficult.We believe that repeating self-attention in multiple, successive layers of a Transformer decoder BID17 can help capture the multiple levels at which self-referential phenomena exist in music.In its original formulation, the Transformer relies on absolute position representations, using either positional sinusoids or learned position embeddings that are added to the per-position input representations.Recurrent and convolutional neural networks instead model position in relative terms: RNNs through their recurrence over the positions in their input, and CNNs by applying kernels that effectively choose which parameters to apply based on the relative position of the covered input representations.Music has multiple dimensions along which relative differences arguably matter more than their absolute values; the two most prominent are timing and pitch.To capture such pairwise relations between representations, BID13 introduce a relation-aware version of self-attention which they use successfully to modulate self-attention by the distance between two positions.We extend this approach to capture relative timing and optionally also pitch, which yields improvement in both sample quality and perplexity for the JSB Chorales dataset.As opposed to the original Transformer, samples from a Transformer with our relative attention mechanism maintain the regular timing grid present in this dataset.The model furthermore captures global timing, giving rise to regular phrases.The original formulation of relative attention BID13 requires O(L 2 D) memory where L is the sequence length and D is the dimension of the model's hidden state.This is prohibitive for long sequences such as those found in the Maestro dataset of human-performed virtuosic, classical piano music BID7 .In Section 3.4, we show how to reduce the memory requirements to O(LD), making it practical to apply relative attention to long sequences.The Maestro dataset consists of MIDI recorded from performances of competition participants, bearing expressive dynamics and timing on a less than 10-millisecond granularity.Discretizing time in a fixed grid on such a resolution would yield unnecessarily long sequences as not all events change on the same timescale.We hence adopt a sparse, MIDI-like, event-based representation from (Oore et al., 2018) , allowing a minute of music with a 10-millisecond resolution to be represented at lengths around 2K.This is in contrast to a 6K to 18K length that would be needed on a serialized multi-attribute fixed-grid representation.As position in sequence no longer corresponds to time, a priori it is not obvious that relative attention should work as well with such a representation.However, we will show in Section 4.2 that it does improve perplexity and sample quality over strong baselines.We speculate that idiomatic piano gestures such as scales, arpeggios and other motifs all exhibit a certain grammar and recur periodically, hence knowing their relative positional distances makes it easier to model this regularity.This inductive bias towards learning relational information, as opposed to patterns based on absolute position, suggests that the Transformer with relative attention could generalize beyond the lengths it was trained on, which our experiments in Section 4.2.1 confirm.In this work we demonstrated that the Transformer equipped with relative attention is very well-suited for generative modeling of symbolic music.The compelling long-term structure in the samples from our model leaves us enthusiastic about this direction of research.Moreover, the ability to expand upon a prime, in particular, suggests potential applications as creative tool.The significant improvement from relative attention highlights a shortcoming of the original Transformer that might also limit its performance in other domains.Improving the Transformer's ability to capture periodicity at various time scales, for instance, or relations between scalar features akin to pitch could improve time-series models.Our memory-efficient implementation enables the application of relative attention to much longer sequences such as long texts or even audio waveforms, which significantly broadens the range of problems to which it could be applied.","answer":"We show the first successful use of Transformer in generating music that exhibits long-term structure."},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(PURPOSE) Prior decision-analytic models are based on outdated or suboptimal efficacy, patient preference, and comorbidity data. We estimated life expectancy (LE) and quality-adjusted life expectancy (QALE) associated with available treatments for localized prostate cancer in men aged>/= 65 years, adjusting for Gleason score, patient preferences, and comorbidity.(METHODS) We evaluated three treatments, using a decision-analytic Markov model: radical prostatectomy (RP), external beam radiotherapy (EBRT), and watchful waiting (WW). Rates of treatment complications and pretreatment incontinence and impotence were derived from published studies. We estimated treatment efficacy using three data sources: cancer registry cohort data, pooled case series, and modern radiotherapy studies. Utilities were obtained from 141 prostate cancer patients and from published studies.(RESULTS) For men with well-differentiated tumors and few comorbidities, potentially curative therapy (RP or EBRT) prolonged LE up to age 75 years but did not improve QALE at any age. For moderately differentiated cancers, potentially curative therapy resulted in LE and QALE gains up to age 75 years. For poorly differentiated disease, potentially curative therapy resulted in LE and QALE gains up to age 80 years. Benefits of potentially curative therapy were restricted to men with no worse than mild comorbidity. When cohort and pooled case series data were used, RP was preferred over EBRT in all groups but was comparable to modern radiotherapy.Question:Do older men benefit from curative therapy of localized prostate cancer?Answer:","answer":"YES"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Age > 50 yearsSmoking history > 10 packs/yearFEV1 30 - 79% of predicted and FEV1/FVC < 70% (GOLD 2-3)FRC > 120 % predictedBorg dyspnea score > 3 during the 3-min constant rate shuttle walking test at V3","answer":"{\\"Condition\\": [], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [\\"FEV1\\", \\"FEV1/FVC\\", \\"Borg dyspnea score\\", \\"GOLD\\", \\"FRC\\", \\"Smoking history\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [\\"Age\\"], \\"Procedure\\": [], \\"Qualifier\\": [\\"V3\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"GOLD 2-3\\", \\"FEV1/FVC u003c 70%\\"], \\"Temporal\\": [\\"3-min constant rate shuttle walking test\\"], \\"Value\\": [\\"u003e 3\\", \\"u003e 10 packs/year\\", \\"u003e 50 years\\", \\"u003e 120 % predicted\\", \\"u003c 70%\\", \\"2-3\\", \\"30 - 79% of predicted\\"], \\"Visit\\": []}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: We propose a novel feature mask network for person re-identification. By incorporating attention mechanism andKeyphrases: person re-identification imagesDataset description:CUHK02: CUHK02 is a dataset for person re-identification. It contains 1,816 identities from two disjoint camera views.DukeMTMC-reID: The DukeMTMC-reID (Duke Multi-Tracking Multi-Camera ReIDentification) dataset is a subset of the DukeMTMC for image-based person re-ID. The dataset is created from high-resolution videos from 8 different cameras.CUHK-PEDES: The CUHK-PEDES dataset is a caption-annotated pedestrian dataset. It contains 40,206 images over 13,003 persons.P-DESTRE: Provides consistent ID annotations across multiple days, making it suitable for the extremely challenging problem of person search, i.e., where no clothing information can be reliably used. Apart this feature, the P-DESTRE annotations enable the research on UAV-based pedestrian detection, tracking, re-identification and soft biometric solutions.Market-1501: Market-1501 is a large-scale public benchmark dataset for person re-identification. It contains 1501 identities which are captured by six different cameras, and 32,668 pedestrian image bounding-boxes obtained using the Deformable Part Models pedestrian detector.BraTS 2017: The BRATS2017 dataset. It contains 285 brain tumor MRI scans, with four MRI modalities as T1, T1ce, T2, and Flair for each scan.Options:- A: CUHK02  B: DukeMTMC-reID  C: CUHK-PEDES  D: P-DESTRE  E: Market-1501  F: BraTS 2017","answer":"[\\"DukeMTMC-reID\\", \\"Market-1501\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Disease evolution in late-onset and early-onset systemic lupus erythematosus Objective The objective of this study was to compare clinical features, disease activity, and outcome in late-onset versus early-onset systemic lupus erythematosus (SLE) over 5 years of follow up Method Patients with SLE since 1970 were followed prospectively according to standard protocol and tracked on a computerized database. Patients entering the cohort within one year of diagnosis constitute the inception cohort. Patients with late-onset (age at diagnosis ≥50) disease were identified and matched 1:2 based on gender and first clinic visit (±5) years with patients with early-onset disease (age at diagnosis 18-40 years). Results A total of 86 patients with late-onset disease (84.9% female, 81.4% Caucasian, mean age at SLE diagnosis ± SD 58.05 ± 7.30) and 169 patients with early-onset disease (86.4% female, 71% Caucasian, mean age at SLE diagnosis ± SD 27.80 ± 5.90) were identified. At enrollment, late-onset SLE patients had a lower total number of American College of Rheumatology (ACR) criteria, with less renal and neurologic manifestations. Mean SLE Disease Activity Index 2000 (SLEDAI-2K) scores were lower in late-onset SLE, especially renal features and anti-dsDNA positivity. Over 5 years, mean SLEDAI-2K scores decreased in both groups, while mean Systemic Lupus International Collaborating Clinics/ACR Damage Index (SDI) scores increased more significantly in the late-onset group; they developed more cardiovascular, renal, and ocular damage, and had higher prevalence of cardiovascular risk factors. Conclusion Although the late-onset SLE group had a milder presentation and less active disease, with the evolution of disease, they developed more organ damage likely as a consequence of cardiovascular risk factors and aging.","answer":"{\\"AnatomicalStructure\\": [\\"organ\\"], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"disease\\", \\"systemic lupus erythematosus\\", \\"aging\\", \\"SLE\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [], \\"ClinicalAttribute\\": [\\"renal features\\"], \\"Eukaryote\\": [], \\"Finding\\": [\\"neurologic manifestations\\", \\"anti-dsDNA positivity\\", \\"less active\\", \\"renal\\", \\"diagnosis\\", \\"early-onset\\", \\"outcome\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"clinic visit\\", \\"follow up\\", \\"standard protocol\\"], \\"InjuryOrPoisoning\\": [\\"cardiovascular\\"], \\"IntellectualProduct\\": [\\"Systemic Lupus International Collaborating Clinics/ACR Damage Index (SDI) scores\\", \\"SLEDAI-2K scores\\", \\"objective\\", \\"American College of Rheumatology (ACR) criteria\\", \\"SLE Disease Activity Index 2000 (SLEDAI-2K) scores\\"], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [\\"Caucasian\\", \\"cohort\\"], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"study\\"], \\"SpatialConcept\\": [], \\"Virus\\": []}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Optogenetics enables real-time spatiotemporal control over spiral wave dynamics in an excitable cardiac system}Article:Abstract:Propagation of non-linear waves is key to the functioning of diverse biological systems. Such waves can organize into spirals, rotating around a core, whose properties determine the overall wave dynamics. Theoretically, manipulation of a spiral wave core should lead to full spatiotemporal control over its dynamics. However, this theory lacks supportive evidence( even at a conceptual level), making it thus a long-standing hypothesis. Here, we propose a new phenomenological concept that involves artificially dragging spiral waves by their cores, to prove the aforementioned hypothesis in silico, with subsequent in vitro validation in optogenetically modified monolayers of rat atrial cardiomyocytes. We thereby connect previously established, but unrelated concepts of spiral wave attraction, anchoring and unpinning to demonstrate that core manipulation, through controlled displacement of heterogeneities in excitable media, allows forced movement of spiral waves along pre-defined trajectories. Consequently, we impose real-time spatiotemporal control over spiral wave dynamics in a biological system.Introduction:Self-organization of macroscopic structures through atomic, molecular or cellular interactions is characteristic of many non-equilibrium systems. Such emergent dynamic ordering often reveals fundamental universalities( Cross and Hohenberg, 1993). One example is the occurrence of rotating spiral waves. Spiral waves are found in diverse natural systems: from active galaxies( Schulman and Seiden, 1986), to simple oscillatory chemical reactions( Belousov, 1985; Zhabotinsky, 1991), to social waves in colonies of giant honey bees( Kastberger et al., 2008), to Min protein gradients in bacterial cell division( Caspi and Dekker, 2016), and to the formation of vortices in fluids flowing past obstacles( Karman, 1937). While being beneficial to some systems, for example slime molds, where they guide morphogenesis, such activity has detrimental consequences for other systems including the heart, where they underlie lethal cardiac arrhythmias( Davidenko et al., 1990). Understanding the dynamics of spiral waves in order to establish functional control over a system, has intrigued researchers for many decades. It has been reported that irrespective of the nature of the excitable medium, spiral wave activity organizes around an unexcitable center( core), whose properties determine its overall dynamics( Krinsky, 1978; Beaumont et al., 1998). Theorists attribute such particle-like behavior of a spiral wave to an underlying topological charge, which controls its short-range interaction, annihilation, and the ability to form intricate bound states with other spirals( Ermakova et al., 1989; Schebesch and Engel, 1999; Steinbock et al., 1992). Rotational activity similar to spiral waves can also occur around small structural or functional heterogeneities( e. g. areas of conduction block). In this case, the dynamics of the rotating wave and its spatial position are determined by the location and properties of the heterogeneity. Thus, in theory, by controlling the position and size of spiral wave cores, one can precisely and directly control the dynamics of spiral waves in general. In order to achieve such control, it is therefore logical, to consider as a first step, possible core-targeting via the conversion of a free spiral wave to an anchored rotational activity. To this end, a detailed mechanistic study was performed by Steinbock et al.( 1993), who demonstrated the possibility to forcibly anchor meandering spiral waves in an excitable light-sensitive Belousov-Zhabotinsky( BZ) reaction system. Furthermore, Ke et al.( 2015) demonstrated in a three-dimensional BZ reaction setting, that forced anchoring of scroll waves to thin glass rods, followed by subsequent movement of the rods themselves, could enable scroll wave relocation. On a broader perspective, this could have significant meaning for the heart, where controlling the dynamics of scroll waves could add to the treatment of cardiac arrhythmias sustained by such waves. In cardiac tissue, the analogs of a classical spiral wave and a wave rotating around a heterogeneity, are, respectively, functional and anatomical reentry, both of which are recognized as drivers of arrhythmias. Interestingly, functional and anatomical reentrant waves are closely related to each other. Seminal findings by Davidenko et al.( 1991) demonstrated that a drifting spiral wave could anchor to an obstacle and thereby make a transition from functional to anatomical reentry. Conversely, Ripplinger et al.( 2006) showed that small electric shocks could unpin a reentrant wave rotating around an obstacle, bringing about the reverse transition from anatomical to functional reentry. Nakouzi et al.( 2016) and Zykov et al.( 2010) demonstrated that the transitions between anchored and free spiral states may be accompanied by hysteresis near the heterogeneities. Furthermore, Defauw et al.( 2014) showed that small-sized anatomical heterogeneities could attract spiral waves from a close distance, and even lead to their termination if located near an unexcitable boundary. However, to date, all studies dedicated to spiral wave attraction and anchoring involved the presence of anatomically predefined, permanent heterogeneities, or continuous-in-time processes, thereby making it impossible to manipulate spiral wave cores in a flexible, systematic and dynamical manner. In the present study, we propose a new phenomenological concept to demonstrate real-time spatiotemporal control over spiral wave dynamics through discrete, systematic, manipulation of spiral wave cores in a spatially extended biological medium, that is cardiac tissue. We establish such control through optogenetics( Boyden et al., 2005; Bi et al., 2006; Deisseroth, 2015; McNamara et al., 2016), which allows the creation of spatially and temporally predefined heterogeneities at superb resolution at any location within an excitable medium. Previous studies for example by Arrenberg et al.( 2010); Bruegmann et al.( 2010); Jia et al.( 2011); Bingen et al.( 2014); Entcheva and Bub( 2016) and Burton et al.( 2015), demonstrate the power of optogenetics in cardiac systems. Thus, the same technology was chosen to strategically exploit fundamental dynamical properties of spiral waves, like attraction, anchoring and unpinning, to discretely and effectively steer spiral wave cores along any desired path within an excitable monolayer of cardiac cells. These findings are highly relevant for understanding non-linear wave dynamics and pattern formation in excitable biological media, as they enable, for the first time, real-time discrete dynamic control over processes that are associated with self-sustained spiraling phenomena, for example reentrant electrical activity, cAMP cycles and movement of cytosolic free Ca2+, to name a few. In particular, in the heart, tight control of spiral waves may allow restoration of normal wave propagation.Discussion:Since we demonstrate AAD control method in a cardiac tissue system, a logical question would be, how to envision the application of this principle to the real heart in order to treat arrhythmias? Currently this topic faces major challenges. The practical application of optogenetics in cardiology is, in itself, a debatable issue. However, with recent advances in cardiac optogenetics( Nussinovitch and Gepstein, 2015; Crocini et al., 2016; Nyns et al., 2017; Bruegmann et al., 2018; Boyle et al., 2018), the future holds much promise. Firstly, we envision the usage of AAD control method in treating arrhythmias that are associated with scroll waves. Since the penetration depth of light in cardiac tissue is relatively short( Bruegmann et al., 2016), full transmural illumination might be challenging, particularly in ventricles of large mammals like pig, monkey or human. There, AAD control may provide a powerful tool to regulate scroll wave dynamics by epicardial or endocardial illumination. Furthermore, we expect the method to prove most useful when dealing with ‘hidden’ spiral waves, that is spiral waves in remote locations of the heart that are unaccessible by ablation catheters. Ideally, one should build upon the concept introduced by Entcheva and Bub( 2016). With live spacetime optogenetic actuation of the electrical activity in different parts of the heart, the first step is to detect the location of the instability. Next, one can use a catheter with an in-built LED to attract the scroll wave filament and steer it towards the nearest tissue border for termination. The advantage of this method lies in that one does not require to ablate, and thereby destroy, excitable cardiac tissue, thus avoiding the possibility to create permanent damage to the heart. In addition, as our study demonstrates, anchoring of the spiral core( scroll filament) can occur even if the ‘precise’ location of the core is not identified. Lastly, the discrete nature of our method allows temporal flexibility in steering the spiral core( scroll filament), in that, temporary loss of communication between the catheter and the spiral core will not lead to failure of the technique in general. The reversible nature of the AAD control technique makes it unsuitable for terminating arrhythmias that rely on the establishment of a permanent conduction block as can be produced via conventional catheter ablation. However, this special feature of AAD may come with certain unique advantages that should be explored in more detail in future studies. For example, in younger patients that are expected to undergo periodic repetitive ablation for termination of reoccurring arrhythmias of unknown origin, the non-destructive nature of AAD may prove to be more desirable than the cumulative widespread destruction of cardiac tissue by radiofrequency or cryoballoon ablation. Alternatively, other methods could be developed and explored for AAD control without the need of optogenetic modification, while still relying on the creation of spatiotemporally controlled heterogeneities for attraction, anchoring and dragging of spiral waves. In this study, we focus on spiral waves in cardiac excitable media, as these abnormal waves have been associated with lethal heart rhythm disturbances, while their management and termination remain a serious challenge. The insights gained from our results, as well as the AAD control method itself, may not only improve our understanding of spiral wave’s dynamics in favor of restoring normal cardiac rhythm, but also create incentive to explore these principles in other excitable media prone to spiral wave development.","answer":"From a spinning galaxy to a swarm of honeybees , rotating spirals are widespread in nature . Even within the muscles of the heart , waves of electrical activity sometimes rotate spirally , leading to irregular heart rhythms or arrhythmia – a condition that can be fatal . Irrespective of where they occur , spiral waves organize around a center or core with different biophysical properties compared to the rest of the medium . The properties of the core determine the overall dynamics of the spiral . This means that , theoretically , it should be possibly to completely control a spiral wave just by manipulating its core . Now , Majumder , Feola et al . have tested this long-standing hypothesis using a combination of computer modeling and experiments with single layers of rat heart cells grown in a laboratory . First , the heart cells were genetically modified so that their electrical properties could be altered with light; in other words , the cells were put under optical control . Next , by using of a narrow beam of light , Majumder , Feola et al . precisely controlled the electrical properties of a small number of cells , which then attracted and supported a rotating spiral wave by acting as its new core . Moving the light beam allowed the core of the spiral wave to be shifted too , meaning the spiral wave could now be steered along any desired path in the cell layer . Majumder , Feola et al . hope that these underlying principles may one day provide the basis of new treatments for irregular heartbeats that are more effective and less damaging to the heart than existing options . Yet first , more work is needed to translate these findings from single layers of cells to actual hearts ."},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Chemical reactions can be described as the stepwise redistribution of electrons in molecules.As such, reactions are often depicted using \\"arrow-pushing\\" diagrams which show this movement as a sequence of arrows.We propose an electron path prediction model (ELECTRO) to learn these sequences directly from raw reaction data.Instead of predicting product molecules directly from reactant molecules in one shot, learning a model of electron movement has the benefits of(a) being easy for chemists to interpret,(b) incorporating constraints of chemistry, such as balanced atom counts before and after the reaction, and(c) naturally encoding the sparsity of chemical reactions, which usually involve changes in only a small number of atoms in the reactants.We design a method to extract approximate reaction paths from any dataset of atom-mapped reaction SMILES strings.Our model achieves excellent performance on an important subset of the USPTO reaction dataset, comparing favorably to the strongest baselines.Furthermore, we show that our model recovers a basic knowledge of chemistry without being explicitly trained to do so.The ability to reliably predict the products of chemical reactions is of central importance to the manufacture of medicines and materials, and to understand many processes in molecular biology.Theoretically, all chemical reactions can be described by the stepwise rearrangement of electrons in molecules (Herges, 1994b) .This sequence of bond-making and breaking is known as the reaction mechanism.Understanding the reaction mechanism is crucial because it not only determines the products (formed at the last step of the mechanism), but it also provides insight into why the products are formed on an atomistic level.Mechanisms can be treated at different levels of abstraction.On the lowest level, quantum-mechanical simulations of the electronic structure can be performed, which are prohibitively computationally expensive for most systems of interest.On the other end, chemical reactions can be treated as rules that \\"rewrite\\" reactant molecules to products, which abstracts away the individual electron redistribution steps into a single, global transformation step.To combine the advantages of both approaches, chemists use a powerful qualitative model of quantum chemistry colloquially called \\"arrow pushing\\", which simplifies the stepwise electron shifts using sequences of arrows which indicate the path of electrons throughout molecular graphs (Herges, 1994b) .Recently, there have been a number of machine learning models proposed for directly predicting the products of chemical reactions BID2 Jin et al., 2017; Schwaller et al., 2018; Segler and Waller, 2017a; Segler et al., 2018; Wei et al., 2016) , largely using graph-based or machine translation models. The taskof reaction product prediction is shown on the left-hand side of FIG0 .In this paperwe propose a machine learning model to predict the reaction mechanism, as shown on the right-hand side of FIG0 , for a particularly important subset of organic reactions. We argue thatour The reaction product prediction problem: Given the reactants and reagents, predict the structure of the product. (Right) The reactionmechanismprediction problem: Given the reactants and reagents, predict how the reaction occurred to form the products.model is not only more interpretable than product prediction models, but also allows easier encoding of constraints imposed by chemistry. Proposed approaches topredicting reaction mechanisms have often been based on combining hand-coded heuristics and quantum mechanics BID0 Kim et al., 2018; Nandi et al., 2017; Segler and Waller, 2017b; Rappoport et al., 2014; Simm and Reiher, 2017; Zimmerman, 2013) , rather than using machine learning. We call our model ELECTRO, as it directly predicts the path of electrons through molecules (i.e., the reaction mechanism). To train the model we devisea general technique to obtain approximate reaction mechanisms purely from data about the reactants and products. This allows one to train oura model on large, unannotated reaction datasets such as USPTO (Lowe, 2012) . We demonstrate that not onlydoes our model achieve impressive results, surprisingly it also learns chemical properties it was not explicitly trained on.In this paper we proposed ELECTRO, a model for predicting electron paths for reactions with linear electron flow.These electron paths, or reaction mechanisms, describe how molecules react together.Our model(i) produces output that is easy for chemists to interpret, and(ii) exploits the sparsity and compositionality involved in chemical reactions.As a byproduct of predicting reaction mechanisms we are also able to perform reaction product prediction, comparing favorably to the strongest baselines on this task.","answer":"A generative model for reaction prediction that learns the mechanistic electron steps of a reaction directly from raw reaction data."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:none, all patients meeting the inclusion criteria will be eligible.","answer":"{\\"Condition\\": [], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [], \\"Procedure\\": [], \\"Qualifier\\": [], \\"ReferencePoint\\": [], \\"Scope\\": [], \\"Temporal\\": [], \\"Value\\": [], \\"Visit\\": []}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Five-year findings of the hypertension detection and follow-up program. I. Reduction in mortality of persons with high blood pressure, including mild hypertension. Hypertension Detection and Follow-up Program Cooperative Group.Abstract 1:The Hypertension Detection and Follow-up Program (HDFP), in a community-based, randomized controlled trial involving 10,940 persons with high blood pressure (BP), compared the effects on five-year mortality of a systematic antihypertensive treatment program (Stepped Care [SC]) and referral to community medical therapy (Referred Care [RC]). Participants, recruited by population-based screening of 158,906 people aged 30 to 69 years in 14 communities througout the United States, were randomly assigned to SC or RC groups within each center and by entry diastolic blood pressure (DBP) (90 to 104, 105 to 114, and 115 + mm Hg). Over the five years of the study, more than two thirds of the SC participants continued to receive medication, and more than 50% achieved BP levels within the normotensive range, at or below the HDFP goal for DBP. Controls of BP was consistently better for the SC than for the RC group. Five-year mortality from all causes was 17% lower for the SC group compared to the RC group (6.4 vs 7.7 per 100, P less than .01) and 20% lower for the SC subgroup with entry DBP of 90 to 104 mm Hg compared to the corresponding RC subgroup (5.9 vs 7.4 per 100, P less than .01). These findings of the HDFP indicate that the systematic effective management of hypertension has a great potential for reducing mortality for the large numbers of people with high BP in the population, including those with \\"mild\\" hypertension.Title 2:Morbidity and mortality in the Swedish Trial in Old Patients with Hypertension (STOP-Hypertension)Abstract 2:Although the benefits of antihypertensive treatment in \\"young\\" elderly (under 70 years) hypertensive patients are well established, the value of treatment in older patients (70-84 years) is less clear. The Swedish Trial in Old Patients with Hypertension (STOP-Hypertension) was a prospective, randomised, double-blind, intervention study set up to compare the effects of active antihypertensive therapy (three beta-blockers and one diuretic) and placebo on the frequency of fatal and non-fatal stroke and myocardial infarction and other cardiovascular death in hypertensive Swedish men and women aged 70-84 years. We recruited 1627 patients at 116 health centres throughout Sweden, who were willing to participate, and who met the entry criteria of three separate recordings during a 1-month placebo run-in period of systolic blood pressure between 180 and 230 mm Hg with a diastolic pressure of at least 90 mm Hg, or a diastolic pressure between 105 and 120 mm Hg irrespective of the systolic pressure. The total duration of the study was 65 months and the average time in the study was 25 months. 812 patients were randomly allocated active treatment and 815 placebo. The mean difference in supine blood pressure between the active treatment and placebo groups at the last follow-up before an endpoint, death, or study termination was 19.5/8.1 mm Hg. Compared with placebo, active treatment significantly reduced the number of primary endpoints (94 vs 58; p = 0.0031) and stroke morbidity and mortality (53 vs 29; p = 0.0081). Although we did not set out to study an effect on total mortality, we also noted a significantly reduced number of deaths in the active treatment group (63 vs 36; p = 0.0079). The benefits of treatment were discernible up to age 84 years. We conclude that antihypertensive treatment in hypertensive men and women aged 70-84 confers highly significant and clinically relevant reductions in cardiovascular morbidity and mortality as well as in total mortality.Title 3:Mortality and morbidity results from the European Working Party on High Blood Pressure in the Elderly trial.Abstract 3:A double-blind randomised placebo-controlled trial of antihypertensive treatment was conducted in patients over the age of 60. Entry criteria included both a sitting diastolic blood pressure on placebo treatment in the range 90-119 mm Hg and a systolic pressure in the range 160-239 mm Hg. 840 patients were randomised either to active treatment (hydrochlorothiazide + triamterene) or to matching placebo. If the blood pressure remained raised, methyldopa was added to the active regimen and matching placebo in the placebo group. An overall intention-to-treat analysis, combining the double-blind part of the trial and all subsequent follow-up, revealed a non-significant change in total mortality rate (-9%, p = 0.41) but a significant reduction in cardiovascular mortality rate (-27%, p = 0.037). The latter was due to a reduction in cardiac mortality (-38%, p = 0.036) and a non-significant decrease in cerebrovascular mortality (-32%, p = 0.16). In the double-blind part of the trial, total mortality rate was not significantly reduced (-26%, p = 0.077). Cardiovascular mortality was reduced in the actively treated group (-38%, p = 0.023), owing to a reduction in cardiac deaths (-47%, p = 0.048) and a non-significant decrease in cerebrovascular mortality (-43%, p = 0.15). Deaths from myocardial infarction were reduced (-60%, p = 0.043). Study-terminating morbid cardiovascular events were significantly reduced by active treatment (-60%, p = 0.0064). Non-terminating cerebrovascular events were reduced (-52%, p = 0.026), but the non-terminating cardiac events were not (+3%, p = 0.98). In the patients randomised to active treatment there were 29 fewer cardiovascular events and 14 fewer cardiovascular deaths per 1000 patient years during the double-blind part of the trial.Title 4:Morbidity and mortality in the Systolic Hypertension in the Elderly Program (SHEP) pilot study.Abstract 4:The pilot study of the Systolic Hypertension in the Elderly Program was a randomized, double-blind, placebo-controlled trial of drug therapy for isolated systolic hypertension. It followed 551 elderly participants with untreated blood pressures of greater than 160/less than 90 mm Hg for an average of 34 months. Mean age of the participants was 72 years; 63% were women, and 82% were white. Pretreatment blood pressures averaged 172/75 mm Hg. Participants were randomly assigned to treatment with chlorthalidone or placebo as Step I medication. Blood pressures at annual visits averaged 141/68 and 157/73 mm Hg for the drug-treated and placebo-treated groups, respectively, with 60% and 33% of the survivors on blinded medication having systolic blood pressures of less than 160 mm Hg at their last annual visit. All-cause mortality rates for the drug-treated and placebo-treated groups were 25.4 and 22.7 deaths per 1,000 participant-years of risk, and rates for definite \\"first stroke\\" were 8.3 and 12.8 per 1,000 years of risk. Differences between groups were significant for systolic and diastolic blood pressure but not for death or stroke rates. A full-scale study has begun to determine the effects of drug therapy for isolated systolic hypertension on stroke and mortality rates.Title 5:Prevention of stroke by antihypertensive drug treatment in older persons with isolated systolic hypertension. Final results of the Systolic Hypertension in the Elderly Program (SHEP). SHEP Cooperative Research Group.Abstract 5:To assess the ability of antihypertensive drug treatment to reduce the risk of nonfatal and fatal (total) stroke in isolated systolic hypertension.                Multicenter, randomized, double-blind, placebo-controlled.                Community-based ambulatory population in tertiary care centers.                4736 persons (1.06%) from 447,921 screenees aged 60 years and above were randomized (2365 to active treatment, 2371 to placebo). Systolic blood pressure ranged from 160 to 219 mm Hg and diastolic blood pressure was less than 90 mm Hg. Of the participants, 3161 were not receiving antihypertensive medication at initial contact, and 1575 were. The average systolic blood pressure was 170 mm Hg; average diastolic blood pressure, 77 mm Hg. The mean age was 72 years, 57% were women, and 14% were black.                --Participants were stratified by clinical center and by antihypertensive medication status at initial contact. For step 1 of the trial, dose 1 was chlorthalidone, 12.5 mg/d, or matching placebo; dose 2 was 25 mg/d. For step 2, dose 1 was atenolol, 25 mg/d, or matching placebo; dose 2 was 50 mg/d.                Primary. Nonfatal and fatal (total) stroke. Secondary. Cardiovascular and coronary morbidity and mortality, all-cause mortality, and quality of life measures.                Average follow-up was 4.5 years. The 5-year average systolic blood pressure was 155 mm Hg for the placebo group and 143 mm Hg for the active treatment group, and the 5-year average diastolic blood pressure was 72 and 68 mm Hg, respectively. The 5-year incidence of total stroke was 5.2 per 100 participants for active treatment and 8.2 per 100 for placebo. The relative risk by proportional hazards regression analysis was 0.64 (P = .0003). For the secondary end point of clinical nonfatal myocardial infarction plus coronary death, the relative risk was 0.73. Major cardiovascular events were reduced (relative risk, 0.68). For deaths from all causes, the relative risk was 0.87.                In persons aged 60 years and over with isolated systolic hypertension, antihypertensive stepped-care drug treatment with low-dose chlorthalidone as step 1 medication reduced the incidence of total stroke by 36%, with 5-year absolute benefit of 30 events per 1000 participants. Major cardiovascular events were reduced, with 5-year absolute benefit of 55 events per 1000.Title 6:Effect of two different therapeutic approaches on total and cardiovascular mortality in a Cardiovascular Study in the Elderly (CASTEL).Abstract 6:Although limited numbers of elderly subjects have occasionally been included in population-based studies, only a few studies have been conducted specifically on elderly hypertensives, and practically none at a population level. We studied 655 hypertensive subjects from a cohort of 2,254 elderly subjects. The intervention consisted of the creation of a Hypertension Outpatients' Clinic under our auspices but with complete co-operation from general practitioners, randomizing the identified hypertensive patients into pre-established therapeutic drug regimens, and early follow-up recording of mortality for 7 years. The drugs used were clonidine (n = 61), nifedipine (n = 146) and the fixed combination of atenolol+chlorthalidone (n = 144); 304 subjects underwent \\"free therapy\\" by their personal physicians without any special intervention. There were 1,404 normotensive subjects. Overall 7-year follow-up mortality was 34.9% in the hypertensive subjects receiving \\"free therapy\\", 22.5% in those receiving \\"special care\\", and 24.2% in the normotensives. Cardiovascular mortality was respectively 23.7%, 12.2%, and 12.0%. Overall and cardiovascular annual cumulative mortality were significantly lower in the < special therapy > than in the < free therapy > group. The fixed combination of atenolol and chlorthalidone reduced mortality below that of the normotensives, independent of other cardiovascular risk factors.","answer":"Hypertension treatment lowers the relative and absolute risk of cardiovascular morbidity and mortality in women ages 55 years and older, and in African American women of all ages. A greater effort should be made to increase awareness and treatment in these groups of women. Although relative risk reductions for cerebrovascular and cardiovascular events are similar for younger and older women, the NNT of younger women is at least 4 times higher. Decisions for treatment of hypertension in younger white women should be influenced by the individual patient's absolute risk of cardiovascular disease."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Education, socioeconomic status and intelligence in childhood and stroke risk in later life: A meta-analysis Stroke is the second most common cause of death, and a common cause of dependency and dementia. Adult vascular risk factors and socioeconomic status (SES) are associated with increased risk, but less is known about early life risk factors, such as education, childhood SES, or intelligence (IQ). We comprehensively searched Medline, PsycINFO and EMBASE from inception to November 2015. We included all studies reporting data on >50 strokes examining childhood /premorbid IQ, SES, and education. Two reviewers independently screened full texts and extracted and cross-checked data, including available risk-factor adjustments. We meta-analyzed stroke risk using hazard ratios (HR), odds ratios (OR) and mean differences (MD). We tested effects of study and participant characteristics in sensitivity analyses and meta-regression, and assessed heterogeneity and publication bias. We identified 90 studies examining stroke risk and education (79), SES (10), or IQ (nine) including approximately 161,001 stroke and over 5 million stroke-free participants. Stroke risk increased with lower education (OR =1.35, 95% CI =1.24 to 1.48), SES (OR =1.28, 95% CI =1.12 to 1.46) and IQ (HR =1.17, 95% CI =1.00 to 1.37) in studies reporting point estimates, with similar associations for MD. We found minimal publication bias. Between-study heterogeneity was partly explained by participant age and case ascertainment method. Education, childhood SES and intelligence have modest but important associations with lifetime stroke, and hence dementia, risks. Future studies distinguishing between the individual and combined effects of education, childhood SES and intelligence are needed to determine the independent contribution of each factor to stroke risk.","answer":"{\\"AnatomicalStructure\\": [\\"vascular\\"], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"Stroke\\", \\"strokes\\", \\"intelligence\\", \\"dementia\\", \\"dependency\\", \\"stroke\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"risk-factor\\", \\"cause of death\\", \\"risk factors\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"reporting\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [\\"Medline\\", \\"case ascertainment method\\", \\"EMBASE\\", \\"meta-regression\\", \\"stroke risk\\", \\"Stroke risk\\"], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [\\"participants\\", \\"reviewers\\", \\"participant\\"], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"studies\\", \\"meta-analyzed\\", \\"meta-analysis\\"], \\"SpatialConcept\\": [], \\"Virus\\": []}"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:ThesedataconfirmtheeffectsofCarfhg2onadiposityandFeml2onlengthandindicatetheisolatedeffectsofCarfhg2aremoresignificantthanoriginallyobserved.","answer":"[]"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:The affected follicular structure is unable to develop terminal hair and sebaceous glands, producing only soft keratin and, more rarely, vellus hair that occludes the adnexal ostia instead (4,7).","answer":"Background"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"SSX\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Purification, cloning, and characterization of a human coactivator, PC4, that mediates transcriptional activation of class II genes. Activator-dependent transcription in mammalian cells requires upstream stimulatory activity (USA)-derived cofactors in addition to those present in TFIID. A novel positive cofactor (PC4) purified from the human USA fraction effected a marked enhancement (up to 85-fold) of GAL4-AH-dependent transcription in conjunction with TFIID and other general factors. Isolation of a corresponding cDNA identified PC4 as a 127 residue single-stranded DNA-binding protein with serine-rich regions near the N-terminus. Recombinant PC4 was functionally equivalent to native PC4, and both proteins markedly enhanced activation by diverse activation domains fused to the DNA-binding domain of GAL4. Recombinant PC4 interacted independently both with free or DNA-bound VP16 activation domains and with free or DNA-bound TFIIA-TBP complexes (but not with TBP alone). These results indicate that PC4 is a general coactivator that functions cooperatively with TAFs and mediates functional interactions between upstream activators and the general transcriptional machinery.","answer":"{\\"Gene\\": [\\"TBP\\", \\"PC4\\", \\"transcriptional activation of class II\\", \\"DNA-bound VP16 activation domains\\", \\"diverse activation domains\\", \\"DNA-binding domain\\", \\"DNA-bound TFIIA-TBP\\", \\"DNA-binding protein\\", \\"TFIID\\", \\"upstream stimulatory activity (USA)-derived cofactors\\", \\"GAL4\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Naloxone\\", ...], \\"Disease\\" : [\\"Hypotensive\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Recurrent use of newer oral contraceptives and the risk of venous thromboembolism. The epidemiological studies that assessed the risk of venous thromboembolism (VTE) associated with newer oral contraceptives (OC) did not distinguish between patterns of OC use, namely first-time users, repeaters and switchers. Data from a Transnational case-control study were used to assess the risk of VTE for the latter patterns of use, while accounting for duration of use. Over the period 1993-1996, 551 cases of VTE were identified in Germany and the UK along with 2066 controls. Totals of 128 cases and 650 controls were analysed for repeat use and 135 cases and 622 controls for switching patterns. The adjusted rate ratio of VTE for repeat users of third generation OC was 0.6 (95% CI:0.3-1.2) relative to repeat users of second generation pills, whereas it was 1.3 (95% CI:0.7-2.4) for switchers from second to third generation pills relative to switchers from third to second generation pills. We conclude that second and third generation agents are associated with equivalent risks of VTE when the same agent is used repeatedly after interruption periods or when users are switched between the two generations of pills. These analyses suggest that the higher risk observed for the newer OC in other studies may be the result of inadequate comparisons of pill users with different patterns of pill use.","answer":"{\\"Chemical\\": [\\"oral contraceptives\\", \\"OC\\"], \\"Disease\\": [\\"VTE\\", \\"venous thromboembolism\\"]}"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: While the absolute encoding methods listed above can be used with message passing GNNs, they also play a crucial role in the (graph) Transformer architecture. Graph Transformer (Dwivedi & Bresson, 2021) provided an early example of how to generalize the Transformer architecture to graphs, using Laplacian eigenvectors as an absolute encoding and computing attention on the immediate neighborhood of each node, rather than on the full graph. SAN (Kreuzer et al., 2021) also used the Laplacian eigenvectors for computing an absolute encoding, but computed attention on the full graph, while distinguishing between true and created edges. Many graph Transformer methods also use a relative encoding (Shaw et al., 2018) in addition to absolute encoding. This strategy incorporates representations of the relative position or distances between nodes on the graph directly into the self-attention mechanism, as opposed to the absolute encoding which is only applied once to the input node features. Mialon et al. (2021) propose a relative encoding by means of kernels on graphs to bias the self-attention calculation, which is then able to incorporate positional information into Transformers via the choice of kernel function. Other recent work seeks to incorporate structural information into the graph Transformer, for example by encoding some carefully selected graph theoretic properties such as centrality measures and shortest path distances as positional representations (Ying et al., 2021) or by using GNNs to integrate the graph structure (Rong et al., 2020; Jain et al., 2021; Mialon et al., 2021; Shi et al., 2021).Question: What are the advantages of using relative encoding compared to absolute encoding, which performs well?","answer":"The advantage of relative encoding compared to absolute encoding is the flexibility of using representations of position or distances into the self-attention mechanism directly.The reason is that self-attentions using absolute encoding only use node features, but self-attention mechanisms with relative encoding are able to utilize representations."},{"question":"You will be shown sections from a scientific research paper, together with a question about the paper. Your task is to answer the question based on the contents of the paper. Your response should be a \`json\` object with two fields:\\"answer\\": An array of strings extracted directly from the paper which, collectively, answer the question.\\"evidence\\": An array of strings. Each should be an excerpt from the paper, in which one or more of the extracted answers can be found.For instance, for the question \\"What baselines did the authors compare against?\\", a sample response might be:{  \\"answer\\": [\\"BERT\\", \\"RoBERTa\\"],  \\"evidence\\": [\\"In our experiments, we compare the performance of our model against BERT and RoBERTa.\\"]}Do not include any text in your response other than the json.If the question is unanswerable given the provided excerpts, respond with the single word \\"null\\".Paper: Improving Quality and Efficiency in Plan-based Neural Data-to-Text GenerationWe follow the step-by-step approach to neural data-to-text generation we proposed in Moryossef et al (2019), in which the generation process is divided into a text-planning stage followed by a plan-realization stage. We suggest four extensions to that framework: (1) we introduce a trainable neural planning component that can generate effective plans several orders of magnitude faster than the original planner; (2) we incorporate typing hints that improve the model's ability to deal with unseen relations and entities; (3) we introduce a verification-by-reranking stage that substantially improves the faithfulness of the resulting texts; (4) we incorporate a simple but effective referring expression generation module. These extensions result in a generation process that is faster, more fluent, and more accurate.IntroductionIn the data-to-text generation task (D2T), the input is data encoding facts (e.g., a table, a set of tuples, or a small knowledge graph), and the output is a natural language text representing those facts. In neural D2T, the common approaches train a neural end-to-end encoder-decoder system that encodes the input data and decodes an output text. In recent work BIBREF0 we proposed to adopt ideas from “traditional” language generation approaches (i.e. BIBREF1, BIBREF2, BIBREF3) that separate the generation into a planning stage that determines the order and structure of the expressed facts, and a realization stage that maps the plan to natural language text. We show that by breaking the task this way, one can achieve the same fluency of neural generation systems while being able to better control the form of the generated text and to improve its correctness by reducing missing facts and “hallucinations”, common in neural systems.In this work we adopt the step-by-step framework of BIBREF0 and propose four independent extensions that improve aspects of our original system: we suggest a new plan generation mechanism, based on a trainable-yet-verifiable neural decoder, that is orders of magnitude faster than the original one (§SECREF3); we use knowledge of the plan structure to add typing information to plan elements. This improves the system's performance on unseen relations and entities (§SECREF4); the separation of planning from realizations allows the incorporation of a simple output verification heuristic that drastically improves the correctness of the output (§SECREF5); and finally we incorporate a post-processing referring expression generation (REG) component, as proposed but not implemented in our previous work, to improve the naturalness of the resulting output (§SECREF6).Step-by-step GenerationWe provide a brief overview of the step-by-step system. See BIBREF0 for further details. The system works in two stages. The first stage (planning) maps the input facts (encoded as a directed, labeled graph, where nodes represent entities and edges represent relations) to text plans, while the second stage (realization) maps the text plans to natural language text.The text plans are a sequence of sentence plans—each of which is a tree— representing the ordering of facts and entities within the sentence. In other words, the plans determine the separation of facts into sentences, the ordering of sentences, and the ordering of facts and entities within each sentence. This stage is completely verifiable: the text plans are guaranteed to faithfully encode all and only the facts from the input. The realization stage then translates the plans into natural language sentences, using a neural sequence-to-sequence system, resulting in fluent output.Fast and Verifiable PlannerThe data-to-plan component in BIBREF0 exhaustively generates all possible plans, scores them using a heuristic, and chooses the highest scoring one for realization. While this is feasible with the small input graphs in the WebNLG challenge BIBREF4, it is also very computationally intensive, growing exponentially with the input size. We propose an alternative planner which works in linear time in the size of the graph and remains verifiable: generated plans are guaranteed to represent the input faithfully.The original planner works by first enumerating over all possible splits into sentences (sub-graphs), and for each sub-graph enumerating over all possible undirected, unordered, Depth First Search (DFS) traversals, where each traversal corresponds to a sentence plan. Our planner combines these into a single process. It works by performing a series of what we call random truncated DFS traversals. In a DFS traversal, a node is visited, then its children are visited recursively in order. Once all children are visited, the node “pops” back to the parent. In a random truncated traversal, the choice of which children to visit next, as well as whether to go to the next children or to “pop”, is non-deterministic (in practice, our planner decides by using a neural-network controller). Popping at a node before visiting all its children truncates the DFS: further descendants of that node will not be visited in this traversal. It behaves as a DFS on a graph where edges to these descendants do not exist. Popping the starting node terminates the traversal.Our planner works by choosing a node with a non-zero degree and performing a truncated DFS traversal from that node. Then, all edges visited in the traversal are removed from the input graph, and the process repeats (performing another truncated DFS) until no more edges remain. Each truncated DFS traversal corresponds to a sentence plan, following the DFS-to-plan procedure of BIBREF0: the linearized plan is generated incrementally at each step of the traversal. This process is linear in the number of edges in the graph.At training time, we use the plan-to-DFS mapping to perform the correct sequence of traversals, and train a neural classifier to act as a controller, choosing which action to perform at each step. At test time, we use the controller to guide the truncated DFS process. This mechanism is inspired by transition based parsing BIBREF5. The action set at each stage is dynamic. During traversal, it includes the available children at each stage and pop. Before traversals, it includes a choose-i action for each available node n_i. We assign a score to each action, normalize with softmax, and train to choose the desired one using cross-entropy loss. At test time, we either greedily choose the best action, or we can sample plans by sampling actions according to their assigned probabilities.Feature Representation and action scoring. Each graph node n_i corresponds to an entity x_{n_i}, and has an associated embedding vector mathbf {x_{n_i}}. Each relation r_i is associated with an embedding vector mathbf {r_i}. Each labeled input graph edge e_k = (n_i, r_ell , n_j) is represented as a projected concatenated vector mathbf {e_k}=mathbf {E}(mathbf {x_{n_i}};mathbf {r_ell };mathbf {x_{n_j}}), where mathbf {E} is a projection matrix. Finally, each node n_i is then represented as a vector mathbf {n_i} = mathbf {V}[mathbf {x_{n_i}};sum _{e_jin pi (i)}mathbf {e_j};sum _{e_jin pi ^{-1}(i)}mathbf {e_j}], where pi (i) and pi ^{-1}(i) are the incoming and outgoing edges from node n_i. The traverse-to-child-via-edge-e_j action is represented as mathbf {e_j}, choose-node-i is represented as mathbf {n_i} and pop-to-node-i is represented as mathbf {n_i}+mathbf {p} where mathbf {p} is a learned vector. The score for an action a at time t is calculated as a dot-product between the action representation and the LSTM state over the symbols generated in the plan so far. Thus, each decision takes into account the immediate surrounding of the node in the graph, and the plan structure generated so far.Speed On a 7 edges graph, the planner of BIBREF0 takes an average of 250 seconds to generate a plan, while our planner takes 0.0025 seconds, 5 orders of magnitude faster.Output verificationWhile the plan generation stage is guaranteed to be faithful to the input, the translation process from plans to text is based on a neural seq2seq model and may suffer from known issues with such models: hallucinating facts that do not exist in the input, repeating facts, or dropping facts. While the clear mapping between plans and text helps to reduce these issues greatly, the system in BIBREF0 still has 2% errors of these kinds.Output verification ::: Existing approaches: soft encouragement via neural modules.Recent work in neural text generation and summarization attempt to address these issues by trying to map the textual outputs back to structured predicates, and comparing these predicates to the input data. BIBREF7 uses a neural checklist model to avoid the repetition of facts and improve coverage. BIBREF8 generate k-best output candidates with beam search, and then try to map each candidate output back to the input structure using a reverse seq2seq model trained on the same data. They then select the highest scoring output candidate that best translates back to the input. BIBREF9 reconstructs the input in training time, by jointly learning a back-translation model and enforcing the back-translation to reconstruct the input. Both of these approaches are “soft” in the sense that they crucially rely on the internal dynamics or on the output of a neural network module that may or may not be correct.Output verification ::: Our proposal: explicit verification.The separation between planning and realization provided by the step-by-step framework allows incorporating a robust and straightforward verification step, that does not rely on brittle information extraction procedures or trust neural network models.The plan-to-text generation handles each sentence individually and translates entities as copy operations. We thus have complete knowledge of the generated entities and their locations. We can then assess the correctness of an output sentence by comparing its sequence of entities to the entity sequence in the corresponding sentence plan, which is guaranteed to be complete. We then decode k-best outputs and rerank them based on their correctness scores, tie-breaking using model scores. We found empirically that, with a beam of size 5 we find at least one candidate with an exact match to the plan's entity sequence in 99.82% of the cases for seen entities and relations compared to 98.48% at 1-best, and 72.3% for cases of unseen entities and relations compared to 58.06% at 1-best. In the remaining cases, we set the system to continue searching by trying other plans, by going down the list of plans (when using the exhaustive planner of BIBREF0) or by sampling a new plan (when using the linear time planner suggested in this paper).Evaluation and Results ::: SetupWe evaluate on the WebNLG dataset BIBREF4, comparing to the step-by-step systems described in BIBREF0, which are state of the art. Due to randomness inherent in neural training, our reported automatic evaluation measures are based on an average of 5 training runs of each system (neural planner and neural realizer), each run with a different random seed.Evaluation and Results ::: Effect of Output VerificationThe addition of output verification resulted in negligible changes in BLEU, reinforcing that automatic metrics are not sensitive enough to output accuracy. We thus performed manual analysis, following the procedure in BIBREF0. We manually inspect 148 samples from the seen part of the test set, containing 440 relations, counting expressed, omitted, wrong and over-generated (hallucinated) facts. We compare to the StrongNeural and BestPlan systems from BIBREF0. Results in Table indicate that the effectiveness of the verification process in ensuring correct output, reducing the already small number of ommited and overgenerated facts to 0 (with the exhaustive planner) and keeping it small (with the fast neural planner).Evaluation and Results ::: Referring Expression Module ::: Intrinsic evaluation of the REG module.We manually reviewed 1,177 pairs of entities and referring expressions generated by the system. We find that 92.2% of the generated referring expressions refer to the correct entity.From the generated expressions, 325 (27.6%) were pronouns, 192 (16.3%) are repeating a one-token entity as is, and 505 (42.9%) are generating correct shortening of a long entity. In 63 (5.6%) of the cases the system did not find a good substitute and kept the entire entity intact. Finally, 92 (7.82%) are wrong referrals. Overall, 73.3% of the non-first mentions of entities were replaced with suitable shorter and more fluent expressions.Interaction of different componentsWe introduced 4 components: neural planner instead of exhaustive one, adding type information, adding output verification stage, and incorporating a referring expression generation (REG). In Table we report BLEU scores BIBREF13 for all 16 combinations of components. The numbers are averages of 5 runs with different random seeds.Output ExamplesThe following output examples demonstrate the kinds of texts produces by the final system. The following outputs are correct, expressing all and only the facts from their input graphs. We enumerate them as number of facts:The leader of Azerbaijan is Artur Rasizade.Baked Alaska, containing Sponge Cake, is from France.Above The Veil, written by Garth Nix, is available in Hardcover and has 248 pages.The Akita Museum Of Art is located in Japan where the Brazilians In Japan are an ethnic group. The Museum is located in Akita, Akita which is part of Akita Prefecture .The AWH Engineering College in Kuttikkattoor, Kerala has Mahé, India to its northwest . The College was established in 2001 and has a staff of 250.An example where the system failed, producing a wrong lexicalization of a fact is: “The AWH Engineering College is located in the state of Kerala, Kochi, in India. The largest city in India is Mumbai and the river is the Ganges”. In this example, the input entity Kochi refers to the leader of Kerala, and not tpo the location (although there is also a location by that name). The text lexicalizes this fact such that Kerala and Kochi are related, but with a relation of part-of, implying Kerala is in Kochi.Table 1: Manual correctness analysis comparing our systems with the ones from Moryossef et al. (2019).Table 2: Effect of the REG component on BLEU scoreTable 3: Average BLEU score for every combination of methods (avg of 5 independent runs).Question: What is the effectiveness plan generation?","answer":"{\\"answer\\": [\\"clear mapping between plans and text helps to reduce these issues greatly, the system in BIBREF0 still has 2% errors\\", \\"work in neural text generation and summarization attempt to address these issues\\"], \\"evidence\\": [\\"While the plan generation stage is guaranteed to be faithful to the input, the translation process from plans to text is based on a neural seq2seq model and may suffer from known issues with such models: hallucinating facts that do not exist in the input, repeating facts, or dropping facts. While the clear mapping between plans and text helps to reduce these issues greatly, the system in BIBREF0 still has 2% errors of these kinds.\\", \\"Recent work in neural text generation and summarization attempt to address these issues by trying to map the textual outputs back to structured predicates, and comparing these predicates to the input data. BIBREF7 uses a neural checklist model to avoid the repetition of facts and improve coverage. BIBREF8 generate k-best output candidates with beam search, and then try to map each candidate output back to the input structure using a reverse seq2seq model trained on the same data. They then select the highest scoring output candidate that best translates back to the input. BIBREF9 reconstructs the input in training time, by jointly learning a back-translation model and enforcing the back-translation to reconstruct the input. Both of these approaches are u201csoftu201d in the sense that they crucially rely on the internal dynamics or on the output of a neural network module that may or may not be correct.\\"]}"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:The results in the two groups after 8 weeks were similar (p > 0.05) and comparable to the normal values found in the specialized literature at 8 weeks after surgery (Andrews et al., 1996; Greis et al., 2002; Maffiuletti, 2010).","answer":"Result"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: What is Telangiectasia?Context: Telangiectasias are prominent small vessels (venules, capillaries or arterioles) that are visible as small red-purple focal lesions in the skin and mucous membranes.Telangiectasias are small focal red macules and papules created by abnormally prominent capillaries, venules, and arteriolesTelangiectasia (macroscopically visible dilated skin vessels)Hereditary hemorrhagic telangiectasia is a dominant disorder characterized by epistaxis, visceral arteriovenous malformations, and telangiectasias.Telangiectasia (macroscopically visible dilated skin vessels) occurring primarily on the hands and face, are a prominent feature in scleroderma and are present in the majority of patients.","answer":"prominent small vessels"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Nevan krogan 's lab at ucsf mapped interactions between human and sars-cov-2 proteins , identifying 66 human proteins that could be targeted with 69 fda-approved drugs or drugs in clinical trials .Abstract:An outbreak of the novel coronavirus SARS-CoV-2, the causative agent of COVID-19 respiratory disease, has infected over 290,000 people since the end of 2019, killed over 12,000, and caused worldwide social and economic disruption(1,2).There are currently no antiviral drugs with proven efficacy nor are there vaccines for its prevention.Unfortunately, the scientific community has little knowledge of the molecular details of SARS-CoV-2 infection.To illuminate this, we cloned, tagged and expressed 26 of the 29 viral proteins in human cells and identified the human proteins physically associated with each using affinity-purification mass spectrometry (AP-MS), which identified 332 high confidence SARS-CoV-2-human protein-protein interactions (PPIs).Among these, we identify 66 druggable human proteins or host factors targeted by 69 existing FDA-approved drugs, drugs in clinical trials and/or preclinical compounds, that we are currently evaluating for efficacy in live SARS-CoV-2 infection assays.The identification of host dependency factors mediating virus infection may provide key insights into effective molecular targets for developing broadly acting antiviral therapeutics against SARS-CoV-2 and other deadly coronavirus strains.","answer":"{\\"verdict\\": \\"SUPPORT\\", \\"evidence\\": [\\"Among these, we identify 66 druggable human proteins or host factors targeted by 69 existing FDA-approved drugs, drugs in clinical trials and/or preclinical compounds, that we are currently evaluating for efficacy in live SARS-CoV-2 infection assays.\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Tubulin cofactors and Arl2 are cage-like chaperones that regulate the soluble αβ-tubulin pool for microtubule dynamics}Article:Abstract:Microtubule dynamics and polarity stem from the polymerization of αβ-tubulin heterodimers. Five conserved tubulin cofactors/chaperones and the Arl2 GTPase regulate α- and β-tubulin assembly into heterodimers and maintain the soluble tubulin pool in the cytoplasm, but their physical mechanisms are unknown. Here, we reconstitute a core tubulin chaperone consisting of tubulin cofactors TBCD, TBCE, and Arl2, and reveal a cage-like structure for regulating αβ-tubulin. Biochemical assays and electron microscopy structures of multiple intermediates show the sequential binding of αβ-tubulin dimer followed by tubulin cofactor TBCC onto this chaperone, forming a ternary complex in which Arl2 GTP hydrolysis is activated to alter αβ-tubulin conformation. A GTP-state locked Arl2 mutant inhibits ternary complex dissociation in vitro and causes severe defects in microtubule dynamics in vivo. Our studies suggest a revised paradigm for tubulin cofactors and Arl2 functions as a catalytic chaperone that regulates soluble αβ-tubulin assembly and maintenance to support microtubule dynamics.Introduction:Microtubules( MTs) are dynamic polymers that modulate fundamental cellular processes through dynamic αβ-tubulin polymerization and depolymerization at their ends, and serve as polarized tracks for molecular motor proteins( Akhmanova and Steinmetz, 2008). Polarity and dynamic instability are fundamental features of the MT polymer, originating from the head-to-tail polymerization of αβ-tubulin heterodimers( Nogales et al., 1999; Alushin et al., 2014). The αβ-tubulin dimer contains two GTP-binding sites: an inactive non-exchangeable site( N-site) on α-tubulin, which is suggested to stabilize αβ-tubulin dimers during their biogenesis, and an active exchangeable site( E-site) on β-tubulin, which is stimulated to hydrolyze GTP upon αβ-tubulin incorporation into MT lattices at the plus ends( Nogales et al., 1999; Alushin et al., 2014). GTP hydrolysis at the E-site leads to dynamic instability( catastrophe) at MT plus ends, due to the strain induced by the curvature of individual protofilaments( Alushin et al., 2014; Brouhard and Rice, 2014). Intracellular MT dynamics critically relies on a tightly controlled pool of soluble αβ-tubulin dimers in the cytoplasm. Despite their importance, the mechanisms for biogenesis, maintenance, and degradation of soluble αβ-tubulin dimers remain poorly understood( Tian and Cowan, 2013). αβ-tubulin is maintained at a high concentration( ∼6 μM) in the cytoplasm through regulation of translation from tubulin mRNAs( Cleveland et al., 1978; Cleveland, 1989). α- and β-tubulin are translated and folded as monomers in the type II chaperonin TRIC/CCT( Lewis et al., 1997). Biogenesis and degradation of the αβ-tubulin heterodimer are non-spontaneous processes that rely on five highly conserved tubulin cofactor( TBC) proteins: TBCA, TBCB, TBCC, TBCD, and TBCE( described in Figure 1A; Lewis et al., 1997; Lundin et al., 2010). Orthologs of these proteins have been identified in all eukaryotes studied to date( Lewis et al., 1997; Lundin et al., 2010). The maintenance of a concentrated pool of tubulin dimers by the TBC proteins is essential for proper MT dynamics in eukaryotic cells( Tian et al., 1996; Lewis et al., 1997; Lundin et al., 2010). The TBC proteins' functions are finely balanced: their loss or their overexpression are both lethal in most eukaryotes, stemming from a complete loss of the MT cytoskeleton( Steinborn et al., 2002; Lacefield et al., 2006; Jin et al., 2009). In budding yeast, the first identified chromosomal instability( CIN) phenotypes, showing severe mitotic spindle defects due to loss of MTs, were ultimately traced to loss of TBC proteins( Hoyt et al., 1990, 1997; Antoshechkin and Han, 2002; Steinborn et al., 2002; Lacefield et al., 2006; Jin et al., 2009). In humans, missense mutations in TBCE and TBCB are linked to hypo-parathyroidism facial dysmorphism( also termed Kenny-Caffey syndrome) and giant axonal neuropathy, in which developmental defects are observed due to impairment of MT cytoskeleton function( Parvari et al., 2002; Wang et al., 2005). In addition to the five conserved TBC proteins, the small Arl2 GTPase( ADP Ribosylation Factor-Like-2) regulates the function of TBC proteins in αβ-tubulin biogenesis/degradation through an unknown mechanism( Figure 1A). Although Arl2 is not considered a tubulin cofactor, its loss causes nearly identical defects to those observed with TBCC, TBCD, or TBCE loss( Hoyt et al., 1997; Radcliffe et al., 2000; Mori and Toda, 2013). 10. 7554/eLife. 08811. 003Figure 1. Tubulin cofactors and Arl2 GTPase: domain organization and paradigm for function.( A) Tubulin cofactors A–E, Arl2 GTPase masses, and domain organization. TBCA and TBCB co-expression is not required for TBC-DEG expression. Red arrowheads mark domains required for forming TBC-DEG complex assembly. Blue arrowheads mark domains not required for TBC-DEG complex assembly.( B) Initial paradigm for tubulin cofactors and Arl2 activities based on previous studies. Each of the molecules is suggested to be monomeric, and only assemble into complexes to drive αβ-tubulin biogenesis or degradation, via interactions regulated by dynamic equilibria. TBCA binds nascent β-tubulin and TBCB binds nascent α-tubulin. TBCA and TBCB are replaced by TBCD and TBCE, respectively. TBCC drives TBCE-α-tubulin and TBCD-β-tubulin to form a supercomplex. GTP hydrolysis in Arl2 is activated by TBCC in a parallel pathway to tubulin assembly. Tubulin biogenesis and degradation intermediate bind and form tubulin dimers, a process that requires Arl2 and tubulin to undergo GTP hydrolysis as an energy source.( Adopted from Lewis et al., 1997.) DOI: http://dx. doi. org/10. 7554/eLife. 08811. 003 A stepwise αβ-tubulin biogenesis/degradation paradigm has been proposed based on genetic and biochemical studies( Tian et al., 1996; Lewis et al., 1997; Lundin et al., 2010; shown in Figure 1B), in which TBC proteins form dynamic assemblies to dimerize αβ-tubulin, as follows:( 1) TBCA and TBCB bind β-tubulin and α-tubulin monomers, respectively, after their folding;( 2) TBCA hands off β-tubulin to TBCD, and TBCB hands off α-tubulin to TBCE;( 3) TBCC drives association of TBCD and TBCE with their bound α- and β-tubulin monomers, to form a ‘super-complex’ that forms and activates the αβ-tubulin dimer( Tian and Cowan, 2013); and( 4) Arl2 is simulated to hydrolyze GTP through the GTPase activating protein( GAP) function of TBCC. The role of Arl2 GTP hydrolysis in this pathway remains unknown( Bhamidipati et al., 2000); Arl2 and its activation by TBCC have been suggested to operate in parallel to the TBC pathway( Figure 1B). However, the roles for TBCC and the Arl2 GTPase remain poorly understood( Tian et al., 1999; Mori and Toda, 2013). Overexpression of TBC proteins results in one of two unique phenotypes: TBCA or TBCB overexpression in budding or fission yeast suppresses defects induced by overexpression of α- or β- tubulin, but does not otherwise affect MT dynamics. In contrast, overexpression of TBCC, TBCD, TBCE, or Arl2 leads to rapid MT loss( Archer et al., 1998; Feierbach et al., 1999; Radcliffe et al., 1999; Lacefield et al., 2006). Here, we show that TBCD, TBCE, and Arl2 assemble into a stable heterotrimeric chaperone( TBC-DEG) with a cage-like structure. This chaperone binds αβ-tubulin and TBCC sequentially, serving as a catalytic platform powered by the Arl2 GTPase for αβ-tubulin assembly and activation. A soluble αβ-tubulin dimer binds TBC-DEG and primes Arl2, followed by TBCC binding and GTP hydrolysis activation. We show that TBCC is a unique GAP for which affinity depends on αβ-tubulin binding onto TBC-DEG. TBCC promotes GTP hydrolysis through its C-terminal β-helix domain, which interfaces with both Arl2 and αβ-tubulin in a ternary complex. We further find that in Saccharomyces cerevisiae cells, a mutation locking the Arl2 GTPase into a GTP-bound state profoundly affects MT dynamics. Overall, our studies reveal a new role for tubulin cofactors TBCD, TBCE, and Arl2, which together assemble a GTP-hydrolyzing tubulin chaperone critical for the biogenesis, maintenance, and degradation of soluble αβ-tubulin, defects in which have a profound effect on MT dynamics in vivo. The finding that αβ-tubulin is assembled on a multi-subunit platform establishes a new paradigm for the mechanisms of the TBC proteins in tubulin biogenesis, maintenance, and degradation( Figure 1B).Discussion:We provide a revised paradigm for the assembly, biochemical activity, and organization of the well-conserved tubulin cofactors and Arl2 GTPase as a cage-like chaperone that catalytically alters tubulin dimers in the cytoplasm, powered by GTP hydrolysis. The GTPase activity of Arl2 is central to power and gate these chaperones, while tubulin cofactors TBCD and TBCE mediate molecular recognition of α- and β-tubulin in the heterodimer( Lewis et al., 1997; Tian and Cowan, 2013). The concept that tubulin cofactors and Arl2 function together as a catalytic chaperone is consistent with long-standing genetics and cell biology studies indicating that their concentration is critical for proper MT dynamics and MT homeostasis. These chaperones represent a new MT regulatory pathway that may enhance MT dynamics by improving the activities of individual soluble αβ-tubulin dimers in the cytoplasmic pool. This regulation is likely critical for the homeostasis of the MT cytoskeleton in eukaryotes, which is underscored by human disorders related to tubulin cofactor mutations.","answer":"Cells contain a network of protein filaments called microtubules . These filaments are involved in many biological processes; for example , they help cells keep the right shape , and they help to transport proteins and other materials inside cells . Two proteins called α-tubulin and β-tubulin are the building blocks of microtubules . The filaments are very dynamic structures that can rapidly change length as individual tubulin units are either added or removed to the filament ends . Several proteins known as tubulin cofactors and an enzyme called Arl2 help to build a vast pool of tubulin units that are able attach to the microtubules . These units—called αβ-tubulin—are formed by α-tubulin and β-tubulin binding to each other , but it not clear exactly what roles the tubulin cofactors and Arl2 play in this process . Nithianantham et al . used a combination of microscopy and biochemical techniques to study how the tubulin cofactors and Arl2 are organised , and their role in the assembly of microtubules in yeast . The experiments show that Arl2 and two tubulin cofactors associate with each other to form a stable ‘complex’ that has a cage-like structure . A molecule of αβ-tubulin binds to the complex , followed by another cofactor called TBCC . This activates the enzyme activity of Arl2 , which releases the energy needed to alter the shape of the αβ-tubulin . Nithianantham et al . also found that yeast cells with a mutant form of Arl2 that lacked enzyme activity had problems forming microtubules . Together , these findings show that the tubulin cofactors and Arl2 form a complex that regulates the assembly and maintenance of αβ-tubulin . The next challenge is to understand how this regulation influences the way that microtubules grow and shrink inside cells ."},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(BACKGROUND) Rebound acid hypersecretion might occur after treatment with proton pump inhibitors. This study looks for a rebound aggravation of symptoms after short-term treatment with lansoprazole.STUDY: Sixty-two patients (19 men and 43 women; mean age, 54 years; range, 32-77 years) with heartburn and regurgitation and normal upper endoscopy findings were studied in a randomized, double-blind, placebo-controlled trial with a crossover design. There were two 5-day treatment periods with lansoprazole 60 mg once daily or placebo in random order, separated by a 9-day washout period. Reflux, total, and antacid scores were calculated for each of the treatment periods. Higher scores during the placebo period in the group given lansoprazole first than in the group given placebo first indicated a rebound aggravation of symptoms.(RESULTS) The mean symptom scores during the placebo period in the groups given lansoprazole first and placebo first were as follows: reflux score, 21.5 and 17.6, respectively (not significant); total score, 11.2 and 10.3, respectively (not significant); and antacid score, 8.2 and 7.2, respectively (not significant).Question:Does short-term treatment with proton pump inhibitors cause rebound aggravation of symptoms?Answer:","answer":"NO"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Retrospective study on antihyperlipidemic efficacy and safety of simvastatin , ezetimibe and their combination in Korean adults . Antihyperlipidemic agents such as 3-hydroxymethyglutaryl-coenzyme A reductase inhibitors and cholesterol transporter inhibitors are used in coronary heart disease. However, controversy remains over the pharmacologic effects and safety of these drugs, especially when used in combination therapies. This retrospective study evaluated the therapeutic effect and safety of simvastatin 20 mg and ezetimibe 10 mg combination therapy compared to simvastatin 20 mg or ezetimibe 10 mg monotherapy in Korean patients according to gender, age, baseline low-density lipoprotein cholesterol, and cardiovascular risk factors. We observed significant differences among patient subgroups. simvastatin and ezetimibe monotherapies and combination therapy reduced low-density lipoprotein cholesterol levels by 27.6%, 10.1%, and 36.8% (p < 0.001) and total cholesterol levels by 17.5%, 9.2%, and 25.3% (p < 0.001), respectively. Both monotherapy and combination therapy groups had similar incidences of all types of adverse events. However, one case of rhabdomyolysis was observed in the combination therapy group. These results suggest that, compared to monotherapy, combination therapy has an additive effect that is not influenced by risk factors. Despite the low incidence of adverse events, caution is required when using these drugs, especially in the context of musculoskeletal side effects.sentence: Retrospective study on antihyperlipidemic efficacy and safety of simvastatin , ezetimibe and their combination in Korean adults .","answer":"[[\\"simvastatin\\", \\"ezetimibe\\", \\"POS\\"]]"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:ThedefectsobservedarehowevernotcompatiblewithacrucialroleforannexinA7inmembranefusionprocessesinthesecelltypes.","answer":"[]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Effects of IL-10 and IL-4 on LPS-induced transcription factors (AP-1, NF-IL6 and NF-kappa B) which are involved in IL-6 regulation. Interleukin-10 (IL-10), like IL-4, is known to inhibit cytokine expression in activated human monocytes. We showed that both IL-10 and IL-4 inhibit LPS-induced IL-6 mRNA and protein expression by inhibiting the transcription rate of the IL-6 gene. The strong inhibition of the IL-6 transcription rate prompted us to study the effect of IL-10 and IL-4 on the expression of transcription factors. We questioned whether or not IL-10 and IL-4 affected the expression of transcription factors that are known to be involved in the control of the IL-6 transcription rate, namely activator protein-1 (AP-1), nuclear factor IL-6 (NF-IL6), and nuclear factor kappa B (NF-kappaB). In electrophoretic mobility shift assays (EMSAs) we showed that IL-10 and IL-4 inhibited LPS-induced AP-1 binding activity. The inhibiting effect of IL-4 was slightly more pronounced than that of IL-10. Downregulation of LPS-induced AP-1 was accompanied, and thus possibly explained, by a reduced expression at mRNA level of the two major components of the AP-1 complex, namely c-fos and c-jun as determined by Northern experiments. Binding activity of NF-IL6 was also strongly inhibited by IL-4 whereas IL-10 showed no effect. NF-IL6 mRNA levels were not affected by IL-10 or IL-4, suggesting that IL-4 affects binding activity of preexisting NF-IL6. Neither IL-10 nor IL-4 inhibited LPS-induced NF-kappa B binding activity. In agreement with this finding, Northern experiments where p65 and p105 mRNA levels were determined, demonstrated that expression of these components of the NF-kappa B transcription factor were not affected by IL-10 or IL-4. Furthermore, neither IL-10 nor IL-4 showed any effect on I-kappa B mRNA expression as determined by Northern experiments. Thus, IL-10 and IL-4 similarly affect IL-6 expression. However, for IL-4 this was accompanied with a reduction of AP-1 and NF-IL6 binding activity whereas IL-10 only inhibited AP-1 binding activity.","answer":"{\\"CellLine\\": [], \\"CellType\\": [\\"activated human monocytes\\"], \\"DNA\\": [\\"c - jun\\", \\"IL - 6 gene\\", \\"c - fos\\"], \\"Protein\\": [\\"Interleukin - 10 (IL - 10)\\", \\"IL - 4\\", \\"NF - IL6\\", \\"NF - kappaB\\", \\"IL - 6\\", \\"cytokine\\", \\"IL - 10\\", \\"AP - 1 complex\\", \\"LPS - induced AP - 1\\", \\"AP - 1\\", \\"Interleukin - 10\\", \\"NF - kappa B\\", \\"nuclear factor\\", \\"nuclear factor kappa B\\", \\"transcription factors\\"], \\"RNA\\": [\\"mRNA\\", \\"NF - IL6\\", \\"NF - IL6 mRNA\\", \\"I - kappa B mRNA\\", \\"activator protein - 1 (AP - 1) , nuclear factor IL - 6 (NF - IL6) , and nuclear factor kappa B (NF - kappaB)\\", \\"LPS - induced IL - 6 mRNA\\"]}"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Generative Adversarial Networks (GANs) have achieved remarkable results in the task of generating realistic natural images.In most applications, GAN models share two aspects in common.On the one hand, GANs training involves solving a challenging saddle point optimization problem, interpreted as an adversarial game between a generator and a discriminator functions.On the other hand, the generator and the discriminator are parametrized in terms of deep convolutional neural networks.The goal of this paper is to disentangle the contribution of these two factors to the success of GANs.In particular, we introduce Generative Latent Optimization (GLO), a framework to train deep convolutional generators without using discriminators, thus avoiding the instability of adversarial optimization problems.Throughout a variety of experiments, we show that GLO enjoys many of the desirable properties of GANs: learning from large data, synthesizing visually-appealing samples, interpolating meaningfully between samples, and performing linear arithmetic with noise vectors.Generative Adversarial Networks (GANs) BID15 are a powerful framework to learn generative models of natural images.GANs learn these generative models by setting up an adversarial game between two learning machines.On the one hand, a generator plays to transform noise vectors into fake samples, which resemble real samples drawn from a distribution of natural images.On the other hand, a discriminator plays to distinguish between real and fake samples.During training, the generator and the discriminator learn in turns.First, the discriminator learns to assign high scores to real samples, and low scores to fake samples.Then, the generator learns to increase the scores of fake samples, as to fool the discriminator.After proper training, the generator is able to produce realistic natural images from noise vectors.Recently, GANs have been used to produce high-quality images resembling handwritten digits, human faces, and house interiors BID36 .Furthermore, GANs exhibit three strong signs of generalization.First, the generator translates linear interpolations in the noise space into semantic interpolations in the image space.In other words, a linear interpolation in the noise space will generate a smooth interpolation of visually-appealing images.Second, the generator allows linear arithmetic in the noise space.Similarly to word embeddings BID31 , linear arithmetic indicates that the generator organizes the noise space to disentangle the nonlinear factors of variation of natural images into linear statistics.Third, the generator is able to to synthesize new images that resemble those of the data distribution.This allows for applications such as image in-painting BID18 and super-resolution BID26 .Despitetheir success, training and evaluating GANs is notoriously difficult. The adversarialoptimization problem implemented by GANs is sensitive to random initialization, architectural choices, and hyper-parameter settings. In many cases,a fair amount of human care is necessary to find the correct configuration to train a GAN in a particular dataset. It is common toobserve generators with similar architectures and hyper-parameters to exhibit dramatically different behaviors. Even when properlytrained, the resulting generator may synthesize samples that resemble only a few localized regions (or modes) of the data distribution BID14 . While several advanceshave been made to stabilize the training of GANs BID37 , this task remains more art than science.The difficulty of training GANs is aggravated by the challenges in their evaluation: since evaluating the likelihood of a GAN with respect to the data is an intractable problem, the current gold standard to evaluate the quality of GANs is to eyeball the samples produced by the generator. The evaluation of discriminatorsis also difficult, since their visual features do not always transfer well to supervised tasks BID12 BID13 . Finally, the application of GANsto non-image data has been relatively limited.Research question To model natural images with GANs, the generator and discriminator are commonly parametrized as deep Convolutional Networks (convnets) BID24 . Therefore, it is reasonable to hypothesizethat the reasons for the success of GANs in modeling natural images come from two complementary sources: (A1) Leveraging the powerful inductive bias of deep convnets. (A2) The adversarial training protocol.Thisworkattempts to disentangle the factors of success (A1) and (A2) in GAN models. Specifically, we propose and study one algorithmthat relies on (A1) and avoids (A2), but still obtains competitive results when compared to a GAN.The experimental results presented in this work suggest that, in the image domain, we can recover many of the properties of GAN models by using convnets trained with simple reconstruction losses.While this does not invalidate the promise of GANs as generic models of uncertainty or as methods for building generative models, our results suggest that, in order to more fully test the adversarial construction, research needs to move beyond images and convnets.On the other hand, practitioners who care only about generating images for a particular application, and find that the parameterized discriminator does improve their results can use reconstruction losses in their model searches, alleviating some of the instability of GAN training.While the visual quality of the results are promising, especially on the CelebA dataset, they are not yet to the level of the results obtained by GANs on the LSUN bedrooms.This suggest several research directions: one possibility, suggested by 3, is that being able to cover the entire dataset is too onerous a task if all that is required is to generate a few nice samples.In that figure we see that GANs have trouble reconstructing randomly chosen images at the same level of fidelity as their generations.However, GANs can produce good images after a single pass through the data with SGD.In future work we hope to better understand the tension between these two observations.There are many possibilities for improving the quality of GLO samples beyond understanding the effects of coverage.For example other loss functions (e.g. a VGG metric, as in BID32 ), model architectures (here we stayed close to DCGAN for ease of comparison), and more sophisticated sampling methods after training the model all may improve the visual quality of the samples.There is also much work to be done in adding structure to the Z space.Because the methods here keep track of the correspondence between samples and their representatives, and because the Z space is free, we hope to be able to organize the Z in interesting ways as we train.","answer":"Are GANs successful because of adversarial training or the use of ConvNets? We show a ConvNet generator trained with a simple reconstruction loss and learnable noise vectors leads many of the desirable properties of a  GAN."},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: À trous and stride. Our fully convolutional architecture enjoys the benefits of the network modifications that are widely used by FCNs for semantic segmentation [15, 2]. Particularly, we reduce ResNet-101’s effective stride from 32 pixels to 16 pixels, increasing the score map resolution. All layers before and on the conv4 stage [9] (stride=16) are unchanged; the stride=2 operations in the first conv5 block is modified to have stride=1, and all convolutional filters on the conv5 stage are modified by the “hole algorithm” [15, 2] (“Algorithme à trous” [16]) to compensate for the reduced stride. For fair comparisons, the RPN is computed on top of the conv4 stage (that are shared with R-FCN), as is the case in [9] with Faster R-CNN, so the RPN is not affected by the à trous trick. The following table shows the ablation results of R-FCN (ktimes k=7times 7, no hard example mining). The à trous trick improves mAP by 2.6 points.Question: What is the hole algorithm?","answer":"The authors do not explain exactly what the hole algorithm is. It is implied that the hole algorithm is a trick that is used to try to improve performance by changing the stride and filters of convolutional layers."},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: What is the function of gasdermin D?Context: gasdermin D (GSDMD) protein to trigger pyroptosis, a lytic form of cell death that is crucial for immune defences and diseases.Here we show that the gasdermin-N domains of the gasdermin proteins GSDMD, GSDMA3 and GSDMA can bind membrane lipids, phosphoinositides and cardiolipin, and exhibit membrane-disrupting cytotoxicity in mammalian cells and artificially transformed bacteria.","answer":"The gasdermin-N domains of the gasdermin proteins can bind membrane lipids, phosphoinositides and cardiolipin to produce membrane-disrupting cytotoxicity."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Mechanism of increased iron absorption in murine model of hereditary hemochromatosis : increased duodenal expression of the iron transporter DMT1. Hereditary hemochromatosis (HH) is a common autosomal recessive disorder characterized by tissue iron deposition secondary to excessive dietary iron absorption. We recently reported that HFE, the protein defective in HH, was physically associated with the transferrin receptor (TfR) in duodenal crypt cells and proposed that mutations in HFE attenuate the uptake of transferrin-bound iron from plasma by duodenal crypt cells, leading to up-regulation of transporters for dietary iron. Here, we tested the hypothesis that HFE-/- mice have increased duodenal expression of the divalent metal transporter (DMT1). By 4 weeks of age, the HFE-/- mice demonstrated iron loading when compared with HFE +/+ littermates, with elevated transferrin saturations (68. 4% vs. 49. 8%) and elevated liver iron concentrations (985 micrograms vs. 381 micrograms). By using Northern blot analyses, we quantitated duodenal expression of both classes of DMT1 transcripts  one containing an iron responsive element (IRE), called DMT1 (IRE), and one containing no IRE, called DMT1 (non-IRE). The positive control for DMT1 up-regulation was a murine model of dietary iron deficiency that demonstrated greatly increased levels of duodenal DMT1 (IRE) mRNA. HFE-/- mice also demonstrated an increase in duodenal DMT1 (IRE) mRNA (average 7. 7-fold), despite their elevated transferrin saturation and hepatic iron content. Duodenal expression of DMT1 (non-IRE) was not increased, nor was hepatic expression of DMT1 increased. These data support the model for HH in which HFE mutations lead to inappropriately low crypt cell iron, with resultant stabilization of DMT1 (IRE) mRNA, up-regulation of DMT1, and increased absorption of dietary iron.","answer":"{\\"Disease\\": [\\"Hereditary hemochromatosis\\", \\"autosomal recessive disorder\\", \\"dietary iron deficiency\\", \\"hereditary hemochromatosis\\", \\"HH\\"]}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Lack of efficacy of citalopram in children with autism spectrum disorders and high levels of repetitive behavior: citalopram ineffective in children with autism.Abstract 1:Selective serotonin reuptake inhibitors are widely prescribed for children with autism spectrum disorders.                To determine the efficacy and safety of citalopram hydrobromide therapy for repetitive behavior in children with autism spectrum disorders.                National Institutes of Health-sponsored randomized controlled trial.                Six academic centers, including Mount Sinai School of Medicine, North Shore-Long Island Jewish Health System, University of North Carolina at Chapel Hill, University of California at Los Angeles, Yale University, and Dartmouth Medical School.                One hundred forty-nine volunteers 5 to 17 years old (mean [SD] age, 9.4 [3.1] years) were randomized to receive citalopram (n = 73) or placebo (n = 76). Participants had autistic spectrum disorders, Asperger disorder, or pervasive developmental disorder, not otherwise specified; had illness severity ratings of at least moderate on the Clinical Global Impressions, Severity of Illness Scale; and scored at least moderate on compulsive behaviors measured with the Children's Yale-Brown Obsessive Compulsive Scales modified for pervasive developmental disorders.                Twelve weeks of citalopram hydrobromide (10 mg/5 mL) or placebo. The mean (SD) maximum dosage of citalopram hydrobromide was 16.5 (6.5) mg/d by mouth (maximum, 20 mg/d).                Positive response was defined by a score of much improved or very much improved on the Clinical Global Impressions, Improvement subscale. An important secondary outcome was the score on the Children's Yale-Brown Obsessive Compulsive Scales modified for pervasive developmental disorders. Adverse events were systematically elicited using the Safety Monitoring Uniform Report Form.                There was no significant difference in the rate of positive response on the Clinical Global Impressions, Improvement subscale between the citalopram-treated group (32.9%) and the placebo group (34.2%) (relative risk, 0.96; 95% confidence interval, 0.61-1.51; P > .99). There was no difference in score reduction on the Children's Yale-Brown Obsessive Compulsive Scales modified for pervasive developmental disorders from baseline (mean [SD], -2.0 [3.4] points for the citalopram-treated group and -1.9 [2.5] points for the placebo group; P = .81). Citalopram use was significantly more likely to be associated with adverse events, particularly increased energy level, impulsiveness, decreased concentration, hyperactivity, stereotypy, diarrhea, insomnia, and dry skin or pruritus.                Results of this trial do not support the use of citalopram for the treatment of repetitive behavior in children and adolescents with autism spectrum disorders. Trial Registration clinicaltrials.gov Identifier: NCT00086645.Title 2:A placebo controlled crossover trial of liquid fluoxetine on repetitive behaviors in childhood and adolescent autism.Abstract 2:Repetitive behaviors are a core symptom domain in autism that has been linked to alterations in the serotonin system. While the selective serotonin-receptive inhibitor fluvoxamine has been shown to be effective in adults with autism, as yet no published placebo controlled trials with these agents document safety and efficacy in children with autism. This study examines the selective serotonin reuptake inhibitor liquid fluoxetine in the treatment of repetitive behaviors in childhood and adolescent autism spectrum disorders (ASDs). In total, 45 child or adolescent patients with ASD were randomized into two acute 8-week phases in a double-blind placebo-controlled crossover study of liquid fluoxetine. Study design included two randomized 8-week fluoxetine and placebo phases separated by a 4-week washout phase. Outcome measures included measures of repetitive behaviors and global improvement. Low-dose liquid fluoxetine (mean final dose: 9.9+/-4.35 mg/day) was superior to placebo in the treatment of repetitive behaviors by CY-BOCS compulsion scale. The effect size was in the moderate to large range, and the doses used were low. Liquid fluoxetine was only slightly, and not significantly, superior to placebo on CGI autism score partially due to a phase order effect. However, fluoxetine was marginally superior to placebo on a composite measure of global effectiveness. Liquid fluoxetine did not significantly differ from placebo on treatment emergent side effects. Liquid fluoxetine in low doses is more effective than placebo in the treatment of repetitive behaviors in childhood autism. Limitations include small sample size and the crossover design of the study. Further replication and long-term maintenance trials are needed.Title 3:Effect of fluoxetine on regional cerebral metabolism in autistic spectrum disorders: a pilot study.Abstract 3:The regional metabolic effects of fluoxetine were examined in patients with autism spectrum disorders. Six adult patients with DSM-IV and Autism Diagnostic Interview (ADI) diagnoses of autism (n = 5) and Asperger's syndrome (n = 1), entered a 16-wk placebo-controlled cross-over trial of fluoxetine. The patients received (18)F-deoxyglucose positron emission tomography with co-registered magnetic resonance imaging at baseline and at the end of the period of fluoxetine administration. After treatment, the patients showed significant improvement on the scores of the Yale--Brown Obsessive--Compulsive Scale -- Obsessions subscale and the Hamilton Anxiety Scale; Clinical Global Impressions -- Autism scores showed 3 of the patients much improved and 3 unchanged. Relative metabolic rates were significantly higher in the right frontal lobe following fluoxetine, especially in the anterior cingulate gyrus and the orbitofrontal cortex. Patients with higher metabolic rates in the medial frontal region and anterior cingulate when unmedicated were more likely to respond favourably to fluoxetine. These results are consistent with those in depression indicating that higher cingulate gyrus metabolic rates at baseline predict SRI response.Title 4:Clinical and neurochemical effects of fenfluramine in children with autism.Abstract 4:Fifteen children with autism were treated with 60 mg d,l-fenfluramine (FEN) or placebo in a double-blind A-B-A protocol followed immediately by double-blind placebo-controlled crossover administration of FEN (total duration 62 weeks). Both biochemical and clinical outcomes were examined. Biochemically, FEN led to an increase in dihydroxyphenylacetic acid (DOPAC) and decreases in whole-blood serotonin (5-HT), plasma norepinephrine (NE), and plasma 3-methoxy-4-hydroxyphenylglycol (MHPG). The decrease in whole-blood 5-HT was seen only during treatment with FEN. However, NE levels did not return to baseline as long as 8 weeks after the first FEN treatment period. Increases in DOPAC were greater during the second FEN treatment period than the first. Persistent changes in catecholamine regulation may be related to previously reported long-term effects on central nervous system 5-HT after FEN. Clinically, FEN led to a modest decrease in parent, but not teacher, ratings of hyperactivity and to a small reduction in sensorimotor abnormalities. Abnormal social and affectual responses also decreased, but this was not directly related to FEN treatment. Effects on cognition were equivocal. Hyperserotonemic subjects did not differ from normoserotonemic subjects in clinical response. Overall, no significant advantage for the use of FEN could be established.Title 5:A double-blind, placebo-controlled study of fluvoxamine in adults with autistic disorder.Abstract 5:Autistic disorder is characterized by a fundamental disturbance in social interaction, impairments in communication, and a markedly restricted repertoire of activities and interests. Abnormalities in the serotonin neurotransmitter system have been identified in some persons with autism. No consistently effective and safe drugs have been developed for treating the symptoms of autism.                Thirty adults with autistic disorder completed a 12-week double-blind, placebo-controlled trial of the potent and selective serotonin uptake inhibitor fluvoxamine maleate. Behavioral ratings were obtained at baseline and after 4, 8, and 12 weeks of treatment.                Eight (53%) of 15 patients in the fluvoxamine-treated group were categorized as responders compared with none of 15 in the placebo group (P = .001). Fluvoxamine was superior to placebo in reducing repetitive thoughts and behavior (P < .001), maladaptive behavior (P < .001), and aggression (P < .03), and in improving some aspects of social relatedness (P < .04), especially language usage (P < .008). Treatment response was not correlated with age level of autistic behavior, or full-scale IQ. Other than mild sedation and nausea in a few patients, fluvoxamine was well tolerated. No dyskinesias, adverse cardiovascular events, or seizures occurred.                Fluvoxamine is more effective than placebo in the short-term treatment of the symptoms of autistic disorder in adults. Controlled studies of fluvoxamine and other potent and selective serotonin uptake inhibitors seem warranted in children and adolescents with autism.Title 6:Urinary dopamine metabolites as indicators of the responsiveness to fenfluramine treatment in children with autistic behavior.Abstract 6:Modifications in serotonin and dopamine metabolism were evaluated in 13 children with autistic behavior and related to their responsiveness to fenfluramine treatment. A double-blind medication-placebo crossover design was used. Each patient received 1.5 mg/kg fenfluramine daily for 3 months followed and preceded by placebo for 1 month. Clinical improvement was observed in 6 children (responders). It included reduction of behavioral symptoms such as motor activity, anxiety, mood disturbances, and distractibility. Modifications of serotonin (5-HT), dopamine (DA), and DA metabolites [homovanillic acid (HVA) and dihydroxyphenylacetic acid (DOPAC)] were assessed at urinary levels. Responders and nonresponders showed a significant decrease of urinary 5-HT levels on fenfluramine. The main differences between the two groups of subjects were found with HVA, the major metabolite of DA. Fenfluramine significantly increased HVA levels in responders whereas no significant modification was found in nonresponders. Moreover the initial level of HVA (lower in responders) significantly differentiated the two groups. These results suggest that the clinical response to fenfluramine could be related to the dopaminergic action of this drug and that urinary DA metabolite levels could be considered as indicators of the responsiveness to fenfluramine treatment in children with autistic behavior.Title 7:Clinical efficacy of fluvoxamine and functional polymorphism in a serotonin transporter gene on childhood autism.Abstract 7:We studied the correlation between response to fluvoxamine and serotonin transporter gene promoter region polymorphism (5-HTTLPR). Eighteen children with autistic disorder completed a 12-week double-blind, placebo-controlled, randomized crossover study of fluvoxamine. Behavioral assessments were obtained before and at 12 weeks of treatment. 5-HTTLPR (long (l) or short(s)), was analyzed by the PCR method. Ten out of 18 patients responded to fluvoxamine treatment; allele type analysis revealed that clinical global effectiveness was noted significantly more in the l allele than in the s allele. However, with respect to language use, a significant effectiveness was noted in the s allele. 5-HTTLPR may influence the individual responses to fluvoxamine administration.","answer":"There is no evidence of effect of SSRIs in children and emerging evidence of harm. There is limited evidence of the effectiveness of SSRIs in adults from small studies in which risk of bias is unclear."},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:Furthermore, similar to an early study by Thiriet and colleagues (10), Boiselle and colleagues have recently demonstrated that the highly collapsed trachea (>50% in cross-sectional area) on dynamicexpiratory CT scans, which is concordant with the current diagnostic criteria of TM/TBM, is frequently observed in subjects with normal lung function (9).","answer":"Result"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Using a fragment-based approach to target protein-protein interactions. The ability to identify inhibitors of protein-protein interactions represents a major challenge in modern drug discovery and in the development of tools for chemical biology. In recent years, fragment-based approaches have emerged as a new methodology in drug discovery; however, few examples of small molecules that are active against chemotherapeutic targets have been published. Herein, we describe the fragment-based approach of targeting the interaction between the tumour suppressor BRCA2 and the recombination enzyme RAD51; it makes use of a screening pipeline of biophysical techniques that we expect to be more generally applicable to similar targets. Disruption of this interaction in vivo is hypothesised to give rise to cellular hypersensitivity to radiation and genotoxic drugs. We have used protein engineering to create a monomeric form of RAD51 by humanising a thermostable archaeal orthologue, RadA, and used this protein for fragment screening. The initial fragment hits were thoroughly validated biophysically by isothermal titration calorimetry (ITC) and NMR techniques and observed by X-ray crystallography to bind in a shallow surface pocket that is occupied in the native complex by the side chain of a phenylalanine from the conserved FxxA interaction motif found in BRCA2. This represents the first report of fragments or any small molecule binding at this protein-protein interaction site.","answer":"[[\\"phenylalanine\\", \\"PART-OF\\", \\"FxxA interaction motif\\"], [\\"phenylalanine\\", \\"PART-OF\\", \\"BRCA2\\"]]"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:For cartilage staining, embryos were fixed for 2 hours to overnight in buffered 4% formaldehyde, rinsed briefly in distilled water and transferred directly into a 0.1% solution of Alcian blue to stain overnight (Dingerkus and Uhler, 1977).","answer":"Method"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Naloxone\\", ...], \\"Disease\\" : [\\"Hypotensive\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Perhexiline maleate and peripheral neuropathy. Peripheral neuropathy has been noted as a complication of therapy with perhexiline maleate, a drug widely used in France (and in clinical trials in the United States) for the prophylactic treatment of angina pectoris. In 24 patients with this complication, the marked slowing of motor nerve conduction velocity and the electromyographic changes imply mainly a demyelinating disorder. Improvement was noted with cessation of therapy. In a few cases the presence of active denervation signified a poor prognosis, with only slight improvement. The underlying mechanism causing the neuropathy is not yet fully known, although some evidence indicates that it may be a lipid storage process.","answer":"{\\"Chemical\\": [\\"Perhexiline maleate\\", \\"perhexiline maleate\\"], \\"Disease\\": [\\"peripheral neuropathy\\", \\"demyelinating disorder\\", \\"angina pectoris\\", \\"neuropathy\\", \\"Peripheral neuropathy\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Identification of the putative transforming protein of the human T-cell leukemia viruses HTLV-I and HTLV-II. The human T-cell leukemia viruses HTLV-I and HTLV-II are unique among the transforming retroviruses of vertebrates in their ability to transform human T cells in vitro and in their close association with human malignancies (T-cell lymphomas and leukemia). Their genomes are relatively simple, containing the genes gag, pol, env, and a 3' region termed \\"X.\\" This 3' region may be responsible for the transforming potential of the viruses. The existence of proteins encoded by the 3' region has been postulated on the basis of multiple open reading frames. In the present study this region is shown to contain a gene encoding a protein of 40 kilodaltons in HTLV-I and 37 kilodaltons in HTLV-II. It is proposed that these proteins be called, respectively, p40xI and p37xII.","answer":"{\\"AnatomicalEntity\\": [\\"3u0027 region\\", \\"leukemia\\", \\"T-cell leukemia\\", \\"T-cell lymphomas\\", \\"malignancies\\", \\"T cells\\", \\"X\\"]}"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:we report a case of herpetic epithelial keratitis that developed after subconjunctival triamcinolone acetonide injection ( sti ) .a 65-year - old female with anterior uveitis and hypotony in her right eye was given a sti ( 2 mg/0.5 ml ) .a clinical examination was performed and real - time polymerase chain reaction ( pcr ) was used to amplify the viral dna in a corneal scraping .slit - lamp biomicroscopy revealed a severe purulent discharge , conjunctival injection , and a geographic corneal ulcer in the right eye .herpes simplex virus 1 dna was identified in the corneal scraping using real - time pcr .herpetic keratitis was diagnosed and topical acyclovir ointment as well as systemic valacyclovir were started . the inflammation subsided with this medication .hypotony is a severe complication of the uveitis and can result in marked vision loss . to treat hypotony ,subconjunctival triamcinolone acetonide injection ( sti ) is used to treat anterior scleritis and uveitis [ 2 , 3 , 4 , 5 ] .the reported adverse events of sti are elevated intraocular pressure ( iop ) , cataract formation or progression , subconjunctival hemorrhage , scleral necrosis , scleral perforation , infectious scleritis , and endophthalmitis [ 4 , 6 , 7 ] .we report a case of herpetic epithelial keratitis after sti for hypotony caused by scleritis and anterior uveitis .a 65-year - old female who had diabetes mellitus visited a private clinic and presented with injection and visual disturbance in her right eye .slit - lamp biomicroscopy revealed scleral injection , inflammatory cells in the anterior chamber as well as iris synechiae .the iop in the right eye was 4 mm hg and b - scan ultrasonography showed choroidal detachment .we diagnosed noninfectious anterior uveitis and began steroid treatment with a 0.1% dexamethasone ophthalmic solution every hour , 1% atropine eye drops every night , and oral prednisolone 25 mg / day .one month after treatment , the inflammation in the anterior chamber and choroidal detachment subsided while the iop increased to 15 mm hg .in addition , her blood sugar increased due to the adverse effects of oral prednisolone .the scleral injection , hypotony , and choroidal detachment reappeared after tapering the systemic steroids .she complained of redness , foreign body sensation , and ocular discharge 1 week after sti .slit - lamp biomicroscopy showed conjunctival injection , discharge , blepharitis with vesicles of the lid margin , and geographic corneal and conjunctival epithelial defects ( fig . 1 , fig .the topical steroid was stopped and she was treated with topical acyclovir ( 3% eye ointment 5 times / day ) and oral valacyclovir ( 3,000 mg / day ) .real time polymerase chain reaction ( pcr ) of a corneal scraping was performed in order to detect a potential human herpes virus , including herpes simplex virus ( hsv ) types 1 and 2 , varicella - zoster virus , epstein barr virus , cytomegalovirus , and human herpes viruses 6 , 7 , and 8 .the real - time pcr results were positive only for hsv dna ( 310 copies / sample ) .since the conjunctival injection and epithelial defect improved with the therapy , the valacyclovir was tapered within 1 month .the scleritis and the inflammation in the anterior chamber as well as her herpetic keratitis were controlled with topical acyclovir . however , the hypotony persisted and the cataract progressed markedly .therefore , a lensectomy and vitrectomy with silicone oil tamponade was performed and the iop increased to 10 mm hg .thereafter , the patient was administered topical acyclovir and steroids , without any uveitis recurrence .the reactivation of latent hsv-1 is associated with several stressors , including drugs and temperature .herpetic keratitis has been reported after using steroids in eye drops , the subconjunctival injection of dexamethasone , and intravitreal triamcinolone injection [ 8 , 9 ] . to our knowledge , however , a reported case of herpetic keratitis after sti has not yet been reported .sti is used for resistant scleritis because triamcinolone is a long - acting synthetic glucocorticoid .sohn et al .   demonstrated the efficacy of sti for nonnecrotizing , noninfectious anterior scleritis .they treated 68 eyes of 53 patients with sti , and 66 eyes ( 97% ) improved after 1 injection .although 14 eyes ( 2.9% ) developed an increased iop , none of the cases developed scleral necrosis or melt .a few cases of infectious scleritis or endophthalmitis after sti have been reported [ 6 , 7 ] .although our patient did not show keratitis while receiving systemic steroids and steroid eye drops , sti can reactivate hsv and trigger severe herpetic keratitis .the sti likely reactivated the hsv rather than the use of systemic steroids and steroid eye drops .however , it is possible that systemic steroids and steroid eye drops reactivate hsv-1 immediately before the occurrence of keratitis and sti finally induces keratitis .the clinical findings included geographic epithelial defects caused by hsv , and real time pcr demonstrated high hsv - dna copy numbers .diabetes is also a risk factor for hsv reactivation   and can be related to the herpetic keratitis that developed in our case .although the etiology of the anterior uveitis in our case is unknown , hsv could be associated with the pathogenesis because antiviral treatment along with steroids reduced the inflammation in the anterior chamber .furthermore , herpetic dermatitis along with herpetic keratitis appeared after sti . a primary hsv-1 infection in the ocular site , including eye and eyelid , could be considered , and anterior uveitis could be caused by hsv-1 .therefore , we should consider herpetic keratitis when sti is used to treat unilateral anterior uveitis or scleritis .hsv-1 could induce a massive inflammation in the ciliary body and reduce aqueous humor production . in conclusionwe should be cautious when treating patients with unilateral anterior uveitis or scleritis with a history of diabetes mellitus and herpetic eye disease .","answer":"purposewe report a case of herpetic epithelial keratitis that developed after subconjunctival triamcinolone acetonide injection ( sti).methodsa 65-year - old female with anterior uveitis and hypotony in her right eye was given a sti ( 2 mg/0.5 ml ) .  after the injection , she developed redness and an ocular discharge .  a clinical examination was performed and real - time polymerase chain reaction ( pcr ) was used to amplify the viral dna in a corneal scraping.resultsslit-lamp biomicroscopy revealed a severe purulent discharge , conjunctival injection , and a geographic corneal ulcer in the right eye .  herpes simplex virus 1 dna was identified in the corneal scraping using real - time pcr .  herpetic keratitis was diagnosed and topical acyclovir ointment as well as systemic valacyclovir were started .  the inflammation subsided with this medication.conclusionwe encountered a case of herpetic epithelial keratitis after a sti ."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:1. The subject is a pregnant or lactating female. 2. The subject has pre-existing sustained supine hypertension greater than 180mmHg systolic and 110mmHg diastolic BP or had these measurements at the Screening Visit. Sustained is defined as persistently greater at 2 separate measurements at least 5 minutes apart with the subject supine and at rest for the 5 minutes. 3. Subjects taking concomitant medications of interest are excluded unless those medications are reviewed and discussed with the Medical Monitor or Study Physician and documented prior to enrolling the subject. If agreement is reached between the Investigator and Sponsor for the subject to continue in the study, all allowed medications should be maintained at a constant dose throughout the study. 4. The Principal Investigator deems any clinical laboratory test (at the Screening Visit) abnormality to be clinically significant 5. The subject has participated in other studies of investigational drugs or devices within 30 days prior to enrollment in this study (other than Study SPD426-406). 6. Current or relevant history of physical or psychiatric illness, any medical disorder that may require treatment or make the subject unlikely to fully comply with the requirements of the study or complete the study, or any condition that presents undue risk from the investigational product or study procedures. 7. The subject has a concurrent chronic or acute illness, disability, or other condition (including significant unexpected laboratory or electrocardiogram [ECG] findings) that might confound the results of the tests and/or measurements administered in this study, or that might have increased the risk to the subject. 8. Known or suspected intolerance or hypersensitivity to the investigational product(s), closely-related compounds, or any of the stated ingredients. 9. Prior enrollment failure or randomization in this study. 10. History of alcohol abuse or other substance abuse within the last year.","answer":"{\\"Condition\\": [\\"supine hypertension\\", \\"other condition\\", \\"disability\\", \\"laboratory findings\\", \\"enrollment failure\\", \\"acute illness\\", \\"substance abuse\\", \\"chronic illness\\", \\"pregnant\\", \\"electrocardiogram [ECG] findings\\", \\"lactating\\", \\"alcohol abuse\\"], \\"Device\\": [], \\"Drug\\": [\\"medications of interest\\"], \\"Measurement\\": [\\"BP\\", \\"measurements\\"], \\"Mood\\": [], \\"Multiplier\\": [\\"2 separate at least 5 minutes apart\\"], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [\\"female\\"], \\"Procedure\\": [\\"electrocardiogram [ECG]\\"], \\"Qualifier\\": [], \\"ReferencePoint\\": [\\"Screening Visit\\"], \\"Scope\\": [\\"alcohol abuse or other substance abuse\\", \\"or at the Screening Visit sustained\\"], \\"Temporal\\": [\\"concomitant\\", \\"pre-existing\\", \\"sustained\\", \\"persistently\\", \\"at the Screening Visit\\", \\"within the last year\\"], \\"Value\\": [\\"greater than 180mmHg systolic\\", \\"greater\\", \\"110mmHg diastolic\\"], \\"Visit\\": []}"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the incidence of diabetes mellitus ( dm ) and prediabetes mellitus is estimated at approximately 113.9 million and 493.4 million people , respectively . in xinjiang , there are no less than 13 ethnic groups with uyghurs accounting for 46% of the total population .the prevalence of t2 dm among this group is estimated at about 6.23% , and those considered prediabetic account for 31.6% of the population .found that uyghurs with type 2 dm ( t2 dm ) had a higher body mass index ( bmi ) .chronic complications of t2 dm , including heart and cerebrovascular disease , visual impairment , and end - stage renal disease , can contribute to high morbidity and mortality , which also creates economic burdens within society and families .studies have confirmed that many human diseases are associated with dna methylation . during dna methylationprevious studies have shown that dna methylation can be changed by age and life style , which suggests that this may be involved in metabolic diseases including t2 dm [ 612 ] .the fos - like antigen 2 ( fosl2 ) gene is located on chromosome 2 and has a full length of 21.74  kb .the fos gene family is constituted by fosl2 , fos , fosb , and fosi , and fosl2 has been described in many different tissue types in both animals and humans .recent studies have found that it plays a crucial role in forming fat cells ; meanwhile , some researchers have demonstrated that metabolism can be affected by fosl2 expression [ 14 , 15 ] .however , the pathogenic potential of methylated fosl2 in t2 dm still remains unknown , especially in the uyghurs of xinjiang .our study aimed to observe the methylation levels of fosl2 and analyze its correlation with clinical and biochemical indicators of t2 dm within this population .the subjects were divided into the t2 dm ( n = 50 ) and nonimpaired glucose tolerance ( ngt ; n = 50 , as controls ) group ; because of the remoteness of the region , glycemic control within the blood samples is difficult .all patients underwent a standard 75  g oral glucose tolerance test . diagnosing t2 dmpatients diagnosed with type 1 diabetes or autoimmune diseases or suspected severe heart disease , liver disease , kidney disease , or malignant tumor were excluded .metabolic markers including fasting plasma glucose ( fpg ) and total cholesterol ( tc ) were measured using clinical chemistry analyzer .bmi was defined as one 's weight in kilograms divided by the square of one 's height in meters .the insulin resistance index ( homa - ir ) and pancreatic  cell function index ( homa- ) were calculated and analyzed using the homeostasis model assessment ( homa ) .this study strictly followed the principles of the declaration of helsinki and was approved by the ethics committee of the shihezi university , xinjiang , china .total rna was extracted with the rnaprep pure blood kit ( tiangen biotech , beijing , china ) .dna was extracted from blood cells using dneasy blood and tissue kit ( qiagen , germany ) according to manufacturer 's instruction , and the productivity and purity of dna were measured using a nanodrop spectrophotometer .protein in serum was measured by fosl2 enzyme - linked immunosorbent assay kit ( elisa , r&d systems , mn , usa ) ; the termination reaction results in photometric color change from blue to yellow .we combined the reverse transcription of rna and polymerase chain reaction of cdna to measure the mrna expression of fosl2 .the primers for fosl2 were designed by epidesigner website ( http://www.epidesigner.com/ ) as follows : forward 5-ccagatgaaatgtcatgg c-3 and reverse 5-ctcggtttggtagacttgga-3 and the primers for-actin as follows : forward 5-cccagcacaatgaagatcaagatcat-3 and reverse 5-atctgctggaaggtggacagcg-3. the reaction conditions for the pcr were as follows : 94c for 4  min then 72c for 2  min , followed by 36 cycles at 94c for 30  sec , 56c for 30  sec and 72c for 30  sec .the level of mrna was analyzed by a gel imaging system ( bio - rad gel doc 2000 , usa ) .dna was modified by sodium bisulfite with the reaction condition as follows : 20 cycles at 95c for 30  sec and 50c for 15  min .the sequence of the fosl2 gene was queried from university of california santa cruz genome biological information network ( http://genome.ucsc.edu/ ) .the primers for fosl2 were designed by the epidesigner website as follows : forward 5-aggaagagaggtaggtttagga gaggggtgtg-3 and reverse 5-cagtaatacgactcactatagggagaagg ctacaacccccaaaacttaactaaaac-3 , primers for the cpg island of fosl2 were used to amply bisulfite treated dna .the reaction conditions for the pcr were as follows : 94c for 4  min and then 72c for 3  min , followed by 45 cycles at 94c for 20  sec , 56c for 30  sec , and 72c for 1  min .the pcr products were spotted on a 384-pad spectrochip ( sequenom , san diego , ca , usa ) , followed by spectral acquisition on a massarray analyzer .methylation data of individual units were generated by the epityper v1.0.5 software ( sequenom ) .student 's t - test was used to compare the mean of two independent groups .fifty uyghur patients with t2 dm and 50 healthy uyghur participants in the ngt group were used in this study .the clinical and metabolic anthropometric characteristics of subjects involved in the study are showed in table 1 .compared with ngt group , patients with t2 dm showed higher bmi , fpg , hba1c , tc , triglyceride ( tg ) , low density lipoprotein cholesterol ( ldl - c ) , and fins levels when compared to control , while t2 dm group showed lower high density lipoprotein cholesterol ( hdl - c ) , insulin sensitivity index ( isi ) , and homa- which is function index of -cell and index of insulin resistance ( ir ) levels . to compare the expression of fosl2 , we measured the mrna in the ngt and t2 dm groups .the results showed that the gene expression level of fosl2 in the t2 dm group was significantly lower than that of the ngt group ( figure 1(a ) ) .further we did relative quantification analysis in the two groups , which revealed the same trend ( 2.46  0.51 , 0.10  0.16 ; p < 0.01 ) ( figure 1(b ) ) . compared with ngt group , the t2 dm group had a significantly lower protein expression level for fosl2 ( 41.48  26.32  ng / ml , 18.09  9.48  ng / ml , p < 0.01 ) ( figure 2 ) .massarray was used to analyze the data from 50 ngt and 50 t2 dm samples .fosl2 dna methylation showed a significant difference with higher methylation in t2 dm ( 0.03  0.01 , 0.05  0.02 ; p < 0.05 ) ( figure 4 ) .the results of fosl2 gene methylation studies showed that the methylation rate of cpg units ( cpg_3 , cpg_4.5 , cpg_6.7 , cpg_8 , cpg_11 , cpg_12.13.14 , cpg_15.16.17 , and cpg_19 ) was higher in the t2 dm group when compared to the ngt group ( p < 0.01 ) ( figure 5 ) .the correlation analyses showed a negative relationship with a correlation coefficient of 0.39 between methylation level and mrna expression of fosl2 .the regression equation is as follows : y = 0.54  0.01x ( figure 6 ) .the correlative analysis showed that methylation of cpg6.7 , cpg8 , cpg11 , cpg12.13.14 , and cpg15.16.17 was positively correlated with fpg ; cpg11 and cpg12.13.14 were positively correlated with fins ; tc and tg were positively correlated with cpg12.13.14 ; cpg6.7 , cpg8 , cpg11 , cpg12.13.14 , and cpg15.16.17 were negatively correlated with isi and methylation of cpg11 and cpg12.13.14 was negatively correlated with homa- ( table 2 ) .dm has become a major public health problem and as a result of its very high incidence and morbidity there is an urgent need for a sustainable public health solution .however , the specific mechanism of t2 dm development remains unknown and to date , fosl2 gene methylation has not been investigated in t2 dm patients .leptin plays important roles in regulating blood glucose and lipid metabolism and has been found to play a negative role in weight gain .the fosl2 gene is widely expressed in various organs and tissues during both human and animal development .meanwhile , fosl2 gene expression has been linked to fat metabolism , cancer , and bone diseases in human and animals [ 14 , 2022 ] .our main findings include fosl2 expression , at both the protein and mrna levels , which is significantly reduced in the t2 dm group when compared to the ngt group .this reveals a correlation between decreased fosl2 expression and t2 dm , which reveals that the loss of fosl2 expression is correlated with t2 dm .secondly , 19 cpg sites were described and their methylation state was evaluated ; we showed that there is a measured increase in methylation of these cpg islands in the t2 dm .dna methylation has been previously described in other genes associated with t2 dm ; ling et al .the increased methylation of fosl2 in the t2 dm group correlates with the reduced mrna levels described in the same group .furthermore , previous research from liliand et al . indicated that dna methylation might regulate blood lipid levels and lead to metabolic disease . in our study ,subjects in the t2 dm group also had higher blood lipid levels , providing evidence that the hypermethylation of fosl2 might be influenced by tc and tg in t2 dm group .found that blood lipid levels increased with dna methylation levels and decreased insulin secretion and induced insulin resistance .the correlative analysis in our study showed that methylation of the cpg sites was positively related to fpg and fins , while negatively correlated with isi and homa- ; these coincide with the brns et al .the correlation between the index of insulin resistance homa and methylation of repetitive sequences of alu was also reported by zhao et al . .our results are in line with this study , which showed that glucose and lipid metabolism disorder was the important cause of islet -cell dysfunction and dna methylation is significantly associated with insulin resistance , resulting in a greater risk of dm .our data shows that fosl2 which is related to glycol - metabolism and pancreas development is hypermethylated in subjects with t2 dm . also , we propose that the high blood glucose and high plasma lipid levels may be positively correlated with hypermethylation and the dysfunction of islet -cells is a result of hypermethylation .one of the limitations in this study is the choice of experimental method ; real - time quantitative pcr may be a better choice for validation in the future . a second, more problematic limitation is the low sample size , and thus our results should be verified in a larger cohort . in conclusion ,fosl2 in t2 dm patients was hypermethylated and exhibited lower mrna and protein expression levels .the results suggested that dna methylation may contribute to these lower expression levels , which may in turn contribute to the onset of t2 dm . our data supports the hypothesis that methylation may be an early event in the development of diabetes .these observations provide evidence that fosl2 methylation state may be a useful biomarker for increasing risk of t2 dm progression within the uyghur population in xinjiang and preventing a potential novel target for therapeutic development .t2 dm often leads to abnormal bone mineral density ; mathen et al . found that subjects with t2 dm had lower bone mineral density .longitudinal studies are needed to clarify the methylation state of fosl2 among osteoporosis and t2 dm with osteoporosis patients ; it is worthwhile to investigate whether fosl2 promotes the formation of osteoblasts and the role of fosl2 in this and other metabolic diseases .","answer":"objective .  we investigated the expression levels of both fosl2 mrna and protein as well as evaluating dna methylation in the blood of type 2 diabetes mellitus ( t2 dm ) uyghur patients from xinjiang .  this study also evaluated whether fosl2 gene expression had demonstrated any associations with clinical and biochemical indicators of t2 dm .  methods .  one hundred uyghur subjects where divided into two groups , t2 dm and nonimpaired glucose tolerance ( ngt ) groups .  dna methylation of fosl2 was also analyzed by massarray spectrometry and methylation data of individual units were generated by the epityper v1.0.5 software .  the expression levels of fos - like antigen 2 ( fosl2 ) and the protein expression levels were analyzed .  results .  significant differences were observed in mrna and protein levels when compared with the ngt group , while methylation rates of eight cpg units within the fosl2 gene were higher in the t2 dm group .  methylation of cpg sites was found to inversely correlate with expression of other markers . conclusions .  results show that a correlation between mrna , protein , and dna methylation of fosl2 gene exists among t2 dm patients from uyghur . fosl2 protein and mrna were downregulated and the dna became hypermethylated , all of which may be involved in t2 dm pathogenesis in this population ."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Surface-modified HK: siRNA nanoplexes with enhanced pharmacokinetics and tumor growth inhibition. We characterized in this study the pharmacokinetics and antitumor efficacy of histidine-lysine (HK):siRNA nanoplexes modified with PEG and a cyclic RGD (cRGD) ligand targeting αvβ3 and αvβ5 integrins. With noninvasive imaging, systemically administered surface-modified HK: siRNA nanoplexes showed nearly 4-fold greater blood levels, 40% higher accumulation in tumor tissue, and 60% lower luciferase activity than unmodified HK: siRNA nanoplexes. We then determined whether the surface-modified HK: siRNA nanoplex carrier was more effective in reducing MDA-MB-435 tumor growth with an siRNA targeting Raf-1. Repeated systemic administration of the selected surface modified HK: siRNA nanoplexes targeting Raf-1 showed 35% greater inhibition of tumor growth than unmodified HK: siRNA nanoplexes and 60% greater inhibition of tumor growth than untreated mice. The improved blood pharmacokinetic results and tumor localization observed with the integrin-targeting surface modification of HK: siRNA nanoplexes correlated with greater tumor growth inhibition. This investigation reveals that through control of targeting ligand surface display in association with a steric PEG layer, modified HK: siRNA nanoplexes show promise to advance RNAi therapeutics in oncology and potentially other critical diseases.","answer":"[]"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Unsupervised embedding learning aims to extract good representations from data without the use of human-annotated labels.Such techniques are apparently in the limelight because of the challenges in collecting massive-scale labels required for supervised learning.This paper proposes a comprehensive approach, called Super-AND, which is based on the Anchor Neighbourhood Discovery model.Multiple losses defined in Super-AND make similar samples gather even within a low-density space and keep features invariant against augmentation.As a result, our model outperforms existing approaches in various benchmark datasets and achieves an accuracy of 89.2% in CIFAR-10 with the Resnet18 backbone network, a 2.9% gain over the state-of-the-art.Deep learning and convolutional neural network have become an indispensable technique in computer vision (LeCun et al., 2015; Krizhevsky et al., 2012; Lawrence et al., 1997) .Remarkable developments, in particular, were led by supervised learning that requires thousands or more labeled data.However, high annotation costs have become a significant drawback in training a scalable and practical model in many domains.In contrast, unsupervised deep learning that requires no label has recently started to get attention in computer vision tasks.From clustering analysis (Caron et al., 2018; Ji et al., 2018) , and self-supervised model (Gidaris et al., 2018; Bojanowski & Joulin, 2017) to generative model (Goodfellow et al., 2014; Kingma & Welling, 2013; Radford et al., 2016) , various learning methods came out and showed possibilities and prospects.Unsupervised embedding learning aims to extract visually meaningful representations without any label information.Here \\"visually meaningful\\" refers to finding features that satisfy two traits:(i) positive attention and(ii) negative separation (Ye et al., 2019; Zhang et al., 2017c; Oh Song et al., 2016) .Data samples from the same ground truth class, i.e., positive samples, should be close in the embedding space (Fig. 1a) ; whereas those from different classes, i.e., negative samples, should be pushed far away in the embedding space (Fig. 1b) .However, in the setting of unsupervised learning, a model cannot have knowledge about whether given data points are positive samples or negative samples.Several new methods have been proposed to find 'visually meaningful' representations.The sample specificity method considers all data points as negative samples and separates them in the feature space (Wu et al., 2018; Bojanowski & Joulin, 2017) .Although this method achieves high performance, its decisions are known to be biased from learning only from negative separation.One approach utilizes data augmentation to consider positive samples in training (Ye et al., 2019) , which efficiently reduces any ambiguity in supervision while keeping invariant features in the embedding space.Another approach is called the Anchor Neighborhood Discovery (AND) model, which alleviates the complexity in boundaries by discovering the nearest neighbor among the data points (Huang et al., 2019) .Each of these approaches overcomes different limitations of the sample specificity method.However, no unified approach has been proposed.This paper presents a holistic method for unsupervised embedding learning, named Super-AND.Super-AND extends the AND algorithm and unifies various but dominant approaches in this domain with its unique architecture.Our proposed model not only focuses on learning distinctive features across neighborhoods, but also emphasizes edge information in embeddings and maintains the unchanging class information from the augmented data.Besides combining existing techniques, we newly introduce Unification Entropy loss (UE-loss), an adversary of sample specificity loss, which is able to gather similar data points within a low-density space.Extensive experiments are conducted on several benchmark datasets to verify the superiority of the model.The results show the synergetic advantages among modules of Super-AND.The main contributions of this paper are as follows:• We effectively unify various techniques from state-of-the-art models and introduce a new loss, UE-loss, to make similar data samples gather in the low-density space.• Super-AND outperforms all baselines in various benchmark datasets.It achieved an accuracy of 89.2% in the CIFAR-10 dataset with the ResNet18 backbone network, compared to the state-of-the-art that gained 86.3%.• The extensive experiments and the ablation study show that every component in Super-AND contributes to the performance increase, and also indicate their synergies are critical.Our model's outstanding performance is a step closer to the broader adoption of unsupervised techniques in computer vision tasks.The premise of data-less embedding learning is at its applicability to practical scenarios, where there exists only one or two examples per cluster.Codes and trained data for Super-AND are accessible via a GitHub link.Generative model.This type of model is a powerful branch in unsupervised learning.By reconstructing the underlying data distribution, a model can generate new data points as well as features from images without labels.Generative adversarial network (Goodfellow et al., 2014) has led to rapid progress in image generation problems Arjovsky et al., 2017) .While some attempts have been made in terms of unsupervised embedding learning (Radford et al., 2016) , the main objective of generative models lies at mimicking the true distribution of each class, rather than discovering distinctive categorical information the data contains.Self-supervised learning.This type of learning uses inherent structures in images as pseudo-labels and exploits labels for back-propagation.For example, a model can be trained to create embeddings by predicting the relative position of a pixel from other pixels (Doersch et al., 2015) or the degree of changes after rotating images (Gidaris et al., 2018) .Predicting future frames of a video can benefit from this technique (Walker et al., 2016) .Wu et al. (2018) proposed the sample specificity method that learns feature representation from capturing apparent discriminability among instances.All of these methods are suitable for unsupervised embedding learning, although there exists a risk of false knowledge from generated labels that weakly correlate with the underlying class information.Learning invariants from augmentation.Data augmentation is a strategy that enables a model to learn from datasets with an increased variety of instances.Popular techniques include flipping, scaling, rotation, and grey-scaling.These techniques do not deform any crucial features of data, but only change the style of images.Some studies hence use augmentation techniques and train models Clustering analysis.This type of analysis is an extensively studied area in unsupervised learning, whose main objective is to group similar objects into the same class.Many studies either leveraged deep learning for dimensionality reduction before clustering (Schroff et al., 2015; Baldi, 2012) or trained models in an end-to-end fashion (Xie et al., 2016; Yang et al., 2016) .Caron et al. (2018) proposed a concept called deep cluster, an iterative method that updates its weights by predicting cluster assignments as pseudo-labels.However, directly reasoning the global structures without any label is error-prone.The AND model, which we extend in this work, combines the advantages of sample specificity and clustering strategy to mitigate the noisy supervision via neighborhood analysis (Huang et al., 2019) .This paper presents Super-AND, a holistic technique for unsupervised embedding learning.Besides the synergetic advantage combining existing methods brings, the newly proposed UE-loss that groups nearby data points even in a low-density space while maintaining invariant features via data augmentation.The experiments with both coarse-grained and fine-grained datasets demonstrate our model's outstanding performance against the state-of-the-art models.Our efforts to advance unsupervised embedding learning directly benefit future applications that rely on various image clustering tasks.The high accuracy achieved by Super-AND makes the unsupervised learning approach an economically viable option where labels are costly to generate.","answer":"We proposed a comprehensive approach for unsupervised embedding learning on the basis of AND algorithm."},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Have machine learning methods been used to predict the severity of major depressive disorder(MDD)?Context: Here, we conduct a meta-review to identify predictors of response to antidepressant therapy in order to select robust input features for machine learning models of treatment response.machine learning framework involving EEG-based functional connectivity to diagnose major depressive disorder (MDD).Identification of risk factors of treatment resistance may be useful to guide treatment selection, avoid inefficient trial-and-error, and improve major depressive disorder (MDD) care. We extended the work in predictive modeling of treatment resistant depression (TRD) via partition of the data from the Sequenced Treatment Alternatives to Relieve Depression (STAR*D) cohort into a training and a testing dataset.persistence and severity of major depressive disorder from baseline self-reportsThese results confirm that clinically useful MDD risk-stratification models can be generated from baseline patient self-reports and that ML methods improve on conventional methods in developing such modelsFurthermore, machine learning weighting factors may reflect an objective biomarker of major depressive disorder illness severity, based on abnormalities of brain structure.Notably, while the only information provided for training the classifiers was T(1)-weighted scans plus a categorical label (major depressive disorder versus controls), both relevance vector machine and support vector machine 'weighting factors' (used for making predictions) correlated strongly with subjective ratings of illness severity.BACKGROUND Although variation in the long-term course of major depressive disorder (MDD) is not strongly predicted by existing symptom subtype distinctions, recent research suggests that prediction can be improved by using machine learning methods.BACKGROUND Although variation in the long-term course of major depressive disorder (MDD) is not strongly predicted by existing symptom subtype distinctions, recent research suggests that prediction can be improved by using machine learning methods.BACKGROUND Growing evidence documents the potential of machine learning for developing brain based diagnostic methods for major depressive disorder (MDD).OBJECTIVE We aimed to integrate neural data and an advanced machine learning technique to predict individual major depressive disorder (MDD) patient severity.Furthermore, machine learning weighting factors may reflect an objective biomarker of major depressive disorder illness severity, based on abnormalities of brain structure.<b>BACKGROUND</b>: Although variation in the long-term course of major depressive disorder (MDD) is not strongly predicted by existing symptom subtype distinctions, recent research suggests that prediction can be improved by using machine learning methods.","answer":"yes"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"IGF\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:TIEG1 deficiency confers enhanced myocardial protection in the infarcted heart by mediating the Pten/Akt signalling pathway. The transforming growth factor (TGF)-β-inducible early gene-1 (TIEG1) plays a crucial role in modulating cell apoptosis and proliferation in a number of diseases, including pancreatic cancer, leukaemia and osteoporosis. However, the functional role of TIEG1 in the heart has not been fully defined. In this study, we first investigated the role of TIEG1 in ischaemic heart disease. For in vitro experiments, cardiomyocytes were isolated from both TIEG1 knockout (KO) and wile-type (WT) mice, and the apoptotic ratios were evaluated after a 48‑h ischaemic insult. A cell proliferation assay was performed after 7 days of incubation under normoxic conditions. In addition, the angiogenic capacity of endothelial cells was determined by tube formation assay. For in vivo experiments, a model of myocardial infarction (MI) was established using both TIEG1 KO and WT mice. Echocardiography was performed at 3 and 28 days post-MI, whereas the haemodynamics test was performed 28 days post-MI. Histological analyses of apoptosis, proliferation, angiogenesis and infarct zone assessments were performed using terminal deoxynucleotidyltransferase-mediated dUTP nick-end labelling (TUNEL) staining, BrdU immunostaining, α-smooth muscle actin (α-SMA)/CD31 immunostaining and Masson's trichrome staining, respectively. Changes in the expression of related proteins caused by TIEG1 deficiency were confirmed using both reverse transcription-quantitative polymerase chain reaction (RT-qPCR) and western blot analysis. Our results demonstrated that the absence of TIEG1 prevented cardiomyocytes from undergoing apoptosis and promoted higher proliferation; it stimulated the proliferation of endothelial cells in vitro and in vivo. Improved cardiac function and less scar formation were observed in TIEG1 KO mice, and we also observed the altered expression of phosphatase and tensin homolog (Pten), Akt and Bcl-2/Bax, as well as vascular endothelial growth factor (VEGF). On the whole, our findings indicate that the absence of TIEG1 plays a cardioprotective role in ischaemic heart disease by promoting changes in Pten/Akt signalling.","answer":"{\\"Gene\\": [\\"Bcl-2\\", \\"CD31\\", \\"Pten\\", \\"transforming growth factoru00a0(TGF)-u03b2-inducible early gene-1\\", \\"a-smooth muscle actin\\", \\"a-SMA\\", \\"phosphatase and tensin homolog\\", \\"vascular endothelial growth factor\\", \\"VEGF\\", \\"Akt\\", \\"TIEG1\\", \\"Bax\\"]}"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: How is yellow fever virus transmitted?Context: Yellow Fever (YF) is an acute viral communicable disease transmitted by an arbovirus of the flavivirus genus. It is primarily a zoonotic disease, especially the monkeys. Worldwide, an estimated 200 000 cases of yellow fever occurred each year, and the case-fatality rate is ~15%. Forty-five endemic countries in Africa and Latin America, with a population of close to 1 billion, are at risk. Up to 50% of severely affected persons from YF die without treatmentyellow fever virus (YFV) are transmitted between arthropod vectors and vertebrate hosts. While barriers limiting arbovirus population diversity have been observed in mosquitoes, whether barriers exist in vertebrate hosts is unclear. To investigate whether arboviruses encounter bottlenecks during dissemination in the vertebrate host, we infected immunocompetent mice and immune-deficient mice lacking alpha/beta interferon (IFN-α/β) receptors (IFNAR⁻/⁻ mice) with a pool of genetically marked viruses to evaluate dissemination and host barriersRe-emergence of vector-borne diseases such as dengue and yellow fever, which are both transmitted by the Aedes aegypti mosquito, has been correlated with insecticide resistance.Arthropod-borne viruses are important emerging pathogens world-wide. Viruses transmitted by mosquitoes, such as dengue, yellow fever, and Japanese encephalitis viruses, infect hundreds of millions of people and animals each year. Global surveillance of these viruses in mosquito vectors using molecular based assays is critical for prevention and control of the associated diseasesfever and dengue fever are mosquito-borne infectious diseases transmitted by Aedes aegyptii, the presence of yellow fever in Sudan and dengue fever in Saudi Arabia are threats to Egypt with the reemerging of Ae. aegyptii in Southern Egypt, larvae control is feasible than flying adultsdengue virus (DENV) and yellow fever virus (YFV), that originated in sylvatic cycles maintained in non-human primates and forest-dwelling mosquitoes have emerged repeatedly into sustained human-to-human transmission by Aedes aegypti mosquitoesSylvatic cycles of both viruses remain active, and where the two viruses overlap in West Africa they utilize similar suites of monkeys and Aedes mosquitoesFirst, the sylvatic cycle of YFV originated in Africa and was introduced into the New World, probably as a result of the slave trade, but is absent in Asia; in contrast, sylvatic DENV likely originated in Asia and has spread to Africa but not to the New World. Second, while sylvatic YFV can emerge into extensive urban outbreaks in humans, these invariably die out, whereas four different types of DENV have established human transmission cycles that are ecologically and evolutionarily distinct from their sylvatic ancestorsFinally, transmission of YFV among humans has been documented only in Africa and the Americas, whereas DENV is transmitted among humans across most of the range of competent Aedes vectors, which in the last decade has included every continent save AntarcticaMosquito-transmitted diseases such as malaria, dengue, yellow fever and filariasis are the main contributors to this burdenyellow fever (YFV) viruses is increasing in many parts of the world. The viruses are primarily transmitted by Aedes aegypti, a highly domesticated mosquito species that is notoriously difficult to control.The first of these to be discovered was yellow fever virus in 1901, and three to four new species are still being found every yearThe causative agent of yellow fever is an arbovirus of the Flaviviridae family transmitted by infected Aedes mosquitoes, particularly in Africa. In the Central African Republic since 2006, cases have been notified in the provinces of Ombella-Mpoko, Ouham-Pende, Basse-Kotto, Haute-Kotto and in Bangui the capital. As the presence of a vector of yellow fever virus (YFV) represents a risk for spread of the disease, we undertook entomological investigations at these sites to identify potential vectors of YFV and their abundancefamily Flaviviridae, includes a number of important arthropod-transmitted human pathogens such as dengue viruses, West Nile virus, Japanese encephalitis virus and yellow fever virusReports of the detection of these viruses with no recognized pathogenic role in humans are increasing in mosquitoes collected around the world, particularly in those sampled in entomological surveys targeting pathogenic flaviviruses. The presence of six potential flaviviruses, detected from independent European arbovirus surveys undertaken in the Czech Republic, Italy, Portugal, Spain and the UK between 2007 and 2010, is reported in this workYellow Fever virus (YFV) is an important arboviral pathogen in much of sub-Saharan Africa and the tropical Americas. It is the prototype member of the genus Flavivirus and is transmitted primarily by Aedes (Stegomyia) mosquitoes. The incidence of human infections in endemic areas has risen in recent years. Prompt and dependable identification of YFV is a critical component of response to suspect casesHealth-care professionals can help travelers by providing accurate pre-travel counseling for mosquito-transmitted diseases such as malaria, yellow fever, and dengue fever. Governments and international organizations will benefit from knowledge survey among health professionals in this field to promote the development of travel health professionUnited States made 12 million visits to developing countries in Asia, South America, Central America, Oceania, the Middle East, and Africa.Yellow fever is a serious illness public health importance and is transmitted by mosquitoes of the genera Haemagogus and Sabethes in the rural and forest environments, and by Aedes aegypti in the urban settingMany specialist human viruses also have mammalian or avian origins. Indeed, a substantial proportion of mammalian viruses may be capable of crossing the species barrier into humans, although only around half of these are capable of being transmitted by humans and around half again of transmitting well enough to cause major outbreaks. A","answer":"Yellow fever virus is transmitted by mosquitoes and is restricted to Africa, Central and South America and the Caribbean. Yellow fever virus is a flavivirus, and there is only one antigenic type. It was taken to the Americas by the early slave traders, and nowadays reported in Africa, America, Asia and Europe. Yellow fever virus is transmitted by two different cycles: -from human to human by the mosquito Aedes aegypti; which is well-adapted to breeding around human habitations; the infection can be maintained in this way as ‘urban’ yellow fever.-from infected monkeys to humans by mosquitoes such as Haemagogus. This is ‘jungle’ yellow fever and is seen in Africa and South America.Yellow fever is not transmitted directly from human to human by day-to-day contact, but transmission from ill patients to healthcare workers has been reported, notably after needlestick injury."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: MHC-compatible bone marrow stromal/stem cells trigger fibrosis by activating host T cells in a scleroderma mouse model}Article:Abstract:Fibrosis of organs is observed in systemic autoimmune disease. Using a scleroderma mouse, we show that transplantation of MHC compatible, minor antigen mismatched bone marrow stromal/stem cells( BMSCs) play a role in the pathogenesis of fibrosis. Removal of donor BMSCs rescued mice from disease. Freshly isolated PDGFRα+ Sca-1+ BMSCs expressed MHC class II following transplantation and activated host T cells. A decrease in FOXP3+ CD25+ Treg population was observed. T cells proliferated and secreted IL-6 when stimulated with mismatched BMSCs in vitro. Donor T cells were not involved in fibrosis because transplanting T cell-deficient RAG2 knock out mice bone marrow still caused disease. Once initially triggered by mismatched BMSCs, the autoimmune phenotype was not donor BMSC dependent as the phenotype was observed after effector T cells were adoptively transferred into naïve syngeneic mice. Our data suggest that minor antigen mismatched BMSCs trigger systemic fibrosis in this autoimmune scleroderma model.Introduction:Systemic fibrosis is a feature of autoimmune disease such as systemic sclerosis( SSc) or Sjögren’s syndrome involving exocrine glands( Ferrara et al., 2009; Filipovich et al., 2005). A mouse model for human SSc reported by Zhang et. al. involves transplantation of B10. D2 bone marrow into MHC matched, minor antigen mismatched BALB/c host( Zhang et al., 2002). This model of SSc occurs spontaneously without the use of artificial agents such as bleomycin( Yamamoto and Nishioka, 2004), and exhibits characteristics of human SSc including fibrosis, inflammation, and autoimmunity. Animal models are effective in screening for therapeutic interventions such as anti IL-6( Le Huu et al., 2012) and angiotensin II type-1 receptor antagonists( Yaguchi et al., 2013). However, such a spontaneous model is also a valuable tool for investigating the pathogenesis of SSc, which is still largely unknown. In order to shed light onto the mechanisms leading to fibrosis in this SSc mouse model, it is necessary to isolate the different cellular fractions within the B10. D2 donor bone marrow, namely, hematopoietic stem cells( HSCs) and bone marrow stromal/stem cells( BMSCs). Multipotent BMSCs in the bone marrow differentiate into several mesenchymal lineages including fibroblasts, adipocytes, osteocytes, and chondrocytes( Pittenger et al., 1999; Prockop, 1997). However, due to the lack of specific markers, a crucial step involving in vitro expansion was required to isolate BMSCs, which may modify their phenotype and function( Banfi et al., 2000). Most current information on BMSCs comes from such in vitro studies of adherent cells referred to as fibroblast CFUs( CFU-Fs)( Conget and Minguell, 1999; Friedenstein et al., 1974; Pittenger et al., 1999; Prockop, 1997), which are a heterogeneous population of cells at best. Therefore, the in vivo dynamics of BMSCs after whole bone marrow transplantation( WBMT) are still unknown, and the establishment of a solid experimental system to trace the fate of BMSCs following transplantation was required. In order to establish an animal model with traceable donor BMSCs and HSCs, we applied our previously reported method for prospectively isolating murine BMSCs based on their expression of PDGF receptor α and Sca-1( PDGFRα+/ Sca-1+( PαS) cells)( Morikawa et al., 2009a). Selectively isolated PαS-BMSCs without in vitro expansion represents highly clonogenic and multi-potent population of cells including hematopoietic niche cells, osteoblasts, and adipocytes after systemic in vivo transplantation( Morikawa et al., 2009a; 2009b). Our model allows for the first time both whole bone marrow transplantation, as well as the selective transplantation of freshly isolated BMSCs and/or HSCs into recipient mice. By applying this modified SSc model using prospectively isolated BMSCs and HSCs, we sought to identify the role of donor HSCs and BMSCs in the pathogenesis of the autoimmune-related fibrosis in SSc. Here, we show how mismatched donor BMSCs not only contribute to fibrosis in various organs, but also trigger the onset of autoimmune disease by activating host T cells.Discussion:We have reported the role of donor BMSCs in the pathogenesis of fibrosis associated with autoimmune SSc in a MHC-matched, minor antigen mismatched mouse model. Our data show that depletion of BMSCs from donor whole bone marrow significantly reduced fibrosis in all organs examined, and rescued mice from lacrimal gland dysfunction associated with the disease. These findings suggest the possible role of donor BMSCs in the initiation of the autoimmune process, as the number of BMSCs in graft correlated with severity of fibrosis( Figure 1E, F). Furthermore, the onset of true autoimmune disease in these mice was shown by the repression of Treg induction, followed by an increase in Th17 effector cells of host origin. This shows that migrating donor PαS-BMSCs are the initial trigger of events leading to increased levels of circulating IL-6, followed by a decrease in Tregs, and conversely an increase in host-derived Th17 cells. Activation or maturation of BMSC-derived progeny is probably also involved in the progression of disease because accumulation of donor-derived fibroblasts was not observed in syngeneic BMSC transplantation, where fibrosis does not occur. In the mixed lymphocyte reaction experiments, Thy-1+ T-cells isolated from host mice after mismatched BMT were activated by PαS-BMSCs in vitro, as shown by enhanced proliferation and IL-6 secretion. In addition, the T-cell proliferation was blocked by anti-MHC antibody. Finally, adoptively transferred T cells from mismatched BMSCs recipients into nude-mice-induced autoimmune-like inflammation and fibrosis in targets organs, indicating that autoreactive recipient T cells were activated by antigens presented by MHC class II molecules in minor antigen mismatched donor BMSCs. Adoptive transferred T cells react recipient BMSCs leading to recipient’ fibrosis( Figure 5) probably because adoptively transferred T cells has already acquired the autoreactive nature to activate the recipient derived BMSCs as shown in vitro analysis from Figure 6A and Figure 6B. Although the auto-antigen responsible for the autoimmune type reaction still needs to be identified, a common antigen specifically expressed in BMSCs of B10. D2 and BALB/c with different isoforms or SNIPs, is one of the most probable candidates. Since naive T cells responded to PαS-BMSCs in vitro at low levels, we speculate that auto-reactive T cells that are only present in basal levels under normal conditions( Sakaguchi et al., 2008) can recognize minor differences between B10. D2 and BALB/c BMSCs. The lack of fibrosis following mismatched HSC transplantation suggests that hematopoietic lineage cells, including DCs, did not express such a molecule. The identical phenotype was observed when host and recipient were reversed( i. e. BALB/c BMSCs transplanted to B10. D2 recipients, data not shown). This implies that both B10. D2 and BALB/c BMSCs can be a primary inducer against mismatched recipient T cells, showing that the autoimmune-related fibrosis in this model was due to difference in strain, and not a specific reaction of B10. D2 BMSCs and BALB/c T cells. The novelty of our study is the use of prospectively isolated BMSCs combined with prospectively isolated HSCs. Previous studies have used culture-isolated BMSCs, which do not reflect the physiological role of these cells in vivo. Functional differences between in vitro and in vivo observations may explain discrepancies in the anti-inflammatory and pro-inflammatory effects of BMSCs reported in the literature( See review by Bernardo et. al.( Bernardo and Fibbe, 2013). Our study has also demonstrated that donor BMSCs can contribute to the fibroblast population observed in fibrotic lesions of the host. Our findings suggest that once mismatched BMSCs migrate into the target organs via certain homing signals, mismatched BMSCs encounter T cells and proliferate and activate under the pathological microenvironment( Figure 2A). This phenomenon may not be present in syngeneic BMSCs transplantation where an allogeneic response does not occur. As for HSP47 expression, it is clearly seen in activated fibroblasts, but only very faint expression is detected in quiescent fibroblasts in the syngeneic BMSC-transplanted recipients’ target organs. Interestingly, a fraction of BMSCs mobilized in the peripheral blood expressed MHC class II molecules( Figure 6B). Preliminary data show that these cells also express CD45 and type I collagen( data not shown), which corresponds with the phenotype of fibrocytes reported in the literature( Abe et al., 2001; Chesney et al., 1997; Mielcarek et al., 2003; Phillips et al., 2004; Wang et al., 2007; Yang et al., 2002). Further studies are required to elucidate the association of PαS-BMSCs and fibrocytes. Interestingly, this SSc mouse model has also been used as a model of chronic graft-versus-host disease( cGVHD)( Kaplan et al., 2004; Kim et al., 2007). The phenotype of cGVHD characterized by systemic fibrosis and severe dry eye is very similar to this SSc mouse phenotype. Unlike conventional cGVHD that is believed to be caused by donor T cells, our results show that radio-resistant residual recipient T cells, but not donor-HSC derived de novo T cells, were activated following mismatched BMSC transplantation. Although we do not believe that our findings in this mouse model could be directly applied to human cGVHD cases, it is worth noting this phenomenon. In fact, several previous reports have shown that residual recipient CD4+ T cells regulate cGVHD( Anderson et al., 2004; Blazar et al., 2000; Jaffee and Claman, 1983). In addition, cGVHD has occurred in a surprisingly high fraction of nonmyeloablative stem cell transplant recipients( Anderson et al., 2004; Mielcarek et al., 2003; Schetelig et al., 2002) since residual host T cells remain in nonmyeloablative transplantation. Notably, BMSC depletion from grafts significantly reduced fibrosis in all organs that we examined. The use of CD34+ selected HSCs as an approach to reducing the risk of cGVHD was suggested in early studies of CD34+ selected peripheral blood HSCs.( Martı́nez et al., 1999; Urbano-Ispizua et al., 1997; 2001) CD34+ selected HSC transplantation depletes not only mature T cells but also donor BMSCs because human BMSCs are negative for CD34 expression( Mabuchi et al., 2013). In addition, recent reports showed that the incidence of cGVHD was less following cord blood transplantation( CBT) compared to peripheral blood stem-cell transplantation( PBSCT)( Takahashi et al., 2007; Uchino et al., 2012). We have found that BMSCs are rarely detected in cord blood but are abundant in G-CSF-mobilized PBL( Mabuchi et al., 2013), which may indicate that the onset of cGVHD may correlate with the number of BMSCs transplanted. Taken all, the reduced risk of cGVHD may have been due to the removal or absence of donor BMSCs as we showed in our BMSC-depleted model. Further studies are required for monitoring the frequency of donor BMSCs in grafts and residual host T cells in human cGVHD patients to elucidate the possible role of donor BMSCs in the pathogenesis. In summary, prospective transplantation of freshly purified BMSCs and HSCs into BALB/c-RAG2KO suggests that transplantation of minor antigen-mismatched MHC-compatible BMSCs interact with residual host T cells to induce the autoimmune phenotype observed in fibrosis associated with the SSc mouse model. While the responsible antigen remains to be elucidated, our data suggest that accidental recognition of self-minor antigens on MHC class II+ BMSCs may be involved in systemic fibrosis observed in autoimmune disease.","answer":"Systemic scleroderma is an autoimmune disease caused by the immune system attacking the body’s connective tissues , which provide the body with structural support . Immune cells called T cells accumulate in connective tissue , which leads to the hardening of the skin and may also damage the heart , lungs and other internal organs . However , it is not clear what prompts the T cells to accumulate in the connective tissues of these individuals . Autoimmune diseases develop when the immune system mistakenly identifies host cells as being a threat to the body . Normally , the immune system recognizes healthy body cells by the presence of particular proteins on the surface of the cells . A set of surface proteins called the major histocompatibility complexes ( MHCs ) play a major role in this process , but there are also many other surface proteins that play more minor roles . In 2002 , researchers developed a method that can trigger the symptoms of systemic scleroderma in mice . This method involves transplanting bone marrow from one mouse into another mouse . Both mice have identical MHC proteins on the surfaces of their cells , but have some differences in other cell surface proteins , and so the bone marrow from the donor mouse triggers an immune response in the recipient . To better understand how this mouse “model” of systemic scleroderma works , Ogawa , Morikawa et al . refined the method so that they could just transplant specific types of bone marrow cells into the recipient mice . The experiments reveal that bone marrow stromal stem cells , but not so-called “hematopoietic stem cells” , from a donor mouse are responsible for triggering the immune response and disease symptoms in the recipients . Ogawa , Morikawa et al . ’s findings show that mismatched minor cell surface proteins on bone marrow stromal stem cells can trigger symptoms of systemic scleroderma in mice . Further studies are required to find out how these cells encourage T cells to trigger an autoimmune response ."},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Posterior-stabilized versus cruciate-retaining total knee arthroplasty: balancing the gap.Abstract 1:A prospective, randomized, double-blind trial was carried out to compare cruciate-retaining (CR) and posterior-stabilized (PS) total knee arthroplasties (TKAs). A total of 40 knees were randomized to receive either a NexGen CR (Zimmer, Warsaw, IN) or a Legacy PS (Zimmer, Warsaw, IN) TKA. All knees were implanted with identical surgical technique, making sure to balance precisely the flexion-extension gaps before implantation of the components. At 2-year follow-up, there was no difference between the CR and the PS TKAs with respect to their Knee Society clinical, functional, and radiographic scores. These findings suggest that with careful attention to surgical technique and balancing the knee, orthopaedic surgeons should expect similar results whether they use a CR or PS TKA.                Copyright 2002, Elsevier Science (USA)Title 2:The role of the posterior cruciate ligament in total knee replacement.Abstract 2:We randomised 129 knees which were to be replaced using a standard posterior-cruciate-ligament (PCL)-retaining cemented total knee replacement into two groups. In one the PCL was retained in the normal way and in the other it was resected. They were well matched, with a predominance of women, and a mean age of 67 years. There was no statistically significant difference in the Hospital for Special Surgery scores at a mean of 57 months (56 to 60) between the two groups although 21 patients (24 knees) were lost to follow-up. Relief from pain, correction of deformity, range of movement, stability and strength were comparable in both. Radiological assessment showed femoral rollback in approximately 20% of knees with a slightly higher incidence in the PCL-resected group. There was no significant loosening detected in either group at review at two years. At five years, one knee in the PCL-retained group had been revised because of infection and one patient in each group was awaiting revision for loosening. Our findings have shown no significant difference in the five-year results for a PCL-retaining total knee replacement if the PCL is excised or preserved. This suggests two important points. First, the PCL is not functional in most patients with a total knee replacement even when retained. Secondly, patients with an excised PCL show a good result with a PCL-retaining implant, thereby questioning the need for a posterior stabilised design in such a situation.Title 3:Functional comparison of posterior cruciate-retaining versus posterior stabilized total knee arthroplasty.Abstract 3:A prospective, randomized comparison of posterior cruciate-retaining (PCR) and posterior stabilized (PS) total knee arthroplasties (TKAs) was conducted in 20 patients who underwent bilateral TKAs for osteoarthritis. All procedures were performed by a single surgeon. One knee was implanted with a PCR TKA, and a contralateral knee with a PS TKA. Both prosthetic designs were of the same TKA series, with comparable surface geometries. Patients had a clinical and radiographic evaluation at a mean of 31.7 months for PCR TKAs and 30.6 months for PS TKAs postoperatively. There were no significant differences between the PCR and PS TKAs in postoperative knee scores. However, postoperative improvement in range of motion was significantly superior in the PS group.Title 4:The stability of the cemented tibial component of total knee arthroplasty: posterior cruciate-retaining versus posterior-stabilized design.Abstract 4:Micromotion of the tibial component in 40 knee arthroplasties for gonarthrosis was studied using Roentgen stereophotogrammetric analysis. The stability of this component was assessed for 2 years' postoperatively. In all arthroplasties, an attempt was made to reconstruct the preoperative posterior slope. Posterior cruciate-retaining (CR) and posterior-stabilized (PS) components showed at 2 years a maximum total point motion of 0.6 +/- 0.4 mm and 0.7 +/- 0.5 mm, respectively. Whereas 92.5% of the implants were determined to be stable, 1 of the CR group and 2 of the PS group displayed migration between the first and the second year of at least 0.2 mm. A negative correlation between subsidence of the tibial component at 2 years of follow-up and the difference between preoperative and postoperative tibial slope was found. Consequently, we suggest that restoring the original posterior slope of the tibial plateau must be a goal of tibial component implantation.Title 5:Proprioception, kinesthesia, and balance after total knee arthroplasty with cruciate-retaining and posterior stabilized prostheses.Abstract 5:The effect of total knee arthroplasty on proprioception, kinesthesia, and postural control remains controversial. It is argued that retaining the posterior cruciate ligament may help to preserve these sensorimotor functions and improve the longevity of the prosthesis and the functional outcome. We performed a prospective, randomized study to assess proprioception, kinesthesia, and balance following total knee arthroplasty with cruciate-retaining and posterior stabilized prostheses.                Twenty patients scheduled to undergo total knee arthroplasty were randomly assigned to receive either a cruciate-retaining or a posterior stabilized prosthesis. Joint-position sense, the threshold to detect joint motion, and the subject's ability to balance on an unstable platform were assessed prior to and at least six months after the operation. Paired two-tailed t tests (with a level of significance of p < 0.05) were used to assess the effect of the arthroplasty on the preoperative measures for all subjects. Analysis of covariance was performed to identify the effects of prosthetic design.                Following total knee arthroplasty, patients detected motion significantly faster and reproduced joint position with less error. The balance index also improved significantly from the preoperative to the postoperative evaluation. The group treated with the posterior stabilized prosthesis more accurately reproduced joint position when the knee was extended from a flexed position.                Total knee arthroplasty results in mild improvements in proprioception, kinesthesia, and balance. These changes may result from the retensioned capsuloligamentous structures and reduced pain and inflammation. Retention of the posterior cruciate ligament does not appear to significantly improve proprioception and balance compared with those functions in patients with a posterior stabilized total knee design.Title 6:Posterior cruciate ligament at total knee replacement. Essential, beneficial or a hindrance?Abstract 6:We report the results of a prospective randomised trial which assessed the role of the posterior cruciate ligament (PCL) following total knee replacement (Genesis I; Smith and Nephew, Memphis, Tennessee). Over a four-year period, 211 patients underwent total knee replacement by the senior author (TJW). They were randomised at surgery to have the PCL either retained, excised or substituted with a posterior stabilised insert. If it was not possible to retain the ligament due to soft-tissue imbalance, it was released from its tibial insertion until suitable tension was obtained. This created a fourth group, those who were intended preoperatively to have the ligament retained, but in whom it was partially released as a result of findings at the time of surgery. All patients were evaluated using the Knee Society rating system (adapted from Insall). A total of 188 patients (212 knees) was available for follow-up at a mean of 3.5 years after surgery. Preoperatively, there was a varus deformity in 191 knees (90%) and a valgus deformity in 21 (10%). There were no statistical differences in the knee or function scores or the range of movement between the excised, retained and substituted groups. There were, however, significantly worse knee and function scores in the group in whom the PCL was released (p = 0.002).","answer":"These results should be interpreted with caution as the methodological quality of the studies was highly variable. We conclude that there is, so far, no solid base for the decision to either retain or sacrifice the PCL with or without use of a posterior stabilized design during total knee arthroplasty. The technique of PCL retention is difficult because the normal configuration and tension need to be reproduced with ligament tensioners. Knowledge of the technique needs to be improved before it can yield superior results compared to the more straightforward techniques of PCL sacrifice or use of a posterior stabilized design. Also, studies evaluating the effect of both techniques should address the right outcome parameters such as range of motion, contact position, and anterior-posterior stability. Suggestions are given to improve future research on this specific topic of knee arthroplasty."},{"question":"Below is an abstract from a computer science research paper. Given this abstract, your task is to extract all unique relationships between entities of the following types:- \\"USED-FOR\\": For instance, \\"Our method models user proficiency\\" -> [\\"method\\", \\"user proficiency\\", \\"USED-FOR\\"].- \\"EVALUATE-FOR\\": For instance, \\"We evaluate our method using F1-measure\\" -> [\\"F1-measure\\", \\"method\\", \\"EVALUATE-FOR\\"].- \\"FEATURE-OF\\": For instance, \\"prior knowledge of the model\\" -> [\\"prior knowledge\\", \\"model\\", \\"FEATURE-OF\\"].- \\"HYPONYM-OF\\": For instance, \\"TUIT is a software library\\" -> [\\"TUIT\\", \\"software library\\", \\"HYPONYM-OF\\"].- \\"PART-OF\\": For instance, \\"We incorporate NLU module into the system.\\" -> [\\"NLU module\\", \\"system\\", \\"PART-OF\\"].- \\"COMPARE\\": For instance, \\"Unlike the quantitative prior, the qualitative prior is often ignored\\" -> [\\"quantitative prior\\", \\"qualitative prior\\", \\"COMPARE\\"].- \\"CONJUNCTION\\": For instance: \\"obtained from human expert or knowledge base\\" -> [\\"human expert\\", \\"knowledge base\\", \\"CONJUNCTION\\"].Format your output as a json array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<Entity_B>\\", \\"<RELATION_A_B>\\"]. An example output might look like:[[\\"neural networks\\", \\"classification\\", \\"USED-FOR\\"], [\\"neuron\\", \\"neural network\\", \\"PART-OF\\"]].If no relations are found, please return an empty array [].Abstract:We present the first known empirical test of an increasingly common speculative claim, by evaluating a representative Chinese-to-English SMT model directly on word sense disambiguation performance, using standard WSD evaluation methodology and datasets from the Senseval-3 Chinese lexical sample task. Much effort has been put in designing and evaluating dedicated word sense disambiguation (WSD) models, in particular with the Senseval series of workshops. At the same time, the recent improvements in the BLEU scores of statistical machine translation (SMT) suggests that SMT models are good at predicting the right translation of the words in source language sentences. Surprisingly however, the WSD accuracy of SMT models has never been evaluated and compared with that of the dedicated WSD models. We present controlled experiments showing the WSD accuracy of current typical SMT models to be significantly lower than that of all the dedicated WSD models considered. This tends to support the view that despite recent speculative claims to the contrary, current SMT models do have limitations in comparison with dedicated WSD models, and that SMT should benefit from the better predictions made by the WSD models.","answer":"[[\\"that\\", \\"WSD accuracy\\", \\"COMPARE\\"], [\\"BLEU scores\\", \\"statistical machine translation (SMT)\\", \\"EVALUATE-FOR\\"], [\\"word sense disambiguation\\", \\"Chinese-to-English SMT model\\", \\"EVALUATE-FOR\\"], [\\"Senseval-3 Chinese lexical sample task\\", \\"Chinese-to-English SMT model\\", \\"EVALUATE-FOR\\"], [\\"WSD evaluation methodology\\", \\"Chinese-to-English SMT model\\", \\"EVALUATE-FOR\\"], [\\"Senseval series of workshops\\", \\"dedicated word sense disambiguation (WSD) models\\", \\"EVALUATE-FOR\\"], [\\"SMT models\\", \\"translation\\", \\"USED-FOR\\"], [\\"WSD accuracy\\", \\"SMT models\\", \\"EVALUATE-FOR\\"], [\\"SMT models\\", \\"dedicated word sense disambiguation (WSD) models\\", \\"COMPARE\\"], [\\"dedicated word sense disambiguation (WSD) models\\", \\"SMT models\\", \\"USED-FOR\\"]]"},{"question":"Given a short query with keyphrases about a research idea in 2016 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: I want to recommend an expert who can answer my question to you. I can use Semantic Web technologies toKeyphrases: expert finding textDataset description:iVQA: An open-ended VideoQA benchmark that aims to: i) provide a well-defined evaluation by including five correct answer annotations per question and ii) avoid questions which can be answered without the video. iVQA contains 10,000 video clips with one question and five corresponding answers per clip.SNIPS: The SNIPS Natural Language Understanding benchmark is a dataset of over 16,000 crowdsourced queries distributed among 7 user intents of various complexity:   SearchCreativeWork (e.g. Find me the I, Robot television show), GetWeather (e.g.CommonsenseQA: The CommonsenseQA is a dataset for commonsense question answering task. The dataset consists of 12,247 questions with 5 choices each.DBpedia: DBpedia (from \\"DB\\" for \\"database\\") is a project aiming to extract structured content from the information created in the Wikipedia project. DBpedia allows users to semantically query relationships and properties of Wikipedia resources, including links to other related datasets.Options:- A: iVQA  B: SNIPS  C: CommonsenseQA  D: DBpedia","answer":"DBpedia"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Results of a Single Institution Experience with Dose-Escalated Chemoradiation for Locally Advanced Unresectable Non-Small Cell Lung Cancer We determined factors associated with morbidity and outcomes of a series of non-small cell lung cancer (NSCLC) patients treated with dose-escalated chemoradiotherapy at the University of Pittsburgh Lung Cancer Program. The records of 170 stage III NSCLC patients treated with definitive intent were retrospectively reviewed. All patients received four-dimensional CT simulation scan and had respiratory gating if tumor movement exceeded 5 mm. Overall survival (OS), locoregional control (LRC), and freedom from distant metastasis (FFDM) were calculated using log-rank and Cox regression analysis. For the present series of patients, median follow-up was 36.6 months, median survival 27.4 months, and the 2- and 4- year OS was 56.0 and 30.7%, respectively. The 4- year LRC and FFDM were 43.9 and 40.7%, respectively. No benefit was associated with irradiation doses above 66 Gy in OS (p = 0.586), LRC (p = 0.440), or FFDM (p = 0.230). On univariate analysis, variables associated with worse survival included: clinical stage IIIB (p = 0.037), planning target volume (PTV) over 450 cc (p < 0.001), heart V30 over 40% (p = -0.048), and esophageal mean dose over 20% (p = 0.024), V5 (p = -0.015), and V60 (p = -0.011). On multivariable analysis, PTV above 450 cc (52.2 vs. 25.3 months, p < 0.001) and esophageal V60 >20% (43.8 vs. 21.3 months, p = -0.01) were associated with lower survival. Grade 2 or higher acute lung toxicity and esophagitis were detected in 9.5 and 59.7%, respectively of patients. Grade 2 or higher acute lung toxicity was reduced if lung V5 was ≤65 (7.4 vs. 23.8%, p = 0.03). Grade 2 or higher acute esophagitis was reduced if V60 ≤ 20% (62 vs. 81.3%, p = 0.018). The use of intensity-modulated radiation therapy was more frequent in stage IIIB compared to stage IIIA patients (56.5 vs. 39.5%, p = 0.048) and was associated with a higher lung V5 and V10. The outcomes of a program of dose-escalated chemoradiotherapy for unresectable stage IIIA and IIIB NSCLC patients were consistent with other studies and showed no benefit to radiation doses above 66 Gy. Furthermore, maintaining low esophageal V60 and lung V5 were associated with lower morbidity and mortality.","answer":"{\\"AnatomicalStructure\\": [\\"lung\\", \\"heart\\"], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"FFDM\\", \\"IIIB\\", \\"tumor\\", \\"Non-Small Cell Lung Cancer\\", \\"stage IIIB\\", \\"NSCLC\\", \\"esophagitis\\", \\"movement\\", \\"stage III NSCLC\\", \\"non-small cell lung cancer\\", \\"locoregional\\", \\"stage IIIA\\", \\"freedom from distant metastasis\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [], \\"ClinicalAttribute\\": [\\"unresectable\\", \\"Unresectable\\"], \\"Eukaryote\\": [], \\"Finding\\": [\\"worse\\", \\"detected\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"chemoradiotherapy\\", \\"intensity-modulated radiation therapy\\", \\"Chemoradiation\\", \\"follow-up\\", \\"four-dimensional CT simulation scan\\", \\"treated\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [\\"Cox regression analysis\\", \\"records\\", \\"Grade 2\\", \\"log-rank\\"], \\"MedicalDevice\\": [\\"respiratory gating\\"], \\"Organization\\": [], \\"PopulationGroup\\": [], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"studies\\", \\"retrospectively reviewed\\"], \\"SpatialConcept\\": [\\"esophageal\\", \\"Locally\\"], \\"Virus\\": []}"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:ischemia in the brain may result from diverse mechanisms , although blockage of an artery with a clot or progressive narrowing due to atherosclerosis is the most common .such occlusions in proximal arteries at the base of the brain may be targeted with numerous revascularization approaches , from systemic thrombolysis to endovascular clot manipulation , in order to restore perfusion .revascularization remains the most intuitive strategy to reverse ischemic injury associated with arterial occlusion in acute stroke .revascularization may lead to opening of an occluded artery , or recanalization , yet restoration of downstream flow , or reperfusion , may not ensue ( figure 1 ) .novel devices and related procedures are rapidly evolving , but effective reperfusion with reversal of all neurological deficits remains an elusive goal .this novel method to measure blood flow from conventional angiography chronicles both recanalization and associated reperfusion in acute stroke .baseline ( top row ) and post - revascularization ( bottom row ) images display changes in cerebral blood flow ( cbf ) , cerebral blood volume ( cbv ) , mean transit time ( mtt ) , and cerebral perfusion pressure ( cpp ) .the last year has yielded several important publications relating to the quandary over current limits in reperfusion for acute ischemic stroke .the natural focus is often placed on the type of device or drug used , ascribing blame or credit to this one piece of the puzzle .much remains unclear , however , in such comparisons regarding one mode of therapy or another .the potential biases and need to maintain equipoise were recently reinstated in a detailed overview of the topic .it has been argued that equipoise should be bolstered by enrolling patients in clinical trials that successively incorporate new interventions. the potential role of intravenous thrombolysis for recanalization of various occlusion sites has also been examined in depth . in the echoplanar imaging thrombolytic evaluation trial , intravenous tissue plasminogen activator administered in the 3- to 6-hour time window showed poor recanalization of intracranial carotid artery ( ica ) lesions and far better results with middle cerebral artery ( mca ) occlusions .the treatment benefit of tissue plasminogen activator over placebo in limiting infarct evolution was greater for mca than for ica obstruction ( p = 0.060 ) .good clinical outcome was also more likely with mca than with ica occlusion ( p = 0.005 ) .this pattern of better recanalization in mca lesions was observed in univariate analyses of another study that looked at occurrence and predictors of futile endovascular recanalization .interestingly , however , the role of occlusion site disappeared in multivariate regression in which only age and baseline stroke severity were influential in predicting failed recanalization .futile recanalization was associated with age of more than 70 years ( odds ratio [ or ] 4.4 , 95% confidence interval [ ci ] 1.9 - 10.5 ; p = 0.0008 ) combined with an initial national institutes of health stroke scale ( nihss ) score of 10 - 19 ( or 3.8 , 95% ci , 1.7 - 8.4 ; p = 0.001 ) , and an initial nihss score of 20 or more ( or 64.4 , 95% ci 28.8 - 144 ; p < 0.0001 ) regardless of age .perhaps the extent of early ischemic changes in baseline imaging may be influential , as well .patients with a baseline nihss score of 10 - 19 may in fact be ideal candidates for endovascular interventions if the patients have small cores with proximal occlusions .accurate predictors of futile recanalization may be important in tailoring endovascular procedures and knowing when to cease attempts at opening an artery .another study looked at the critical number of passes to be used with the merci retriever system ( concentric medical , inc ., mountain view , ca , usa ) , noting that more than three thrombectomy attempts may be the cutoff .when at least four attempts were performed , the final result was more often failed revascularization and procedural complications ( p = 0.006 ) . such limitations with novel devices must be considered as new technology and methods are introduced . a recent report on the use of the enterprise stent (cordis corporation , bridgewater , nj , usa ) in just over a handful of patients reported successful angiographic reperfusion scores in all , yet the limitations of the scale parameter used ( e.g. , thrombolysis in cerebral infarction [ tici ] score of 2 or more ) may not be synonymous with full reperfusion .another study demonstrated appropriately defined reperfusion success , defining successful reperfusion as a tici grade of 2b or 3 in 18 of 20 ( 90% ) vessels treated with the solitaire stent ( ev3 inc . ,baseline imaging patterns , such as the extent of cerebral blood volume abnormalities , have also recently proven to predict fatal outcomes   and ultimately may prove to be very important in proper case selection .presumably , such variation is due to underlying differences in the potential of collateral compensation , and future diagnostic strategies may be able to better discern these key features .this surgery is currently reserved for life - threatening massive infarcts , yet one group suggested that it may be used at an earlier stage or pre - emptively or as early as possible in cases of failed multimodal therapy .finally , understanding the basic mechanisms of reperfusion and improved approaches is also under study .mechanisms such as ischemic post - conditioning , in which gradual reperfusion is employed to obtain optimal reperfusion , are worthy of further study .revascularization strategies and novel devices continue to broaden options for the treatment of acute stroke , but it is increasingly apparent that selection criteria to identify ideal cases are needed to refine triage and minimize adverse events .recent study results reinforce the need to be wary of trial results as the definitions of reperfusion may vary considerably .this focus on reperfusion is warranted because it is the closest surrogate of clinical outcome and the results of recent work on reperfusion may rapidly alter routine clinical practice for evolving ischemia in the brain .the topic of reperfusion is greatly expanding along molecular mechanisms to animal models to increasing attention in stroke cases subject to revascularization .finally , it should not be forgotten that clinical outcome is ultimately what matters most .randomized controlled studies have yet to unequivocally demonstrate that novel revascularization and prompt reperfusion impact outcome .","answer":"revascularization remains the most intuitive strategy to reverse ischemic injury associated with arterial occlusion in acute stroke .  revascularization may lead to opening of an occluded artery , or recanalization , yet restoration of downstream flow , or reperfusion , may not ensue .  revascularization strategies and novel devices continue to broaden options for the treatment of acute stroke , but it is increasingly apparent that selection criteria to identify ideal cases are needed to refine triage and minimize adverse events .  the results of recent work on reperfusion may rapidly alter routine clinical practice for evolving ischemia in the brain ."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: COVID-19 is a lung infection that aggressively attacks the lungs and even leaves lung cells and tissue deadAbstract:Some comorbidities are associated with severe coronavirus disease (Covid-19) but it is unclear whether some increase susceptibility to Covid-19.In this case-control Mexican study we found that obesity represents the strongest predictor for Covid-19 followed by diabetes and hypertension in both sexes and chronic renal failure in females only.Active smoking was associated with decreased odds of Covid-19.These findings indicate that these comorbidities are not only associated with severity of disease but also predispose for getting Covid-19.Future research is needed to establish the mechanisms involved in each comorbidity and the apparent \\"protective\\" effect of cigarette smoking.","answer":"{\\"verdict\\": \\"NEI\\", \\"evidence\\": []}"},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Does radiation for tinea capitis increases brain tumor risk?Context: Emphasis is placed on meningiomas resulting from childhood treatment for primary brain tumor or tinea capitis, exposure to dental x-rays, and exposure to atomic explosions in Hiroshima and Nagasaki.It is well known that radiation can induce meningiomas. These tumors usually arise in patients with a history of low-dose radiation to the scalp for treatment of tinea capitis or high-dose radiation for a previous brain tumor.This paper describes six cases of radiation-associated intracranial meningiomas in patients previously treated with low-dose radiation to the scalp for tinea capitis.After a median follow-up of 40 years, an ERR/Gy of 4.63 and 1.98 (95% CI = 2.43-9.12 and 0.73-4.69) and an EAR/Gy per 10(4) PY of 0.48 and 0.31 (95% CI = 0.28-0.73 and 0.12-0.53) were observed for benign meningiomas and malignant brain tumors, respectively.The estimated ERR/Gy for malignant brain tumors decreased with increasing age at irradiation from 3.56 to 0.47 (P = 0.037), while no trend with age was seen for benign meningiomas. The ERR for both types of tumor remains elevated at 30-plus years after exposure.Although meningiomas are known to be induced by low doses of cranial irradiation, such as those given to treat tinea capitis, little experience has been reported on the induction of meningiomas by high-dose cranial irradiation.The exposed rats had a greater incidence of pituitary chromophobe adenomas, epithelial and mesothelial cell tumors than the unexposed controls but the excessive occurrence of malignant gliomas that was observed in the monkeys was absent in the rats.We have analyzed 60 cases of intra-axial brain tumors associated with antecedent radiation therapy. These include four new cases. The patients had originally received radiation therapy for three reasons: (a) cranial irradiation for acute lymphoblastic leukemia (ALL), (b) definitive treatment of CNS neoplasia, and (c) treatment of benign disease (mostly cutaneous infections).Long-term follow-up for brain tumor development after childhood exposure to ionizing radiation for tinea capitis.Benign and malignant thyroid neoplasms after childhood irradiation for tinea capitis.There is evidence to show that moderate doses of ionising radiations given in childhood for tinea capitis are associated with a late risk of developing a meningiomaThis paper describes six cases of radiation-associated intracranial meningiomas in patients previously treated with low-dose radiation to the scalp for tinea capitis.These tumors usually arise in patients with a history of low-dose radiation to the scalp for treatment of tinea capitis or high-dose radiation for a previous brain tumor.There is evidence to show that moderate doses of ionising radiations given in childhood for tinea capitis are associated with a late risk of developing a meningioma.In addition to high dose radiation-induced meningiomas, intracranial meningiomas were observed in patients who underwent low-dose radiation for tinea capitis in childhood, applied en mass to immigrants coming to Israel from the North Africa and the Middle East during the 1950.A 39-year-old male developed primary brain lymphoma 33 years after receiving scalp irradiation for tinea capitis.Secondary glioblastoma multiforme (sGBM) can occur after a long latency period following radiation treatment of various diseases including brain tumors, leukemia, and more benign disorders like tinea capitis.The main data come from series of patients who underwent radiotherapy during childhood: a high incidence of tumors of the nervous system is found after irradiation of one to a few grays as treatment of a benign disease (especially tinea capitis), as well as after irradiation at higher doses of a few tens of grays for the treatment of cancer (in particular cerebral irradiation in acute lymphoblastic leukaemia).","answer":"yes"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Cardiac Na(+) channel dysfunction in Brugada syndrome is aggravated by beta(1)-subunit. BACKGROUND  Mutations in the gene encoding the human cardiac Na (+) channel alpha-subunit (hH1) are responsible for chromosome 3-linked congenital long-QT syndrome (LQT3) and idiopathic ventricular fibrillation (IVF). An auxiliary beta (1) -subunit, widely expressed in excitable tissues, shifts the voltage dependence of steady-state inactivation toward more negative potentials and restores normal gating kinetics of brain and skeletal muscle Na (+) channels expressed in Xenopus oocytes but has little if any functional effect on the cardiac isoform. Here, we characterize the altered effects of a human beta (1) -subunit (hbeta (1)) on the heterologously expressed hH1 mutation (T1620M) previously associated with IVF. METHODS AND RESULTS  When expressed alone in Xenopus oocytes, T1620M exhibited no persistent currents, in contrast to the LQT3 mutant channels, but the midpoint of steady-state inactivation (V (1/2)) was significantly shifted toward more positive potentials than for wild-type hH1. Coexpression of hbeta (1) did not significantly alter current decay or recovery from inactivation of wild-type hH1; however, it further shifted the V (1/2) and accelerated the recovery from inactivation of T1620M. Oocyte macropatch analysis revealed that the activation kinetics of T1620M were normal. CONCLUSIONS  It is suggested that coexpression of hbeta (1) exposes a more severe functional defect that results in a greater overlap in the relationship between channel inactivation and activation (window current) in T1620M, which is proposed to be a potential pathophysiological mechanism of IVF in vivo. One possible explanation for our finding is an altered alpha-/beta (1) -subunit association in the mutant..","answer":"{\\"Disease\\": [\\"LQT3\\", \\"idiopathic ventricular fibrillation\\", \\"Brugada syndrome\\", \\"IVF\\", \\"congenital long-QT syndrome\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Experimental expression in mice and spontaneous expression in human SLE of polyomavirus T-antigen. A molecular basis for induction of antibodies to DNA and eukaryotic transcription factors. We have previously demonstrated that experimental expression of the polyomavirus transcription factor T-antigen has the potential to induce anti-DNA antibodies in mice. Two sets of independent evidences are presented here that demonstrate a biological relevance for this model. First, we describe results demonstrating that mice inoculated with T-antigen-expressing plasmids produced antibodies, not only to T-antigen and DNA, but also to the DNA-binding eukaryotic transcription factors TATA-binding protein (TBP), and to the cAMP-response-element-binding protein (CREB). Secondly, we investigated whether polyomavirus reactivation occurs in SLE patients, and whether antibodies to T-antigen, DNA, and to TBP and CREB are linked to such events. Both within and among these SLE patients, frequent polyomavirus reactivations were observed that could not be explained by certain rearrangements of the noncoding control regions, nor by corticosteroid treatment. Linked to these events, antibodies to T-antigen, DNA, TBP, and CREB were detected, identical to what we observed in mice. Antibodies recognizing double-stranded DNA were confined to patients with frequent polyomavirus reactivations. The results described here indicate that cognate interaction of B cells recognizing DNA or DNA-associated proteins and T cells recognizing T antigen had taken place as a consequence of complex formation between T ag and DNA in vivo in the context of polyomavirus reactivations.","answer":"{\\"CellLine\\": [], \\"CellType\\": [\\"T cells\\"], \\"DNA\\": [\\"DNA\\", \\"T - antigen - expressing plasmids\\"], \\"Protein\\": [\\"DNA - associated proteins\\", \\"TBP\\", \\"the polyomavirus transcription factor T - antigen\\", \\"TATA - binding protein\\", \\"T ag\\", \\"eukaryotic transcription factors\\", \\"anti - DNA antibodies\\", \\"T antigen\\", \\"T - antigen -\\", \\"polyomavirus T - antigen\\", \\"CREB\\", \\"antibodies\\", \\"T - antigen\\", \\"DNA - binding eukaryotic transcription factors\\", \\"cAMP - response - element - binding protein\\", \\"polyomavirus transcription factor T - antigen\\", \\"the DNA - binding eukaryotic transcription factors TATA - binding protein (TBP)\\", \\"transcription factors\\"], \\"RNA\\": []}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: The paper presents a novel funnel-structured cascade (FuSt) detection framework forKeyphrases: multi-view face detection imagesDataset description:AFLW: The Annotated Facial Landmarks in the Wild (AFLW) is a large-scale collection of annotated face images gathered from Flickr, exhibiting a large variety in appearance (e.g., pose, expression, ethnicity, age, gender) as well as general imaging and environmental conditions. In total about 25K faces are annotated with up to 21 landmarks per image.SCUT-HEAD: Includes 4405 images with 111251 heads annotated.WHU: Created for MVS tasks and is a large-scale multi-view aerial dataset generated from a highly accurate 3D digital surface model produced from thousands of real aerial images with precise camera parameters.CelebA: CelebFaces Attributes dataset contains 202,599 face images of the size 178×218 from 10,177 celebrities, each annotated with 40 binary labels indicating facial attributes like hair color, gender and age.AFW: AFW (Annotated Faces in the Wild) is a face detection dataset that contains 205 images with 468 faces. Each face image is labeled with at most 6 landmarks with visibility labels, as well as a bounding box.Options:- A: AFLW  B: SCUT-HEAD  C: WHU  D: CelebA  E: AFW","answer":"[\\"AFLW\\", \\"CelebA\\", \\"AFW\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Potential drug interactions for doxylamine include, increased sedation if doxylamine is combined with other CNS depressant drugs. Antihistamines may partially counteract the anticoagulation effects of heparin or warfarin. Doxylamine may enhance the effects of epinephrine.","answer":"{\\"Brand\\": [], \\"Drug\\": [\\"Doxylamine\\", \\"epinephrine\\", \\"warfarin\\", \\"doxylamine\\", \\"heparin\\"], \\"DrugGroup\\": [\\"CNS depressant drugs\\", \\"Antihistamines\\"], \\"UnapprovedDrug\\": []}"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the dynamical systems approach @xcite has been used with great success over the last 30 years , to a gain ( qualitative ) description of the global dynamics of cosmological models .this method provides a useful tool for finding exact solutions which correspond to fixed points of the system .carloni _ et al _ @xcite have recently used this method to study the dynamics of @xmath0-theories in friedmann - lematre - robertson - walker ( flrw ) universes .clifton and barrow @xcite used the dynamical systems approach to determine the extent to which exact solutions can be considered as attractors of spatially flat universes at late times .they compared the predictions of these results with a range of observations and argued that the parameter @xmath1 in flrw may only deviate from gr by a very small amount ( @xmath2 ) .the main aim of this paper @xcite is to see how the shear behaves in lrs bianchi i cosmologies in @xmath0- gravity and whether these models isotropises at early and late times . to achieve this goal we use the theory of dynamical systems @xcite to analyse the system of equations governing the evolution of this model with and without matterthe cosmological equations that we require for our analysis are : @xmath3 where @xmath4 is the volume expansion and @xmath5 is the shear ( @xmath6 ) .    in order to convert the above equations into a system of autonomous first order differential equations , we define the following set of expansion normalised variables ; @xmath7 whose equations are @xmath8 , nonumber  & & z ' = zleft[ 2z-(1 + 3w)-3x-frac{2y}{n-1}+4sigmaright ] , nonumber & & 1-sigma+x - y - z=0 , nonumberend{aligned} ] ] where primes denote derivatives with respect to a new time variable @xmath9 .the solutions associated to the fixed points can be obtained from : @xmath10 under the condition that @xmath11 and the terms inside the brackets of , do not add up to zero , these equations may be integrated to give the following solutions @xmath12    in terms of our expansion normalised variables , the energy density is given by @xmath13 from this relation it can be seen that when @xmath14 and @xmath15 the energy density is zero .however when @xmath16 and @xmath17 the behaviour of @xmath18 does depend on the value of @xmath1 . in this case the energy density is zero when @xmath19 but is divergent when @xmath20 .when both @xmath21 and @xmath22 are equal to zero and @xmath20 , one can only determine the behaviour of @xmath18 by direct substitution into the cosmological equations .the vacuum case is characterised by @xmath14 . in this casewe can obtain the fixed points of by setting @xmath23 and @xmath24 .we find one isotropic fixed point ( @xmath25 and a line of fixed points ( @xmath26 , with non - vanishing shear .the isotropic fixed point is an attractor ( stable node ) for values of the parameter @xmath1 in the ranges @xmath27 , @xmath28 and @xmath29 . in the range@xmath30 this point is a repeller ( unstable node ) and therefore may be seen as a past attractor .however , we also have attractors for @xmath31 on @xmath32 .therefore inflation may not be needed since the shear anisotropy approaches a constant value which may be chosen as the expansion normalised shear observed today@xcite ( @xmath33 ) , provided that other observational constraints such as nucleosynthesis are satisfied .    the phase space is divided into two regions by the line @xmath34 , which represents all points for which the shear dissipate at the same rate as in gr .the region @xmath35 represents a _ fast shear dissipation _( fsd ) regime where shear dissipates faster than in gr , and the region @xmath36 , is a _slow shear dissipation _ ( ssd )regime where the shear dissipates slower than in gr ( see figure 1 ) .# 1    ( # 1 )      setting @xmath23 , @xmath24 and @xmath37 we obtain three isotropic fixed points and a line of fixed points with non - vanishing shear .we observe the same kind of behaviour as in the vacuum case ; the phase space is however 3-dimensional , but is similarly divided into two regions , by the plane @xmath38 .the space above the plane is a ssd region and below a fsd region .in conclusion we have shown that @xmath0- gravity modifies the dynamics of the shear in lrs bianchi i cosmologies by altering the rate at which the shear dissipates .there are cases in which the shear always dissipates slower or faster than in gr , and there are ones which make the transition from first evolving faster and then slower ( and _ vice versa _ ) than in gr .","answer":"we consider the case of @xmath0-gravity and perform a detailed analysis of the dynamics in bianchi i cosmologies which exhibit _ local rotational symmetry _  ( lrs ) .  we find exact solutions and study their behaviour and stability in terms of the values of the parameter @xmath1 .  in particular , we found a set of cosmic histories in which the universe is initially isotropic , then develops shear anisotropies which approaches a constant value ."},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:INTRODUCTION: COVID-19 emerged as a global pandemic in 2020 and has affected millions of lives. Surgical training has also been significantly affected by this pandemic, but the exact effect remains unknown. We sought to perform a national survey of general surgery residents in the United States to assess the effect of COVID-19 on surgical resident training, education, and burnout. METHODS: An anonymous online survey was created and distributed to general surgery residents across the United States. The survey aimed to assess changes to surgical residents' clinical schedules, operative volume, and educational curricula as a result of the COVID-19 pandemic. Additionally, we sought to assess the impact of COVID-19 on resident burnout. RESULTS: One thousand one hundred and two general surgery residents completed the survey. Residents reported a significant decline in the number of cases performed during the pandemic. Educational curricula were largely shifted toward online didactics. The majority of residents reported spending more time on educational didactics than before the pandemic. The majority of residents feared contracting COVID-19 or transmitting it to their family during the pandemic. CONCLUSIONS: COVID-19 has had significant impact on surgical training and education. One positive consequence of the pandemic is increased educational didactics. Online didactics should continue to be a part of surgical education in the post-COVID-19 era. Steps need to be taken to ensure that graduating surgical residents are adequately prepared for fellowship and independent practice despite the significantly decreased case volumes during this pandemic. Surgery training programs should focus on providing nontechnical clinical training and professional development during this time.","answer":"[\\"Prevention\\"]"},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: that smokers with Covid-19 are more likely to develop severe diseaseAbstract:Introduction Epidemiological and laboratory research seems to suggest that smoking and perhaps nicotine alone could reduce the severity of COVID-19.Likewise, there is some evidence that inhaled corticosteroids could also reduce its severity, opening the possibility that nicotine and inhaled steroids could be used as treatments.Methods In this prospective cohort study, we will link English general practice records from the QResearch database to Public Health England's database of SARS-CoV-2 positive tests, Hospital Episode Statistics, admission to intensive care units, and death from COVID-19 to identify our outcomes: hospitalisation, ICU admission, and death due to COVID.Using Cox regression, we will perform sequential adjustment for potential confounders identified by separate directed acyclic graphs to: 1.Assess the association between smoking and COVID-19 disease severity, and how that changes on adjustment for smoking-related comorbidity.2. More closely characterise the association between smoking and severe COVID-19 disease by assessing whether the association is modified by age (as a proxy of length of smoking), gender, ethnic group, and whether people have asthma or COPD.3. Assess for evidence of a dose-response relation between smoking intensity and disease severity, which would help create a case for causality.4.Examine the association between former smokers who are using NRT or are vaping and disease severity.5. Examine whether pre-existing respiratory disease is associated with severe COVID-19 infection.6. Assess whether the association between chronic obstructive pulmonary disease (COPD) and asthma and COVID-19 disease severity is modified by age, gender, ethnicity, and smoking status.7. Assess whether the use of inhaled corticosteroids is associated with severity of COVID-19 disease.8. To assess whether the association between use of inhaled corticosteroids and severity of COVID-19 disease is modified by the number of other airways medications used (as a proxy for severity of condition) and whether people have asthma or COPD.Conclusions This representative population sample will, to our knowledge, present the first comprehensive examination of the association between smoking, nicotine use without smoking, respiratory disease, and severity of COVID-19.We will undertake several sensitivity analyses to examine the potential for bias in these associations.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Introduction Epidemiological and laboratory research seems to suggest that smoking and perhaps nicotine alone could reduce the severity of COVID-19.\\"]}"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: Understanding temporal sequences is important for solving many problems in theAI-set. Recently, recurrent neural networks using the Long Short Term Memory(LSTM) architecture (Hochreiter & Schmidhuber, 1997) have been used successfully to perform various supervisedsequence learning tasks, such as speech recognition (Graves & Jaitly, 2014), machinetranslation (Sutskever et al., 2014; Cho et al., 2014), and caption generation for images(Vinyals et al., 2014). They have also been applied on videos for recognizingactions and generating natural language descriptions (Donahue et al., 2014). Ageneral sequence to sequence learning framework was described by Sutskever et al. (2014)in which a recurrent network is used to encode a sequence into a fixed lengthrepresentation, and then another recurrent network is used to decode a sequenceout of that representation. In this work, we apply and extend this framework tolearn representations of sequences of images. We choose to work in theunsupervised setting where we only have access to a dataset of unlabelledvideos.Question: How good the LSTM based encode/decoder work for real time applications keeping in view their sequential nature?","answer":"Since LSTM based encoder/decoder method successfully worked for real time sequential nature application, it is a good method."},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Theoretical study of the decomposition of ethyl and ethyl 3-phenyl glycidate. The mechanism of the decomposition of ethyl and ethyl 3-phenyl glycidate in gas phase was studied by density functional theory (DFT) and MP2 methods. A proposed mechanism for the reaction indicates that the ethyl side of the ester is eliminated as ethylene through a concerted six-membered cyclic transition state, and the unstable intermediate glycidic acid decarboxylates rapidly to give the corresponding aldehyde. Two possible pathways for glycidic acid decarboxylation were studied: one via a five-membered cyclic transition state, and the other via a four-membered cyclic transition state. The results of the calculations indicate that the decarboxylation reaction occurs via a mechanism with five-membered cyclic transition state.","answer":"[]"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Solvent-free powder synthesis and thin film chemical vapour deposition of a zinc bipyridyl-triazolate frameworkPaper sections:Introduction<p>Coordination polymers are built from metal ion nodes interconnected by organic linkers. Among these materials, crystalline and microporous metal-organic frameworks (MOFs) have been extensively studied because of their record-breaking specific surface area (up to 7500 m² g -1 ) and functionalisable pore interior. [1,2] MOFs are typically synthesized under solvothermal conditions. For example, Yaghi and co-workers prepared zeolitic imidazolate frameworks (ZIFs), a subclass of MOFs, using metal salts and various imidazole linkers in solution. [3] At the same time, Chen and co-workers obtained similar or identical materials, and called these metal-azolate frameworks (MAFs). [4,5] Later, a more sustainable preparation method was demonstrated, based on solvent-free reactions in mixtures of metal oxide and linker (OSFR). [6,7] Interestingly, a number of MOF materials can only be obtained under solvent-free conditions. [8] The deposition of new materials as thin film, a prerequisite for their introduction in several applications (e.g., microelectronics), [9] is often achieved through adaptation of powder preparation routes. [10] For example, MOF chemical vapour deposition (MOF-CVD) was inspired by OSFR chemistry. [11] The MOF-CVD approach relies on two steps: vapour-phase deposition of an oxide precursor followed by its reaction with the vaporised linker. [11][12][13][14] Recently, we developed CVD protocols for the microporous zinc 2-methylimidazolate ([Zn(mIm)2]) MAF-4 (also known as ZIF-8) and mesoporous zinc 2-ethylimidazolate ([Zn(eIm)2]) MAF-6. [11,14] Other candidates to expand the scope of this CVD approach are an isostructural series of MAFs based on ). [6,7] Here, we focused on the undocumented reaction of ZnO with the commercially available linker Hdpt. Surprisingly, the reaction yields a material that is not the Znanalogue of MAF-25, but rather a novel non-porous crystalline coordination polymer to which we further refer as MAF-252 (read: 'MAF-25 two'). This study reports the solvent-free formation and characterisation of MAF-252 in powder form and as thin films (Figure 1).</p>Results and Discussion<p>MAF-252 powder was synthesized by heating a mixture of ZnO and Hdpt at 270 °C for 16 h in a glass ampoule, as for the OSFR of other H(m)dpt-based MAFs. [6,7] This approach can be translated to a thin film deposition process following a two-step reaction scheme, as in MOF-CVD: (1) deposition a thin (1-15 nm) ZnO layer and (2) reaction of the ZnO layer with Hdpt vapour. The resulting MAF-252 powder has a beige colour, while the MAF-252 films have a homogeneous mirror-like appearance (Figure 1). MAF-252 CVD requires a reaction temperature ≥ 175 °C (step 2) (Figure S3.1). For this study, MAF-252 thin films were deposited within an hour in a simple glass reactor kept at 200 °C to ensure a high enough vapour pressure of this low-volatily linker (Figures Supporting information for this article is given via a link at the end of the document.((Please delete this text if not appropriate)) S2.1 and S2.2). MAF-252 CVD is a very simple and robust film deposition process, while ZIF-8 and MAF-6 CVD require precise control over the atmosphere composition (e.g., relative humidity), as well as the temperature gradient between substrate and reactor to achieve reproducible film morphology. [15] MAF-252 powder and films are crystalline and have similar ATR-FTIR spectra and diffraction patterns (Figure 2a,d). No match was found with a known crystal structure. The cell parameters and symmetry cannot be unambiguously identified from the powder pattern because of the limited number of reflections and broad peaks. In both cases, no ZnO is observed by X-ray diffraction, suggesting complete reaction of ZnO with the linker, as also reported for MAF-28. [6] MAF-252 CVD is sensitive to the ZnO crystallinity and orientation. MAF-252 films grown from amorphous or poorly crystalline ZnO display a powder-like GIXRD pattern, characteristic of a random crystallite orientation (Figure S3.5). Conversely, diffraction spots instead of continuous rings are observed in the GIXRD pattern of MAF-252 films grown from (100)-oriented and (002)-oriented crystalline ZnO layers, suggesting some degree of crystallite orientation (Figure 2e, Figure S3.5). These observations are reflected in the film morphology. The morphology of MAF-252 films grown from nonoriented ZnO and powders as observed by SEM is identical and consists of elongated micron-sized crystallites, as for MAF-27 ([Mg(mdpt)2]) (Figure 2c). [6] Films grown from oriented ZnO display larger crystallites lying parallel to the surface, that we believe result in the observed out-of-plane orientation in the GIXRD patterns. The formation of these large crystallites likely stems from a difference in MAF-252 nucleation, growth and crystallite ripening for the different types of ZnO precursor, as observed elsewhere for ZIF-8 CVD. [15] MAF-252 CVD is insensitive to the substrate surface chemistry: films with identical morphology can be deposited on Si, Au, and TiO2 (Figure S3.7).</p><p>Thermogravimetric analysis of MAF-252 in air shows no weight loss below 400 °C. (Figure 2b). Above 400 °C, the material decomposes to ZnO. Since the observed weight loss (83 %) matches the weight loss expected for [Zn(dpt)2] (84 %), MAF-252 likely has this chemical formula, similar to MAF-25 ([Co(dpt)2]) and MAF-28 ([Zn(mdpt)2]) prepared under the same conditions (Table S4.1). [6,7] Temperature-dependent PXRD and SEM confirm the degradation of MAF-252 above 400 °C (Figures S4.2-S4.4).</p><p>While MAF-25 is porous to both N2 and CO2, no porosity was detected in MAF-252 powder by N2 and CO2 physisorption, and in MAF-252 films by Kr physisorption and MeOH ellipsometric porosimetry, even after activation for 12 h at 350 °C under dynamic vacuum. MAF-252 CVD was also investigated as a function of starting ZnO thickness and CVD reaction time by SEM, GIXRD, AFM, and ellipsometry. MAF-252 films grown from 1 nm of ZnO show scattered crystals on the surface. Thicker ZnO layers yield MAF-252 films with full surface coverage (Figures S3.2 and S3.3). Conversion of ZnO to MAF-252 is paired with a significant thickness increase. Starting from 1, 4 and 11 nm of ZnO yields MAF-252 films with a thickness of 19, 77, and 109 nm after 16 h, respectively (Figure S3.4). The corresponding film thickness expansion factors are respectively 19, 19 and 10, which is remarkably large for oxide-to-MAF conversions (Table 1). As observed for other materials, linker diffusion hindered by the growing film causes incomplete oxide-to-MAF conversion and a lower apparent expansion factor (10 vs 19) when starting from thick oxide layers. [11]   Theoretical values based on the bulk ZnO density (5.6 g cm -3 ) and measured ALD ZnO density (3.9 g cm -3 ), and the know crystal structure of ZIF-8 (MAF-4), MAF-6, and MAF-28. Experimental value from the ratio of the measured ellipsometric film thickness of ZnO precursor and MAF-252 films.</p><p>Different growth stages can be observed: smooth and thin amorphous films in the first 10 min likely corresponding to the surface reaction between ZnO and Hdpt vapour, followed by MAF-252 nucleation and crystallization observed as a steep increase in film thickness and roughness. After 1 h reaction, the growing MAF-252 film hinders the linker diffusion and further oxide conversion. At the same time, larger crystallites are formed by ripening (Figure 3 and S3.4). A similar growth process was observed for ZIF-8 CVD. [15] Some applications could benefit from the large film expansion upon conversion of ZnO to MAF-252 and the high carbon content of the resulting films (e.g., carbonization for use in microsupercapacitors). For integration into microelectronics, compatibility of the deposition process with typical microfabrication steps is critical. Therefore, the conformality of MAF-252 CVD and film patterning were evaluated (Figure 4). Conformal ZnO precursor layers were deposited by atomic layer deposition (ALD) on high aspect ratio (25:1) silicon micropillars and converted to conformal MAF-252 films over the whole micropillar length. ZnO was also patterned on a flat substrate by lithography and converted to MAF-252. The original pattern was maintained with high fidelity.</p>Conclusions<p>The formation of the non-porous crystalline coordination polymer MAF-252 from ZnO and a commercially available linker is an example of the potential of solvent-free, vapour-phase processing. MAF-252 CVD is compatible with microfabrication. While the crystal structure of MAF-252 remains to be solved, its integration in applications could benefit from the robustness and the large film expansion factor of the deposition process.</p>Experimental Section<p>Material and methods can be found in the electronic supporting information.</p>","answer":"MAF-252, a non-porous crystalline coordination polymer, is obtained from the solvent-free reaction of ZnO with 3-(2-pyridyl)-5-(4pyridyl)-1,2,4-triazole. MAF-252 can be synthesized in powder form and deposited as thin films, starting from ZnO powder and layers, respectively. Chemical vapour deposition (CVD) of MAF-252 enables conformal and patterned thin films, even on high aspect ratio features."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Activating glucocorticoid receptor-ERK signaling pathway contributes to ginsenoside Rg1 protection against β-amyloid peptide-induced human endothelial cells apoptosis.The deposition of β-amyloid (Aβ) in neurons and vascular cells of the brain has been characterized in Alzheimer's disease. Ginsenoside Rg1 (Rg1) is an active components in Panax ginseng, a famous traditional Chinese medicines recorded in Compendium of Materia Medica. Present study attempted to evaluate the potential mechanisms of Aβ-mediated insult and the protective effects of Rg1 on human endothelial cells. Rg1 attenuated the Aβ25-35-associated mitochondrial apoptotic events, accompanied by inhibiting HIF-1α expression followed by intracellular reactive nitrogen species generation, and protein nitrotyrosination. These protective effects were abolished by glucocorticoid receptor (GR) antagonist RU486 or p-ERK inhibitor U0126 rather than estrogen receptor α antagonist ICI 82,780. Taken together, our results suggested that Rg1 protected against Aβ25-35-induced apoptosis at least in part by two complementary GR-dependent ERK phosphorylation pathways: (1) down-regulating HIF-1α initiated protein nitrotyrosination, and (2) inhibiting mitochondrial apoptotic cascades. These data provided a novel insight to the mechanisms of Rg1protective effects on Aβ25-35-induced endothelial cells apoptosis, suggesting that GR-ERK signaling pathway might play an important role in it.","answer":"{\\"Chemical\\": [\\"ginsenoside Rg1\\", \\"Ginsenoside Rg1\\", \\"ICI 82,780\\", \\"U0126\\", \\"RU486\\", \\"nitrogen\\", \\"estrogen\\", \\"Rg1\\"], \\"Protein\\": [\\"Au03b225-35\\", \\"ERK\\", \\"u03b2-amyloid peptide\\", \\"Au03b2\\", \\"glucocorticoid receptor\\", \\"u03b2-amyloid\\", \\"GR\\", \\"HIF-1u03b1\\", \\"p-ERK\\", \\"estrogen receptor u03b1\\"]}"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: What is the mechanism of action of donanemab?Context: Considering the recent clinical success of donanemab, which targets AβΝ3pE, small molecule-based QC inhibitors may also provide potential therapeutic options for early-stage AD treatment.Recently, passive immunization of AD patients with Donanemab, an antibody directed against the N-terminus of pyroglutamate Aβ, showed beneficial effects in a phase II trial, supporting the concept that N-truncated Aβ is a relevant target for AD therapy.The late-stage agents with positive clinical or biomarker data include four antibodies that engage Aβ oligomers (aducanumab, lecanemab, gantenerumab, and donanemab) and ALZ-801, an oral agent that fully blocks the formation of Aβ oligomers at the clinical dose.Donanemab (LY3002813) is a new monoclonal antibody that uniquely targets Aβ(p3-42), a pyroglutamate form of Amyloid-β (Aβ) exclusively found in plaques.matically changed with the report that passive immunization with donanemab, an AβpE3-specific antibody, cleared aymloid plaques and stabilized cognitive deficits in a group of patients with mild AD in a phase II trial. This review summarizes the current knowledgtion has dramatically changed with the report that passive immunization with donanemab, an AβpE3-specific antibody, cleared aymloid plaques and stabilized cognitive deficits in a group of patients with mild AD in a phase II trial. This reaches targeting pGlu3-Aβ by glutaminyl cyclase (QC) inhibition (Varoglutamstat) or monoclonal antibodies (Donanemab) are currently in clinical development. Here, wepeptide. Donanemab, an antibody that targets a modified form of deposited Aβ, is being investigated for the treatment of early Alzheimer's dy, passive immunization of AD patients with Donanemab, an antibody directed against the N-terminus of pyroglutamate Aβ, showed beneficial effects in a phase II trial, supporting the concept that N-truncated Aβ is a relevant target for AD therapy. There iss costly. Donanemab (LY3002813) is a new monoclonal antibody that uniquely targets Aβ(p3-42), a pyroglutamate form of Amyloid-β (Aβ) exclusively found in plBACKGROUND: Donanemab (LY3002813) is an IgG1 antibody directed at an N‑terminal pyroglutamate of amyloid beta epitope that is present only in brain amyloBACKGROUND: Donanemab (LY3002813) is an IgG1 antibody directed at an N‑terminal pyroglutamate of amyloid beta epitope that is present only in brain amylβ) peptide. Donanemab, an antibody that targets a modified form of deposited Aβ, is being investigated for the treatment of early Alzheimend is costly. Donanemab (LY3002813) is a new monoclonal antibody that uniquely targets Aβ(p3-42), a pyroglutamate form of Amyloid-β (Aβ) exclusively found in plaques.AREAS COVERED: The phase 2 trial of donanemab in participants with early symptomatic Alzheimeβ) peptide. Donanemab, an antibody that targets a modified form of deposited Aβ, is being investigated for the treatment of early Alzheimer's disease.METHODS: We conducted a phase 2 trial of donanemab in patients with early symptomatic Alzheimer's disease who had tau and amyloid deposition on positron-emissBACKGROUND: Donanemab (LY3002813) is an IgG1 antibody directed at an N‑terminal pyroglutamate of amyloid beta epitope that is present only in brain amyloid plaques.OBJECTIVES: To assess effects of donanemab on brain amyloid plaque load after single and multiple intravenous doses, as well as pharmacokinetics, safety/tolerability, and immunogenicity.DESIGN: Phase 1b, investigator- and patient-blind, randomized, placebo-controlled study.SETTING: Patients recruited at clinical research sites in the United States and Japan.PARTICIPANTS: 61 amyloid plaque-positive patients with mild cognitive impairment due to Alzheimer's disease and mild-to-moderate Alzheimer's disease dementia.INTERVENTION: Six cohorts were dosed with donanemab: single dose 10-, 20- or 40- mg/kg (N = 18), multiple doses of 10-mg/kg every 2 weeks for 24 weeks (N = 10), and 10- or 20-mg/kg every 4 weeks for 72 weeks (N=18) or placebo (N = 15).MEASUREMENTS: Brain amyloid plaqueRecently, passive immunization of AD patients with Donanemab, an antibody directed against the N-terminus of pyroglutamate Aβ, showed beneficial effects in a phase II trial, supporting the concept that N-truncated Aβ is a relevant target for AD therapy.This situation has dramatically changed with the report that passive immunization with donanemab, an AβpE3-specific antibody, cleared aymloid plaques and stabilized cognitive deficits in a group of patients with mild AD in a phase II trial.Approaches targeting pGlu3-Aβ by glutaminyl cyclase (QC) inhibition (Varoglutamstat) or monoclonal antibodies (Donanemab) are currently in clinical development.","answer":"Donanemab is a new monoclonal antibody that uniquely targets Aβ(p3-42), a pyroglutamate form of Amyloid-β (Aβ) exclusively found in plaques."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:No information provided","answer":"{\\"Brand\\": [], \\"Drug\\": [], \\"DrugGroup\\": [], \\"UnapprovedDrug\\": []}"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:(2010) 6(9) 1436 future science group Review Grotenhuis, Vermeulen & Kiemeney presence of visceral (lung, liver or bone) metastasis showing the most consistent results [24].","answer":"Background"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: What states the second parity rule (PR2)?Context: Chargaff' s second parity rule (PR2) states that complementary nucleotides are met with almost equal frequencies in single stranded DNA.Sueoka and Lobry declared respectively that, in the absence of bias between the two DNA strands for mutation and selection, the base composition within each strand should be A=T and C=G (this state is called Parity Rule type 2, PR2)The intra-strand Parity Rule 2 of DNA (PR2) states that A=T and G=C within each strands.deviations from the PR2 is a sign of strand-specific (or asymmetric) mutation and/or selection pressures.PR2 is an intra-strand rule where A=T and G=C are expected when there are no biases between the two complementary strands of DNA in mutation and selection rates (substitution rates)When there are no biases in mutation and selection between the two strands of DNA, the 12 possible substitution rates of the four nucleotides reduces to six (type 1 parity rule or PR1), and the intrastrand average base composition is expected to be A = T and G = C at equilibrium without regard to the G + C content of DNA (type 2 parity rule or PR2)The second method was to plot the intrastrand bias of the third codon position from Parity Rule 2 (PR2), where A = T and G = C.The extent of deviation from intra-strand equality rule of A = T and G = C (Parity Rule 2, or PR2) is specific for individual amino acids and has been expressed as the PR2-bias fingerprint.When there are no biases in mutation and selection between the two strands of DNA, the 12 possible substitution rates of the four nucleotides reduces to six (type 1 parity rule or PR1), and the intrastrand average base composition is expected to be A = T and G = C at equilibrium without regard to the G + C content of DNA (type 2 parity rule or PR2).Chargaff s second parity rule (PR2) states that complementary nucleotides are met with almost equal frequencies in single stranded DNA.The second parity rule of Chargaff (AHT and GHC within one strand) holds all over the living world with minor exceptions.The second method was to plot the intrastrand bias of the third codon position from Parity Rule 2 (PR2), where A = T and G = C.The extent of deviation from intra-strand equality rule of A = T and G = C (Parity Rule 2, or PR2) is specific for individual amino acids and has been expressed as the PR2-bias fingerprint.Chargaff' s second parity rule (PR2) states that complementary nucleotides are met with almost equal frequencies in single stranded DNAThe intra-strand Parity Rule 2 of DNA (PR2) states that A=T and G=C within each strandsThe second method was to plot the intrastrand bias of the third codon position from Parity Rule 2 (PR2), where A = T and G = CThe extent of deviation from intra-strand equality rule of A = T and G = C (Parity Rule 2, or PR2) is specific for individual amino acids and has been expressed as the PR2-bias fingerprint","answer":"The second parity rule (PR2), also known as Chargaff' s second parity rule, is an intra-strand rule which states that, when there are no biases between the two complementary strands of DNA in mutation and selection rates (substitution rates), complementary nucleotides are expected to have almost equal frequencies within single stranded DNA, namely A = T and G = C at equilibrium, without regard to the G + C content of the DNA."},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:animal care and procedures were approved and performed in accordance with the standards set forth by the national institutes of health and the university of iowa animal care and use committee .animal care and procedures were approved and performed in accordance with the standards set forth by the national institutes of health and the university of iowa animal care and use committee .","answer":"many neuromuscular conditions are characterized by an exaggerated exercise - induced fatigue response that is disproportionate to activity level .  this fatigue does not necessarily correlate with elevated central or peripheral fatigue in patients1 , and some patients experience severe fatigue without any demonstrable somatic disease2 . except in myopathies that are due to specific metabolic defects ,  the mechanism underlying this type of fatigue remains unknown2 . with no treatment available  , this form of inactivity is a major determinant of disability3 . here  we show , using mouse models , that this exaggerated fatigue response is distinct from a loss in specific force production by muscle , and that sarcolemma - localized nnos signaling in skeletal muscle is required to maintain activity after mild exercise . of significance , we show that nnos - null mice do not have muscle pathology and have no loss of muscle specific - force after exercise , but do display this exaggerated fatigue response to mild exercise . in mouse models of nnos mislocalization from the sarcolemma ,  prolonged inactivity was only relieved by pharmacologically enhancing the cgmp signal that results from muscle nnos activation during the nitric oxide signaling response to mild exercise .  our findings suggest that the mechanism underlying the exaggerated fatigue response to mild exercise is a lack of contraction - induced signaling from sarcolemma - localized nnos , which reduces cgmp - mediated vasomodulation in the vessels that supply active muscle after mild exercise .  notably , sarcolemmal nnos was reduced in patient biopsies from a large number of distinct myopathies , suggesting a common mechanism of fatigue .  our results suggest that patients with an exaggerated fatigue response to mild exercise would show clinical improvement in response to treatment strategies aimed at improving exercise - induced signaling ."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Crystal Structure of an Ammonia-Permeable Aquaporin}Article:Abstract:Aquaporins of the TIP subfamily( Tonoplast Intrinsic Proteins) have been suggested to facilitate permeation of water and ammonia across the vacuolar membrane of plants, allowing the vacuole to efficiently sequester ammonium ions and counteract cytosolic fluctuations of ammonia. Here, we report the structure determined at 1. 18 Å resolution from twinned crystals of Arabidopsis thaliana aquaporin AtTIP2;1 and confirm water and ammonia permeability of the purified protein reconstituted in proteoliposomes as further substantiated by molecular dynamics simulations. The structure of AtTIP2;1 reveals an extended selectivity filter with the conserved arginine of the filter adopting a unique unpredicted position. The relatively wide pore and the polar nature of the selectivity filter clarify the ammonia permeability. By mutational studies, we show that the identified determinants in the extended selectivity filter region are sufficient to convert a strictly water-specific human aquaporin into an AtTIP2;1-like ammonia channel. A flexible histidine and a novel water-filled side pore are speculated to deprotonate ammonium ions, thereby possibly increasing permeation of ammonia. The molecular understanding of how aquaporins facilitate ammonia flux across membranes could potentially be used to modulate ammonia losses over the plasma membrane to the atmosphere, e. g., during photorespiration, and thereby to modify the nitrogen use efficiency of plants.Introduction:Nitrogen is a macronutrient that is often limiting for plant growth. Hence, efficient channeling and storage of ammonia, a central molecule in nitrogen metabolism, is of fundamental importance. Tonoplast Intrinsic Proteins( TIPs) belonging to the Major Intrinsic Protein family, also known as the aquaporin( AQP) superfamily, have been shown to conduct both water[1] and ammonia[2–4]. TIPs are present in all land plants, but whereas primitive plants like mosses only have one type of TIP( TIP6), five specialized subgroups( TIP1‒5) have evolved in higher plants[5]. TIPs may constitute up to 40% of the protein in the vacuolar membrane, i. e., the tonoplast[6], and have been suggested to enhance nitrogen uptake efficiency and detoxification by acid entrapment of ammonium ions in vacuoles[3]. Furthermore, TIP-mediated increase of ammonia permeability was proposed to play a role in remobilization of vacuolar ammonia during nitrogen starvation[2] and in reallocation of nitrogen at senescence[7]. Recently, TIPs were included in a revised model of futile cycling under high ammonia conditions[8]. Sequence similarities to TIPs are observed in mammalian AQP8s[9], which are also ammonia-permeable[10] and have been implicated in pathological conditions like hyperammonemia and hepatic encephalopathy[11]. Crystal structures have established that AQPs are homotetramers, where each of the monomers holds a functional pore created by six membrane-spanning helices( helix 1‒helix 6), five connecting loops( loop A‒loop E), and two shorter helices( helix B and helix E; Fig 1), both displaying the AQP-signature motif Asn-Pro-Ala( NPA)[12–16]. Helices B and E connect at the NPA motifs in the middle of the membrane, thus forming a bipartite transmembrane segment. Different AQP isoforms facilitate permeation of a variety of small uncharged polar molecules, while protons are efficiently excluded from the pore in part by the positive charge, which is focused at the NPA region by the macro dipoles of the short helices[17]. Substrate specificity is thought to be achieved by the aromatic/arginine selectivity filter[18], which has been defined as four residues located at the noncytosolic end of the pore[19]. Of these residues, an arginine is conserved in the short helix E of most AQPs and contributes to the exclusion of protons[20], whereas a histidine in helix 5 is associated with water specificity[13]. AQPs permeable to ammonia and water called aquaammoniaporins, including the human HsAQP8, typically lack the histidine in helix 5 but instead have a histidine in helix 2[2–4]. However, all previously published AQP structures represent either water-specific channels( true AQPs) or the water- and glycerol-conducting aquaglyceroporins, so a further understanding of the structural features that confer ammonia selectivity has been missing. To close this gap in knowledge, we set out to crystallize the aquaammoniaporin AtTIP2;1 from A. thaliana. Here, we present the crystal structure of AtTIP2;1 determined at atomic resolution( 1. 18 Å with partial twinning). Combined with molecular dynamics( MD) simulations and functional studies of mutants, the structure provides new insight into the molecular basis of substrate selectivity in the AQP superfamily.Discussion:The atomic structure of the water and ammonia permeable AtTIP2;1 provides new insights into the substrate selectivity of AQPs. The structure reveals an extended selectivity filter, including a fifth amino acid residue at position LCP in loop C that also may play a role in defining substrate profiles of the entire AQP superfamily. The importance of the extended selectivity filter is demonstrated by mutational studies in vivo and in vitro, showing gain-of-function of AtTIP2;1 substrate selectivity in the water-specific human AQP1. MD simulations support ammonia conductance and a lack of ammonium permeability. As expected from the structure, ammonia interacts with LCP-His 131 and behaves similar to water in the pores of AQPs[18], reorienting in the NPA region at the N-termini of helix B and helix E due to their macro dipoles( S1 Movie). Based on structural analyses and simulations, we describe a selectivity filter that is highly permeable to ammonia due to its width and many potential polar contacts with the substrate and speculate on a mechanism in which ammonia permeation may be further increased by ammonium accumulation at the vacuolar protein surface, deprotonation through the TIP2-specific LCP-His 131, and proton transfer via a previously unidentified water-filled side pore. It should be stressed that there is only limited support from simulations for this speculation, and without confirmatory structures it is difficult to specifically target the side pore by mutations or to predict if it is a conserved feature of other TIPs and AQP8s. However, we find it most likely that the conserved arginine at position HEP in helix E of other TIPs and AQP8s adopt the same conformation, as shown here for AtTIP2;1, due to aromatic residues at position LCP in loop C and hydrogen bonding residues at position H2P in helix 2. The conservation patterns in the selectivity filter of AQP8s and separate subgroups of TIPs indicate that a functional differentiation has evolved among aquaammoniaporins. TIP2s and TIP4s of higher plants are similar to TIP6s found in primitive plants like mosses and are therefore likely to represent original functions and mechanistic features of TIPs. In contrast, TIP1s and TIP3s, which appear with the emergence of seed plants, as well as AQP8s in animals, lack the histidine at position LCP, which is proposed here to enhance deprotonation of ammonium. Such variations among aquaammoniaporins may relate to pH-dependent properties, which however remains to be investigated. In this context, it should be mentioned that both AQP8 and an AtTIP2;1 mutant lacking the histidine at position LCP complemented ammonia permeability in the growth assay equally well or better than the wild type AtTIP2;1, demonstrating that a histidine at this position is not essential for efficient ammonia uptake under these conditions. The AtTIP2;1 structure will facilitate modeling of other AQPs including human AQP8 and may therefore also help to elucidate the molecular basis of ammonia permeation in man. From our results, it is clear that AtTIP2;1 can enhance the ammonia permeability of membranes, but conditions linking an ammonia-related phenotype to TIPs have so far not been reported in plants[30]. Plants emit significant amounts of ammonia from their leaves, and ammonia generated by photorespiration further accentuate losses, implying a limited capacity of ammonia reassimiliation enzymes[31]. We expect that high ammonia permeability of the tonoplast and rapid acid-entrapment of ammonium in the vacuole is especially important under transient periods of photorespiration when it counteracts high levels of ammonia in the cytosol and thereby reduces losses over the plasma membrane, giving reassimilation pathways time to incorporate more of the generated ammonia. Hence, we propose that expression of ammonia-permeable mutant AQP isoforms in the plasma membrane, such as PIP2 mutants having a TIP2-like extended selectivity filter, combined with regulation of TIP expression can be used to vary the relative ammonia permeability of the plasma membrane and the tonoplast to explore effects on ammonia emission under these conditions. Control of ammonia emission by regulation of ammonia permeability in membranes could potentially open up a new way to improve the nitrogen use efficiency in plants.","answer":"Ammonia is a central molecule in nitrogen metabolism . Aquaporins are integral membrane proteins that form channels that accelerate the passive permeation of small polar uncharged molecules , like water and ammonia , across lipid membranes of the cell . Structural information of ammonia-permeable aquaporins has been lacking . Here , we report a high-resolution structure of the ammonia-permeable aquaporin AtTIP2;1 and explore it by functional assays of mutants and by molecular dynamics simulations . Our data uncover unexpected features of the substrate selectivity filter , including a conserved arginine in a new orientation that is stabilized by interactions to a histidine that is linked to ammonia specificity . An additional histidine in a different part of AtTIP2;1 fortifies the position of the arginine and interacts directly with the substrate in the channel . This histidine is therefore included in an extended selectivity filter , which should prompt a reinterpretation of the determinants of specificity in all types of aquaporins . We speculate that an intriguing water-filled side pore , next to the substrate-binding histidine , participates in deprotonating ammonium ions , which could increase the net permeation of ammonia . Understanding the principles of ammonia permeability may , in the future , allow us to modulate the passage of ammonia and generate crops with higher nitrogen-use efficiency ."},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:A pilot study to evaluate the effects of Cerebrolysin on cognition and qEEG in vascular dementia: cognitive improvement correlates with qEEG acceleration.Abstract 1:The effects of the neurotrophic compound Cerebrolysin (Cere) on cognitive performance, evaluated with the ADAS-cog, and on qEEG activity were investigated in forty one patients with mild to moderate severe probable vascular dementia (VaD) according to NINDS-AIREN criteria, included in a placebo-controlled pilot study. Patients received i.v. infusions of Cere (10 or 30 ml) or placebo (normal saline) 5 days/week for 4 weeks. Mean score of change from baseline in the ADAS-cog and percent change from baseline in slow to fast EEG power ratio (PR) scores were the two primary endpoints. Correlations between cognition and qEEG were also evaluated for both baseline scores and for scores of change from baseline in ADAS-cog and in qEEG parameters, including EEG power ratio (PR) as an index of EEG slowing. Baseline ADAS-cog scores showed significant positive correlations with delta power, theta power and PR scores, and correlated negatively with alpha activity. These correlations indicating that an increased EEG slowing is associated with a worst cognitive performance in VaD patients. Cere treatment improved cognitive performance significantly at the 10 ml dose and reduced EEG slowing with both 10 and 30 ml dosages. A significant positive correlation between PR and ADAS-cog scores of change from baseline was observed in Cere-treated patients. According to results of this pilot study, it is concluded that Cere improves cognitive performance and reduces EEG slowing in patients with VaD, and that there is a positive relationship between changes in cognition and qEEG activity induced by Cere. The conduction of further regular clinical trials is required to confirm the potential utility of Cere in the treatment of VaD suggested by the present results.","answer":"Cerebrolysin may have positive effects on cognitive function and global function in elderly patients with vascular dementia of mild to moderate severity, but there is still insufficient evidence to recommend Cerebrolysin as a routine treatment for vascular dementia due to the limited number of included trials, wide variety of treatment durations and short-term follow-up in most of the trials."},{"question":"Given a short query with keyphrases about a research idea in 2017 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: I want to extract terminological ontologies from a large number of heterogeneous documents.Keyphrases: ontology learningDataset description:DBpedia: DBpedia (from \\"DB\\" for \\"database\\") is a project aiming to extract structured content from the information created in the Wikipedia project. DBpedia allows users to semantically query relationships and properties of Wikipedia resources, including links to other related datasets.DocRED: DocRED (Document-Level Relation Extraction Dataset) is a relation extraction dataset constructed from Wikipedia and Wikidata. Each document in the dataset is human-annotated with named entity mentions, coreference information, intra- and inter-sentence relations, and supporting evidence.DWIE: The 'Deutsche Welle corpus for Information Extraction' (DWIE) is a multi-task dataset that combines four main Information Extraction (IE) annotation sub-tasks: (i) Named Entity Recognition (NER), (ii) Coreference Resolution, (iii) Relation Extraction (RE), and (iv) Entity Linking. DWIE is conceived as an entity-centric dataset that describes interactions and properties of conceptual entities on the level of the complete document.SNIPS: The SNIPS Natural Language Understanding benchmark is a dataset of over 16,000 crowdsourced queries distributed among 7 user intents of various complexity:   SearchCreativeWork (e.g. Find me the I, Robot television show), GetWeather (e.g.Options:- A: DBpedia  B: DocRED  C: DWIE  D: SNIPS","answer":"DBpedia"},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Is it possible to analyze exosomes with FACS?Context: whose presence was validated by a bead-exosome FACS assay.We analyzed exosomes from mouse (C57Bl/6) and breast, lung, and ovarian cancer patient samples and cultured cancer cells with different approaches, including nanoparticle tracking analysis, biolayer interferometry, FACS, and electron microscopy.we applied a technique to generate native fluorescent exosomes characterized by vesicles integrity, size, density, markers expression, and quantifiable by direct FACS analysiswe used a novel strategy for generating metabolically-labeled fluorescent exosomes that can be counted by flow cytometry assay (FACS) and characterized.","answer":"yes"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Regional anesthesia and lipid resuscitation for local anesthetic systemic toxicity in China: results of a survey by the orthopedic anesthesia group of the Chinese Society Of Anesthesiology. Intravenous lipid emulsions have been introduced for the management of patients with Local Anesthetic Systemic Toxicity (LAST). These emulsions have been stated as a first-line treatment in the guidelines of several international anesthesia organizations. Nevertheless, the adoption of lipid rescue therapy by Chinese practitioners remains unknown. We, therefore, evaluated the current approaches to treat LAST and the use of lipid rescue therapy among anesthesiologists in China.  methods In September 2013, a 23-question survey on regional anesthesia practice and availability of lipid emulsions was sent by e-mail to directors or designated individuals at 41 academic anesthesiology departments listed by the orthopedic anesthesia group of the Chinese Society of Anesthesiology.  results Responses were received from 36 of the 41 (88 %) anesthesiology departments. To simplify the analysis, responses were divided into two groups according to the annual percentage of patients who received regional anesthesia (RA) for orthopedic anesthesia: 14 departments (39%) with high-utilization (≥ 50%) and 22 departments (61%) low-utilization (<50%) of RA. Ropivacaine and bupivacaine were the common drugs used for RA , which were independent of RA utilization . Interestingly, ultrasound-guided techniques were much more frequently used in low-utilization institutions than in high-utilization institutions (P = 0.025). Lipid emulsion was readily available in 8 of the 36 (22%) responding institutions, with 7 of the other 28 (25%) institutions planning to stock lipid emulsion. No differences in lipid availability and storage plans were observed between high- and low-utilization institutions. Lipid resuscitation was performed in five of the eight departments that had lipid emulsion. Eleven patients were successfully resuscitated and one was not.  conclusion Lipid emulsion is not widely available in China to treat LAST resulted from RA for orthopedic patients. Efforts are required to promote lipid rescue therapy nationwide.  Trial Registration Chinese Clinical Trail Registry (Registration number # ChiCTR-EOR-15006960; Date of Retrospective Registration on August 23rd, 2015) http://www.chictr.org.cn/showproj.aspx?proj=11703 .sentence: Ropivacaine and bupivacaine were the common drugs used for RA , which were independent of RA utilization .","answer":"[]"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Venetoclax Plus Rituximab in Relapsed Chronic Lymphocytic Leukemia: 4-Year Results and Evaluation of Impact of Genomic Complexity and Gene Mutations From the MURANO Phase III Study.  In previous analyses of the MURANO study , fixed-duration venetoclax plus rituximab ( VenR ) resulted in improved progression-free survival ( PFS ) compared with bendamustine plus rituximab ( BR ) in patients with relapsed or refractory chronic lymphocytic leukemia ( CLL ) . At the 4-year follow-up, we report long-term outcomes, response to subsequent therapies, and the predictive value of molecular and genetic characteristics.  Patients And Methods Patients with CLL were randomly assigned to 2 years of venetoclax (VenR for the first six cycles) or six cycles of BR. PFS, overall survival (OS), peripheral-blood minimal residual disease (MRD) status, genomic complexity (GC), and gene mutations were assessed.  results Of 389 patients, 194 were assigned to VenR and 195 to BR. Four-year PFS and OS rates were higher with VenR than BR, at 57.3% and 4.6% (hazard ratio [HR], 0.19; 95% CI, 0.14 to 0.25), and 85.3% and 66.8% (HR, 0.41; 95% CI, 0.26 to 0.65), respectively. Undetectable MRD (uMRD) at end of combination therapy (EOCT) was associated with superior PFS compared with low MRD positivity (HR, 0.50) and high MRD positivity (HR, 0.15). Patients in the VenR arm who received ibrutinib as their first therapy after progression (n = 12) had a reported response rate of 100% (10 of 10 evaluable patients); patients subsequently treated with a venetoclax-based regimen (n = 14) had a reported response rate of 55% (six of 11 evaluable patients). With VenR, the uMRD rate at end of treatment (EOT) was lower in patients with GC than in those without GC (  conclusion Efficacy benefits with fixed-duration VenR are sustained and particularly durable in patients who achieve uMRD. Salvage therapy with ibrutinib after VenR achieved high response rates. Genetic mutations and GC affected MRD rates and PFS.sentence: In previous analyses of the MURANO study , fixed-duration venetoclax plus rituximab ( VenR ) resulted in improved progression-free survival ( PFS ) compared with bendamustine plus rituximab ( BR ) in patients with relapsed or refractory chronic lymphocytic leukemia ( CLL ) .","answer":"[[\\"venetoclax\\", \\"rituximab\\", \\"POS\\"], [\\"bendamustine\\", \\"rituximab\\", \\"COMB\\"]]"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Identification of unique mutations in sars-cov-2 strains isolated from china suggests its attenuated pathotypeAbstract:Severe Acute Respiratory Syndrome Coronavirus-2 (SARS-CoV-2), which was first reported in Wuhan, China in November 2019 has developed into a pandemic since March 2020, causing substantial human casualties and economic losses.Studies on SARS-CoV-2 are being carried out at an unprecedented rate to tackle this threat.Genomics studies, in particular, are indispensable to elucidate the dynamic nature of the RNA genome of SARS-CoV-2.RNA viruses are marked by their unique ability to undergo high rates of mutation in their genome, much more frequently than their hosts, which diversifies their strengths qualifying them to elude host immune response and amplify drug resistance.In this study, we sequenced and analyzed the genomic information of the SARS-CoV-2 isolates from two infected Indian patients and explored the possible implications of point mutations in its biology.In addition to multiple point mutations, we found a remarkable similarity between relatively common mutations of 36-nucleotide deletion in ORF8 of SARS-CoV-2.Our results corroborate with the earlier reported 29-nucleotide deletion in SARS, which was frequent during the early stage of human-to-human transmission.The results will be useful to understand the biology of SARS-CoV-2 and itsattenuation for vaccine development.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"In this study, we sequenced and analyzed the genomic information of the SARS-CoV-2 isolates from two infected Indian patients and explored the possible implications of point mutations in its biology.\\", \\"In addition to multiple point mutations, we found a remarkable similarity between relatively common mutations of 36-nucleotide deletion in ORF8 of SARS-CoV-2.\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Anti-asthmatic Effects of Baicalin in a Mouse Model of Allergic Asthma. The aim of the study was to investigate the anti-asthmatic effects of baicalin (BA) and the possible mechanisms. Asthma model was established by ovalbumin (OVA) intraperitoneal injection. A total of 60 mice were randomly assigned to six experimental groups: control, model, dexamethasone (2   mg/kg), and BA (10   mg/kg, 20   mg/kg, 40   mg/kg). Airway resistance (RI) and lung compliance (Cdyn) were measured, histological studies were evaluated by the hematoxylin and eosin staining, Th1/Th2, OVA-specific serum, and BALF IgE levels and Th17 cytokines were evaluated by enzyme-linked immunosorbent assay, and Th17 cells was evaluated by flow cytometry (FCM). Our study demonstrated that BA inhibited OVA-induced increases in RI and eosinophil count; interleukin (IL) -4, IL-17A levels, and Cdyn were recovered and increased IFN-γ level in bronchoalveolar lavage fluid. Histological studies demonstrated that BA substantially inhibited OVA-induced eosinophilia in lung tissue and airway tissue. FCM studies demonstrated that BA substantially inhibited Th17 cells. These findings suggest that BA may effectively ameliorate the progression of asthma and could be used as a therapy for patients with allergic asthma. Copyright © 2013 John Wiley & Sons, Ltd.","answer":"[]"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:Indeed, current knowledge on insertions and fiber orientation of the supinator can be found in old works [8, 10, 18, 29, 33].","answer":"Background"},{"question":"Below is an abstract from a computer science research paper. Given this abstract, your task is to extract all unique relationships between entities of the following types:- \\"USED-FOR\\": For instance, \\"Our method models user proficiency\\" -> [\\"method\\", \\"user proficiency\\", \\"USED-FOR\\"].- \\"EVALUATE-FOR\\": For instance, \\"We evaluate our method using F1-measure\\" -> [\\"F1-measure\\", \\"method\\", \\"EVALUATE-FOR\\"].- \\"FEATURE-OF\\": For instance, \\"prior knowledge of the model\\" -> [\\"prior knowledge\\", \\"model\\", \\"FEATURE-OF\\"].- \\"HYPONYM-OF\\": For instance, \\"TUIT is a software library\\" -> [\\"TUIT\\", \\"software library\\", \\"HYPONYM-OF\\"].- \\"PART-OF\\": For instance, \\"We incorporate NLU module into the system.\\" -> [\\"NLU module\\", \\"system\\", \\"PART-OF\\"].- \\"COMPARE\\": For instance, \\"Unlike the quantitative prior, the qualitative prior is often ignored\\" -> [\\"quantitative prior\\", \\"qualitative prior\\", \\"COMPARE\\"].- \\"CONJUNCTION\\": For instance: \\"obtained from human expert or knowledge base\\" -> [\\"human expert\\", \\"knowledge base\\", \\"CONJUNCTION\\"].Format your output as a json array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<Entity_B>\\", \\"<RELATION_A_B>\\"]. An example output might look like:[[\\"neural networks\\", \\"classification\\", \\"USED-FOR\\"], [\\"neuron\\", \\"neural network\\", \\"PART-OF\\"]].If no relations are found, please return an empty array [].Abstract:Probabilistic models have been previously shown to be efficient and effective for modeling and recognition of human motion. In particular we focus on methods which represent the human motion model as a triangulated graph. Previous approaches learned models based just on positions and velocities of the body parts while ignoring their appearance. Moreover, a heuristic approach was commonly used to obtain translation invariance. In this paper we suggest an improved approach for learning such models and using them for human motion recognition. The suggested approach combines multiple cues, i.e., positions, velocities and appearance into both the learning and detection phases. Furthermore, we introduce global variables in the model, which can represent global properties such as translation, scale or viewpoint. The model is learned in an unsupervised manner from un-labelled data. We show that the suggested hybrid proba-bilistic model (which combines global variables, like translation, with local variables, like relative positions and appearances of body parts), leads to: (i) faster convergence of learning phase, (ii) robustness to occlusions, and, (iii) higher recognition rate.","answer":"[[\\"positions\\", \\"velocities\\", \\"CONJUNCTION\\"], [\\"global variables\\", \\"global properties\\", \\"USED-FOR\\"], [\\"velocities\\", \\"human motion model\\", \\"USED-FOR\\"], [\\"approach\\", \\"learning and detection phases\\", \\"USED-FOR\\"], [\\"un-labelled data\\", \\"unsupervised manner\\", \\"USED-FOR\\"], [\\"faster convergence\\", \\"robustness\\", \\"CONJUNCTION\\"], [\\"unsupervised manner\\", \\"approach\\", \\"USED-FOR\\"], [\\"translation\\", \\"scale\\", \\"CONJUNCTION\\"], [\\"translation\\", \\"global variables\\", \\"HYPONYM-OF\\"], [\\"scale\\", \\"global properties\\", \\"HYPONYM-OF\\"], [\\"faster convergence\\", \\"learning phase\\", \\"FEATURE-OF\\"], [\\"scale\\", \\"viewpoint\\", \\"CONJUNCTION\\"], [\\"translation\\", \\"global properties\\", \\"HYPONYM-OF\\"], [\\"viewpoint\\", \\"global properties\\", \\"HYPONYM-OF\\"], [\\"relative positions\\", \\"appearances of body parts\\", \\"CONJUNCTION\\"], [\\"positions\\", \\"cues\\", \\"HYPONYM-OF\\"], [\\"Probabilistic models\\", \\"modeling and recognition of human motion\\", \\"USED-FOR\\"], [\\"triangulated graph\\", \\"human motion model\\", \\"USED-FOR\\"], [\\"global variables\\", \\"approach\\", \\"USED-FOR\\"], [\\"positions\\", \\"human motion model\\", \\"USED-FOR\\"], [\\"approach\\", \\"human motion model\\", \\"USED-FOR\\"], [\\"robustness\\", \\"recognition rate\\", \\"CONJUNCTION\\"], [\\"appearances of body parts\\", \\"local variables\\", \\"HYPONYM-OF\\"], [\\"appearance\\", \\"cues\\", \\"HYPONYM-OF\\"], [\\"relative positions\\", \\"local variables\\", \\"HYPONYM-OF\\"], [\\"velocities\\", \\"appearance\\", \\"CONJUNCTION\\"], [\\"human motion model\\", \\"human motion recognition\\", \\"USED-FOR\\"], [\\"heuristic approach\\", \\"translation invariance\\", \\"USED-FOR\\"], [\\"velocities\\", \\"cues\\", \\"HYPONYM-OF\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Naloxone\\", ...], \\"Disease\\" : [\\"Hypotensive\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Magnetic resonance volumetry of the cerebellum in epileptic patients after phenytoin overdosages. The aim of this study was to evaluate the relationship between phenytoin medication and cerebellar atrophy in patients who had experienced clinical intoxication. Five females and 6 males, 21-59 years of age, were examined with a 1.5-T whole-body system using a circular polarized head coil. Conventional spin echo images were acquired in the sagittal and transverse orientation. In addition, we performed a high-resolution 3D gradient echo, T1-weighted sequences at a 1-mm slice thickness. The images were subsequently processed to obtain volumetric data for the cerebellum. Cerebellar volume for the patient group ranged between 67.66 and 131.08 ml (mean 108.9 ml). In addition 3D gradient echo data sets from 10 healthy male and 10 healthy female age-matched volunteers were used to compare cerebellar volumes. Using linear regression we found that no correlation exists between seizure duration, elevation of phenytoin serum levels and cerebellar volume. However, multiple regression for the daily dosage, duration of phenytoin treatment and cerebellar volume revealed a correlation of these parameters. We conclude that phenytoin overdosage does not necessarily result in cerebellar atrophy and it is unlikely that phenytoin medication was the only cause of cerebellar atrophy in the remaining patients. Quantitative morphometric studies of the cerebellum provide valuable insights into the pathogenesis of cerebellar disorders.","answer":"{\\"Chemical\\": [\\"phenytoin\\"], \\"Disease\\": [\\"cerebellar disorders\\", \\"epileptic\\", \\"overdosages\\", \\"cerebellar atrophy\\", \\"overdosage\\", \\"seizure\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Apoptosis induced by oxidized lipids is associated with up-regulation of p66Shc in intestinal Caco-2 cells: protective effects of phenolic compounds.In this study, we investigated the alterations of the redox balance induced by the lipid fraction of oxLDL in Caco-2 intestinal cells, and the effects of tyrosol and protocatechuic acid, two dietary phenolic compounds. We found that oxidized lipids extracted from oxLDL (LipE) induced oxidative stress by determining, 6 h after treatment, ROS overproduction (about a 100% and a 43% increase of O*2 and H2O2 production, respectively, P<.05: LipE vs. control) and, 12 h after treatment, GSH depletion (about a 26% decrease, P<.05: LipE vs. control), and by impairing the activities of superoxide dismutase, catalase and glutathione peroxidase. In response to the induced oxidative stress, we observed significant overexpression of glutathione peroxidase (6 h after treatment: P<.05), glutathione reductase and gamma-glutamylcysteine synthetase (12 h after treatment: P<.05). Notably, when GSH depletion occurred, p66Shc protein expression increased by about 300% with respect to control (P<.001; LipE vs. control). These effects were fully counteracted by dietary phenolics which inhibited ROS overproduction and GSH consumption, rendered the reactive transcription of glutathione-associated enzymes unnecessary and blocked the intracellular signals leading to the overexpression and rearrangement of p66Shc signalling molecule. Altogether, these results suggest that the impairment of the antioxidant system hijacks intestinal cells towards an apoptotic-prone phenotype via the activation of p66Shc molecule. They also propose a reappraisal of dietary polyphenols as intestinal protecting agents, indicating the antiapoptotic effect as a further mechanism of action of these antioxidant compounds.","answer":"{\\"Chemical\\": [\\"glutathione\\", \\"O*2\\", \\"phenolic\\", \\"H2O2\\", \\"gamma-glutamylcysteine\\", \\"polyphenols\\", \\"phenolics\\", \\"tyrosol\\", \\"protocatechuic acid\\", \\"superoxide\\"], \\"Protein\\": [\\"glutathione peroxidase\\", \\"oxLDL\\", \\"LipE\\", \\"superoxide dismutase\\", \\"catalase\\", \\"glutathione reductase\\", \\"p66Shc\\", \\"gamma-glutamylcysteine synthetase\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Universal rule on chirality-dependent bandgaps in graphene antidot lattices. Graphene with periodically patterned antidots has attracted intense research attention as it represents a facile route to open a bandgap for graphene electronics. However, not all graphene antidot lattices (GALs) can open a bandgap and a guiding rule is missing. Here, through systematic first-principles calculations, it is found that bandgaps in triangular GALs are surprisingly well defined by a chirality vector R = n a1 + ma2 connecting two neighboring antidots, where a1 and a2 are the basis vectors of graphene. The bandgap opens in the GALs with (n-m) mod3 = 0 but remains closed in those with (n-m) mod3 = ±1, reminiscent of the gap-chirality rule in carbon nanotubes. Remarkably, the gap value in GALs allows ample modulation by adjusting the length of chirality vectors, shape and size of the antidots. The gap-chirality relation in GALs stems from the chirality-dependent atomic structures of GALs as revealed by a super-atom model as well as Clar sextet analyses. This chirality-dependent bandgap is further shown to be a generic behavior in any parallelogram GAL and thus serves as an essential stepping stone for experimenters to realize graphene devices by antidot engineering.","answer":"[]"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Prolonged sars-cov-2 deficiency in an immunocompromised patientAbstract:We describe a case of chronic COVID-19 in a patient with lymphoma and associated B-cell immunodeficiency.Viral cultures and sequence analysis demonstrate ongoing replication of infectious SARS-CoV-2 virus for at least 119 days.The patient had three admissions related to COVID-19 over a four-month period and was treated twice with remdesivir and convalescent plasma with resolution of symptoms.The patient's lack of seroconversion and prolonged course illustrate the importance of humoral immunity in resolving SARS-CoV-2 infection.This case highlights challenges in managing immunocompromised hosts, who may act as persistent shedders and sources of transmission.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"This case highlights challenges in managing immunocompromised hosts, who may act as persistent shedders and sources of transmission.\\"]}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey on Network Security Monitoring Systems Chapter Title:  II. NETWORK SECURITY MONITORING IMPLEMENTATIONS 1. Abstract of Cited Paper (BIB001):  Flow monitoring has become a prevalent method for monitoring traffic in high-speed networks. By focusing on the analysis of flows, rather than individual packets, it is often said to be more scalable than traditional packet-based traffic analysis. Flow monitoring embraces the complete chain of packet observation, flow export using protocols such as NetFlow and IPFIX, data collection, and data analysis. In contrast to what is often assumed, all stages of flow monitoring are closely intertwined. Each of these stages therefore has to be thoroughly understood, before being able to perform sound flow measurements. Otherwise, flow data artifacts and data loss can be the consequence, potentially without being observed. This paper is the first of its kind to provide an integrated tutorial on all stages of a flow monitoring setup. As shown throughout this paper, flow monitoring has evolved from the early 1990s into a powerful tool, and additional functionality will certainly be added in the future. We show, for example, how the previously opposing approaches of deep packet inspection and flow monitoring have been united into novel monitoring approaches. 2. Abstract of Cited Paper (BIB002):  Users' demands have dramatically increased due to widespread availability of broadband access and new Internet avenues for accessing, sharing and working with information. In response, operators have upgraded their infrastructures to survive in a market as mature as the current Internet. This has meant that most network processing tasks (e.g., routing, anomaly detection, monitoring) must deal with challenging rates, challenges traditionally accomplished by specialized hardware—e.g., FPGA. However, such approaches lack either flexibility or extensibility—or both. As an alternative, the research community has proposed the utilization of commodity hardware providing flexible and extensible cost-aware solutions, thus entailing lower operational and capital expenditure investments. In this scenario, we explain how the arrival of commodity packet engines has revolutionized the development of traffic processing tasks. Thanks to the optimization of both NIC drivers and standard network stacks and by exploiting concepts such as parallelism and memory affinity, impressive packet capture rates can be achieved in hardware valued at a few thousand dollars. This tutorial explains the foundation of this new paradigm, i.e., the knowledge required to capture packets at multi-Gb/s rates on commodity hardware. Furthermore, we thoroughly explain and empirically compare current proposals, and importantly explain how apply such proposals with a number of code examples. Finally, we review successful use cases of applications developed over these novel engines.Literature Review:","answer":"This section classifies the current network security monitoring implementations into packet capture representatives, deep packet inspection representatives and flow-based observation representatives. It also provides information about the suitability of particular tools for development of new network traffic analysis methods. Packet capture is to intercept a data packet that is crossing or moving over a specific computer network. Once a packet is captured, it is stored temporarily so that it can be analyzed BIB003 . Deep packet inspection (DPI) is an advanced method of packet filtering that functions at the application layer of the OSI (Open Systems Interconnection) reference model. The use of DPI makes it possible to find, identify, classify, reroute or block packets with specific data or code payloads that conventional packet filtering, which examines only packet headers, cannot detect BIB001 . Traffic flow is a sequence of packets sent from a particular source to a particular unicast, anycast, or multicast destination that the source desires to label as a flow. A flow could consist of all packets in a specific transport connection or a media stream BIB002 ."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:Urban emergency department overcrowding: defining the problem and eliminating misconceptions.Abstract 1:STUDY OBJECTIVE To develop an operational definition and a parsimonious list of postulated determinants for urban emergency department ( ED ) overcrowding .  METHODS A panel was formed from clinical and administrative experts in pre-hospital , ED and hospital domains . Key studies and reports were review ed in advance by panel members , an experienced health services research er facilitated the panel 's discussion s , and a formal content analysis of audiotaped recordings was conducted . RESULTS The panel considered community , patient , ED and hospital determinants of overcrowding . Of 46 factors postulated in the literature , 21 were not retained by the experts as potentially important determinants of overcrowding . Factors not retained included access to primary care services and seasonal influenza outbreaks . Key determinants retained included admitted patients awaiting beds and patient characteristics .  Ambulance diversion was considered to be an appropriate operational definition and proxy measure of ED overcrowding . CONCLUSION These results help to clarify the conceptual framework around ED overcrowding , and may provide a guide for future research . The relative importance of the determinants must be assessed by prospect i ve studiesTitle 2:The impact of co-located NHS walk-in centres on emergency departmentsAbstract 2:Objectives : To determine the impact of establishing walk-in centres alongside emergency departments ( EDs ) on attendance rates , visit duration , process , costs and outcome of care . Methods : Eight hospitals with co-located EDs and walk-in centres were compared with eight matched EDs without walk-in centres .  Site visits were conducted . Routine data about attendance numbers and use of re sources were analysed . A r and om sample of records of patients attending before and after the opening of walk-in centres  was also assessed . Patients who had not been admitted to hospital were sent a postal question naire . Results : At most sites , the walk-in centres did not have a distinct identity and there were few differences in the way services were provided compared with control sites . Overall , there was no evidence of an increase in attendance at sites with walk-in centres , but considerable variability across sites was found . The proportion of patients managed within the 4 h National Health Service target improved at sites both with and without walk-in centres . There was no evidence of any difference in reconsultation rates , costs of care or patient outcomes at sites with or without walk-in centres . Conclusions : Most hospitals in this study implemented the walk-in centre concept to a very limited extent . Consequently , there was no evidence of any effect on attendance rates , process , costs or outcome of careTitle 3:How effective are mental health nurses in A&E departments?Abstract 3:Background : A&E departments are key points of contact for many people with mental health problems . Various models of care have been developed in A&E departments for delivering mental health services , but few have been assessed for effectiveness . The present study aim ed to assess the impact of a dedicated A&E psychiatric nurse service on several outcomes relevant to patients and clinicians . Methods : A crossover design was used to introduce a  dedicated psychiatric nurse service ( comprising four experienced community psychiatric nurses ) into two busy UK A&E departments . St and ardised assessment s were completed for each patient , and a r and om sample of these independently assessed for quality . Data were also collected on the number of patients assessed , psychiatric nurse time employed , waiting times , onward referrals , repeat attendances , patient satisfaction , and staff views . Results : A&E staff referred about a third of patients judged to have mental health problems to the psychiatric nurse service ; approximately half of those assessed had a psychiatric history . On average , assessment s took 60 min and over 90 % of the formulated management plans were judged appropriate by independent assessors . The psychiatric nurse intervention had little impact on waiting times or satisfaction levels for mental health patients , although there was evidence of a change in onward referral patterns . Comment : Psychiatric nurse assessment services have been introduced in many A&E departments , although the evidence base for the effectiveness of this development is not well established . This study presents evidence that psychiatric nurses can provide an accurate assessment and referral service with advantages for patient careTitle 4:Computer visualisation of patient safety in primary care: a systems approach adapted from management science and engineering.Abstract 4:Patient safety and medical errors in ambulatory primary care are receiving increasing attention from policy makers , accreditation bodies and research ers , as well as by practising family physicians and their patients . While a great deal of progress has been made in underst and ing errors in hospital setting s , it is important to recognise that ambulatory setting s pose a very large and different set of challenges and that the types of hazards that exist and the strategies required to reduce them are very different . What is needed is a logical theoretical model for underst and ing the causes of errors in primary care , the role of healthcare systems in contributing to errors , the propagation of errors through complex systems and , importantly , for underst and ing ambulatory primary care in the context of the larger healthcare system . The authors have developed such a model using a formal ' systems engineering ' approach borrowed from the management sciences and engineering . This approach has not previously been formally described in the medical literature .This paper outlines the formal systems approach , presents our visual model of the system , and describes some experiences with and potential applications of the model for monitoring and improving safety . Applications include providing a framework to help focus research efforts , creation of new ( visual ) error reporting and taxonomy systems , furnishing a common and unambiguous vision for the healthcare team , and facilitating retrospective and prospect i ve analyses of errors and adverse events . It is aim ed at system re design for safety improvement through a computer-based patient-centred safety enhancement and monitoring instrument ( SEMI-P ) . This model can be integrated with electronic medical records ( EMRs )Title 5:Entry overload, emergency department overcrowding, and ambulance bypassAbstract 5:Objectives : To describe an experience of emergency department ( ED ) overcrowding and ambulance bypass . Methods : A prospect i ve observational study at Royal Perth Hospital , a major teaching hospital . Episodes of ambulance bypass and their characteristics were recorded . Results : From 1 July 1999 to 30 June 2001 , there were 141 episodes of ambulance bypass ( mean duration 187 min , range 35–995 ) . Monday was the most common day with 39 ( 28 % ) episodes . Entry block alone was the most common reason bypass was activated ( n=38 , 30.4 % ) . The mean number of patients in ED  at these times was 40 ( occupancy 174 % ) , including nine in the corridor , seven awaiting admission , and 14 waiting to be seen . Episodes attributable to entry block were typically preceded by a presentation rate of ⩾10 patients per hour for ⩾2 hours ( OR 6.2 , 95 % CI 4.3 to 8.5 ) . Mid-afternoon to early evening was the most common time for activation  . Ambulance bypass  is increasing in frequency and duration . Conclusions : Entry overload result ing in entry block results from overwhelming numbers of patients presenting to the ED in a short space of time . Entry block impairs access to emergency care . Unless something is done in the near future , the general public may no longer be able to rely on EDs for quality and timely emergency care . A “ whole of system ” approach is necessary to tackle the problemTitle 6:Patients presenting to the emergency department: the use of other health care services and reasons for presentation.Abstract 6:OBJECTIVE Some low-acuity emergency department ( ED ) presentations are considered convenience visits and potentially avoidable with improved access to primary care services . This study assessed the frequency and determinants of patients ' efforts to access alternative care before ED presentation . METHODS Patients aged 17 years and older were r and omly selected from 2 urban ED sites in Edmonton .  Survey data were collected on use and characteristics of alternative care before the ED visit . Information was also collected on patient demographics and factors influencing their perception of whether the ED was the best care option . RESULTS Of the 1,389 patients approached , 905 ( 65 % ) completed the survey and data from 894 participants were analyzed . Sixty-one percent reported that they sought alternative care  before visiting the ED . Eighty-nine of the patients who attempted alternative access before the ED visit felt that the ED was their best care option . Results of the multivariate logistic regression analysis showed that injury presentation , living arrangements , smoking status and whether or not patients had a family practitioner were predictors for seeking alternative care before visiting the ED . CONCLUSION Most ambulatory patients attempt to look for other sources of care before presenting to the ED . Despite this attempted access to alternative care , while patients wait for ED care , they perceive that the ED is their best care option at that point in timeTitle 7:Development of a site sampling form for evaluation of ED overcrowding.Abstract 7:BACKGROUND ED overcrowding is fast becoming a national crisis although no definition exists . The purpose of this study is to develop and pilot a sampling form that accurately reflects the concept of ED Overcrowding . MATERIAL / METHODS A 26- question site-sampling form was design ed based on input from academic physicians at 11 medical schools nationwide . The study was conducted at an inner city Academic medical center . Site-samplings were conducted at 20 times over a one-week period by an independent observer . These times ranged from very slow to severely overcrowded . Information was obtained by counting patients in the waiting room , ED rooms , ED halls and registration /triage , ancillary services , the charge nurse , and the attending physicians . The charge nurse , and ED physicians rated the degree of overcrowding and the ED physician rated the feeling of being rushed . A ' combined outcome variable ' was created which consisted of the average responses of nurses and physician 's opinion of ED overcrowding and physician 's feeling of being rushed . All other data was compared to this outcome variable . RESULTS Seven questions were significantly correlated with the combined outcome variable . These were the number of people in the waiting room , patients awaiting triage , patients awaiting registration , full patient rooms , hallway patient , patients awaiting beds , and total registered patients . According to this scale our ED was overcrowded 20 % of the time . CONCLUSIONS This analysis clarifies the definition of overcrowding , helps indicate the variance among responses to overcrowding questions , and provides the foundation for prospect i ve analysis of overcrowding in multiple EDs","answer":"RESULTS There is an established international literature on ED crowding .It suggests consistently that crowding has significant negative consequences .CONCLUSIONS While current evidence is poor , this does not justify maintaining current practice which risks lives ."},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:hepatitis e virus ( hev ) infection is an emerging problem in developed countries , but hev is a rare cause of acute viral hepatitis in south korea .several cases of acute hepatitis e infection have been reported in korea [ 2 - 8 ] .most patients of acute hepatitis e infection are self - limiting and require no treatment .moreover , a small number of patients with acute hev genotype 1 or 3 infection have been treated with antiviral therapy [ 9 - 11 ] .however , reports on the clinical significance of use of steroid in patients with cholestatic hepatitis e are very limited . guillain - barr syndrome ( gbs )is triggered by a preceding infection including acute hepatitis a , b , and c. occasionally , it has been triggered by hev infection [ 12 - 14 ] .we reported a case of persistent cholestasis caused by an autochthonous hev infection that was resolved with steroid treatment .after 2.5 months , the patients developed weakness of the lower limbs , and were diagnosed with gbs associated with acute hepatitis e.on 20 march 2014 , a 58-years - old korean male was referred to our hospital with severe hepatitis of unknown cause . on 10 march 2014 ,he was a heavy alcohol drinker , with a consumption rate of 120 g / day of alcohol for 30 years .three months before hospitalization , he ingested raw deer meat with the intention of improving his stamina. he had ingested about 200 g of raw meat obtained from a wild deer captured on jiri - mountain in the gyeongnam province , south korea . on physical examination , he had jaundice , right upper quadrant tenderness and an enlarged liver , but showed no feature of hepatic encephalopathy .initial laboratory data showed white blood cell count of 6.3610/mm ( polymorphonuclear neutrophils , 60.1% ; lymphocytes , 24.1% ; and eosinophils , 2.2% ) , serum total bilirubin level of 23.59 mg / dl , serum aspartate aminotransferase ( ast ) level of 292 iu / l , and serum alanine aminotransferase ( alt ) level of 525serologic study was negative for immunoglobulin ( ig ) m anti - hepatitis a virus ( hav ) antibody and positive for igg anti - hav antibody .hepatitis b virus surface antigen and antibody to hepatitis c were absent , and hcv rna was negative .abdominal computed tomography showed findings compatible with chronic liver disease with splenomegaly . on the ninth day of admission, laboratory data showed a peak total bilirubin level of > 35.0 mg / dl and liver biopsy and blood test for igm and igg anti - hev ( dia .pro , milan , italy for igg anti - hev elisa and dsi , milan , italy for igm anti - hev elisa ) were performed . on liver biopsy ( fig .1 ) , the lymphocyte - dominant inflammatory cells were accumulated in the periportal area .sixteen days after admission , we started 30 mg / day of prednisolone despite the normal prothrombin time because of a steady increase in total bilirubin levels and pruritus . on the fourteen day of admission ,commercially available immunoassay for igm anti - hev and igg anti - hev were both positive .the optical density value of igm anti - hev was 0.849 ( cut - off value 0.294 ) and igg anti - hev was 3.356 ( cut - off value : 0.367 ) . at the time of the diagnosis of acute hev , we decided to taper steroid therapy , but the total bilirubin level was elevated ( 17.8 mg / dl to 21.3 mg / dl ) after steroid tapering ( 30 mg / day to 5 mg / day over 10 days ) ( fig ., prednisolone was given at a dosage of 20 mg / day , and the dose of steroid was tapered and discontinued after 5 weeks .two months after admission , laboratory data showed a total bilirubin level of 2.30 mg / dl , ast level of 24 iu / l , and alt level of 26 iu / l ( fig .the muscle weakness progressed rapidly and in 2 days he was bedridden , unable to move against gravity .cerebrospinal fluid ( csf ) analysis showed a normal protein concentration ( 44.6 mg / dl ) without cellular response .intravenous immunoglobulin 30 g / day was administered for 5 days , and resulted in significantly improved neurologic symptom . during the follow - up period ,igm anti - hev persisted as positive until 6 months after admission ( value 1.883 ) , but igm anti - hev converted negative on 12 months after admission ( value 0.049 ) .at first , we considered his severe jaundice may be a manifestation of alcoholic hepatitis on underlying alcoholic cirrhosis . the diagnosis of acute hepatitis e infection was delayed because we performed blood tests for igm and igg anti - hev due to persistent jaundice on the ninth day of administration .steroid therapy with prednisolone was started on the sixteenth day , because of pruritus and the possibility of acute - on - chronic liver failure with progressive liver injury .immunosuppressive treatment for acute viral hepatitis seems to be counterproductive , hence prednisolone was tapered to 5 mg / day . since the total bilirubin level was elevated after tapering , we decided to continue prednisolone treatment at 20 mg / day .two months after admission , the patients liver function was almost normalized . an ast / alt ratio< 1 and periportal lymphocyte infiltration in the absence of fatty liver , neutrophil infiltration , and mallory bodies suggest that severe jaundice may be caused by viral - induced cholestasis , not alcoholic hepatitis in our case . to our knowledge , this is the second report on supportive steroid therapy for severe acute hev infection .they showed that steroid treatment might be an option to prevent the progression of liver failure in patients with hev induced acute liver injury . in a recent study , 5% of patients with gbs had an associated acute hev infection in the netherlands .in korea , reported hev data on seroprevalence of igg hev ranges from 17% to 27% .however , there has been no report on acute hev complicated by gbs in korea , and this is the first report of gbs in a hepatitis e patient in korea .therefore , further studies are required to determine the frequency of antecedent hev infection in patients with gbs in other geographical areas including korea .extrahepatic symptoms may develop even after the clearance of hev virus and not only during active hev infection .in our case , the neurologic symptom developed at 2.5 months after acute hev infection .hev rna becomes undetectable in blood about 3 weeks after symptom onset with reported sensitivity of hev igm tests between 72% and 98% and specificities between 78.2% and 95.6% . during the follow - up period ,igm anti - hev persisted as positive thrice until 1 october 2014 , but igm anti - hev converted to negative on 12 months after admission .recovery of severe cholestasis might just reflect the natural course of hev infection without steroid treatment .however , figure 2 showed that serum bilirubin level was promptly decreased following treatment of steroid .in addition , it is possible that steroid therapy had some influence on the development of gbs . in conclusion, this case suggested that steroid therapy might be a beneficial option to relieve pruritus related to persistent cholestasis complicated with acute hepatitis e infection .in addition , further investigations is needed to assess the prevalence of hev infection in patients with gbs .","answer":"autochthonous hepatitis e virus ( hev ) is an emerging pathogen in developed countries , and several cases of acute hev infection have been reported in south korea .  however , there have been no reports on hev - associated guillain - barr syndrome ( gbs ) in korea .  we recently experienced the case of a 58-year - old korean male with acute hev infection after ingesting raw deer meat .  persistent cholestasis was resolved by the administration of prednisolone . at 2.5 months after the clinical presentation of hev infection ,  the patient developed weakness of the lower limbs , and was diagnosed with gbs associated with acute hepatitis e. to our knowledge , this is the second report on supportive steroid therapy for persistent cholestasis due to hepatitis e , and the first report of gbs in a korean patient with acute hev infection ."},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:Cerebral saturation in the earlier study (mean6standard deviation: 58%613% ) [37] compares well with both the first (56%610%) and the second (62%66%) layer values, as well as the homogenous values (64%68%) reported here.","answer":"Result"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:conclusionContext before the citation:We could also introduce new variables, e.g., nonterminal refinements (Matsuzaki et al., 2005), or secondary links Mid (not constrained by TREE/PTREE) that augment the parse with representations of control, binding, etc. (Sleator and Temperley, 1993; Buch-Kromann, 2006). For projective parsing, it is significantly faster than exact dynamic programming, at the cost of small amounts of search error, We are interested in extending these ideas to phrase-structure and lattice parsing, and in trying other higher-order features, such as those used in parse reranking (Charniak and Johnson, 2005; Huang, 2008) and history-based parsing (Nivre and McDonald, 2008). Belief propagation improves non-projective dependency parsing with features that would make exact inference intractable.Citation Sentence:We could also introduce new variables , e.g. , nonterminal refinements ( Matsuzaki et al. , 2005 ) , or secondary links Mid ( not constrained by TREE/PTREE ) that augment the parse with representations of control , binding , etc. ( Sleator and Temperley , 1993 ; Buch-Kromann , 2006 ) .Context after the citation:Other parsing-like problems that could be attacked with BP appear in syntax-based machine translation. Decoding is very expensive with a synchronous grammar composed with an n-gram language model (Chiang, 2007)âbut our footnote 10 suggests that BP might incorporate a language model rapidly. String alignment with synchronous grammars is quite expensive even for simple synchronous formalisms like ITG (Wu, 1997)âbut Duchi et al. (2007) show how to incorporate bipartite matching into max-product BP. Finally, we can take advantage of improvements to BP proposed in the context of other applications.","answer":"FutureWork"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:in seeking to understand the nature and causes of activity in galaxy nuclei , we are conducting a multi - wavelength study of a well - defined sample of 21 radio - loud , early - type galaxies in the local universe .the sample contains all nearby ( @xmath1 ) , elliptical or s0 galaxies in the ugc catalog ( nilson 1973 ; magnitude limit @xmath2 , declination range @xmath3 and angular size @xmath4 ) that are extended radio - loud sources ( larger than 10  on vla a - array maps and brighter than 150 mjy from single dish flux measurements at 1400 mhz ) .all of these galaxies fall into fanaroff & riley s ( 1974 ) type - i ( fr - i ) radio classification ( see xu et al .2000 , for a description of the radio properties of our sample ) .though the black hole paradigm has become widely accepted as an essential ingredient in radio galaxies , the mechanics and time - scales of fueling and jet production are poorly understood . in unified schemes ( see urry & padovani 1995 for a review ) , which suggest the appearance of agn depends strongly on orientation , fr - i galaxies are thought to be the unbeamed population of bl - lac objects .understanding the central regions of such objects on scales of tens and hundreds of parsecs will allow us to better understand and characterize these connections .we have observed 19 of our sample galaxies with stis ( the space telescope imaging spectrograph ; see kimble et al .1998 ) , the sample members m84 and m87 having previously been observed by others . by placing three parallel slits adjacent to each other on the galaxy nuclei ( figure 1 ) along the stellar major axis we have obtained sets of spectra which allow us to map , for example , the kinematics and h@xmath0 + [ nii ] flux for the very central regions of each galaxy .by inspecting the velocity field of each galaxy it has been possible to classify them into three broad groups ( see also baum , heckman , & van breugel 1992 ) : _ rotators _ ; which show a clear , systematic , rotation pattern in their velocity field ( i.e. we observe a systematic gradient in velocity across the nucleus ) . _systematic non - rotators _ ; which show some kind of systematic behavior in their velocity field , but do not appear to be in rotation . _ undefined _ ; which do not show any clear pattern in their velocity fields .    initially we have made use of the mean velocity dispersion ( @xmath5 ) and @xmath6 , as estimators of the global parameters within some physical scale of the peak in emission line flux ( see table 1 ) .lcccc & & + & @xmath7 & @xmath5 & @xmath7 & @xmath5 + & @xmath8 & @xmath9 & @xmath10 & @xmath10 + rotators ( 11 ) & @xmath11 & @xmath12 & @xmath13 & @xmath14 + sys .nr ( 3 ) & @xmath15 & @xmath16 & @xmath17 & @xmath18 + undefined ( 5 ) & @xmath19&@xmath20&@xmath21&@xmath22 +    the similarity in velocity dispersion across the categories suggests that they represent systems that are kinematically alike , and the failure to detect rotation in some cases may simply be due to adverse slit placement , the presence of dust masking part of the rotation curve or projection effects .we fail to detect rotation in galaxies that have an axis ratio of their central light distribution @xmath23 ( with the exception of ngc 383 ) , i.e. the members of the sample with more nearly face - on central morphologies . bearing this in mind, we can not rule out the possibility that all of the sample galaxies harbor gas systems of the same type viewed from a range of orientations through different obscurations .in sample members where we have been able to identify systematic rotation in the nucleus , we have made estimates of the total mass enclosed in the central region by using the maximum and minimum velocities observed ( not corrected for the inclination ) and the radius over which they are separated ( see table 2 ) .further modeling will allow us to improve our central mass estimates and enable us to identify and characterize the contributions of the various components that we expect , in particular the contributions of stellar populations and supermassive black holes ( for example , by building on the work of van der marel & van den bosch 1998 ; marconi , et al .2001 ; sarzi , et al .  2001 ; or barth , et al .this modeling will also shed light on the relative importance of non - gravitational motions in the gas .an estimate of the anticipated black hole mass ( @xmath24 ) , computed using the relationship found by ferrarese & merritt ( 2001 ; see also gebhardt et al .2000 ) is provided in table 2 ( @xmath25 is the central velocity dispersion corrected to an @xmath26 aperture ) .we note that all of the enclosed masses calculated ( which are lower limits ) are greater than or similar to the black hole mass predicted from the ground based stellar kinematics using this relation as we would expect .cccccc galaxy & @xmath7 ( rotn ) & radius & @xmath27 & @xmath25 & @xmath24 + & @xmath9 & @xmath28 & @xmath29 & @xmath9 & @xmath29 + ngc 315 & 344.8 & 25 & @xmath30 & 295 & @xmath31 + ngc 383 & 420.2 & 48 & @xmath32 & 254 & @xmath33 + ngc 741 & 530.3 & 138 & @xmath34 & 265 & @xmath35 + ugc 7115 & 413.3 & 44 & @xmath36 & 175 & @xmath37 + ngc 4261@xmath38 & 174.0 & 73 & @xmath39 & 291 & @xmath40 + ngc 4335 & 305.9 & 121 & @xmath41 & + ngc 5127 & 315.3 & 190 & @xmath42 & 178 & @xmath43 + ngc 5141 & 471.9 & 87 & @xmath44 & + ngc 7052@xmath45 & 531.5 & 54 & @xmath46 & 247 & @xmath47 + ugc 12064 & 229.1 & 34 & @xmath48 & 257 & @xmath49 + ngc 7626 & 472.6 & 34 & @xmath36 & 248 & @xmath50 +    barth , a. j. , et al .2001 , , in press ( astro - ph/0012213 ) baum , s. a. , heckman , t. m. , & van breugel , w. 1992 , , 389 , 208 fanaroff , b. l. , & riley , j. m. 1974 , , 167 , 31p ferrarese , l. , ford , h. c. , & jaffe , w. 1996 , , 470 , 444 ferrarese , l. , & merritt , d. 2001 , , 547 , 140 gebhardt , k. , et al .2000 , , 539 , 13 jorgensen , i. , franx , m. , & kjaergaard , p. 1995, , 276 , 1341 kimble , r. , et al .1998 , , 492l , 83 marconi , a. , et al .  2001 , , 549 , 915 nilson , p. 1973the uppsala general catalog of galaxies [ ugc ] , ( uppsala : astronomiska observatorium ) sarzi , m. , et al .2001 , , 550 , 65 urry , c. m. , & padovani p. 1995, , 107 , 803 van der marel , r. p. , & van den bosch , f. c. 1998 , , 116 , 2220 xu , c. , baum , s. a. , odea , c. p. , wrobel , j. m. , & condon , j. j. 2000 , , 120 , 2950","answer":"we present initial results of our analysis of line emission produced in gas disks found at the centers of a sample of nearby , radio galaxies with radio jets .  we obtained data using stis ( the space telescope imaging spectrograph ) at three parallel slit positions on the nucleus of each galaxy .  this allows us to map the h@xmath0 + [ nii ] flux , the gas radial velocity and the velocity dispersion .  we find evidence of rotating disks in 11 of the sample galaxies and we can not currently rule out a rotating disk model for the remaining eight . for rotating systems , we find that the minimum central enclosed mass is greater than or similar to the predicted black hole mass based on ground - based stellar velocity dispersions . by modeling the gas dynamics  we will go on to constrain the masses of the black holes .  we will also investigate the properties of the gas disks themselves , giving us an insight into fueling , ionization mechanisms and the structure of the central regions ."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Elastic instability during branchial ectoderm development causes folding of the Chlamydosaurus erectile frill}Article:Abstract:We study the morphogenesis and evolutionary origin of the spectacular erectile ruff of the frilled dragon( Chlamydosaurus kingii). Our comparative developmental analyses of multiple species suggest that the ancestor of Episquamata reptiles developed a neck fold from the hyoid branchial arch by preventing it to fully fuse with posterior arches. We also show that the Chlamydosaurus embryonic neck fold dramatically enlarges and its anterior surface wrinkles, establishing three convex ridges on each lobe of the frill. We suggest that this robust folding pattern is not due to localised increased growth at the positions of the ridges, but emerges from an elastic instability during homogeneous growth of the frill skin frustrated by its attachment to adjacent tissues. Our physical analog experiments and 3D computational simulations, using realistic embryonic tissue growth, thickness and stiffness values, recapitulate the transition from two to three ridges observed during embryonic development of the dragon’s frill.Introduction:Lizards can exhibit moveable skin folds at various locations of their body, such as the wings of the flying dragon( Draco volans), the oral display frill of the ‘secret toadhead agama’( Phrynocephalus mystaceus), and the dewlap of many anole lizard species( Anolis spp.). Here, we investigate the evolutionary developmental origin of the distinctive large erectile ruff( Figure 1A, B) of the emblematic Australian/New-Guinean frilled dragon( Chlamydosaurus kingii). This animal spreads its spectacular neck frill for predator deterrence, territorial display and courtship( Shine, 1990). Figure 1C illustrates that the ventral sides of the ruff are supported by the two ceratobranchial I bones( CBI) of the hyoid apparatus( Beddard, 1905) and the dorsal sides are held by the so-called ‘Grey’s cartilages’( De Vis, 1883). Erection of the frill is caused by the coordinated movements of the CBI bones and Grey’s cartilages and requires the opening of the mouth. Although their primary function in tetrapods is associated with deglutition, the bones of the hyoid apparatus are also involved in a variety of specialised morphologies and functions such as improved lung ventilation through gular pumping in monitor lizards( Bels et al., 1995; Owerkowicz et al., 1999), extension of the throat in bearded dragons( Throckmorton et al., 1985) and of the dewlap in Anolis lizards( Bels, 1990; Font and Rome, 1990), tongue projection in chameleons( Herrel et al., 2001), as well as tongue extension and shock absorption in woodpeckers( Yoon and Park, 2011). In reptiles, the central part of the hyoid apparatus, anteriorly prolonged by an entoglossal process( EP; Figure 1C–D), is associated to three pairs of horns( Bellairs and Kamal, 1981). The first pair is composed of the hypohyal( HH), ceratohyal( CH) and epihyal( EH). The second pair is made of the CBI and epibranchial( EB), while the third pair of horns consists of the ceratobranchial II( CBII). During embryogenesis, the hyoid apparatus develops from the pre-cartilage( mesenchyme condensation of neural crest origin) of three branchial arches( BA): the hyoid arch( i. e., the second BA = BA2) contributes to the development of the central and anterior parts of the hyoid body as well as the first pair of horns, whereas the third and fourth BAs( BA3 and BA4) generate the second and third pairs of horns, respectively( Bellairs and Kamal, 1981; Creuzet et al., 2005; Kaufman and Bard, 1999; Köntges and Lumsden, 1996). Contrary to that of the hyoid skeletal elements, the morphogenesis of the frill soft tissues and of the ‘Grey’s cartilage’ are unknown. Here, using computed-tomography and histology approaches, we first show that the highly-developed CBI bones of the frilled dragon are localised into the third( most dorsal) skin ridge of the frill and that the ‘Grey’s cartilage’ is not made of cartilage per se, but is a dense connective tissue mainly composed of collagen fibres. Second, our comparative developmental analyses indicate that the existence of a spectacular frill in Chlamydosaurus was made possible by the incomplete fusion of the BA2 with the cardiac eminence and posterior BAs, an evolutionary event that probably occurred at the origin of Episquamata reptiles. This event allowed most members of that lineage to exhibit a conspicuous neck fold( although it was lost in chameleons, snakes and legless lizards) that develops from the hyoid BA( BA2). Hence, the Chlamydosaurus frill is a dramatic outgrowth of the hyoid arch ectoderm. Finally, using 3D reconstruction, analyses of proliferation and computational simulations, we show that the very robust folding pattern of the Chlamydosaurus frill( all individuals develop three ridges on each of the two lobes of the frill) is not due to localised increased growth at the position of the ridges, but likely emerges from an elastic instability during the homogeneous growth of the anterior sheet frustrated by the underlying tissues and by its attachment to the neck. This physical( mechanical) process also explains the transition from two to three ridges observed during embryonic development of the dragon frill.Discussion:The emblematic erectile ruff of the frilled dragon is a large and sagitally-symmetric piece of skin attached to the neck and the head. At rest, the frill pleats into three convex ridges and two concave folds while the animal can spread this structure by the coordinated movements of hyoid-derived hypertrophied CBI bone( incorporated in the most dorsal ridge) and the so-called ‘Grey’s cartilage’ that we identify not to be bona fide cartilage. Here, we identify an ancient evolutionary developmental event that paved the way to the much more recent evolution of the spectacular Chlamydosaurus frill. Indeed, by comparing the embryonic development of representatives of the Squamata lineage, we suggest that the ancestor of Episquamata( Figure 5) lost the ability to completely fuse the hyoid branchial arch( BA2) with the cardiac eminence and posterior BAs, allowing for the transformation of this 'embryonic opercular flap' into a conspicuous neck fold. The latter was subsequently lost in chameleons, snakes as well as various legless lizards, while it hypertrophied in Chlamydosaurus. Second, by producing and analysing embryonic series of frill dragons, we show that wrinkles form in the developing frill’s anterior skin, establishing a pattern of three convex ridges that, later in development, allow the structure to robustly fold when rested along the animal's neck. Third, using histological data, analysis of proliferation, physical analogs and computational models, we suggest that the convex ridges are generated by an elastic instability rather than by local increased proliferation patterned by signalling morphogen gradients or positional information. Indeed, we show that homogeneous growth of the embryonic frill's anterior surface is sufficient to robustly produce on each lobe of the frill, first two then three convex ridges when the frill's growth is frustrated by its attachment to the neck. Finally, numerical simulations, implementing( i) a more realistic morphology( inferred from HREM 3D reconstructions) of the embryonic frill, incorporating the shape of it's skin and connective tissue substrate,( ii) measured mechanical parameters of Chlamydosaurus embryonic tissues, and( iii) a realistic growth model derived from embryonic series, indicate that the development of two ridges, and the later transition to three ridges, can be explained by a mechanical process that does not require any pre-patterning.","answer":"In Jurassic Park , while the computer programmer Dennis Nedry attempts to smuggle dinosaur embryos off the island , he gets attacked and killed by a mid-sized dinosaur that erects a frightening neck frill . This fictional dinosaur is clearly inspired from a real animal known as the ‘frilled dragon’ , that lives today in northern Australia and southern New Guinea . These lizards , also known as Chlamydosaurus kingii , have a large disc of skin that sits around their head and neck . This frill is usually folded back against the body , but can spread in a spectacular fashion to scare off predators and competitors . Folding of the left and right side of the frill occurs at three pre-formed ridges . But , it remains unclear which ancestral structure evolved to become the dragon’s frill , and how the ridges in the frill form during development . Now , Montandon , Fofonjka , and Milinkovitch show that the dragon’s frill , as well as the bone and cartilage that support it , develop from a part of the embryo known as the branchial arches . These are a series of bands of tissue in the embryo that evolved to become the gill supports in fish , and that now give rise to multiple structures in the ear and neck of land vertebrates . In most species , the second branchial arch will eventually fuse with the arches behind it . But in the frilled dragon , this arch instead continues to expand , leading to the formation of the dragon’s spectacular frill . As the frill develops , the front side of the skin forms three successive folds , which make up the pre-formed ridges . Studying the formation of these ridges revealed that they do not emerge from increased growth at the folding sites , but from physical forces – whereby the growth of the frill is constrained by its attachment to the neck . This causes the top layer to buckle , creating the folds of the frill . Montandon , Fofonjka , and Milinkovitch then simulated this mechanism of growth in a computer model and found it could recapitulate how folds develop in the frill of real lizard embryos . These results provide further evidence that physical processes , as well as genetic programs , can shape tissues and organs during an embryo’s development . Furthermore , changes in how the branchial arches develop between lizard species highlights how evolution is able to ‘recycle’ old structures into new shapes with different roles ."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: Busting garlic cures coronavirusAbstract:OBJECTIVE To analyze the characteristics of YouTube videos in Spanish on the basic measures to prevent coronavirus disease 2019 (COVID-19).METHODS On 18 March 2020, a search was conducted on YouTube using the terms \\"Prevencion Coronavirus\\" and \\"Prevencion COVID-19\\".We studied the associations between the type of authorship and the country of publication with other variables (such as the number of likes and basic measures to prevent COVID-19 according to the World Health Organization, among others) with univariate analysis and a multiple logistic regression model.RESULTS A total of 129 videos were evaluated; 37.2% were produced in Mexico (25.6%) and Spain (11.6%), and 56.6% were produced by mass media, including television and newspapers.The most frequently reported basic preventive measure was hand washing (71.3%), and the least frequent was not touching the eyes, nose, and mouth (24.0%).Hoaxes (such as eating garlic or citrus to prevent COVID-19) were detected in 15 videos (10.9%).In terms of authorship, papers produced by health professionals had a higher probability of reporting hand hygiene (OR (95% CI) = 4.20 (1.17-15.09)) and respiratory hygiene (OR (95% CI) = 3.05 (1.22-7.62)) as preventive measures.CONCLUSION Information from YouTube in Spanish on basic measures to prevent COVID-19 is usually not very complete and differs according to the type of authorship.Our findings make it possible to guide Spanish-speaking users on the characteristics of the videos to be viewed in order to obtain reliable information.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Hoaxes (such as eating garlic or citrus to prevent COVID-19) were detected in 15 videos (10.9%).\\"]}"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: So far, we have shown the quantity and diversity of the generated data, but its quality remains uncertain. To investigate this, we randomly sample 200 instructions and randomly select 1 instance per instruction. We asked an expert annotator (co-author of this work) to label whether each instance is correct or not, in terms of the instruction, the instance input, and the instance output.Evaluation results in Table 2 show that most of the generated instructions are meaningful, while the generated instances may contain more noise (to a reasonable extent). However, we found that even though the generations may contain errors, most of them are still in the correct format or even partially correct, which can provide useful guidance for training models to follow instructions. We listed a number of good generations and bad generations in Table 10 and Table 11 respectively.Question: How did the authors judge that the generated instructions were \\"meaningful\\"?","answer":"The authors judged a generated instruction as meaningful by seeing if it described a valid task. Out of the 200 randomly sampled instructions, they found 92% of them described a valid task."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Signed Informed Consent FormPatients having physical and mental ability to participate in the studyPatients of both sexes aged 35 to 65 yearsPresence of documented ST-elevation myocardial infarction confirmed by ECG, as well as troponin I and CK-MB levels.Presence of hemodynamically relevant stenosis of one artery (i.e., the infarct-related artery) confirmed by coronary angiography (CAG), with the occlusion of other arteries not exceeding 30%.","answer":"{\\"Condition\\": [\\"osis of one ry (i.\\", \\"ST-elevation myocardial infarction\\", \\"infarct-related artery\\", \\"occlusion of other arteries\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [\\"CK-MB\\", \\"troponin I\\"], \\"Mood\\": [], \\"Multiplier\\": [\\"one\\", \\"not exceeding 30%\\"], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [\\"aged\\", \\"sexes\\"], \\"Procedure\\": [\\"ECG\\", \\"coronary angiography\\", \\"CAG\\"], \\"Qualifier\\": [\\"hemodynamically relevant\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"ECG, as well as troponin I and CK-MB\\"], \\"Temporal\\": [], \\"Value\\": [\\"35 to 65 years\\", \\"both\\"], \\"Visit\\": []}"},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:AMSTAR is a reliable and valid measurement tool to assess the methodological quality of systematic reviews.Abstract 1:OBJECTIVE Our purpose was to measure the agreement , reliability , construct validity , and feasibility of a measurement tool to assess  systematic review s ( AMSTAR ) . STUDY DESIGN AND SETTING We r and omly selected 30 systematic review s from a data base . Each was assessed by two review ers using : ( 1 ) the enhanced quality assessment question naire ( Overview of Quality Assessment Question naire [ OQAQ ] ) ; ( 2 ) Sacks ' instrument ; and ( 3 ) our newly developed measurement tool ( AMSTAR ) . We report on reliability ( interobserver kappas of the 11 AMSTAR items ) , intraclass correlation coefficients ( ICCs ) of the sum scores , construct validity ( ICCs of the sum scores of AMSTAR compared with those of other instruments ) , and completion times . RESULTS The interrater agreement of the individual items of AMSTAR was substantial with a mean kappa of 0.70 ( 95 % confidence interval [ CI ] : 0.57 , 0.83 ) ( range : 0.38 - 1.0 ) . Kappas recorded for the other instruments were 0.63 ( 95 % CI : 0.38 , 0.78 ) for enhanced OQAQ and 0.40 ( 95 % CI : 0.29 , 0.50 ) for the Sacks ' instrument . The ICC of the total score for AMSTAR was 0.84 ( 95 % CI : 0.65 , 0.92 ) compared with 0.91 ( 95 % CI : 0.82 , 0.96 ) for OQAQ and 0.86 ( 95 % CI : 0.71 , 0.94 ) for the Sacks ' instrument . AMSTAR proved easy to apply , each review taking about 15 minutes to complete . CONCLUSIONS AMSTAR has good agreement , reliability , construct validity , and feasibility . These findings need confirmation by a broader range of assessors and a more diverse range of reviewTitle 2:Early, involuntary top-down guidance of attention from working memory.Abstract 2:Four experiments explored the interrelations between working memory , attention , and eye movements .  Observers had to identify a tilted line amongst vertical distractors .  Each line was surrounded by a colored shape that could be precued by a matching item held in memory . Relative to a neutral baseline , in which no shapes matched the memory item , search was more efficient when the memory cue matched the shape containing the target , and it was less efficient when the cued stimulus contained a distractor . Cuing affected the shortest reaction times and the first saccade in search . The effect occurred even when the memory cue was always invalid but not when the cue did not have to be held in memory . There was also no evidence for priming effects between consecutive trials . The results suggest that there can be early , involuntary top-down directing of attention to a stimulus matching the contents of working memoryTitle 3:A prospective test of the dual-pathway model of bulimic pathology: mediating effects of dieting and negative affect.Abstract 3:Because there have been few longitudinal investigations of integrative etiological theories of bulimia nervosa , this study prospect ively tested the dual-pathway model using r and om regression growth curve models and data from a 3-wave community sample of adolescent girls ( N = 231 ) . Initial pressure to be thin and thin-ideal internalization predicted subsequent growth in body dissatisfaction , initial body dissatisfaction predicted growth in dieting and negative affect , and initial dieting and negative affect predicted growth in bulimic symptoms . There was prospect i ve evidence for most of the hypothesized mediational effects . Results are consistent with the assertion that pressure to be thin , thin-ideal internalization , body dissatisfaction , dieting , and negative affect are risk factors for bulimic pathology and provide support for the dual-pathway modelTitle 4:Quantitative evaluation of the clinical efficacy of attention bias modification treatment for anxiety disorders.Abstract 4:BACKGROUND Attention bias modification treatment ( ABMT ) is a novel treatment for anxiety disorders . Although a number of other meta-analytic review s exist , the purpose of the present meta- analysis is to examine issues unaddressed in prior review s. Specifically , the review estimates the efficacy of ABMT in clinical ly anxious patients and examines the effect of delivery context ( clinic vs. home ) on symptom reduction . METHODS A literature search using PsychInfo and Web of Science data bases was performed . Only r and omized controlled trials ( RCTs ) examining dot-probe-based ABMT in clinical ly diagnosed anxious patients were included . From 714 articles located through the search , 36 ABMT studies were identified and 11 studies met inclusion criteria ( N = 589 patients ) . RESULTS ABMT was associated with greater clinician-rated reductions in anxiety symptoms relative to control training : between-groups effect ( d = 0.42 , P = .001 , confidence interval ( CI ) = 0.18 - 0.66 ) , contrast of within-group effects ( Q = 7.25 , P < .01 ) . More patients in the treatment group no longer met formal diagnostic criteria for their anxiety disorder posttreatment relative to patients in the control condition ( P < .05 ) . Analyses of patients ' self-reported anxiety were nonsignificant for the between-groups contrast ( P = .35 ) , and were at a trend level of significance for the contrast between the within-group effects ( P = .06 ) . Moderation analysis of the between-groups effect revealed a significant effect for ABMT delivered in the clinic ( d = 0.34 , P = 0.01 , CI = 0.07 - 0.62 ) , and a nonsignificant effect for ABMT delivered at home ( d = -0.10 , P = 0.40 , CI = -0.33 - 0.13 ) . CONCLUSIONS The current meta- analysis provides support for ABMT as a novel evidence d-based treatment for anxiety disorders . Overall , ABMT effects are mainly evident when it is delivered in the clinic and when clinical outcome is evaluated by a clinician . More RCTs of ABMT in specific anxiety disorders are warranted","answer":"METHOD Electronic data bases were queried for review s of neurocognitive domains ( i.e. , inhibitory control , decision-making , central coherence , set-shifting , working memory , and attention bias ) in EDs , which identified 28 systematic and meta-analytic review s. RESULTS Broadly , the literature indicates deficits across these neurocognitive domains in EDs , though heterogeneity was noted in the magnitude of these effects , which varied to some extent across ED subtypes , sample characteristics , and method ological approaches ."},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: Which is the catalytic activity of the protein encoded by the gene KMT2C? Context: The lysine methyltransferase KMT2C (also known as MLL3), a subunit of the COMPASS complex, implements monomethylation of Lys4 on histone H3 (H3K4) at gene enhancers.KMT2C histone methyltransferaselysine methyltransferase 2C (KMT2C)","answer":"lysine methyltransferase activity"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:the kerr solution is a vacuum solution , and thus the riemann curvature tensor equals the weyl tensor , @xmath5 .all invariant and tensorial expressions in curvature shall be derived from the weyl tensor alone .let us start by defining the two cartan invariants @xcite @xmath6 where hatted indices refer to the orthonormal coframe @xmath7 .these quantities capture the mass ( \`\` gravitational charge '' ) and angular momentum ( \`\` gravitational current '' ) of the kerr solution .they are ubiquitous in analytic expressions for different ( pseudo-)scalar invariants .    focusing the discussion somewhat ,let us now introduce the curvature invariants that will be examined in this work .the kretschmann scalar @xmath8 and chern  pontryagin pseudoscalar @xmath9 take the values @xcite @xmath10 where @xmath11 is the left dual of the weyl tensor . following ref .@xcite we consider the additional karlhede  lindstrm  man invariants @xcite @xmath12left ( nabla{}^a c{}^{bcde } right ) .end{split}end{aligned} ] ] they vanish on the kerr ergosphere ( and hence at the schwarzschild horizon , for @xmath13 ) , but they are not very useful in locating the horizon of the kerr solution .their explicit form can be found in ref .by contrast , the following invariant vanishes on the kerr horizon @xcite : @xmath14     & = 16times12 ^ 8times frac{m^8a^2cos^2theta(r^2 - 2mr+a^2)}{left(r^2+a^2cos^2thetaright){}^{16 } } .end{split}end{aligned} ] ] we close by defining the bel robinson tensor @xcite as well as the vacuum kummer tensor @xcite : @xmath15 the bel robinson tensor is related to the notion of superenergy , since its full contraction with any timelike vector is positive , @xmath16 @xcite .the kummer tensor can be introduced by analogy with electromagnetism . in ref .@xcite , it was suggested that this tensor may encode specific properties of gravitational waves .robinson tensor and the kummer tensor admit the following invariants : @xmath17 now we can define invariant curvature surfaces by setting @xmath18 where @xmath19 is some polynomial function .of course , one may also consider simpler cases where just one of the invariants assumes a constant value , as can be seen in fig .[ fig:2d - invariants ] .these invariants define surfaces that may extend well outside the horizon and can take relatively complicated shapes .one may ask : what is a special value for these invariants to take ?since the kerr solution can be written as @xmath20 , where the new line element @xmath21 only depends on the dimensionless parameter @xmath22 , there is no intrinsic length scale other than @xmath23 . in other words ,if all distances are measured in terms of @xmath23 , the dimensionless parameter @xmath24 no longer provides a length scale related to the rotation parameter .of course , one special value still exists : zero .suppose we consider the dynamics of a non - minimally coupled matter field in the vicinity of a black hole . under some assumptions on the lagrangian , the non - minimally coupled curvature expressions can serve as an effective potential for the matter field .therefore , in a wkb approximation where the field dynamics are fast compared to the gravitational dynamics , the field may condense in the minimum of its potential .notably , in some circumstances , the expression of this minimum may have the structure of eq ., see fig .[ fig:3d - zero - curvature ] for a few zero - curvature surfaces around the kerr black hole .again , they may extend far outside the horizon .suppose we have a vector field at our disposal : then , we may consider scalar invariants formed by contractions of expressions in the curvature and that vector field : @xmath25 n{}^{a_1 } dots n{}^{a_p } = text{const } .end{aligned} ] ] an important class of vector fields , @xmath26 , intrinsic to a given spacetime , are the principal null directions ( pnds ) of the weyl tensor , defined by @xmath27mn[k } n{}^{l ] } n{}_m n{}_n = 0  ] with @xmath28 @xcite .the algebraic multiplicity of the corresponding eigenvalue problem then defines the petrov type of the given spacetime at each point .the kerr spacetime is of type d , and the pnds are @xmath29 here , @xmath30 denotes the components of the pnds with respect the coframe @xmath7 . according to eq .( 6 ) in bel s work @xcite , there is an equivalent way to formulate this eigenvalue problem for petrov type d spacetimes ( what bel calls type iib ) . for the kerr solution it reads@xmath31 it is straightforward to check that the above implies @xmath32 is the converse also true ? interestingly , inserting instead the general null vector @xmath33 into the left - hand side of eq .   implies @xmath34 respectively . for @xmath35 and @xmath36 ,the unique solution is @xmath37 for any @xmath38 .hence either the bel  robinson surface or the kummer surface imply the pnds of the kerr spacetime . due to the algebraic nature of this proof , it seems plausible to us that this result may hold for general type d spacetimes .it remains to be seen whether these concepts can be generalized to different petrov types .invariant curvature surfaces and projective surfaces seem to play an important role in the study of the kerr geometry , both for experimental reasons ( non - minimally coupled matter fields ) as well as for theoretical considerations ( petrov classification ) .more work is necessary to extend our conclusions beyond the kerr metric to general petrov type d solutions and perhaps to other algebraically special spacetimes as well .discussions with friedrich w.  hehl ( cologne & missouri ) are greatly appreciated .jb was supported by a doctoral recruitment scholarship and the golden bell jar graduate scholarship in physics at the university of alberta .          c.  heinicke and f.  w.  hehl , \`\` schwarzschild and kerr solutions of einstein s field equation  an introduction , '' int .j.  mod .d * 24 * ( 2014 ) no.02 , 1530006 ; https://arxiv.org/abs/1503.02172[arxiv:1503.02172 [ gr - qc ] ] .b.  carter , \`\` global structure of the kerr family of gravitational fields , '' phys .* 174 * ( 1968 ) 1559 ; \`\` hamilton  jacobi and schrodinger separable solutions of einstein s equations , '' comm.  math .* 10 * ( 1968 ) 280 .d.  a.  nichols _ et al ._ , \`\` visualizing spacetime curvature via frame - drag vortexes and tidal tendexes i. general theory and weak - gravity applications , '' phys .d * 84 * ( 2011 ) 124014 ; https://arxiv.org/abs/1108.5486[arxiv:1108.5486 [ gr - qc ] ] .m.  abdelqader and k.  lake , \`\` visualizing spacetime curvature via gradient flows .the kerr metric and the transitional values of the spin parameter , '' phys .d * 88 * ( 2013 ) no.6 , 064042 ; https://arxiv.org/abs/1308.1433[arxiv:1308.1433 [ gr - qc ] ] .j.  boos , \`\` plebaski  demiaski solution of general relativity and its expressions quadratic and cubic in curvature : analogies to electromagnetism , '' int .j.  mod .d * 24 * ( 2015 ) no.10 , 1550079 ; https://arxiv.org/abs/1412.1958[arxiv:1412.1958 [ gr - qc ] ] .m.  abdelqader and k.  lake , \`\` invariant characterization of the kerr spacetime : locating the horizon and measuring the mass and spin of rotating black holes using curvature invariants , '' phys .  rev .d * 91 * ( 2015 ) no.8 , 084017 ; https://arxiv.org/abs/1412.8757[arxiv:1412.8757 [ gr - qc ] ] .d.  n.  page and a.  a.  shoom , \`\` local invariants vanishing on stationary horizons : a diagnostic for locating black holes , '' phys .* 114 * ( 2015 ) no.14 , 141102 ; https://arxiv.org/abs/1501.03510[arxiv:1501.03510 [ gr - qc ] ] .l.  bel , \`\` les tats de radiation et le problme de lnergie en relativit gnrale , '' cah .* 16 * ( 1962 ) 59 ; eng .\`\` radiation states and the problem of energy in general relativity , '' gen .* 32 * ( 2000 ) 2047 .p.  baekler , a.  favaro , y.  itin and f.  w.  hehl , \`\` the kummer tensor density in electrodynamics and in gravity , '' annals phys .( ny ) * 349 * ( 2014 ) 297 ; https://arxiv.org/abs/1403.3467[arxiv:1403.3467 [ gr - qc ] ] .","answer":"in the kerr geometry , we calculate various surfaces of constant curvature invariants . these extend well beyond the kerr horizon , and we argue that they might be of observational significance in connection with non - minimally coupled matter fields .  moreover , we demonstrate that the principal null directions of the kerr geometry can be obtained by projections involving either the bel  robinson or the kummer tensor .  we conjecture that this is also possible in more general settings .     essay written for the gravity research foundation 2017 awards for essays on gravitation .     _ file : 28_kerr_v2.tex , mar 31 , 2017 , jb _    the kerr solution @xcite , describing a rotating black hole , is a truly remarkable exact solution of the vacuum einstein field equations : it is not only important in astrophysics , has not only spawned a wealth of mathematical tools and devices in the context of the finding of solutions to the einstein field equations @xcite , but it has also served as a testing ground for new physical ideas . for example , the concept of hidden symmetries @xcite was discovered after studying the separability of the geodesic equation and the appearance of carter s constant @xcite .  more recently , the emergence of conformal symmetry in the near - horizon region of a maximally rotating kerr black hole has given rise to the kerr / cft correspondence @xcite .     in this essay , we would like to focus on properties of the kerr black hole that can be described using invariant expressions obtained from the curvature .  we will apply two techniques : visual analysis of invariant curvature surfaces , and projective methods involving the principal null directions of the kerr spacetime as contracted with tensorial expressions in the curvature .  see also refs .   @xcite regarding different visualization procedures of spacetime curvature .     the kerr solution in boyer   lindquist coordinates @xmath0 takes the form @xmath1 ^ 2 , label{eq : kerr - metric }   end{split}end{aligned} ] ] where we defined @xmath2 and @xmath3 .  we may readily read off a possible orthonormal coframe such that @xmath4 ."},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:In this paper, we propose an end-to-end deep learning model, called E2Efold, for RNA secondary structure prediction which can effectively take into account the inherent constraints in the problem.The key idea of E2Efold is to directly predict the RNA base-pairing matrix, and use an unrolled constrained programming algorithm as a building block in the architecture to enforce constraints.With comprehensive experiments on benchmark datasets, we demonstrate the superior performance of E2Efold: it predicts significantly better structures compared to previous SOTA (29.7% improvement in some cases in F1 scores and even larger improvement for pseudoknotted structures) and runs as efficient as the fastest algorithms in terms of inference time.Ribonucleic acid (RNA) is a molecule playing essential roles in numerous cellular processes and regulating expression of genes (Crick, 1970) .It consists of an ordered sequence of nucleotides, with each nucleotide containing one of four bases: Adenine (A), Guanine (G), Cytosine (C) and Uracile (U).This sequence of bases can be represented asx := (x 1 , . . . , x L ) where x i ∈ {A, G, C, U }, which is known as the primary structure of RNA.The bases can bond with one another to form a set of base-pairs, which defines the secondary structure.A secondary structure can be represented by a binary matrix A * where A * ij = 1 if the i, j-th bases are paired (Fig 1) .Discovering the secondary structure of RNA is important for understanding functions of RNA since the structure essentially affects the interaction and reaction between RNA and other cellular components.Although secondary structure can be determined by experimental assays (e.g. X-ray diffraction), it is slow, expensive and technically challenging.Therefore, computational prediction of RNA secondary structure becomes an important task in RNA research and is useful in many applications such as drug design (Iorns et al., 2007) .(ii) Pseudo-knot(i) Nested Structure Research on computational prediction of RNA secondary structure from knowledge of primary structure has been carried out for decades.Most existing methods assume the secondary structure is a result of energy minimization, i.e., A * = arg min A E x (A).The energy function is either estimated by physics-based thermodynamic experiments (Lorenz et al., 2011; Markham & Zuker, 2008) or learned from data (Do et al., 2006) .These approaches are faced with a common problem that the search space of all valid secondary structures is exponentially-large with respect to the length L of the sequence.To make the minimization tractable, it is often assumed the base-pairing has a nested structure (Fig 2 left) , and the energy function factorizes pairwisely.With this assumption, dynamic programming (DP) based algorithms can iteratively find the optimal structure for subsequences and thus consider an enormous number of structures in time O(L 3 ).Although DP-based algorithms have dominated RNA structure prediction, it is notable that they restrict the search space to nested structures, which excludes some valid yet biologically important RNA secondary structures that contain 'pseudoknots', i.e., elements with at least two non-nested base-pairs (Fig 2 right) .Pseudoknots make up roughly 1.4% of base-pairs (Mathews & Turner, 2006) , and are overrepresented in functionally important regions (Hajdin et al., 2013; Staple & Butcher, 2005) .Furthermore, pseudoknots are present in around 40% of the RNAs.They also assist folding into 3D structures (Fechter et al., 2001 ) and thus should not be ignored.To predict RNA structures with pseudoknots, energy-based methods need to run more computationally intensive algorithms to decode the structures.In summary, in the presence of more complex structured output (i.e., pseudoknots), it is challenging for energy-based approaches to simultaneously take into account the complex constraints while being efficient.In this paper, we adopt a different viewpoint by assuming that the secondary structure is the output of a feed-forward function, i.e., A * = F θ (x), and propose to learn θ from data in an end-to-end fashion.It avoids the second minimization step needed in energy function based approach, and does not require the output structure to be nested.Furthermore, the feed-forward model can be fitted by directly optimizing the loss that one is interested in.Despite the above advantages of using a feed-forward model, the architecture design is challenging.To be more concrete, in the RNA case, F θ is difficult to design for the following reasons:(i) RNA secondary structure needs to obey certain hard constraints (see details in Section 3), which means certain kinds of pairings cannot occur at all (Steeg, 1993) .Ideally, the output of F θ needs to satisfy these constraints.(ii) The number of RNA data points is limited, so we cannot expect that a naive fully connected network can learn the predictive information and constraints directly from data.Thus, inductive biases need to be encoded into the network architecture.(iii) One may take a two-step approach, where a post-processing step can be carried out to enforce the constraints when F θ predicts an invalid structure.However, in this design, the deep network trained in the first stage is unaware of the post-processing stage, making less effective use of the potential prior knowledge encoded in the constraints.In this paper, we present an end-to-end deep learning solution which integrates the two stages.The first part of the architecture is a transformer-based deep model called Deep Score Network which represents sequence information useful for structure prediction.The second part is a multilayer network called Post-Processing Network which gradually enforces the constraints and restrict the output space.It is designed based on an unrolled algorithm for solving a constrained optimization.These two networks are coupled together and learned jointly in an end-to-end fashion.Therefore, we call our model E2Efold.By using an unrolled algorithm as the inductive bias to design Post-Processing Network, the output space of E2Efold is constrained (see Fig 3 for an illustration), which makes it easier to learn a good model in the case of limited data and also reduces the overfitting issue.Yet, the constraints encoded in E2Efold are flexible enough such that pseudoknots are included in the output space.In summary, E2Efold strikes a nice balance between model biases for learning and expressiveness for valid RNA structures.We conduct extensive experiments to compare E2Efold with state-of-the-art (SOTA) methods on several RNA benchmark datasets, showing superior performance of E2Efold including:• being able to predict valid RNA secondary structures including pseudoknots;• running as efficient as the fastest algorithm in terms of inference time;• producing structures that are visually close to the true structure;• better than previous SOTA in terms of F1 score, precision and recall.Although in this paper we focus on RNA secondary structure prediction, which presents an important and concrete problem where E2Efold leads to significant improvements, our method is generic and can be applied to other problems where constraints need to be enforced or prior knowledge is provided.We imagine that our design idea of learning unrolled algorithm to enforce constraints can also be transferred to problems such as protein folding and natural language understanding problems (e.g., building correspondence structure between different parts in a document).We propose a novel DL model, E2Efold, for RNA secondary structure prediction, which incorporates hard constraints in its architecture design.Comprehensive experiments are conducted to show the superior performance of E2Efold, no matter on quantitative criteria, running time, or visualization.Further studies need to be conducted to deal with the RNA types with less samples.Finally, we believe the idea of unrolling constrained programming and pushing gradient through post-processing can be generic and useful for other constrained structured prediction problems.Here we explain the difference between our approach and other works on unrolling optimization problems.First, our view of incorporating constraints to reduce output space and to reduce sample complexity is novel.Previous works (Hershey et al., 2014; Belanger et al., 2017; Ingraham et al., 2018) did not discuss these aspects.The most related work which also integrates constraints is OptNet (Amos & Kolter, 2017) , but its very expensive and can not scale to the RNA problem.Therefore, our proposed approach is a simple and effective one.Second, compared to (Chen et al., 2018; Shrivastava et al., 2019) , our approach has a different purpose of using the algorithm.Their goal is to learn a better algorithm, so they commonly make their architecture more flexible than the original algorithm for the room of improvement.However, we aim at enforcing constraints.To ensure that constraints are nicely incorporated, we keep the original structure of the algorithm and only make the hyperparameters learnable.Finally, although all works consider end-to-end training, none of them can directly optimize the F1 score.We proposed a differentiable loss function to mimic the F1 score/precision/recall, which is effective and also very useful when negative samples are much fewer than positive samples (or the inverse).","answer":"A DL model for RNA secondary structure prediction, which uses an unrolled algorithm in the architecture to enforce constraints."},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Interventions for mycosis fungoides. Mycosis fungoides is the most common type of cutaneous T-cell lymphoma, a malignant, chronic disease initially affecting the skin. Several therapies are available, which may induce clinical remission for a time.  objectives To assess the effects of interventions for mycosis fungoides in all stages of the disease.  Search Methods We searched the following databases up to January 2011: the Cochrane Skin Group Specialised Register, CENTRAL in The Cochrane Library, MEDLINE (from 2005), EMBASE (from 2010), and LILACS (from 1982). We also checked reference lists of included studies for further references to relevant RCTs. We searched online trials registries for further references to unpublished trials and undertook a separate search for adverse effects of interventions for mycosis fungoides in non-RCTs in MEDLINE in May 2011.  Selection Criteria Randomised controlled trials (RCTs) of interventions for mycosis fungoides in people with any stage of the disease. At least 90% of participants in the trials must have been diagnosed with mycosis fungoides (Alibert-Bazin-type).  Data Collection And Analysis Two authors independently assessed eligibility and methodological quality for each study and carried out data extraction. We resolved any disagreement by discussion. Primary outcomes were the impact on quality of life and the safety of interventions. When available, we reported on our secondary outcomes, which were the improvement or clearance of skin lesions, disease-free intervals, survival rates, relapse rates, and rare adverse effects. When possible, we combined homogeneous studies for meta-analysis. We used The Cochrane Collaboration's 'Risk of bias' tool to assess the internal validity of all included studies in six different domains.  Main Results The review included 14 RCTs involving 675 participants, covering a wide range of interventions. Eleven of the included trials assessed participants in clinical stages IA to IIB only (please see Table 1 for definitions of these stages).Internal validity was considerably low in studies with a high or unclear risk of bias. The main reasons for this were low methodological quality or missing data, even after we contacted the study authors, and a mean dropout rate of 26% (0% to 72%). Study size was generally small with a minimum of 4 and a maximum of 103 participants. Only one study provided a long enough follow-up for reliable survival analysis.Included studies assessed topical treatments, such as imiquimod, peldesine, hypericin, nitrogen mustard, as well as intralesional injections of interferon-α (IFN-α). The light therapies investigated included psoralen plus ultraviolet A light (PUVA), extracorporeal photopheresis (photochemotherapy), and visible light. Oral treatments included acitretin, bexarotene, and methotrexate. Treatment with parenteral systemic agents consisted of denileukin diftitox; a combination of chemotherapy and electron beam radiation; and intramuscular injections of active transfer factor. Nine studies evaluated therapies by using an active comparator; five were placebo-controlled RCTs.Twelve studies reported on common adverse effects, while only two assessed quality of life. None of these studies compared the health-related quality of life of participants undergoing different treatments. Most of the reported adverse effects were attributed to the interventions. Systemic treatments , and here in particular a combined therapeutic regimen of chemotherapy and electron beam , bexarotene , or denileukin diftitox , showed more adverse effects than topical or skin-directed treatments .In the included studies, clearance rates ranged from 0% to 83%, and improvement ranged from 0% to 88%. The meta-analysis combining the results of 2 trials comparing the effect of IFN-α and PUVA versus PUVA alone showed no significant difference in the relative risk of clearance: 1.07 (95% confidence interval 0.87 to 1.31). None of the included studies demonstrated a significant increase in disease-free intervals, relapse, or overall survival.  Authors Conclusions This review identified trial evidence for a range of different topical and systemic interventions for mycosis fungoides. Because of substantial heterogeneity in design, small sample sizes, and low methodological quality, the comparative safety and efficacy of these interventions cannot be established on the basis of the included RCTs. Taking into account the possible serious adverse effects and the limited availability of efficacy data, topical and skin-directed treatments are recommended first, especially in the early stages of disease. More aggressive therapeutic regimens may show improvement or clearance of lesions, but they also result in more adverse effects; therefore, they are to be considered with caution. Larger studies with comparable, clearly-defined end points for all stages of mycosis fungoides, and a focus on safety, quality of life, and duration of remission as part of the outcome measures, are necessary.sentence: Systemic treatments , and here in particular a combined therapeutic regimen of chemotherapy and electron beam , bexarotene , or denileukin diftitox , showed more adverse effects than topical or skin-directed treatments .","answer":"[[\\"bexarotene\\", \\"denileukin diftitox\\", \\"NEG\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Arsenic\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Biomimetic diversity-oriented synthesis of benzannulated medium rings via ring expansion. Nature has exploited medium-sized 8- to 11-membered rings in a variety of natural products to address diverse and challenging biological targets. However, owing to the limitations of conventional cyclization-based approaches to medium-ring synthesis, these structures remain severely underrepresented in current probe and drug discovery efforts. To address this problem, we have established an alternative, biomimetic ring expansion approach to the diversity-oriented synthesis of medium-ring libraries. Oxidative dearomatization of bicyclic phenols affords polycyclic cyclohexadienones that undergo efficient ring expansion to form benzannulated medium-ring scaffolds found in natural products. The ring expansion reaction can be induced using three complementary reagents that avoid competing dienone-phenol rearrangements and is driven by rearomatization of a phenol ring adjacent to the scissile bond. Cheminformatic analysis of the resulting first-generation library confirms that these molecules occupy chemical space overlapping with medium-ring natural products and distinct from that of synthetic drugs and drug-like libraries.","answer":"{\\"Chemical\\": [\\"polycyclic cyclohexadienones\\", \\"bicyclic phenols\\", \\"phenol\\", \\"dienone-phenol\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: ADAMTS5 Is a Critical Regulator of Virus-Specific T Cell Immunity}Article:Abstract:The extracellular matrix( ECM) provides physical scaffolding for cellular constituents and initiates biochemical and biomechanical cues that are required for physiological activity of living tissues. The ECM enzyme ADAMTS5, a member of the ADAMTS( A Disintegrin-like and Metalloproteinase with Thrombospondin-1 motifs) protein family, cleaves large proteoglycans such as aggrecan, leading to the destruction of cartilage and osteoarthritis. However, its contribution to viral pathogenesis and immunity is currently undefined. Here, we use a combination of in vitro and in vivo models to show that ADAMTS5 enzymatic activity plays a key role in the development of influenza-specific immunity. Influenza virus infection of Adamts5-/- mice resulted in delayed virus clearance, compromised T cell migration and immunity and accumulation of versican, an ADAMTS5 proteoglycan substrate. Our research emphasises the importance of ADAMTS5 expression in the control of influenza virus infection and highlights the potential for development of ADAMTS5-based therapeutic strategies to reduce morbidity and mortality.Introduction:Influenza A virus infection is responsible for substantial global morbidity and mortality( >500, 000 deaths each year[1]) and largely afflicts high-risk groups, including the very young and elderly. There are currently two countermeasures employed to control influenza virus infection: vaccines and antivirals. Although generally effective, the imperfect proofreading capacity of the RNA-dependent RNA polymerase drives constant genetic drift. Moreover, a segmented genome facilitates rapid genetic shift, resulting in the need for reformulation of seasonal vaccines or the emergence of resistance following administration of antivirals, leading to suboptimal prophylactic or therapeutic intervention[2]. T cells are a vital component of the adaptive immune response following influenza virus infection. Critically, trafficking of activated influenza-specific T cells from draining lymph nodes( including the mediastinal lymph node[MLN]) to the site of primary infection in the lung requires direct contact and interaction with the extracellular matrix( ECM)[3]. The ECM provides adhesive substrates, such as proteoglycans and collagen, to encourage and facilitate lymphocyte trafficking[4]. Expression and remodelling of ECM components is strictly regulated to control movement of immune cells. Therefore, it is not surprising that perturbations in substrate availability and ECM remodelling significantly impact granulocyte and lymphocyte migration in a number of model systems[5–7]. The A Disintegrin-like and Metalloproteinase with Thrombospondin-1 motifs( ADAMTS) family are a group of secreted metalloproteinases found within the zinc-dependent metzincin super-family that also consists of matrix metalloproteinases( MMPs) and ADAMs[8]. The ADAMTS family comprises 19 mammalian ADAMTs enzymes[9]. ADAMTS5 is one of the most highly characterised and well-known proteinases in this family and has been shown to cleave the hyalectan class of chondroitin sulphate proteoglycans( CSPGs), including aggrecan, brevican, neurocan, and versican[10–13]. Hyalectans/CSPGs are large aggregating macromolecules that hydrate tissue and confer rigidity to the extracellular space. ADAMTS5 has become a major drug target for arthritis therapy as ADAMTS5 knockout mice( Adamts5-/- mice) are resistant to aggrecan cleavage in articular cartilage and are thus protected from experimentally induced arthritis[14, 15]. Aside from the documented role in arthritis, ADAMTS5 has been shown to play a role in embryonic development, including limb and cardiac morphogenesis, and skeletal muscle development through its versican remodelling properties[11, 16, 17]. Importantly, its role in viral immunity is currently undefined. Versican, a substrate of ADAMTS5, is a widely expressed tissue proteoglycan involved in cell adhesion, proliferation, and migration[4]. The two predominant splice-variants of versican that harbour ADAMTS cleavage sites in their shared glycosaminoglycan( GAG)-β domain are V0 and V1[18]. GAG chains provide interactive points for antigen recognition receptors( Toll-like receptor 2 and 4), chemokines( MCP-1, MCP-2, CCL5), and cell surface markers( CD62L, CD44), some of which are directly linked to immune cell migration[19–21]. Furthermore, in vitro studies have shown that Poly I:C induced versican expression can restrict CD4+ T cell migration by preventing ECM adhesion[22]. Given the fact that ADAMTS5 is a versicanase[11], we hypothesised that it would play a key role in viral immunity. Our data demonstrates that host expression of ADAMTS5 is required to help ameliorate disease following influenza virus infection. Adamts5-/- mice clearly show increased weight loss and higher viral titres throughout the course of influenza virus infection along with impaired CD8+ T cell migration and immunity.Discussion:Increasing evidence in the literature highlights the importance of zinc-dependent metzincins in the regulation of immune responses. MMPs and ADAMs have been strongly associated with neutrophil, macrophage, dendritic cell, and lymphocyte migration[6, 34–36]. Here, we show for the first time that ADAMTS5, a member of the ADAMTS family, has a key role in influenza virus-specific immunity through a mechanism that involves ECM remodelling. Adamts5-/- mice had higher peak viremias and showed signs of delayed influenza virus clearance when compared to C57. BL/6 controls( Fig 2). The defect contributed to fewer total CD4+ and CD8+ T cells in the periphery and an accumulation of these cells in the MLN( Figs 3–5). Results from our transwell migration assays and Adamts5-/-Vcan+/hdf mouse studies further support our hypothesis that the absence of ADAMTS5 reduces ECM proteoglycan cleavage and impedes( but does not entirely block) the movement of influenza-specific lymphocytes to effector sites, such as the lung or to the periphery( Figs 7 and 8). Migration of CD8+ T cells from draining lymph nodes to the periphery is critically important for the establishment of full effector function and eventual clearance of pathogens, such as influenza virus. Our research suggests that the lack of ADAMTS5 enzymatic activity in influenza virus-infected Adamts5-/- mice results in accumulation of the large extracellular proteoglycan V0/V1 versican( Fig 6A). Increased V0/V1 versican expression has also been noted in the developing limb[11] and heart valves[17] of Adamts5-/- mice. We believe that the accumulation in the MLN shown in this current study prevents lymphocyte trafficking and results in the exacerbation of disease following influenza virus infection. Furthermore, corroborating evidence by others in the field demonstrates that an epitope in the N-terminal globular domain of versican promoted CD4+ T cell migration and lymphocyte rolling[22]. Additionally, versican overexpression was associated with decreased infiltration of CD8+ T cells in stromal compartments of cervical cancer[28]. Further studies have suggested that the related zinc-dependent metzincins, the MMPs, are essential for immune cell trafficking. Like ADAMTs enzymes, MMPs contain a catalytic domain that utilises a conserved zinc binding sequence( HEXXHXXXGXX) for catalysing reactions[8] and have a broad range of cleavage substrates. This is in contrast to the highly specific cleavage moieties associated with ADAMTS enzyme activity. It is therefore not surprising that the MMPs have been identified in a vast number of physiological processes[37]. For example, MMP9, a highly characterised extracellular metalloproteinase associated with immune cell trafficking, has been detected in neutrophils, macrophages, dendritic cells, and T cells[31, 38]. MMP9 and related MMPs( MMP2, 7, 10, 14) have been shown to degrade ECM roadblocks associated with immune cell trafficking in a similar fashion to what we have proposed in our study. Specifically, MMP9 and MMP2 expressing Th1 T cells demonstrate increased motility through collagen in a transwell migration assay[39]. Supporting in vivo data has suggested that a blockade of the MMP9 and MMP2 signalling pathway( Wnt) is associated with impaired T cell extravasation in an experimentally induced skin inflammation model[6]. Moreover, lipopolysaccharide-stimulated macrophages isolated from Mmp10-/- mice fail to migrate efficiently in transwell studies when compared to C57. BL/6 control macrophages[5]. In these studies, ECM components, such as collagen and elastin, inhibited immune cell migration. Collagen and elastin form key ECM components of basement membranes, and so dampened MMP activity would, in turn, lead to accumulation of these components and inhibition of immune cell migration and tissue infiltration. In contrast to the abovementioned studies, versican, a key ADAMTS5 substrate, is widely expressed in tissues and is not predominately associated with the basement membrane( as are MMP substrates). ECM components, such as versican, provide a “sticky” surface for T cell adherence. Versican GAG chains interact directly or indirectly with molecules on the T cell surface, such as CD62L and CD44[20, 21, 40], both of which are known to contribute to T cell trafficking. Increased levels of versican, such as those observed in Adamts5-/- mice, may therefore prevent T cell interaction with the ECM, leading to perturbations in T cell migration. Thus, we propose that cleavage and removal of versican blockades via the action of proteoglycanases, such as ADAMTS5, is required for efficient T cell interaction with the ECM to encourage migration to effector sites in the periphery and for the subsequent resolution of infection( Fig 8G). Our hypothesis is further strengthened by data demonstrating that reduction of versican restores normal T cell function in Adamts5-/-Vcan+/hdf mice( Fig 8). It is important to note that the migration of influenza-specific CD8+ T cells was not fully impeded in our experimental model. ADAMTS5 may therefore be working in concert with other metalloproteinases to facilitate T cell migration. The proteoglycanases, ADAMTS1, 4, 8, 9, 15, and 20, as well as MMP1, 2, 3, 7, and 9, are capable of producing versican fragments in a similar fashion to ADAMTS5[9, 16, 32, 41, 42]. It is reasonable to suspect that there is redundancy built into the trafficking system, as related family members, such as ADAMTS9( Fig 1F), may be providing some compensatory function in the absence of ADAMTS5, allowing some T cell migration( although highly restricted) to occur into the periphery( Figs 3 and 4). The cooperative requirement of versican cleavage by ADAMTS9 with ADAMTS5 has been observed in embryogenesis, and so its presence in regulation of immune cell migration cannot be discounted[11, 43–45]. Furthermore, the transwell migration assay indicated that multiple ADAMTS enzymes can mediate T cell migration( Fig 7A). Further studies with related family members are required to ascertain their specific contribution to influenza-specific immunity. Our findings would suggest that overexpression of ADAMTS5 or reduced versican expression could restore and improve immunity. Evidence from MMP9-related influenza studies suggests that a more circumspect approach may be required. MMP9 has been shown to be involved in the repair of lung tissue following influenza virus infection and can prevent bleomycin-mediated lung fibrosis by remodelling the ECM and degrading cytokines[46]. However, MMP9 overactivity in MMP9 transgenic mice has been associated with excessive neutrophil infiltration following influenza virus infection, leading to poor survival[38]. An inhibitor targeting ADAMTS5 has already undergone clinical trial as an osteoarthritic therapeutic( https://clinicaltrials. gov/show/NCT00454298). Administration of ADAMTS5 inhibitors for osteoarthritis may therefore be contraindicated in elderly patients, as they are more susceptible to influenza infection. Careful dissection and characterisation of metalloproteinase expression may therefore be required to determine the contribution of these enzymes to overall tissue repair and immunity. In summary, our data show that the ADAMTS5 ECM enzyme activity is critically important for lymphocyte trafficking following influenza virus infection( especially CD8+ T cell immunity). In conclusion, interventions that facilitate increased ADAMTS5 expression used in conjunction with current approved antivirals and/or vaccines offer a new approach for combating unexpected emerging influenza virus pandemic threats.","answer":"Movement of immune cells is critical for effective clearance of pathogens . The response to influenza virus infection requires immune cell trafficking between the lung , mediastinal lymph node and other peripheral lymphoid organs such as the spleen . We set out to assess the contribution of a specific extracellular matrix enzyme , ADAMTS5 , to migration of lymphocytes and overall pathogenesis following infection . In our studies , we demonstrate that mice lacking Adamts5 have fewer influenza-specific lymphocytes in the lung and spleen following infection . These observations correlated with an accumulation of influenza-specific lymphocytes in the mediastinal lymph node and increased virus titres . This work suggests that ADAMTS5 is necessary for immune cell migration to the periphery , where lymphocyte function is required to fight infection ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Changing attitudes to childhood immunisation in English parents We undertook a national survey of parental attitudes to childhood vaccinations and compared results with those in earlier comparable surveys covering a 10year period. We randomly selected 275 nationally representative sampling locations in England. Interviewers identified eligible primary care givers (referred to as parents) of children aged from 2 months to <5 years and conducted home -based interviews between January and April 2015. We aimed to recruit 1000 parents of children aged 0-2 years and 1000 of children aged 3-4 years. The questionnaire covered all aspects of the immunisation process, vaccines administered in pregnancy and from infancy to pre-school with a maximum of 86 mixed questions. Interviews were completed with 1792 parents of whom 1130 had children aged 0-2 years and 999 had children aged 3-4 years; 337 had children of both ages. The findings showed that confidence in and acceptance of the vaccination programme was high. Only 2% of parents reported refusing vaccination whilst 90% reported vaccinating their children automatically when due. Almost all parents (97%) consulted web-based resources for information on vaccination. Parents who used chat rooms or discussion forums for this purpose were significantly more likely to say they had seen something that would make them doubt having their child(ren) immunised (31% compared to 8% amongst all parents). Health professionals and the NHS were seen as the most trusted source of advice on immunisation (90% agreed / strongly agreed with each). Very few parents did not trust these sources (4% and 3% disagreed, respectively). Health professionals remain extremely important in communicating information about vaccination and are highly trusted by parents; a trust that has increased in recent years. Despite most parents seeking information on the Internet, trust in and advice from health care professionals appeared to be key factors influencing parental decisions.","answer":"{\\"AnatomicalStructure\\": [], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"confidence\\", \\"pregnancy\\", \\"decisions\\", \\"attitudes\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [\\"vaccines\\"], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"due\\", \\"vaccinating\\", \\"disagreed\\", \\"agreed\\", \\"immunised\\", \\"acceptance\\", \\"strongly agreed\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"vaccinations\\", \\"advice\\", \\"vaccination programme\\", \\"vaccination\\", \\"immunisation\\", \\"NHS\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [\\"surveys\\", \\"web-based resources\\", \\"questionnaire\\"], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [\\"English\\"], \\"ProfessionalOrOccupationalGroup\\": [\\"Interviewers\\", \\"care givers\\", \\"Health professionals\\", \\"health care professionals\\"], \\"ResearchActivity\\": [], \\"SpatialConcept\\": [\\"England\\", \\"locations\\", \\"home\\"], \\"Virus\\": []}"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: What is the mode of action of the drug Prolia?Context: Recently anti-RANKL agents (receptor activator of nuclear factor-kappaB ligand) such as denosumab (Prolia, Amgen Inc., California, USA) that have a similar mode of action to bisphosphonates have been introduced to treat such diseasesRecently anti-RANKL agents (receptor activator of nuclear factor-kappaB ligand) such as denosumab (Prolia, Amgen Inc., California, USA) that have a similar mode of action to bisphosphonates have been introduced to treat such diseases.To evaluate the efficacy and safety of Denosumab (Prolia), a first-line osteoporosis (OP) medication that is a fully human monoclonal antibody to the receptor activator of nuclear factor xB ligand (RANKL), within an open-label observational study.Denosumab (Prolia) is a fully human monoclonal antibody directed against receptor activator of nuclear factor-κB ligand (RANKL), which interferes with the formation, activation, and survival of osteoclasts.","answer":"Anti-RANKL antibody which prevents bone catabolism in osteoporosis"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Primary total hip arthroplasty (THA)","answer":"{\\"Condition\\": [\\"total hip arthroplasty\\", \\"THA\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [], \\"Procedure\\": [], \\"Qualifier\\": [\\"Primary\\"], \\"ReferencePoint\\": [], \\"Scope\\": [], \\"Temporal\\": [], \\"Value\\": [], \\"Visit\\": []}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A review of state-of-the-art numerical methods for simulating flow through mechanical heart valves Chapter Title:  Future outlook 1. Abstract of Cited Paper (BIB001):  We have performed high-resolution fluid-structure interaction simulations of physiologic pulsatile flow through a bi-leaflet mechanical heart valve (BMHV) in an anatomically realistic aorta. The results are compared with numerical simulations of the flow through an identical BMHV implanted in a straight aorta. The comparisons show that although some of the salient features of the flow remain the same, the aorta geometry can have a major effect on both the flow patterns and the motion of the valve leaflets. For the studied configuration, for instance, the BMHV leaflets in the anatomic aorta open much faster and undergo a greater rebound during closing than the same valve in the straight axisymmetric aorta. Even though the characteristic triple-jet structure does emerge downstream of the leaflets for both cases, for the anatomic case the leaflet jets spread laterally and diffuse much faster than in the straight aorta due to the aortic curvature and complex shape of the anatomic sinus. Consequently the leaflet shear layers in the anatomic case remain laminar and organized for a larger portion of the accelerating phase as compared to the shear layers in the straight aorta, which begin to undergo laminar instabilities well before peak systole is reached. For both cases, however, the flow undergoes a very similar explosive transition to the small-scale, turbulent-like state just prior to reaching peak systole. The local maximum shear stress is used as a metric to characterize the mechanical environment experienced by blood cells. Pockets of high local maximum shear are found to be significantly more widespread in the anatomic aorta than in the straight aorta throughout the cardiac cycle. Pockets of high local maximum shear were located near the leaflets and in the aortic arc region. This work clearly demonstrates the importance of the aortic geometry on the flow phenomena in a BMHV and demonstrates the potential of our computational method to carry out image-based patient-specific simulations for clinically relevant studies of heart valve hemodynamics.Literature Review:","answer":"The review of recent work presented in this paper underscores the major progress made in the last few years in our ability to simulate numerically BMHV flows at physiologic conditions and at resolution sufficiently high to start probing the links between valve fluid mechanics and thromboembolic complications. A major computational challenge that has yet to be tackled in this regard is the development of computational models that can elucidate the hemodynamics in microscopic regions of BMHV designs, such as the valve hinges and the leakage jet during closure, which could induce hemodynamic stresses large enough to damage blood cells. Such models should be inherently multi-scale, due to the large disparity in the macro-(aorta diameter *cm) and micro-scales (typical size of the gaps in the hinge region *10 2 lm), and also account for the two-phase, non-Newtonian nature of blood. Another limitation of all existing computational models is that they have thus far treated the aorta as a rigid-wall vessel. This assumption is obviously incorrect but has been adopted so far for computational expedience since the main emphasis of previous work was on simulating and understanding the hemodynamics induced by the moving leaflets alone. The compliance of the aortic wall, however, could play an important role in the BMHV hemodyanmics and needs to be taken into account by developing complete FSI models that resolve both the valve motion and the deformation of the aorta in a coupled manner. Finally, the Fig. 6 Simulations of a BMHV implanted in an anatomic aorta BIB001 BIB002 . Left instantaneous out-ofplane vorticity contours on the midplane of the valve. Right 3D instantaneous vortical structures visualized by iso-surfaces of qcriterion computational tools need to be coupled with state-of-theart medical imaging modalities to develop a patient-specific computational framework that will allow surgeons to optimize the implantation of mechanical valves in a virtual surgery environment. Even though these challenges are significant or even daunting, the progress we have made so far coupled with the rapidly increasing power of modern massively parallel computational platforms and advances in medical imaging allow us to be more than optimistic. The computational advances needed to meet these challenges are well within the reach of our present-day capabilities and will define the future research agenda in the area of computational hemodynamics for mechanical heart valves."},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:Thereductioninthescotopicresponsesincludeddecreasesinbothb-wave(Figure8C)anda-wave(Figure8D)amplitudesmediatedbypostreceptoralandreceptoralneurons,respectively.","answer":"[]"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:endophthalmitis is a rare postoperative complication which is potentially devastating to visual function and the structural integrity of the eye . in the postoperativeonce detected postoperatively , the condition is treated with intravitreal antibiotics and vitrectomy and/or tap as per the recommendations of the endophthalmitis vitrectomy study ( evs ) . in recent years , there has been an increase of the number of antibiotic - resistant bacterial strains and new strains which are normally not part of the traditional etiological spectrum of postoperative infection [ 3 , 4 ] .the following case report has the objective of describing the diagnosis , treatment , and unfavorable evolution of one case of postoperative endophthalmitis , secondary to streptococcus uberis .  this environmental pathogen is commonly responsible for a high proportion of cases of clinical ( and subclinical ) mastitis in lactating cows .the organism is highly resistant to the majority of the latest generation antibiotics which are commonly employed in the treatment of endophthalmitis .  a 52-year - old , hispanic male presented to the retina department of our hospital complaining of a three - month history of progressive visual loss in his left eye .his past medical history was remarkable for diabetes mellitus ( 18 years ) with poor metabolic control ( last glucose level was 167  mg / dl , with a hba1c of 14.7% ) , high blood pressure , chronic renal failure ( treated with peritoneal dialysis ) , and diabetic ischemic foot problems ( previous amputation of three toes ) . the patient also had history of previous abdominal surgeries ( 23 years ago ) .  as for the ophthalmologic background , the patient had a previous diagnosis of proliferative diabetic retinopathy , which had been treated previously with bilateral panretinal photocoagulation , and vitrectomy od along with chronic open angle glaucoma ou .    the best corrected visual acuity was 20/40 in od and counting fingers at 30  cm in os , and the anterior chamber examination was unremarkable .the lens in the left eye was cataractous ( c2n3p2 , according to locs iii classification ) , and intraocular pressure was 16  mmhg ou .ultrasound examination of the left eye confirmed the presence of low reflective mobile vitreous opacities , consistent with vitreous hemorrhage , despite not show , evidence of traction retinal detachment .  based on the existing evidence , we decided to offer the patient phacoemulsification surgery combined with a 23  ga vitrectomy .the surgery was performed without complications shortly after the initial examination , leaving balanced saline solution in the vitreous cavity at the end of the procedure .although the vitrectomy ports were self - sealing , we decided to place a suture ( 8 - 0 vicryl , ethicon , san angelo tx , usa ) in all of them .we also placed a suture in the phacoemulsification incision ( 10 - 0 nylon , ethicon , san angelo tx , usa ) .     twenty - four hours after surgery , the patient complained of severe ocular pain , along with significant reduction of visual acuity ( hand movements ) and tearing .on ocular examination , we found severe conjunctival hyperemia , ciliary injection , clear cornea , hypopyon in the anterior chamber ( 1.2  mm ) , and intraocular pressure of 30  mmhg .the ultrasound examination revealed images of increased echogenicity which correspond to cellularity in vitreous cavity , pseudomembranes formation , and choroidal thickening ( figure 1(a ) ) .the diagnosis of postoperative endophthalmitis was evident , and we proceeded to immediately obtain aqueous and vitreous cavity samples for staining , cultures , and sensitivity tests .  intravitreal ceftazidime ( 2.25  mg/0.1  ml ) , vancomycin ( 1  mg/0.1  ml ) , and dexamethasone ( 0.4  mg/0.1  ml ) were injected .the patient was admitted to the hospital , and treatment was started with topical moxifloxacin every hour ( vigamox , alcon lab , dallas fort worth , tx ) and oral moxifloxacin ( 400  mg ) .the following day , the visual acuity decreased to no light perception and severe pain and hypopyon continued . at the same day ,the microbiology department reported the presence of gram - positive cocci in the vitreous cavity sample ( which was classified as streptococcus uberis two days later ( figure 1(b ) ) . the sensitivity test documented resistance to cephalothin , cefotaxime , ceftazidime , cefuroxime , dicloxacillin , vancomycin , azithromycin , clarithromycin , erythromycin , amikacin , gentamicin , netilmicin , tobramycin , clindamycin polymyxin , ciprofloxacin , gatifloxacin , moxifloxacin , ofloxacin , perfloxacin , and tetracycline ( figures 1(c ) and 1(d ) ) .due to the lability of the patient and the possibility of systemic dissemination of the bacteria , we offered to the patient an air - fluid exchange , silicone oil as tamponade , anterior chamber washout , and intraocular lens removal after the failure of the first intravitreal antibiotics .however , the patient refused to sign the informed consent form for the second surgery , delaying treatment for three days . after knowing the specific sensitivity of the microorganism , we added an intravitreal injection of ampicillin sodium 5  mg/0.1  ml to the original plan .finally , after extensive and exhaustive explanation , the patient agreed to the procedure .  the next day , the patient reported decreased pain , and on examination the vision remained no light perception , though there was no evidence of hypopyon and only mild conjunctival hyperemia .the patient remained hospitalized for the next three days , and during that time ampicillin sodium was administered intravenously , at adjusted doses of 1000  mg bid according to creatinine clearance .after discharge , the patient continued treatment with maintenance doses of intramuscular ampicillin sodium for two weeks .four weeks later , the integrity of the eye was preserved but the vision remained no light perception ( figure 2 ) .despite the advances in surgical techniques and the technology available to perform ocular surgery , the incidence of postoperative endophthalmitis in the last 10 years appears to be increasing [ 6 , 7 ] . what possibly play a role in this development has been the indiscriminate and inappropriate dosing of broad - spectrum antibiotics by doctors and the inadequate compliance to full treatment duration by the patients .  this has led to the emergence of new resistant strains to the latest generations of drugs [ 3 , 4 , 6 ] .evidence of this has been seen in the results published by the ocular tracking resistance in the u.s . today ( trust ) program , which reported an increase of 12.1% of methicillin - resistant staphylococcus aureus ( mrsa ) strains , with more than 80% of mrsa being resistant to fluoroquinolones . however , despite the considerable increase of this numbers , it is also important to note that the study has the limitation that they based the bacterial susceptibility to antibiotics on systemic drug - exposure breakpoints and not in local concentration ( as in an intravitreal injection ) .   streptococcus uberis is an environmental pathogen which is typically responsible for mastitis cases in lactating cows .it is also the predominant organism isolated from mammary glands during the nonlactating period in cows .although -lactams are the treatment of choice , the bacteria possess unique mechanism to generate resistance to antibiotics like the mph(b ) gene for resistance to macrolide and sos response - like dna repair mechanism which may induce sos - driven adaptive mutations [ 5 , 8 ] . the uncommon strong resistance to antibiotics found in the strain cultured from the patient 's vitreous samples could be the result of all these conditions .the reason and circumstances by which this microorganism was able to reach the eye remains hidden to all of us .   since there was no improvement clinically of our patient after the first intravitreal injection , and the isolated organism was resistant to practically all the intravitreal antibiotics that are commonly employed , we decided to use the only antibiotic to which the organism   appeared to be sensitive .our use of 5  mg/0.1  ml of intravitreal ampicillin sodium was based on two previous reports in which the intravitreal administration proved to be safe .those reports were based on unpublished data from g. a. peyman in which he established that the ampicillin sodium could be safely administered intraocularly up to a dose of 10  mg/0.1  ml . however , although the results were published in his book , the original study was never published [ 9 , 10 ] .the fact that almost all the traditional pathogens responsible for endophthalmitis cases are beta - lactamase producing strains limits the use of this antibiotic as part of the first choice drugs for the treatment of postoperative endophthalmitis .the possibility of toxicity - induced damage due to ampicillin sodium is also a factor to be considered , although this patient 's vision already showed   no light perception prior to administration of the intravitreal ampicillin .    in this case , the eye was anatomically salvaged with this treatment regimen , although without visual recovery .","answer":"purpose . to describe the clinical characteristics , diagnosis , and treatment with intravitreal ampicillin sodium of a postoperative endophthalmitis case due to streptococcus uberis ; an environmental pathogen commonly seen in mastitis cases of lactating cows  . methods . case report . a 52-year - old , hispanic diabetic patient who suddenly developed severe pain and severe loss of vision , following vitrectomy . results .  the patient was diagnosed with postoperative endophthalmitis secondary to a highly resistant strain of streptococcus uberis that did not respond to intravitreal antibiotics .  he was treated with an air - fluid interchange , anterior chamber washout , intravitreal ampicillin sodium ( 5  mg/0.1  ml ) , and silicon oil tamponade ( 5000  ck ) .  the eye was anatomically stabilized , though there was no functional recovery .  conclusion .  streptococcus uberis is an uncommon pathogen to the human eye , which has unique features that help the strain in developing resistance to antibiotics . while treatment with intravitreal ampicillin is feasible , there are still concerns about its possible toxicity ."},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Trastuzumab and Pertuzumab Plant Biosimilars : Modification of Asn297-linked Glycan of the mAbs Produced in a Plant with Fucosyltransferase and Xylosyltransferase Gene Knockouts . Plant biosimilars of anticancer therapeutic antibodies are of interest not only because of the prospects of their practical use, but also as an instrument and object for study of plant protein glycosylation. In this work, we first designed a pertuzumab plant biosimilar (PPB) and investigated the composition of its Asn297-linked glycan in comparison with trastuzumab plant biosimilar (TPB). Both biosimilars were produced in wild-type (WT) Nicotiana benthamiana plant (PPB-WT and TPB-WT) and transgenic ΔXTFT N. benthamiana plant with XT and FT genes knockout (PPB-ΔXTFT and TPB-ΔXTFT). Western blot analysis with anti-α1,3-fucose and anti-xylose antibodies, as well as a test with peptide-N-glycosidase F, confirmed the absence of α1,3-fucose and xylose in the Asn297-linked glycan of PPB-ΔXTFT and TPB-ΔXTFT. Peptide analysis followed by the identification of glycomodified peptides using MALDI-TOF/TOF showed that PPB-WT and TPB-WT Asn297-linked glycans are mainly of complex type GnGnXF. The core of PPB-WT and TPB-WT Asn297-linked GnGn-type glycan contains α1,3-fucose and β1,2-xylose, which, along with the absence of terminal galactose and sialic acid, distinguishes these plant biosimilars from human IgG. Analysis of TPB-ΔXTFT total carbohydrate content indicates the possibility of changing the composition of the carbohydrate profile not only of the Fc, but also of the Fab portion of an antibody produced in transgenic ΔXTFT N. benthamiana plants. Nevertheless, study of the antigen-binding capacity of the biosimilars showed that absence of xylose and fucose residues in the Asn297-linked glycans does not affect the ability of the glycomodified antibodies to interact with HER2/neu positive cancer cells.sentence: Trastuzumab and Pertuzumab Plant Biosimilars : Modification of Asn297-linked Glycan of the mAbs Produced in a Plant with Fucosyltransferase and Xylosyltransferase Gene Knockouts .","answer":"[]"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Kinetochore protein depletion underlies cytokinesis failure and somatic polyploidization in the moss Physcomitrella patens}Article:Abstract:Lagging chromosome is a hallmark of aneuploidy arising from errors in the kinetochore–spindle attachment in animal cells. However, kinetochore components and cellular phenotypes associated with kinetochore dysfunction are much less explored in plants. Here, we carried out a comprehensive characterization of conserved kinetochore components in the moss Physcomitrella patens and uncovered a distinct scenario in plant cells regarding both the localization and cellular impact of the kinetochore proteins. Most surprisingly, knock-down of several kinetochore proteins led to polyploidy, not aneuploidy, through cytokinesis failure in >90% of the cells that exhibited lagging chromosomes for several minutes or longer. The resultant cells, containing two or more nuclei, proceeded to the next cell cycle and eventually developed into polyploid plants. As lagging chromosomes have been observed in various plant species in the wild, our observation raised a possibility that they could be one of the natural pathways to polyploidy in plants.Introduction:The kinetochore is a macromolecular complex that connects chromosomes to spindle microtubules and plays a central role in chromosome segregation. Kinetochore malfunction causes checkpoint-dependent mitotic arrest, apoptosis, and/or aneuploidy-inducing chromosome missegregation( Potapova and Gorbsky, 2017). Most of our knowledge on kinetochore function and impact on genome stability is derived from animal and yeast studies( Musacchio and Desai, 2017). Another major group of eukaryotes, plants, also possesses conserved kinetochore proteins( Yu et al., 2000; van Hooff et al., 2017; Yamada and Goshima, 2017). Although the localization and loss-of-function phenotype of some plant kinetochore proteins have been reported before( Shin et al., 2018; Zhang et al., 2018; Wang et al., 2012; Caillaud et al., 2009; Komaki and Schnittger, 2017; Lermontova et al., 2013; Sandmann et al., 2017; Sato et al., 2005; Du and Dawe, 2007; Ogura et al., 2004), the data are mostly obtained from fixed cells of specific tissues. No comprehensive picture of plant kinetochore protein dynamics and functions can be drawn as of yet. For example, 12 out of 16 components that form CCAN( constitutive centromere associated network) in animal and yeast cells cannot be identified by homology searches( Musacchio and Desai, 2017; Yamada and Goshima, 2017). How the residual four putative CCAN subunits act in plants is also unknown. The moss Physcomitrella patens is an emerging model system for plant cell biology. The majority of its tissues are in a haploid state, and, owing to an extremely high rate of homologous recombination, gene disruption and fluorescent protein tagging of endogenous genes are easy to obtain in the first generation( Cove et al., 2006). The homology search indicated that all the P. patens proteins identified as the homologue of human kinetochore components are conserved in the most popular model plant species A. thaliana( Yamada and Goshima, 2017): therefore, the knowledge gained in P. patens would be largely applicable to flowering plants, including crop species. Another remarkable feature of P. patens is its regeneration ability; for example, differentiated gametophore leaf cells, when excised, are efficiently reprogrammed to become stem cells( Sato et al., 2017; Ishikawa et al., 2011). Thus, genome alteration even in a somatic cell can potentially spread through the population. In this study, we aimed to comprehensively characterize conserved kinetochore proteins in a single-cell type, the P. patens caulonemal apical cell. We observed that many proteins displayed localization patterns distinct from their animal counterparts. Furthermore, kinetochore malfunction led to chromosome missegregation and microtubule disorganization in the phragmoplast, eventually resulting in cytokinesis failure and polyploidy.Discussion:This study provides a comprehensive view of the dynamics of conserved kinetochore proteins in a single cell type of P. patens; furthermore, to the best of our knowledge, several proteins, including borealin, KNL1 and SKA subunits, have been characterized for the first time in plant cells. The tagged proteins were expressed under their native promoter at the original chromosome locus; thus, fluorescent signals of most, if not all, proteins would represent the endogenous localization. Overall, the behavior of outer subunits was largely consistent with their animal counterparts, suggesting that the mitotic function is also conserved. However, the timing of kinetochore enrichment differed from that of animal cells and even flowering plants( e. g. Arabidopsis, maize)( Shin et al., 2018; Du and Dawe, 2007; Hori et al., 2003): for example, P. patens Ndc80 complex gradually accumulated at the kinetochore after NEBD, unlike Arabidopsis and maize, where it showed kinetochore enrichment throughout the cell cycle( Shin et al., 2018; Du and Dawe, 2007). More unexpected localizations were observed for inner CCAN subunits, namely CENP-C, CENP-O, CENP-S and CENP-X. For example, CENP-C disappeared from the centromeres shortly after mitotic exit. In animal cells, CENP-C has been suggested to act in cooperation with Mis18BP1/KNL2 to facilitate CENP-A deposition in late telophase and early G1( 2). Hence, the mechanism of CENP-A incorporation might have been modified in plants. CENP-O,-S, or –X did not show kinetochore enrichment at any stage. CENP-X localization was unlikely an artifact of Citrine tagging, since the tagged protein rescued the RNAi phenotype. In human cells, 16 CCAN subunits, forming four sub-complexes, have been identified and shown to be critical for kinetochore assembly and function, not only in cells, but also in reconstitution systems( Guse et al., 2011; Weir et al., 2016). In plants, only four CCAN homologues have been identified through sequence homology search. It is therefore possible that less conserved CCAN subunits are present but could not be identified by the homology search. However, the complete lack of kinetochore localization for CENP-O,-S,-X suggests that plants have lost the entire kinetochore-enriched CCAN complex. Somewhat puzzlingly, CENP-X, despite its unusual localization, remained an essential factor for chromosome segregation in P. patens. In animals, it has been proposed that CENP-S and CENP-X form a complex and play an important role in outer kinetochore assembly( Amano et al., 2009). It is an interesting target for further investigation if plant CENP-S/CENP-X preserves such a function. We observed lagging chromosomes as well as cytokinesis failure after knocking down kinetochore components. Failure in chromosome separation/segregation and cytokinesis can be caused by a single gene mutation, if the gene has multiple functions; for example, separase Rsw4( radially swollen4) in A. thaliana is involved in sister chromatid separation, cyclin B turnover and vesicle trafficking that is required for phragmoplast formation( Chang et al., 2003; Yang et al., 2011; Moschou et al., 2013; Wu et al., 2010). By contrast, in our study, both phenotypes were observed after RNAi treatment of CENP-A, a constitutive centromeric histone protein that is unlikely to play a direct role in cytokinesis. Furthermore, the cytokinesis phenotype frequently appeared in RNAi lines targeting other six kinetochore proteins, and only when lagging chromosomes were present. Based on these data, we propose that persistent lagging chromosomes cause cytokinesis failure. Lagging chromosomes might act as physical obstacles to perturb phragmoplast microtubule amplification and/or cell plate formation. Alternatively, persistent lagging chromosomes might produce an unknown signal or induce a certain cell state that inhibits phragmoplast expansion and/or cell plate formation in order to prevent chromosome damage, reminiscent of the NoCut pathway in animal cytokinesis( Norden et al., 2006; Amaral et al., 2016). We favor the latter model, as abnormal microtubule interdigitates were observed in the whole phragmoplast and not limited to the region proximal to the lagging chromosome( Figure 2E). Notably, in a recent study, cytokinesis in moss protonema cells could be completed despite longer microtubule overlaps( de Keijzer et al., 2017). It suggests that abnormal microtubule interdigitates represent the consequence of microtubule dynamics mis-regulation rather than the direct cause of cytokinesis failure. Our data further suggest that, in P. patens, chromosome missegregation in a single cell could lead to the generation of polyploid plants. Could lagging chromosomes cause polyploidization through somatic cell lineage in wild-type plants? In our imaging of control moss cells, we could not find any lagging chromosome, since mitotic fidelity is very high in our culture conditions. Intriguingly, however, various mitotic abnormalities, including lagging chromosomes have been long observed in wild-type plants and crops, albeit at a low frequency and/or under harsh natural conditions( Menéndez-Yuffá et al., 2000; Nichols, 1941; Kvitko et al., 2011). Those studies did not analyze the relationship between lagging chromosomes and cytokinesis integrity; we expect the presence of lagging chromosomes for a certain duration to similarly perturb cytokinesis as observed in our study of moss, since the cytokinesis process is highly conserved between bryophytes and angiosperms( Smertenko et al., 2017). Genome sequencing suggests that P. patens, like many other plant species, experienced whole genome duplication at least once during evolution( Rensing et al., 2008). Polyploidization through spontaneous mitotic errors in somatic cells might have a greater impact on de novo formation of polyploid plants than previously anticipated.","answer":"Plants and animals , like all living things , are made of self-contained units called cells that are able to grow and multiply as required . Each cell contains structures called chromosomes that provide the genetic instructions needed to perform every task in the cell . When a cell is preparing to divide to make two identical daughter cells – a process called mitosis – it first needs to duplicate its chromosomes and separate them into two equal-sized sets . This process is carried out by complex cell machinery known as the spindle . Structures called kinetochores assemble on the chromosomes to attach them to the spindle . Previous studies in animal cells have shown that , if the kinetochores do not work properly , one or more chromosomes may be left behind when the spindle operates . These ‘lagging’ chromosomes may ultimately land up in the wrong daughter cell , resulting in one of the cells having more chromosomes than the other . This can lead to cancer or other serious diseases in animals . However , it was not known what happens in plant cells when kinetochores fail to work properly . To address this question , Kozgunova et al . used a technique called RNA interference ( or RNAi for short ) to temporarily interrupt the production of kinetochores in the cells of a moss called Physcomitrella patens . Unexpectedly , the experiments found that most of the moss cells with lagging chromosomes were unable to divide . Instead , they remained as single cells that had twice the number of chromosomes as normal , a condition known as polyploidy . After the effects of the RNAi wore off , these polyploid moss cells were able to divide normally and were successfully grown into moss plants with a polyploid number of chromosomes . Polyploidy is actually widespread in the plant kingdom , and it has major impacts on plant evolution . It is also known to increase the amount of food that crops produce . However , it is still unclear why polyploidy is so common in plants . By showing that errors in mitosis may also be able to double the number of chromosomes in plant cells , the findings of Kozgunova et al . provide new insights into plant evolution and , potentially , a method to increase polyploidy in crop plants in the future ."},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:CelllinesdefectiveineitherBRCA1orBRCA2aresensitivetodamagingagentsthatformdouble-strandbreaks(DSBs),asareothercelllinesdefectiveinrecombinationalrepair(reviewedin[15]).","answer":"[]"},{"question":"Given a short query with keyphrases about a research idea in 2016 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: I want to classify human actions in videos.Keyphrases: action classification videoDataset description:UCF101: UCF101 dataset is an extension of UCF50 and consists of 13,320 video clips, which are classified into 101 categories. These 101 categories can be classified into 5 types (Body motion, Human-human interactions, Human-object interactions, Playing musical instruments and Sports).KTH: The efforts to create a non-trivial and publicly available dataset for action recognition was initiated at the KTH Royal Institute of Technology in 2004. The KTH dataset is one of the most standard datasets, which contains six actions: walk, jog, run, box, hand-wave, and hand clap.Kinetics-700: Kinetics-700 is a video dataset of 650,000 clips that covers 700 human action classes. The videos include human-object interactions such as playing instruments, as well as human-human interactions such as shaking hands and hugging.Kinetics-600: The Kinetics-600 is a large-scale action recognition dataset which consists of around 480K videos from 600 action categories. The 480K videos are divided into 390K, 30K, 60K for training, validation and test sets, respectively.Options:- A: UCF101  B: KTH  C: Kinetics-700  D: Kinetics-600","answer":"KTH"},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: A Transformer-based approach for multi-instrumental music score generation.Keyphrases: music score generation audio midiDataset description:Multi-Domain Sentiment Dataset v2.0: The Multi-Domain Sentiment Dataset contains product reviews taken from Amazon.com from many product types (domains). Some domains (books and dvds) have hundreds of thousands of reviews.NSynth: NSynth is a dataset of one shot instrumental notes, containing 305,979 musical notes with unique pitch, timbre and envelope. The sounds were collected from 1006 instruments from commercial sample libraries and are annotated based on their source (acoustic, electronic or synthetic), instrument family and sonic qualities.MAESTRO: The MAESTRO dataset contains over 200 hours of paired audio and MIDI recordings from ten years of International Piano-e-Competition. The MIDI data includes key strike velocities and sustain/sostenuto/una corda pedal positions.OpenMIC-2018: OpenMIC-2018 is an instrument recognition dataset containing 20,000 examples of Creative Commons-licensed music available on the Free Music Archive. Each example is a 10-second excerpt which has been partially labeled for the presence or absence of 20 instrument classes by annotators on a crowd-sourcing platform.Options:- A: Multi-Domain Sentiment Dataset v2.0  B: NSynth  C: MAESTRO  D: OpenMIC-2018","answer":"MAESTRO"},{"question":"You will be shown sections from a scientific research paper, together with a question about the paper. Your task is to answer the question based on the contents of the paper. Your response should be a \`json\` object with two fields:\\"answer\\": An array of strings extracted directly from the paper which, collectively, answer the question.\\"evidence\\": An array of strings. Each should be an excerpt from the paper, in which one or more of the extracted answers can be found.For instance, for the question \\"What baselines did the authors compare against?\\", a sample response might be:{  \\"answer\\": [\\"BERT\\", \\"RoBERTa\\"],  \\"evidence\\": [\\"In our experiments, we compare the performance of our model against BERT and RoBERTa.\\"]}Do not include any text in your response other than the json.If the question is unanswerable given the provided excerpts, respond with the single word \\"null\\".Paper: The Wiki Music dataset: A tool for computational analysis of popular musicIs it possible use algorithms to find trends in the history of popular music? And is it possible to predict the characteristics of future music genres? In order to answer these questions, we produced a hand-crafted dataset with the intent to put together features about style, psychology, sociology and typology, annotated by music genre and indexed by time and decade. We collected a list of popular genres by decade from Wikipedia and scored music genres based on Wikipedia descriptions. Using statistical and machine learning techniques, we find trends in the musical preferences and use time series forecasting to evaluate the prediction of future music genres.Data DescriptionFrom the description of music genres provided above emerges that there is a limited number of super-genres and derivation lines BIBREF19, BIBREF20, as shown in figure FIGREF1.From a computational perspective, genres are classes and, although can be treated by machine learning algorithms, they do not include information about the relations between them. In order to formalize the relations between genres for computing purposes, we define a continuous genre scale from the most experimental and introverted super-genre to the most euphoric and inclusive one. We selected from Wikipedia the 77 genres that we mentioned in bold in the previous paragraph and asked to two independent raters to read the Wikipedia pages of the genres, listen to samples or artists of the genres (if they did not know already) and then annotate the following dimensions:genre features: genre scale (a score between 0 and 1 where 0=downtempo/industrial, 0.1=metal, 0.15=garage/punk/hardcore, 0.2=rock, 0.25=pop rock, 0.3=blues, 0.4=country, 0.5=pop/traditional, 0.55=gospel, 0.6=jazz, 0.65=latin, 0.7=RnB/soul/funk, 0.75=reggae/jamaican, 0.8=rap, 0.85=DnB, 0.9=electro/house, 0.95=EDM, 1=techno/trance) and category of the super-genre (as defined in figure FIGREF1) and influence variety 0.1=influence only from the same super-genre, 1=influences from all the supergenresperceived acoustic features: sound (0=acoustic, 0.35=amplified, 0.65=sampled/manipulated, 1=synthetic), vocal melody (1=melodic vocals, 0=rhythmical vocals/spoken words), vocal scream (1=screaming, 0=soft singing), vocal emotional (1=emotional vocals, 0=monotone vocals), virtuous (0.5=normal, 0=not technical at all, 1=very technical); richbass 1=the bass is loud and clear, 0=there is no bass sound; offbeat 1=the genre has a strong offbeat, 0=the genre has not offbeattime: decade (classes between 1900s and 2010s) and year representative of the time when the genre became meainstreamplace features: origin place 0=Australia, 0.025=west USA, 0.05=south USA, 0.075=north/east USA, 0.1=UK, 0.2=jamaica, 0.3=carribean, 0.4=latin america, 0.5=africa, 0.6=south EU, 0.65=north/east EU, 0.7=middle east, 0.8=India, 0.9=China/south asia, 1=Korea/north asia; place urban (0=the origin place is rural, 1=the origin place is urban), place poor (0=the origin place is poor, 1=the origin place is rich)media features: media mainstream (0=independent media, 1=mainstream media, 0.5=both), media live 0=sell recorded music, 1=sell live performance)emotion features: joy/sad (1=joy, 0=sad), anticipation/surprise (1=anticipation or already known, 0=surprise), anger/calm (1=anger, 0=calm).style features: novelty 0=derivative, 0.5=normal, 1=totally new characteristics and type retro 1=the genre is a revival, 0.5=normal, 0=the genre is not a revival, lyrics love/explicit 0.5=normal, 1=love lyrics, 0=explicit lyrics, style upbeat 1=extroverted and danceable, 0=introverted and depressive, style instrumental 1=totally instrumental, 0=totally singed, style eclecticism 1=includes many styles, 0=has a stereotypical style, style longsongs 0.5=radio format (3.30 minutes), 1=more than 6 minutes by average, 0=less than 1 minute by average; largebands 1=bands of 10 or more people, 0.1=just one musician; subculture 1=the audience one subculture or more, 0=the audience is the main culture; hedonism 1=the genre promotes hedonism, 0=the genre does not promote hedonism; protest 1=the genre promotes protest, 0=the genere does not promote protest; onlyblack 1=genere produced only by black communities, 0=genre produced only by white communities; ; 44beat 1=the genre has 4/4 beat, 0=the genre has other types of measures; outcasts 1=the audience is poor people, 0=the audience is rich people; dancing 1=the genre is for dancing, 0=the genre is for home listening; drugs 1=the audience use drugs, 0=the audience do not use drugsMUSIC features: mellow (1=slow and romantic, 0=fast and furious), sophisticated (1=culturally complex, 0=easy to understand), intense (1=aggressive and loud, 0=soft and relaxing), contemporary (1=rhythmical and catchy, 0=not rhythmical and old-fashioned), uncomplicated (1=simple and well-known, 0=strange and disgustive)We computed the agreement between the two annotators using Cronbach's alpha statistics BIBREF21. The average between all features is alpha =0.793, which is good. Among the most agreed features there are genre, place, sound and MUSIC features. In particular, the genre scale got an excellent alpha =0.957, meaning that the genre scale is a reliable measure. In the final annotation all the divergences between the two annotators were agreed upon and the scores were averaged or corrected accordingly. The final dataset is available to the scientific community.Fig. 1. Distribution of genre derivation by super-genres and decade.Question: Which decades did they look at?","answer":"{\\"answer\\": [\\"between 1900s and 2010s\\"], \\"evidence\\": [\\"time: decade (classes between 1900s and 2010s) and year representative of the time when the genre became meainstream\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Naloxone\\", ...], \\"Disease\\" : [\\"Hypotensive\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Liver disease caused by propylthiouracil. This report presents the clinical, laboratory, and light and electron microscopic observations on a patient with chronic active (aggressive) hepatitis caused by the administration of propylthiouracil. This is an addition to the list of drugs that must be considered in the evaluation of chronic liver disease.","answer":"{\\"Chemical\\": [\\"propylthiouracil\\"], \\"Disease\\": [\\"Liver disease\\", \\"chronic active (aggressive) hepatitis\\", \\"liver disease\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Glucose 6-phosphate dehydrogenase variants: Gd (+) Alexandra associated with neonatal jaundice and Gd (-) Camperdown in a young man with lamellar cataracts. Two male subjects are described, with unusual clinical presentations and with hitherto undescribed G6PD variants. The first, of Italian extraction, suffered from severe neonatal jaundice following maternal ingestion of fresh broad beans (Vicia fava) both prenatally and postnatally  the expression of the enzymatic defect was much more severe in the neonatal period than on retesting in adolescence, when biochemical characterization showed unique features which justify designation as a new variant Gd (+) Alexandra. The second patient, a boy of Maltese extraction who was found to have bilateral lamellar cataracts at the age of 4 years, was identified as G6PD deficient only as a result of a survey of children of Mediterranean origin with unexplained cataract formation; he has approximately 15% of normal enzyme activity, with another unique combination of biochemical characteristics which has led to its designation as Gd (-) Camperdown. Although this association may be coincidental, it prompts further attention to the possibility that under certain circumstances G6PD deficiency may favor cataract formation. The two cases illustrate the value of characterization of the mutant enzyme whenever unexpected clinical or laboratory results are obtained..","answer":"{\\"Disease\\": [\\"cataract\\", \\"neonatal jaundice\\", \\"bilateral lamellar cataracts\\", \\"lamellar cataracts\\", \\"G6PD deficient\\", \\"G6PD deficiency\\"]}"},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: Learning the meaning of gradable adjectives of size from visually-grounded contextsKeyphrases: semantic size adjectives assessment images textDataset description:OpenViDial: OpenViDial is a large-scale open-domain dialogue dataset with visual contexts. The dialogue turns and visual contexts are extracted from movies and TV series, where each dialogue turn is paired with the corresponding visual context in which it takes place.SpeakingFaces: SpeakingFaces is a publicly-available large-scale dataset developed to support multimodal machine learning research in contexts that utilize a combination of thermal, visual, and audio data streams; examples include human-computer interaction (HCI), biometric authentication, recognition systems, domain transfer, and speech recognition. SpeakingFaces is comprised of well-aligned high-resolution thermal and visual spectra image streams of fully-framed faces synchronized with audio recordings of each subject speaking approximately 100 imperative phrases.CLEVR: CLEVR (Compositional Language and Elementary Visual Reasoning) is a synthetic Visual Question Answering dataset. It contains images of 3D-rendered objects; each image comes with a number of highly compositional questions that fall into different categories.TopLogo-10: Collected from top 10 most popular clothing/wearable brandname logos captured in rich visual context.Options:- A: OpenViDial  B: SpeakingFaces  C: CLEVR  D: TopLogo-10","answer":"CLEVR"},{"question":"You will be presented with the full text of a biomedical research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:he had been diagnosed with aortic arch aneurysm 4 years earlier . at that time , a computed tomography ( ct ) scan had demonstrated a huge aortic arch aneurysm with a maximal diameter of about 6.8 cm ( fig .ct scan , the size of the aneurysm had increased up to a maximal diameter about 9 cm and the trachea was nearly collapsed and deviated into the right side ( fig .the proximal descending aorta was also involved down to the level of the 7th thoracic vertebra .the patient was also diagnosed with single vessel disease by coronary angiography performed for preoperative evaluation .general anesthesia was administered and a double - lumen endotracheal tube was used to permit deflation of the left lung during the distal anastomosis .the patient was maintained in a supine position with the left chest elevated by about 30 degrees .initially , the right axillary artery and left femoral artery were exposed for cardiopulmonary bypass .after exposure of the right axillary artery and left femoral artery , an l - shaped skin incision was made through an upper partial sternotomy and left anterior thoracotomy along the 5th intercostal space ( fig ., the left internal thoracic artery was harvested for coronary arterial bypass grafting in a skeletonized fashion .after exposure of the innominate artery and left common carotid artery , the left subclavian artery was exposed through a small left supraclavicular incision to the neck because the left subclavian artery was seated deeply and deviated upwards .after systemic heparinization , arterial cannulae in each artery for systemic circulation were inserted through the right axillary and left femoral artery with seldinger 's technique .venous drainage was performed through a single two - stage cannula inserted into the right atrial appendage .cardiopulmonary bypass was established and a left ventricular vent catheter was inserted through the right upper pulmonary vein prior to lowering the body temperature .after aortic cross - clamping , htk solution ( custodiol ; kohler chemie , alsbach - hahnlein , germany ) was delivered via the aortic root .the ascending aorta was transected at the sinotubular junction level and proximal anastomosis was constructed with a three - branched dacron graft prepared previously ( fig .3 ) from a 28 mm intergard four - branched graft ( maquet , rasttat , germany ) . after hypothermic circulatory arrest was accomplished by cooling to a rectal temperature of 20 with cardiopulmonary bypass , the aortic arch was opened .the innominate artery was clamped and antegrade selective cerebral perfusion was started using the right axillary artery and a catheter placed into the left carotid artery .after clamping the descending aorta at the level of the 9th thoracic vertebra , cardiopulmonary bypass was started for lower body perfusion through the femoral artery cannula .next , the left subclavian artery was ligated with an endogia 304.8 mm stapler ( covidien , mansfield , ma , usa ) and an innominate artery and left common carotid artery were reconstructed with the branches of the graft .the heart and brain were reperfused from the other branch of the graft after discontinuation of cerebral perfusion ( fig .4 ) . after left lung deflation , distal anastomosis was performed with another 28 mm dacron tube graft .after completion of the graft anastomosis , we performed a carotid to left subclavian bypass graft using a remnant of the 8 mm dacron graft through the left supraclavicular incision previously made .systemic rewarming was then initiated . during rewarming , we performed a left internal mammary artery to left anterior descending artery bypass graft .the total operation time was 350 minutes . the total cardiopulmonary bypass time and aortic cross clamping time were 280 and 120 minutes , respectively .a postoperative follow - up ct scan revealed no aneurysmal dilatation of the aorta ( fig .although many surgical approaches have been reported for treatment of aortic arch aneurysm , the median sternotomy is most frequently used . however , in patients who have extensive aortic pathology involving the distal arch , exposure through a sternotomy frequently results in the need for troublesome procedures . in general , a two - stage operation is recommended for the treatment of extensive aortic disease involving the distal arch .choi et al .   reported entire thoracic aortic replacement via full sternotomy and anterior thoracotomy .however , frequently , these approach methods involve respiratory and wound complications closely related to extensive bone splitting and muscle division .it secures a clear view during distal anastomosis and intracardiac procedures comparable to previous approaches ; therefore , it can reduce the risk of occurrence of postoperative hemorrhage from the site of distal anastomosis . at the same time ,the lower part of the sternum is not split , and the structure of the thorax can be maintained , which is favorable for maintaining postoperative pulmonary function and for wound healing . in conclusion ,the l - incision approach should be considered one useful option for operating on extensive aortic arch disease .in addition , through the l - incision approach , it is feasible to perform coronary revascularization or intracardiac procedures .","answer":"there are various methods for approaching the aortic arch , such as median sternotomy or lateral thoracotomy .  however , accessing the site of distal anastomosis is problematic when the distal arch is extensively involved .  we report a case of extended aortic arch replacement and coronary artery bypass through the l - incision approach ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Gene\\"].Please return the output as a JSON object of the format: {\\"Gene\\": [\\"SSX\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Identification of a retinoic acid responsive aldoketoreductase expressed in HL60 leukaemic cells. Neutrophil and monocyte differentiation can be induced in HL60 leukaemia cells by all-trans-retinoic acid (ATRA) and 1alpha,25-dihydroxyvitamin D3 (D3), respectively, whose differentiating effects can be enhanced by exposure to 'anti-inflammatory agents' and steroids. We have provided evidence that this potentiation is via inhibition of the activity of an enzyme of the aldoketoreductase (AKR) family, but had failed to identify expression of known AKRs in HL60 cells. In this study, we have identified a previously unclassified aldoketoreductase family member (termed HAKR e) that is expressed in HL60 cells. HAKR e is dramatically and transiently up-regulated in HL60 cells within 24 h of exposure to ATRA, further supporting the proposition that a member(s) of this family of enzymes play(s) a role in controlling cell growth and/or differentiation.","answer":"{\\"Gene\\": [\\"AKRs\\", \\"aldoketoreductase\\", \\"HAKR e\\", \\"AKR\\"]}"},{"question":"You will be provided with the titles and abstracts of a collection of medical RCT reports studying a clinical question -- for instance, the efficacy of an intervention on some medical outcome. Please write a few sentences synthesizing the findings of these reports, which could serve as a conclusion section for a systematic review article. Your response should not include any other text. The RCT reports are below.Title 1:Enhancing behavioral and social skill functioning in children newly diagnosed with attention-deficit hyperactivity disorder in a pediatric setting.Abstract 1:The objective of this study was to evaluate the effectiveness of an 8-week behavioral and social skill (BSS) class for children newly diagnosed with attention-deficit hyperactivity disorder (ADHD) and their parents, initiating stimulant treatment in primary care. The subjects were 100 children, aged 5 to 12 years, recently diagnosed with ADHD and treated with stimulant medication, and their parents or guardians. Eligible families were randomly assigned to an intervention group (IG: n = 59) or control group (CG: n = 41). The BSS function of each child was assessed using DuPaul's ADHD Parent Rating Scale (18-item) and Child Attention Profile (12-item) during blinded baseline and follow-up interviews. Parent discipline practice was assessed using a five-item inventory based on Likert-scale ratings during identical periods. Computerized pharmacy records were used to track psychostimulant use over time. IG children exhibited significantly lower parent-rated ADHD symptoms, whereas IG parents reported significantly better and more consistent discipline practices compared with CG parents across time. No significant differences were found between groups in Child Attention Profile scores across time. Psychostimulant use did not significantly differ between groups across time. BSS training was well accepted and seemed to significantly improve BSS functioning among IG children in the home setting only.Title 2:Symptomatic improvement in children with ADHD treated with long-term methylphenidate and multimodal psychosocial treatment.Abstract 2:To test the hypotheses that in children with attention-deficit/hyperactivity disorder (ADHD) (1) symptoms of ADHD, oppositional defiant disorder, and overall functioning are significantly improved by methylphenidate combined with intensive multimodal psychosocial treatment compared with methylphenidate alone and with methylphenidate plus attention control and (2) more children receiving combined treatment can be taken off methylphenidate.                One hundred three children with ADHD (ages 7-9), free of conduct and learning disorders, who responded to short-term methylphenidate were randomized for 2 years to (1) methylphenidate alone; (2) methylphenidate plus psychosocial treatment that included parent training and counseling, social skills training, psychotherapy, and academic assistance, or (3) methylphenidate plus attention psychosocial control treatment. Assessments included parent, teacher, and psychiatrist ratings, and observations in academic and gym classes.                Combination treatment did not lead to superior functioning and did not facilitate methylphenidate discontinuation. Significant improvement occurred across all treatments and continued over 2 years.                In stimulant-responsive children with ADHD, there is no support for adding ambitious long-term psychosocial intervention to improve ADHD and oppositional defiant disorder symptoms. Significant benefits from methylphenidate were stable over 2 years.                Copyright 2004 American Academy of Child and Adolescent PsychiatryTitle 3:Social skills training with parent generalization: treatment effects for children with attention deficit disorder.Abstract 3:The effectiveness of brief social skills training (SST) was evaluated in a controlled outcome study with 27 children meeting criteria of the Diagnostic and Statistical Manual of Mental Disorders (3rd ed., revised; American Psychiatric Association, 1987) for an attention deficit disorder. Children were randomly assigned to either SST with parent-mediated generalization (SST-PG), child-only SST, or a wait-list control group. SST consisted of 8 group sessions in which skill modules were taught sequentially. Parents of children in the SST-PG group simultaneously participated in group generalization training designed to support their children's transfer of skills. Significant improvement in children's skill knowledge and in parent reports of social skills and disruptive behavior occurred for both treatment groups relative to the wait-list control group and maintained at a 4-month follow-up. More modest evidence was found for generalization of SST to the school setting.Title 4:Effects of a school-based cognitive-behavioral intervention for ADHD children.Abstract 4:Two variations of school-based cognitive-behavioral training (CBT) program were compared to each other and to a waiting-list control condition in the treatment of children with attention-deficit hyperactivity disorder (ADHD). The experimental interventions included a multicomponent condition that provided coordinated training programs for parents, teachers, and children and a teacher-only condition that offered training for classroom teachers only. Evaluation of outcome occurred at pre-intervention, post-intervention and at 6-week followup periods. Depedent measures included classroom behavior observations, teacher ratings of child behavior, child self-report, and teacher ratings of adjustment. The multicomponent CBT condition was significantly better than the other conditions at improving observed off-task/disruptive behavior at post-test. This improvement was maintained at followup, although treatment condition differences were no longer significant. There were no treatment condition differences on any other measures at post-intervention or followup. It was concluded that the intervention had minimal short-term effects on the ADHD children. The results are discussed within the context of several methodological limitations of the study which serve as proposals for continued research in this area.Title 5:A randomized, controlled trial of integrated home-school behavioral treatment for ADHD, predominantly inattentive type.Abstract 5:To evaluate the efficacy of a behavioral psychosocial treatment integrated across home and school (Child Life and Attention Skills Program) with attention-deficit/hyperactivity disorder (ADHD) predominantly inattentive type (ADHD-I).                Sixty-nine children ages 7 to 11 years were randomized to the Child Life and Attention Skills Program or a control group who did not receive the intervention. We compared groups posttreatment and at 3- to 5-month follow-up on parent and teacher ratings of inattention, sluggish cognitive tempo, and functional impairment.                Children randomized to the Child Life and Attention Skills Program were reported to have significantly fewer inattention and sluggish cognitive tempo symptoms, and significantly improved social and organizational skills, relative to the control group. Gains were maintained at follow-up.                Behavioral psychosocial treatment, when specifically adapted for ADHD-I and coordinated among parents, teachers, and children, appears efficacious in reducing symptoms and impairment associated with ADHD-I.Title 6:Social skills training in children with attention deficit hyperactivity disorder: a randomized-controlled clinical trial.Abstract 6:Evaluated efficacy of social skills training (SST) on children with 2 subtypes of attention deficit hyperactivity disorder (ADHD). Participants were 120 children (30 girls, 90 boys), ages 8 to 12 with ADHD-Inattentive type (ADHD-I; n = 59) or Combined type (ADHD-C; n = 61). The children were randomly assigned within diagnosis subtype to the treatment condition (8 weeks of SST) or the no-intervention control condition. SST led to greater improvements in both parent- and child-perceived assertion skills in the children with ADHD, yet did not affect the other domains of social competence. Diagnostically heterogeneous groups led to greater improvements on parent-report of their child's cooperation and assertion abilities as well as children's report of their own empathy skills. Diagnostically homogeneous groups led to greater decreases in externalizing behaviors at posttreatment but not at follow-up. Children with comorbid oppositional defiant disorder (ODD) did not benefit as much from the intervention. Children with ADHD-I improved in assertion skills more than children with ADHD-C, yet the 2 diagnostic entities did not differ in improvement levels across all other social skills.Title 7:Effects of atomoxetine with and without behavior therapy on the school and home functioning of children with attention-deficit/hyperactivity disorder.Abstract 7:To evaluate the effects of atomoxetine alone and in combination with behavior therapy on the school functioning of children with attention-deficit/hyperactivity disorder (ADHD). Most atomoxetine studies have not assessed school functioning other than by measuring the change in ADHD symptoms. Combining behavior therapy with atomoxetine may be particularly beneficial for the academic domain as medication has not been found to produce sustained benefits in this realm. However, there is little research examining the effects of combining atomoxetine and behavior therapy.                In an 8-week open-label trial, 56 children aged 6-12 years with ADHD diagnosed according to DSM-IV-TR were randomly assigned to receive atomoxetine and behavior therapy or atomoxetine alone. Behavior therapy consisted of an 8-week parenting course, a child social skills course, and a teacher-implemented daily report card of classroom behavior. The primary outcome was direct observation of the subject's classroom behavior. Secondary outcomes included change in ADHD symptoms and functioning at home and school. All data were collected between March 2007 and May 2008.                Classroom observations showed that atomoxetine decreased rule violations (P < .0001). Moreover, atomoxetine was associated with significant improvements in ADHD and oppositional defiant disorder symptoms at home and school and enhanced functioning in both domains (Impairment Rating Scale: all P < .001). Combined treatment led to greater improvements in parent-rated symptoms of inattention (P < .01), problem behaviors (P < .001), and academic impairment (P < .05). However, teachers did not report significant group differences.                Atomoxetine improved ADHD symptoms and classroom functioning as measured by parents, teachers, and direct observation. The addition of behavior therapy led to further improvements at home but not at school.                clinicaltrials.gov Identifier: NCT00918567.                © Copyright 2010 Physicians Postgraduate Press, Inc.Title 8:Evaluation of the relative effectiveness of methylphenidate and cognitive behavior modification in the treatment of kindergarten-aged hyperactive children.Abstract 8:This study of kindergarten-aged hyperactive children evaluated the effects of three modes of treatment in relation to an untreated control group. The treatments were administered over a 3-month period and included cognitive behavior modification, methylphenidate, and the two treatments combined. A follow-up assessment was done approximately 1 year later at the end of the first grade. Analyses of psychological, rating scale observational, and interview data showed that hyperactive children became less symptomatic over time; the data did not provide evidence indicating that any of the treatments studied was more effective than any other or than no treatment at all.Title 9:Does brief, clinically based, intensive multimodal behavior therapy enhance the effects of methylphenidate in children with ADHD?Abstract 9:The additional value of a short-term, clinically based, intensive multimodal behavior therapy to optimally titrated methylphenidate in children with attention-deficit hyperactivity disorder (ADHD) was investigated.                Fifty children with ADHD (ages 8-12) were randomized to treatment of methylphenidate or treatment with methylphenidate combined with 10 weeks of multimodal behavior therapy. The multimodal behavior therapy consisted of a child and parent behavioral therapy and a teacher behavioral training. Assessments included parent, teacher and child ratings of ADHD symptoms, oppositional and conduct behavior, social skills, parenting stress, anxiety and self-worth.                Both treatment conditions yielded significant improvements on all outcome domains. No significant differences were found between both treatments.                No evidence was found for the additive effect of multimodal behavior therapy next to optimally titrated methylphenidate.                This study does not support the expectation that optimally dosed stimulant treated children with ADHD should routinely receive psychosocial treatment to further reduce ADHD- and related symptoms.","answer":"The review suggests that there is little evidence to support or refute social skills training for adolescents with ADHD. There is need for more trials, with low risk of bias and with a sufficient number of participants, investigating the efficacy of social skills training versus no training for both children and adolescents."},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:Sliding-window object detectors that generate bounding-box object predictions over a dense, regular grid have advanced rapidly and proven popular. In contrast, modern instance segmentation approaches are dominated by methods that first detect object bounding boxes, and then crop and segment these regions, as popularized by Mask R-CNN. In this work, we investigate the paradigm of dense sliding-window instance segmentation, which is surprisingly under-explored. Our core observation is that this task is fundamentally different than other dense prediction tasks such as semantic segmentation or bounding-box object detection, as the output at every spatial location is itself a geometric structure with its own spatial dimensions. To formalize this, we treat dense instance segmentation as a prediction task over 4D tensors and present a general framework called TensorMask that explicitly captures this geometry and enables novel operators on 4D tensors. We demonstrate that the tensor view leads to large gains over baselines that ignore this structure, and leads to results comparable to Mask R-CNN. These promising results suggest that TensorMask can serve as a foundation for novel advances in dense mask prediction and a more complete understanding of the task. Code will be made available.Cited Abstract(s):[1]: For object recognition, the current state-of-the-art is based on exhaustive search. However, to enable the use of more expensive features and classifiers and thereby progress beyond the state-of-the-art, a selective search strategy is needed. Therefore, we adapt segmentation as a selective search by reconsidering segmentation: We propose to generate many approximate locations over few and precise object delineations because (1) an object whose location is never generated can not be recognised and (2) appearance and immediate nearby context are most effective for object recognition. Our method is class-independent and is shown to cover 96.7 of all objects in the Pascal VOC 2007 test set using only 1,536 locations per image. Our selective search enables the use of the more expensive bag-of-words method which we use to substantially improve the state-of-the-art by up to 8.5 for 8 out of 20 classes on the Pascal VOC 2010 detection challenge.[2]: We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and segmentation detection results using a Deformable Parts Model.[3]: Recent object detection systems rely on two critical steps: (1) a set of object proposals is predicted as efficiently as possible, and (2) this set of candidate proposals is then passed to an object classifier. Such approaches have been shown they can be fast, while achieving the state of the art in detection performance. In this paper, we propose a new way to generate object proposals, introducing an approach based on a discriminative convolutional network. Our model is trained jointly with two objectives: given an image patch, the first part of the system outputs a class-agnostic segmentation mask, while the second part of the system outputs the likelihood of the patch being centered on a full object. At test time, the model is efficiently applied on the whole test image and generates a set of segmentation masks, each of them being assigned with a corresponding object likelihood score. We show that our model yields significant improvements over state-of-the-art object proposal algorithms. In particular, compared to previous approaches, our model obtains substantially higher object recall using fewer proposals. We also show that our model is able to generalize to unseen categories it has not seen during training. Unlike all previous approaches for generating object masks, we do not rely on edges, superpixels, or any other form of low-level segmentation.[4]: [5]: We aim to detect all instances of a category in an image and, for each instance, mark the pixels that belong to it. We call this task Simultaneous Detection and Segmentation (SDS). Unlike classical bounding box detection, SDS requires a segmentation and not just a box. Unlike classical semantic segmentation, we require individual object instances. We build on recent work that uses convolutional neural networks to classify category-independent region proposals (R-CNN [16]), introducing a novel architecture tailored for SDS. We then use category-specific, top-down figure-ground predictions to refine our bottom-up proposals. We show a 7 point boost (16 relative) over our baselines on SDS, a 5 point boost (10 relative) over state-of-the-art on semantic segmentation, and state-of-the-art performance in object detection. Finally, we provide diagnostic tools that unpack performance and provide directions for future work.[6]: Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30 relative to the previous best result on VOC 2012 -- achieving a mAP of 53.3 . Our approach combines two key insights: (1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http: www.cs.berkeley.edu rbg rcnn.","answer":"The modern instance segmentation task was introduced by Hariharan al [5] (before being popularized by COCO [2] ). In their work, the method proposed for this task involved first generating object [1] [4] , then classifying these proposals [5] . In earlier work, the methodology was used for other tasks. For example, Selective Search [1] and the original R-CNN [6] classified mask proposals to obtain box detections and semantic segmentation results; these methods could easily be applied to instance segmentation. These early methods relied on bottom-up mask proposals computed by pre-deep-learning era methods [1] [4] ; our work is more closely related to dense sliding-window methods for mask object proposals as pioneered by DeepMask [3] . We discuss this connection shortly."},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: Open-set recognition is reformulated as a traditional classification problem.Keyphrases: open-set recognition imagesDataset description:PMLB: The Penn Machine Learning Benchmarks (PMLB) is a large, curated set of benchmark datasets used to evaluate and compare supervised machine learning algorithms. These datasets cover a broad range of applications, and include binary/multi-class classification problems and regression problems, as well as combinations of categorical, ordinal, and continuous features.CIFAR-10: The CIFAR-10 dataset (Canadian Institute for Advanced Research, 10 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are labelled with one of 10 mutually exclusive classes: airplane, automobile (but not truck or pickup truck), bird, cat, deer, dog, frog, horse, ship, and truck (but not pickup truck).BDD100K: Datasets drive vision progress, yet existing driving datasets are impoverished in terms of visual content and supported tasks to study multitask learning for autonomous driving. Researchers are usually constrained to study a small set of problems on one dataset, while real-world computer vision applications require performing tasks of various complexities.Syn2Real: Syn2Real, a synthetic-to-real visual domain adaptation benchmark meant to encourage further development of robust domain transfer methods. The goal is to train a model on a synthetic \\"source\\" domain and then update it so that its performance improves on a real \\"target\\" domain, without using any target annotations.Options:- A: PMLB  B: CIFAR-10  C: BDD100K  D: Syn2Real","answer":"CIFAR-10"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:A local algorithm is a distributed algorithm where each node must operate solely based on the information that was available at system startup within a constant-size neighbourhood of the node. We study the applicability of local algorithms to max-min LPs where the objective is to maximise mink Sigmav CkvXv subject to Sigmav alphaivXv les 1 far each i and Xv ges 0 far each v. Here ckv ges 0, and the support sets Vi = v : alphaiv> 0 , Vk = v : ckv > 0 , Iv = i: alphaiv > 0 and Kv = k : Ckv > 0 have bounded size. In the distributed setting, each agent v is responsible for choosing the value of Xv, and the communication network is a hypergraph H where the sets Vk and Vi constitute the hyperedges. We present inapproximability results for a wide range of structural assumptions; for example, even if |Vi| and |Vk| are bounded by some constants larger than 2, there is no local approximation scheme. To contrast the negative results, we present a local approximation algorithm which achieves good approximation ratios if we can bound the relative growth of the vertex neighbourhoods in H.Cited Abstract(s):[1]: We study fractional scheduling problems in sensor networks, in particular, sleep scheduling (generalisation of fractional domatic partition) and activity scheduling (generalisation of fractional graph colouring). The problems are hard to solve in general even in a centralised setting; however, we show that there are practically relevant families of graphs where these problems admit a local distributed approximation algorithm; in a local algorithm each node utilises information from its constant-size neighbourhood only. Our algorithm does not need the spatial coordinates of the nodes; it suffices that a subset of nodes is designated as markers during network deployment. Our algorithm can be applied in any marked graph satisfying certain bounds on the marker density; if the bounds are met, guaranteed near-optimal solutions can be found in constant time, space and communication per node.We also show that auxiliary information is necessary--no local algorithm can achieve a satisfactory approximation guarantee on unmarked graphs.[2]: Finding a small dominating set is one of the most fundamental problems of traditional graph theory. In this paper, we present a new fully distributed approximation algorithm based on LP relaxation techniques. For an arbitrary parameter k and maximum degree Δ, our algorithm computes a dominating set of expected size O(kΔ2 k log Δ|DSOPT|) in O(k2) rounds where each node has to send O(k2Δ) messages of size O(logΔ). This is the first algorithm which achieves a non-trivial approximation ratio in a constant number of rounds.[3]: In this paper, we review a recently developed class of algorithms that solve global problems in unit distance wireless networks by means of local algorithms. A local algorithm is one in which any node of a network only has information on nodes at distance at most k from itself, for a constant k. For example, given a unit distance wireless network N, we want to obtain a planar subnetwork of N by means of an algorithm in which all nodes can communicate only with their neighbors in N, perform some operations, and then halt. We review algorithms for obtaining planar subnetworks, approximations to minimum weight spanning trees, Delaunay triangulations, and relative neighbor graphs. Given a unit distance wireless network N, we present new local algorithms to solve the following problems:1.Calculate small dominating sets (not necessarily connected) of N. 2.Extract a bounded degree planar subgraph H of N and obtain a proper edge coloring of H with at most 12 colors. The second of these algorithms can be used in the channel assignment problem.[4]: This paper concerns a number of algorithmic problems on graphs and how they may be solved in a distributed fashion. The computational model is such that each node of the graph is occupied by a processor which has its own ID. Processors are restricted to collecting data from others which are at a distance at most t away from them in t time units, but are otherwise computationally unbounded. This model focuses on the issue of locality in distributed processing, namely, to what extent a global solution to a computational problem can be obtained from locally available data.Three results are proved within this model: • A 3-coloring of an n-cycle requires time @math . This bound is tight, by previous work of Cole and Vishkin. • Any algorithm for coloring the d-regular tree of radius r which runs for time at most @math requires at least @math colors. • In an n-vertex graph of largest degree @math , an @math -coloring may be found in time @math .[5]: The purpose of this paper is a study of computation that can be done locally in a distributed network, where \\"locally\\" means within time (or distance) independent of the size of the network. Locally checkable labeling (LCL) problems are considered, where the legality of a labeling can be checked locally (e.g., coloring). The results include the following: There are nontrivial LCL problems that have local algorithms. There is a variant of the dining philosophers problem that can be solved locally. Randomization cannot make an LCL problem local; i.e., if a problem has a local randomized algorithm then it has a local deterministic algorithm. It is undecidable, in general, whether a given LCL has a local algorithm. However, it is decidable whether a given LCL has an algorithm that operates in a given time @math . Any LCL problem that has a local algorithm has one that is order-invariant (the algorithm depends only on the order of the processor IDs).[6]: [7]: In this paper, we study distributed approximation algorithms for fault-tolerant clustering in wireless ad hoc and sensor networks. A k-fold dominating set of a graph G = (V,E) is a subset S of V such that every node v V S has at least k neighbors in S. We study the problem in two network models. In general graphs, for arbitrary parameter t, we propose a distributed algorithm that runs in time O(t^2) and achieves an approximation ratio of O(t ^2 t log ), where n and denote the number of nodes in the network and the maximal degree, respectively. When the network is modeled as a unit disk graph, we give a probabilistic algorithm that runs in time O(log log n) and achieves an O(1) approximation in expectation. Both algorithms require only small messages of size O(log n) bits.","answer":"For combinatorial problems, there are both negative [3]0 [4] and positive [1] [3]1 [2] [3]6 [3] results on the applicability of local algorithms."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:19 years old and above.Patients who previously have received a liver transplant over the last six months and within last three years.Patients who are on Tacrolimus immunosuppressive therapy twice a day for at least two weeks.Patients who have normal liver function and renal function.Patients who have been monitored without complication such as acute rejection.Patients willing to sign his/her consent.","answer":"{\\"Condition\\": [\\"complication\\", \\"renal function\\", \\"liver function\\", \\"acute rejection\\"], \\"Device\\": [], \\"Drug\\": [\\"Tacrolimus\\"], \\"Measurement\\": [], \\"Mood\\": [], \\"Multiplier\\": [\\"twice a day\\"], \\"Negation\\": [\\"without\\"], \\"Observation\\": [], \\"Person\\": [\\"old\\"], \\"Procedure\\": [\\"liver transplant\\"], \\"Qualifier\\": [\\"normal\\"], \\"ReferencePoint\\": [], \\"Scope\\": [], \\"Temporal\\": [\\"at least two weeks\\", \\"last six months and within last three years\\"], \\"Value\\": [\\"19 years and above\\"], \\"Visit\\": []}"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:one of the most fascinating complex adaptive systems in nature is the brain . despite its relatively simple basic unitsthe neurons the cooperative bebaviour of the interconnected neurons and their functional implications are only poorly understood .the problem in investigating this system is not only its complexity , because e.g. the human brain consists of about @xmath0 neurons @xcite , but also its characteristic cycle structure which is known as action - perception - cycle .the difficulty with the action - perception - cycle , which was already known to von uexkll in 1928 @xcite , is that a closed formulation of the problem has to include a coupled description of the brain and the environment because the actions of an animal are transformed by the environment to perceptions which are transformed by the brain to actions and so on . from thisit is also clear that neither the perceptions nor the actions occurring in the system are randomly generated .    in this paperwe address the question : how is the learning dynamics of a neural network affected by different mechanisms for the selection of an action ?because learning in neural networks is modulated by a learning rule for the modification of the synaptic weights one can ask more precisely , if the learning rule itself is concerned by the action - selection mechanism .we approach this problem by comparing two different biologically motivated learning rules for neural networks .the first was proposed by bak and chialvo @xcite and combines experimental findings of frey and morris @xcite about _ synaptic tagging _ with a global reinforcement signal which can be interpreted as a dopamin signal e.g. as in the experiments of otmakhova and lisman @xcite .the second was introduced by the author @xcite and extends the ingredients above by the results of fitzsimonds @xcite about heterosynaptic _ long - term depression _( ltd ) which can be qualitatively explained by our stochastic learning rule .both learning rules are local in the sense that the information , which is used for the synaptic modification , is only provided by the neurons which enclose the synapse and hence can be interpreted as extentions to the classical hebbian learning rule @xcite .    as problemto be learned we choose the problem of timing , e.g. catching a ball , in a recurrent network topology which is generated by an algorithm of watts and strogatz @xcite .this network class was chosen because the topology is generated in dependence of one parameter , the so called rewiring parameter , and allows to convert a regularly connected network continously in a random one .recently of special interest was the regime between these two extrema , called small world networks , which could be brought in contact with experimental results about the neuroanatomic structure @xcite .this paper is organized as follows . in section [ model_timing ]we define our model .section [ results ] demonstrates the practical working mechanism exemplified in learning the problem of timing in a recurrent neural network .we compare the learning behavior of our learning rule @xcite with the learning rule of chialvo and bak @xcite in dependence of two different action - selection - mechanisms .the paper ends in section [ conclusions ] with conclusions and an prospect on future work .if one wants to investigate the learning dynamic of a neural network one has to define every item of table [ gen_sys ] which characterizes the entire system ..[gen_sys]characterization of the entire system [ cols=\\"^ , < \\" , ]     one recognizes by comparison with table [ list_ens1 ] that the overall results are confirmed .learning rule 4.b ) obtains always significantly better results than 4.a ) .moreover , a direct comparison between the learning rules for asm i. and ii . reveals that learning rule 4.a ) seems to be unaffected by the action - selection mechanism whereas learning rule 4.b ) is clearly influenced .      to quantify the dependence of the learning behavior of the action - selection mechanism we calculate the mean first - passage time @xmath1 from the simulation results obtained so far .figure [ meanfpt_rs ] compares the results for learning rule 4.a ) and 4.b ) in dependence of the rewiring parameter @xmath2 and the patterns to be learned .one can clearly see that the mean first - passage time for learning rule 4.b ) ( upper ( lower ) two curves correspond to @xmath3 ( @xmath4 ) ) is significantly reduced for asm ii .( full lines ) whereas the results for learning rule 4.a ) are not affected ( middle curves correspond to @xmath4 ) .this can be explained by the different structure of both learning rules .learning rule 4.a ) possesses no memory with respect to the outcomings of past results but only a tagging mechanism for the neurons which were involved in the last signal processing step .hence it can not detect the differences of the two action - selection mechanisms because they differ only in the order of the presented patterns but not in the overall presentation statistics .this follows from the fact that learning the last pattern takes about @xmath5 of the first - passage time .learning rule 4.b ) is due to the neuron counters @xmath6 different in this point .the neuron counters are a memory for the outcomings of the past results and thus can detect the slight difference in the two action - selection mechanisms .we think that this result is worth to be discussed in detail because it reveals some deep characteristics of animals which is normally neglected in investigations of neural networks .the consequences of the results obtained above are not only that the learning rule of a neural network effects on the neural activity by synaptic changes and hence on the behavior of an animal which is common sense , but also that the reverse holds .that means the actions of an animal influence the learning rule of its neural network .this is caused by the stimuli generated by the animal s actions which are represented in the examples above as patterns which lead to a modulation of the neural activity in the network and hence to a modulation of the learning rule due to memory effects by the neuron counters .this seems to be plausible because we do not choose our actions randomly but we choose them to learn something as fast as possible to survive .moreover , it is not only plausible but also efficient to us the action - selection mechanism as source of information which is shown in figure [ meanfpt_rs ] .hence our investigations lead not only to a bottom - up communication but also to a top - down communication between different system levels . in this respectour learning rule with neuron counters is different to all other hebb - like learning rules which has been proposed as extentions to the classical hebbian rule @xcite which lack the ability of a memory because they can not be affected by action - selection mechanisms which differ not in the presentation statistics but only in the presentation order .in this article we investigated the properties of our recently proposed stochastic hebb - like learning rule for neural networks .we demonstrated by extensive numerical simulations that the problem of timing can be learned in different topologies of a neural network generated by the algorithm of watts and strogatz @xcite .a comparison with the learning rule of chialvo and bak @xcite gave not only always significantly better results but revealed that our stochastic hebb - like learning rule can discriminate between different action - selection mechanisms with the same presentation statistics but different presentation order .this difference forms a source of information and can positively effect the learning behavior due to the bidirectional communication between different system levels .this effect was only recognized because we did not want to model the brain of an animal but its action - perception - cycle schematically depicted in table [ gen_sys ] where the brain is only one part of the entire system .    in summary our stochastic hebb - like learning ruleis not only universal applicable in feedforward multilayer networks @xcite but also in a class of recurrent networks generated by @xcite as demonstrated in this article . together with its biological interpretation as qualitative form of heterosynaptic plasticity @xcite and its sensitivity to the presentation order of the patterns to be learnedwe belief that our learning rule unites some crucial ingredients on the way of our understanding of the action - perception - cycle and hence of the brain .we belief that only such an integrated ansatz can explain the functional working method of the entire system because its parts are coupled in a nonlinear or stochastic way .","answer":"we demonstrate that our recently introduced stochastic hebb - like learning rule @xcite is capable of learning the problem of timing in general network topologies generated by an algorithm of watts and strogatz @xcite .  we compare our results with a learning rule proposed by bak and chialvo @xcite and obtain not only a significantly better convergence behavior but also a dependence of the presentation order of the patterns to be learned by introduction of an additional degree of freedom which allows the neural network to select the next pattern itself whereas the learning rule of bak and chialvo stays uneffected .  this dependence offers a bidirectional communication between a neuronal and a behavioural level and hence completes the action - perception - cycle which is a characteristics of any living being with a brain ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:A neuropsychological rehabilitation program for patients with Multiple Sclerosis based on the model of the ICF . BACKGROUND Forty to sixty percent of MS patients suffer from cognitive impairments . Cognitive deficits are a great burden for patients affected . In particular they may lead to a reduced quality of life , loss of work and problems with the social environment . OBJECTIVE The aim of this study was to evaluate a specific neuropsychological rehabilitation program for MS patients according to the ICF to be able to meet more properly individual requirements on the therapy level of function as well as of activities and participation . METHODS Forty patients with MS were randomised in an intervention ( IG ) - and a control group ( CG ) . The outcome measure of the IG , who started an intensive computer based home training of attention and attended psychological counselling was compared to the untrained CG . RESULTS In specific domains of attention ( simple and cued alertness and divided attention ) significant group differences between CG and IG could be found . The IG reported an improvement of mental fatigue and retardation . CONCLUSION These findings support the idea that a neuropsychological rehabilitation program , which based on the model of ICF , could improve cognitive impairment and could also have a positive influence of activities and participation .","answer":"{\\"Intervention\\": [\\"IG\\", \\"control group\\", \\"specific neuropsychological rehabilitation program\\", \\"psychological counselling\\", \\"intensive computer based home training of attention\\", \\"untrained CG\\", \\"( CG )\\", \\"intervention ( IG )\\", \\"neuropsychological rehabilitation program\\"], \\"Outcome\\": [\\".\\", \\"outcome measure\\", \\"mental fatigue and retardation .\\", \\"cognitive impairment\\", \\"cognitive impairments\\", \\"function\\", \\"quality of life\\", \\"Cognitive deficits\\", \\"attention ( simple and cued alertness and divided attention )\\", \\"loss of work and problems with the social environment\\", \\"activities and participation .\\"], \\"Participant\\": [\\"MS\\", \\"Forty\\", \\"patients with Multiple Sclerosis based on the model of the ICF\\"]}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey of Online Data-Driven Proactive 5G Network Optimisation Using Machine Learning Chapter Title:  1) CONTEXT GRANULARITY 1. Abstract of Cited Paper (BIB001):  Coordinated multi-point (CoMP) is a key feature for mitigating inter-cell interference, improve system throughput, and cell edge performance. However, CoMP implementation requires complex beamforming/scheduling design, increased backhaul bandwidth, additional pilot overhead, and precise synchronization. Cooperation needs to be limited to a few cells only due to this imposed overhead and complexity. Hence, small CoMP clusters will need to be formed in the network. In this paper, we first present a self-organizing, user-centric CoMP clustering algorithm in a control/data plane separation architecture, proposed for 5G to maximize spectral efficiency (SE) for a given maximum cluster size. We further utilize this clustering algorithm and introduce a novel two-stage re-clustering algorithm to reduce high load on cells in hotspot areas and improve user satisfaction. Stage-1 of the algorithm utilizes maximum cluster size metric to introduce additional capacity in the system. A novel re-clustering algorithm is introduced in stage-2 to distribute load from highly loaded cells to neighboring cells with less load for multi-user joint transmission CoMP case. We show that unsatisfied users due to high load can be significantly reduced with minimal impact on SE. 2. Abstract of Cited Paper (BIB002):  Self-organizing network (SON) mechanisms in cellular systems automate network management procedures to improve performance while reducing operational expenditure (OPEX) and capital expenditure (CAPEX). Within the area of SON research and development, self-optimization is an especially hot research topic, and key use cases have been defined by Third-Generation Partnership Project (3GPP) standards. This article proposes to apply the context-awareness concept to self-optimizing small-cell networks. Context information provides valuable additional data to enhance self-optimization mechanisms. In this context, a framework for context-aware (CA) self-optimization in smallcell environments is described, and a particular self-optimization use case, load balancing (LB), is used to evaluate the benefits of the proposed approach. The results show that the proposed CA-LB algorithms increase the users? satisfaction, while the optimization time is significantly reduced. 3. Abstract of Cited Paper (BIB003):  Blackspots are areas of poor signal coverage or service delivery that leads to customer complaints and loss in business revenue. Understanding their spatial–temporal patterns at a high resolution is important for interventions. Conventional methods such as customer helplines, drive-by testing, and network analysis tools often lack the real-time capability and spatial accuracy required. The potential of utilising geo-tagged Twitter data to uncover blackspots is investigated. Lexicon and machine-learning natural language processing techniques are applied to over 1.4 million Tweets in London to uncover blackspots for both pre-4G (2012) and post-4G (2016) roll out. It was found that long-term poor signal complaints make up the majority of complaints (86%) pre-4G roll out, but short-term network failure was responsible for most complaints (66%) post-4G roll out.Literature Review:","answer":"Granularity represents the measure of the distinguishable scale of detail in the context. Specifically, in the popular area prediction, various levels of granularity of locations are provided according to different data sizes, geo-tags accuracy, and data-mining methods. For example, in BIB001 the festivals' areas were estimated in the scale of ward or town, while in BIB004 the Quality of Experience (QoE) blackspots and high traffic zones were detected in a much smaller granularity (in the London Bridge Station). There is no best granularity for every optimisation, but the real-world data sets indeed have granularity limitations. Therefore, the first challenge is to judge if the online data source has an achievable granularity in expectation. Furthermore, the granularity of context should be consistent with the requirements of proactive network optimisation. For load balancing examples in BIB002 and BIB003 , in BIB002 the granularity of cell load (traffic or area popularity) was at a small-cell level for the cell-offloading research, while the traffic distribution granularity in BIB003 was finer as at the intrasmall-cell level for more efficient offloading. In other words, each network optimisation has required granularity, so it is necessary to determine it before data analysing. For the 5G, the cell size varies, and there exist dense deployments of small cells. In that case, the context granularity becomes the premise factor, and the context extracted from data sets should achieve at least a small-cell level. Besides, the authors expect that real-time network data to be collected and used, so new challenges emerge about the prediction errors."},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(BACKGROUND) This paper uses a life-course approach to explore whether the timing and/or duration of urban (vs rural) exposure was associated with risk factors for NCDs.(METHODS) A cross-sectional survey was conducted among health care workers in two hospitals in Thailand. Two measures of urbanicity were considered: early-life urban exposure and the proportion of urban life years. We explored four behavioral NCD risk factors, two physiological risk factors and four biological risk factors.(RESULTS) Both measures of urbanicity were each independently associated with increases in all behavioral and physiological risk factors. For some biological risk factors, people spending their early life in an urban area may be more susceptible to the effect of increasing proportion of urban life years than those growing up in rural areas.Question:Living in an urban environment and non-communicable disease risk in Thailand: Does timing matter?Answer:","answer":"YES"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Antigenic specificities of human CD4 + T-cell clones recovered from recurrent genital herpes simplex virus type 2 lesions. Lesions resulting from recurrent genital herpes simplex virus (HSV) infection are characterized by infiltration of CD4 + lymphocytes. We have investigated the antigenic specificity of 47 HSV-specific CD4 + T-cell clones recovered from the HSV-2 buttock and thigh lesions of five patients. Clones with proliferative responses to recombinant truncated glycoprotein B (gB) or gD of HSV-2 or purified natural gC of HSV-2 comprised a minority of the total number of HSV-specific clones isolated from lesions. The gC2-and gD2-specific CD4 + clones had cytotoxic activity. The approximate locations of the HSV-2 genes encoding HSV-2 type-specific CD4 + antigens have been determined by using HSV-1 x HSV-2 intertypic recombinant virus and include the approximate map regions 0. 30 to 0. 46, 0. 59 to 0. 67, 0. 67 to 0. 73, and 0. 82 to 1. 0 units. The antigenic specificity of an HLA DQ2-restricted, HSV-2 type-specific T-cell clone was mapped to amino acids 425 to 444 of VP16 of HSV-2 by sequential use of an intertypic recombinant virus containing VP16 of HSV-2 in an HSV-1 background, recombinant VP16 fusion proteins, and synthetic peptides. Each of the remaining four patients also yielded at least one type-specific T-cell clone reactive with an HSV-2 epitope mapping to approximately 0. 67 to 0. 73 map units. The antigenic specificities of lesion-derived CD4 + T-cell clones are quite diverse and include at least 10 epitopes. Human T-cell clones reactive with gC and VP16 are reported here for the first time.","answer":"{\\"CellLine\\": [\\"gC2 - and gD2 - specific CD4 + clones\\", \\"human CD4 + T - cell clones\\", \\"Human T - cell clones\\", \\"HSV - specific CD4 + T - cell clones\\", \\"HSV - 2\\", \\"lesion - derived CD4 + T - cell clones\\", \\"type - specific T - cell clone\\", \\"HLA DQ2 - restricted , HSV - 2 type - specific T - cell clone\\", \\"HSV - specific clones\\"], \\"CellType\\": [\\"CD4 + lymphocytes\\"], \\"DNA\\": [], \\"Protein\\": [\\"recombinant truncated glycoprotein B\\", \\"gC\\", \\"VP16\\", \\"CD4 + antigens\\", \\"gD\\", \\"gB\\", \\"amino acids 425 to 444\\", \\"recombinant VP16 fusion proteins\\"], \\"RNA\\": []}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Dopamine D2 receptor occupancy by risperidone: implications for the timing and magnitude of clinical response. The objective of the study is to investigate whether dopamine D2 receptor occupancy by risperidone and plasma levels over time can account for therapeutic efficacy and the latency period to response. Thirty-eight examinations with (123) I-IBZM single photon emission computed tomography were performed on 22 patients with schizophrenia, at diagnosis, 48 h after starting risperidone treatment and at a stable dose. Risperidone plasma levels were determined and psychopathologic evaluations (Brief Psychiatric Rating Scale, Positive and Negative Syndrome Scale) were carried out. No differences in the striatal/occipital (S/O) ratio or plasma levels were found between examinations at the 48-h time point and when a stable dose level had been established, so these parameters could not account for the latency period required for clinical response. D2 receptor occupancy at 48 h correlated positively with clinical improvement after 2 weeks of treatment. Therefore, if these results are confirmed, D2 receptor occupancy at the beginning of treatment with risperidone may be a predictor of subsequent clinical response.","answer":"[[\\"risperidone\\", \\"DIRECT-REGULATOR\\", \\"Dopamine D2 receptor\\"], [\\"risperidone\\", \\"DIRECT-REGULATOR\\", \\"dopamine D2 receptor\\"], [\\"risperidone\\", \\"DIRECT-REGULATOR\\", \\"D2 receptor\\"]]"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:The effectiveness of a cardiovascular magnetic resonance (CMR) scan depends on the ability of the operator to correctly tune the acquisition parameters to the subject being scanned and on the potential occurrence of imaging artifacts, such as cardiac and respiratory motion. In the clinical practice, a quality control step is performed by visual assessment of the acquired images; however, this procedure is strongly operator-dependent, cumbersome, and sometimes incompatible with the time constraints in clinical settings and large-scale studies. We propose a fast, fully automated, and learning-based quality control pipeline for CMR images, specifically for short-axis image stacks. Our pipeline performs three important quality checks: 1) heart coverage estimation; 2) inter-slice motion detection; 3) image contrast estimation in the cardiac region. The pipeline uses a hybrid decision forest method—integrating both regression and structured classification models—to extract landmarks and probabilistic segmentation maps from both long- and short-axis images as a basis to perform the quality checks. The technique was tested on up to 3000 cases from the UK Biobank and on 100 cases from the UK Digital Heart Project and validated against manual annotations and visual inspections performed by expert interpreters. The results show the capability of the proposed pipeline to correctly detect incomplete or corrupted scans (e.g., on UK Biobank, sensitivity and specificity, respectively, 88 and 99 for heart coverage estimation and 85 and 95 for motion detection), allowing their exclusion from the analyzed dataset or the triggering of a new acquisition.Cited Abstract(s):[1]: Accurate localization of anatomical landmarks is an important step in medical imaging, as it provides useful prior information for subsequent image analysis and acquisition methods. It is particularly useful for initialization of automatic image analysis tools (e.g. segmentation and registration) and detection of scan planes for automated image acquisition. Landmark localization has been commonly performed using learning based approaches, such as classifier and or regressor models. However, trained models may not generalize well in heterogeneous datasets when the images contain large differences due to size, pose and shape variations of organs. To learn more data-adaptive and patient specific models, we propose a novel stratification based training model, and demonstrate its use in a decision forest. The proposed approach does not require any additional training information compared to the standard model training procedure and can be easily integrated into any decision tree framework. The proposed method is evaluated on 1080 3D high-resolution and 90 multi-stack 2D cardiac cine MR images. The experiments show that the proposed method achieves state-of-the-art landmark localization accuracy and outperforms standard regression and classification based approaches. Additionally, the proposed method is used in a multi-atlas segmentation to create a fully automatic segmentation pipeline, and the results show that it achieves state-of-the-art segmentation accuracy.[2]: The correct acquisition of short axis (SA) cine cardiac MR image stacks requires the imaging of the full cardiac anatomy between the apex and the mitral valve plane via multiple 2D slices. While in the clinical practice the SA stacks are usually checked qualitatively to ensure full heart coverage, visual inspection can become infeasible for large amounts of imaging data that is routinely acquired, e.g. in population studies such as the UK Biobank (UKBB). Accordingly, we propose a learning-based technique for the fully-automated estimation of the heart coverage for SA image stacks. The technique relies on the identification of cardiac landmarks (i.e. the apex and the mitral valve sides) on two chamber view long axis images and on the comparison of the landmarks’ positions to the volume covered by the SA stack. Landmark detection is performed using a hybrid random forest approach integrating both regression and structured classification models. The technique was applied on 3000 cases from the UKBB and compared to visual assessment. The obtained results (error rate = 2.3 , sens. = 73 , spec. = 90 ) indicate that the proposed technique is able to correctly detect the vast majority of the cases with insufficient coverage, suggesting that it could be used as a fully-automated quality control step for CMR SA image stacks.","answer":"In this paper, we present a fully-automated, learning-based quality control pipeline for CMR SA stacks. AE.3, .1 The proposed approach builds upon our previous work [2] , which used a hybrid decision forest method [1] to extract LMs from LA 2CH view images in order to perform heart coverage estimation. With respect to our previous approach as well as to state-of-the-art techniques, the main contributions of the present work can be listed as follows:"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:Imagestackswerecollapsedtoviewtheentireprojectioninonesectioninonefocalplane.","answer":"[]"},{"question":"You will be shown an excerpt from a computer science scientific research paper, followed by a question about the paper. Please answer the question. Do not include any text in your response other than the answer.Context: A central issue with applying (2) to highly multi-relational data is the rapid growth in number of parameters with the number of relations in the graph. In practice this can easily lead to overfitting on rare relations and to models of very large size. Paragraph 10 : To address this issue, we introduce two separate methods for regularizing the weights of R-GCN-layers: basisand block-diagonal-decomposition. With the basis decomposition, each W(l) r is defined as follows:Question: Why author introduce two regularization methods in this model?","answer":"Authors use two regularization methods to handle overfitting issue.The reason is that RGCN has to solve the issue that the number of parameters grows rapidly as the number of relations, and two regularization methods are used to learn the issue."},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:introductionContext before the citation:Not having to represent the frame explicitly not only enables the linguist to express only the relevant things, but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up (Meurers 1994). This idea of preserving properties can be considered an instance of the well-known frame problem in AT (McCarthy and Hayes 1969), and we will therefore refer to the specifications left implicit by the linguist as the frame specification, or simply frame, of a lexical rule. (Pollard and Sag [1994, 3141, following Flickinger [19871).Citation Sentence:Not having to represent the frame explicitly not only enables the linguist to express only the relevant things , but also allows a more compact representation of lexical rules where explicit framing would require the rules to be split up ( Meurers 1994 ) .Context after the citation:One thus needs to distinguish the lexical rule specification provided by the linguist from the fully explicit lexical rule relations integrated into the theory. The formalization of DLRs provided by Meurers (1995) defines a formal lexical rule specification language and provides a semantics for that language in two steps: A rewrite system enriches the lexical rule specification into a fully explicit description of the kind shown in Figure 1. This description can then be given the standard set-theoretical interpretation of King (1989, 1994).' 10 Note that the passivization lexical rule in Figure 2 is only intended to illustrate the mechanism.","answer":"Background"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: [Neuropsychiatric Systemic Lupus Erythematosus]. Central nervous system damage, a major organ manifestation of systemic lupus erythematosus (SLE), causes significant morbidity and mortality. Designating this condition as neuropsychiatric SLE (NPSLE), the American College of Rheumatology defines it as involving the central and peripheral nervous systems and being characterized by various manifestations including stroke, seizures, and psychosis. NPSLE treatment mainly seeks to reduce damage accrual. In patients with NPSLE , the use of high-dose corticosteroids is recommended in combination with immunosuppressants , such as mycophenolate mofetil and intravenous cyclophosphamide pulse therapy . This can be accomplished by controlling the activity of the disease, minimizing the use of corticosteroids, and optimizing the management of comorbidities, including cardiovascular risk factors. An international task force analysis of a treat-to-target strategy for SLE (T2T/SLE) recommended targeting remission, preventing damage, and improving quality of life. Thus, more effective and less toxic treatments, such as those using biologics or kinase inhibitors, are still being developed for the treatment of SLE/NPSLE.sentence: In patients with NPSLE , the use of high-dose corticosteroids is recommended in combination with immunosuppressants , such as mycophenolate mofetil and intravenous cyclophosphamide pulse therapy .","answer":"[[\\"mycophenolate\\", \\"corticosteroids\\", \\"POS\\"], [\\"cyclophosphamide\\", \\"corticosteroids\\", \\"POS\\"], [\\"corticosteroids\\", \\"mofetil\\", \\"POS\\"]]"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Women must be postmenopausal (i.e.12 months without menstrual period), or surgically sterile, i.e. women of child bearing potential are not allowed to be included into the study. In cases of doubt a pregnancy test should be performed. (NB -post menopausal women currently receiving hormone replacement are permissible) Acute myocardial infarction < 12 h defined as: 1. Angina or equivalent symptoms > 20 min and 2. ST elevation in 2 contiguous ECG leads (= 2 mm precordial lead, = 1 mm limb lead). This ECG recording serves as baseline ECG, i.e. ECG I. Planned primary percutaneous coronary intervention The subject has given written informed, dated consent to participate in the study","answer":"{\\"Condition\\": [\\"surgically sterile\\", \\"postmenopausal\\", \\"Acute myocardial infarction\\", \\"Angina\\", \\"child bearing potential\\", \\"ST elevation\\", \\"pregnancy test\\", \\"menstrual period\\", \\"Angina symptoms\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [\\"contiguous ECG leads\\", \\"limb lead\\", \\"precordial lead\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [\\"not\\", \\"without\\"], \\"Observation\\": [\\"Planned\\", \\"given written informed consent\\"], \\"Person\\": [\\"Women\\", \\"women\\"], \\"Procedure\\": [\\"primary percutaneous coronary intervention\\"], \\"Qualifier\\": [\\"doubt\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"Angina or equivalent symptoms\\", \\"12 months without menstrual period\\", \\"women of child bearing potential\\", \\"2 contiguous ECG leads\\", \\"2 mm precordial lead, = 1 mm limb lead\\"], \\"Temporal\\": [\\"u003c 12 h\\", \\"12 months\\", \\"u003e 20 min\\"], \\"Value\\": [\\"2\\", \\"2 mm\\", \\"1 mm\\"], \\"Visit\\": []}"},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Hepatocellular Carcinoma with Portal Vein Tumor Involvement: Best Management Strategies. Portal vein tumor thrombosis (PVTT) commonly occurs in patients with hepatocellular carcinoma (HCC). Patients with PVTT usually have an aggressive disease course, decreased liver function reserve, limited treatment options, higher recurrence rates after treatment, and, therefore, worse overall survival. Among untreated HCC patients with PVTT, the median overall survival has been reported as low as 2 to 4 months. Historically, many aspects of PVTT have impacted the theoretical and practical safety and efficacy of treatment, for example, disordered blood flow and associated impairment of liver function, heat-sink effects of blood flow in the area of the PVTT, and risk of recurrence due to tumor location in the blood vessel. The current Barcelona Clinic Liver Cancer staging system categorizes HCC patients with PVTT as advanced stage, for which the standard of care is targeted therapy with sorafenib. However, sorafenib is associated with only marginal benefits among patients with PVTT. First-line lenvatinib , which was shown to be noninferior to sorafenib , excluded patients with main portal trunk invasion . regorafenib and nivolumab, an immune-based therapy, were recently approved in the United States for second-line therapy after sorafenib. Preliminary results for cabozantinib suggest a benefit in the second-/third-line after sorafenib failure. In addition, rapid advances in many fields (surgery, interventional radiology, nuclear medicine, and immunotherapy) have increased the potential treatment options for the management of this complex disease entity. A large portion of the emerging evidence focuses on the broader category of advanced HCC of which PVTT is a subgroup. While many of these studies show promising results, the efficacy among PVTT patients requires validation in prospective studies. Real-world data may help fill the evidence gap for patients not eligible for clinical trials due to common hepatic function requirements. The variety of new treatment advances for the heterogeneous and complex disease entity of HCC with PVTT means that personalized, multidisciplinary management may be necessary to achieve optimal outcomes. In this narrative review, we summarize the evolving management strategies for patients with HCC and PVTT.sentence: First-line lenvatinib , which was shown to be noninferior to sorafenib , excluded patients with main portal trunk invasion .","answer":"[]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Myocardial Blood Flow and Inflammatory Cardiac Sarcoidosis This study sought to evaluate the effects of inflammatory sarcoid disease on coronary circulatory function and the response to immune-suppressive treatment. Although positron emission tomography assessment of myocardial inflammation is increasingly applied to identify active cardiac sarcoidosis, its effect on coronary flow and immune-suppressive treatment remains to be characterized. Thirty-two individuals, who were referred for positron emission tomography / computed tomography, were evaluated for known or suspected cardiac sarcoidosis applying (18)F-fluorodeoxyglucose to determine inflammation and (13)N-ammonia to assess for perfusion deficits following a high-fat / low-carbohydrate diet and fasting state >12 h to suppress myocardial glucose uptake. Inflammation was quantified with standardized uptake value and regional myocardial blood flow at rest and during regadenoson - stimulated hyperemia was determined in ml/g/min. Positron emission tomography studies were repeated in 18 cases with a median follow-up of 2.5 years (interquartile range [IQR]:1.3 to 3.4 years). Twenty-five exams had normal perfusion but evidence of regional inflammation (group 1), and 21 exams presented a regional perfusion deficit associated with inflammation (group 2). Median myocardial blood flow did not differ between inflamed and noninflamed myocardium in both groups (0.86 ml/g/min [IQR: 0.66 to 1.11 ml/g/min] vs. 0.83 ml/g/min [IQR: 0.64 to 1.12 ml/g/min] and 0.74 ml/g/min [IQR: 0.60 to 0.93 ml/g/min] vs. 0.77 ml/g/min [IQR: 0.59 to 0.95 ml/g/min], respectively). As regards median hyperemic myocardial blood flows, they were significantly lower in the inflamed than in the remote regions in group 1 and 2 (2.31 ml/g/min [IQR: 1.81 to 2.95 ml/g/min] vs. 2.70 ml/g/min [IQR: 2.07 to 3.30 ml/g/min] and 1.61 ml/g/min [IQR: 1.17 to 2.18 ml/g/min] vs. 1.94 ml/g/min [IQR: 1.49 to 2.39 ml/g/min]; p < 0.001, respectively). Immune-suppression -mediated decrease in inflammation was associated with preserved myocardial flow reserve (MFR) at follow-up, whereas MFR significantly worsened in regions without changes or even increases in inflammation (median Δ MFR: 0.07 [IQR: -0.29 to 0.45] vs. -0.24 [IQR: -0.84 to 0.21]; p < 0.001). There was an inverse correlation between pronounced alterations in myocardial inflammation (Δ regional myocardial volume with standardized uptake value >4.1) and Δ MFR (r = -0.47; p = 0.048). Sarcoid -mediated myocardial inflammation is associated with a regional impairment of coronary circulatory function. The association between immune-suppressive treatment -related alterations in myocardial inflammation and changes in coronary vasodilator capacity suggests direct adverse effect of inflammation on coronary circulatory function in cardiac sarcoidosis.","answer":"{\\"AnatomicalStructure\\": [\\"myocardial\\", \\"myocardium\\"], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"active cardiac sarcoidosis\\", \\"inflammation\\", \\"hyperemic\\", \\"coronary flow\\", \\"inflamed\\", \\"Inflammation\\", \\"myocardial inflammation\\", \\"hyperemia\\", \\"coronary circulatory\\", \\"Sarcoid\\", \\"suppress\\", \\"inflammatory\\", \\"sarcoid disease\\", \\"Inflammatory\\", \\"adverse effect\\", \\"myocardial blood flow\\", \\"Cardiac Sarcoidosis\\", \\"glucose uptake\\", \\"myocardial blood flows\\", \\"cardiac sarcoidosis\\", \\"Myocardial Blood Flow\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [\\"(13)N-ammonia\\", \\"(18)F-fluorodeoxyglucose\\", \\"regadenoson\\", \\"coronary vasodilator\\"], \\"ClinicalAttribute\\": [\\"MFR\\", \\"myocardial flow reserve\\"], \\"Eukaryote\\": [], \\"Finding\\": [\\"perfusion deficits\\", \\"fasting state\\", \\"worsened\\", \\"perfusion deficit\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"Positron emission tomography\\", \\"high-fat\\", \\"low-carbohydrate diet\\", \\"perfusion\\", \\"follow-up\\", \\"Immune-suppression\\", \\"exams\\", \\"immune-suppressive treatment\\", \\"computed tomography\\", \\"positron emission tomography\\"], \\"InjuryOrPoisoning\\": [], \\"IntellectualProduct\\": [], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [\\"individuals\\"], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"studies\\", \\"study\\"], \\"SpatialConcept\\": [\\"remote regions\\", \\"regional\\"], \\"Virus\\": []}"},{"question":"You will be shown sections from a scientific research paper, together with a question about the paper. Your task is to answer the question based on the contents of the paper. Your response should be a \`json\` object with two fields:\\"answer\\": An array of strings extracted directly from the paper which, collectively, answer the question.\\"evidence\\": An array of strings. Each should be an excerpt from the paper, in which one or more of the extracted answers can be found.For instance, for the question \\"What baselines did the authors compare against?\\", a sample response might be:{  \\"answer\\": [\\"BERT\\", \\"RoBERTa\\"],  \\"evidence\\": [\\"In our experiments, we compare the performance of our model against BERT and RoBERTa.\\"]}Do not include any text in your response other than the json.If the question is unanswerable given the provided excerpts, respond with the single word \\"null\\".Paper: Evaluation of basic modules for isolated spelling error correction in Polish textsSpelling error correction is an important problem in natural language processing, as a prerequisite for good performance in downstream tasks as well as an important feature in user-facing applications. For texts in Polish language, there exist works on specific error correction solutions, often developed for dealing with specialized corpora, but not evaluations of many different approaches on big resources of errors. We begin to address this problem by testing some basic and promising methods on PlEWi, a corpus of annotated spelling extracted from Polish Wikipedia. These modules may be further combined with appropriate solutions for error detection and context awareness. Following our results, combining edit distance with cosine distance of semantic vectors may be suggested for interpretable systems, while an LSTM, particularly enhanced by ELMo embeddings, seems to offer the best raw performance.IntroductionSpelling error correction is a fundamental NLP task. Most language processing applications benefit greatly from being provided clean texts for their best performance. Human users of computers also often expect competent help in making spelling of their texts correct.Because of the lack of tests of many common spelling correction methods for Polish, it is useful to establish how they perform in a simple scenario. We constrain ourselves to the pure task of isolated correction of non-word errors. They are traditionally separated in error correction literature BIBREF0 . Non-word errors are here incorrect word forms that not only differ from what was intended, but also do not constitute another, existing word themselves. Much of the initial research on error correction focused on this simple task, tackled without means of taking the context of the nearest words into account.It is true that, especially in the case of neural networks, it is often possible and desirable to combine problems of error detection, correction and context awareness into one task trained with a supervised training procedure. In language correction research for English language also grammatical and regular spelling errors have been treated uniformly with much success BIBREF1 .However, when more traditional methods are used, because of their predictability and interpretability for example, one can mix and match various approaches to dealing with the subproblems of detection, correction and context handling (often equivalent to employing some kind of a language model). We call it a modular approach to building spelling error correction systems. There is recent research where this paradigm was applied, interestingly, to convolutional networks trained separately for various subtasks BIBREF2 . In similar setups it is more useful to assess abilities of various solutions in isolation. The exact architecture of a spelling correction system should depend on characteristics of texts it will work on.Similar considerations eliminated from our focus handcrafted solutions for the whole spelling correction pipeline, primarily the LanguageTool BIBREF3 . Its performance in fixing spelling of Polish tweets was already tested BIBREF4 . For our purposes it would be given an unfair advantage, since it is a rule-based system making heavy use of words in context of the error.Problems of spelling correction for PolishPublished work on language correction for Polish dates back at least to 1970s, when simplest Levenshtein distance solutions were used for cleaning mainframe inputs BIBREF5 , BIBREF6 . Spelling correction tests described in literature have tended to focus on one approach applied to a specific corpus. Limited examples include works on spellchecking mammography reports and tweets BIBREF7 , BIBREF4 . These works emphasized the importance of tailoring correction systems to specific problems of corpora they are applied to. For example, mammography reports suffer from poor typing, which in this case is a repetitive work done in relative hurry. Tweets, on the other hand, tend to contain emoticons and neologisms that can trick solutions based on rules and dictionaries, such as LanguageTool. The latter is, by itself, fairly well suited for Polish texts, since a number of extensions to the structure of this application was inspired by problems with morphology of Polish language BIBREF3 .These existing works pointed out more general, potentially useful qualities specific to spelling errors in Polish language texts. It is, primarily, the problem of leaving out diacritical signs, or, more rarely, adding them in wrong places. This phenomenon stems from using a variant of the US keyboard layout, where combinations of AltGr with some alphabetic keys produces characters unique to Polish. When the user forgets or neglects to press the AltGr key, typos such as writing *olowek instead of ołówek appear. In fact, BIBREF4 managed to get substantial performance on Twitter corpus by using this ”diacritical swapping” alone.Baseline methodsThe methods that we evaluated are baselines are the ones we consider to be basic and with moderate potential of yielding particularly good results. Probably the most straightforward approach to error correction is selecting known words from a dictionary that are within the smallest edit distance from the error. We used the Levenshtein distance metric BIBREF8 implemented in Apache Lucene library BIBREF9 . It is a version of edit distance that treats deletions, insertions and replacements as adding one unit distance, without giving a special treatment to character swaps. The SGJP – Grammatical Dictionary of Polish BIBREF10 was used as the reference vocabulary.Another simple approach is the aforementioned diacritical swapping, which is a term that we introduce here for referring to a solution inspired by the work of BIBREF4 . Namely, from the incorrect form we try to produce all strings obtainable by either adding or removing diacritical marks from characters. We then exclude options that are not present in SGJP, and select as the correction the one within the smallest edit distance from the error. It is possible for the number of such diacritically-swapped options to become very big. For example, the token Modlin-Zegrze-Pultusk-Różan-Ostrołęka-Łomża-Osowiec (taken from PlEWi corpus of spelling errors, see below) can yield over INLINEFORM0 states with this method, such as Módłiń-Żęgrzę-Pułtuśk-Roźąń-Óśtróleką-Lómzą-Óśówięć. The actual correction here is just fixing the ł in Pułtusk. Hence we only try to correct in this way tokens that are shorter than 17 characters.Vector distanceA promising method, adapted from work on correcting texts by English language learners BIBREF11 , expands on the concept of selecting a correction nearest to the spelling error according to some notion of distance. Here, the Levenshtein distance is used in a weighted sum to cosine distance between word vectors. This is based on the observation that trained vectors models of distributional semantics contain also representations of spelling errors, if they were not pruned. Their representations tend to be similar to those of their correct counterparts. For example, the token enginir will appear in similar contexts as engineer, and therefore will be assigned a similar vector embedding.The distance between two tokens INLINEFORM0 and INLINEFORM1 is thus defined as INLINEFORM2 Here INLINEFORM0 is just Levenshtein distance between strings, and INLINEFORM1 – cosine distance between vectors. INLINEFORM2 denotes the word vector for INLINEFORM3 . Both distance metrics are in our case roughly in the range [0,1] thanks to the scaling of edit distance performed automatically by Apache Lucene. We used a pretrained set of word embeddings of Polish BIBREF12 , obtained with the flavor word2vec procedure using skipgrams and negative sampling BIBREF13 .Recurrent neural networksAnother powerful approach, if conceptually simple in linguistic terms, is using a character-based recurrent neural network. Here, we test uni- and bidirectional Long Short-Term Memory networks BIBREF14 that are fed characters of the error as their input and are expected to output its correct form, character after character. This is similar to traditional solutions conceptualizing the spelling error as a chain of characters, which are used as evidence to predict the most likely chain of replacements (original characters). This was done with n-gram methods, Markov chains and other probabilistic models BIBREF15 . Since nowadays neural networks enjoy a large awareness as an element of software infrastructure, with actively maintained packages readily available, their evaluation seems to be the most practically useful. We used the PyTorch BIBREF16 implementation of LSTM in particular.The bidirectional version BIBREF17 of LSTM reads the character chains forward and backwards at the same time. Predictions from networks running in both directions are averaged.In order to provide the network an additional, broad picture peek at the whole error form we also evaluated a setup where the internal state of LSTM cells, instead of being initialized randomly, is computed from an ELMo embedding BIBREF18 of the token. The ELMo embedder is capable of integrating linguistic information carried by the whole form (probably often not much in case of errors), as well as the string as a character chain. The latter is processed with a convolutional neural network. How this representation is constructed is informed by the whole corpus on which the embedder was trained. The pretrained ELMo model that we used BIBREF19 was trained on Wikipedia and Common Crawl corpora of Polish.The ELMo embedding network outputs three layers as matrices, which are supposed to reflect subsequent compositional layers of language, from phonetic phenomena at the bottom to lexical ones at the top. A weighted sum of these layers is computed, with weights trained along with the LSTM error-correcting network. Then we apply a trained linear transformation, followed by INLINEFORM0 non-linearity: INLINEFORM1 (applied cellwise) in order to obtain the initial setting of parameters for the main LSTM. Our ELMo-augmented LSTM is bidirectional.Experimental setupPlEWi BIBREF20 is an early version of WikEd BIBREF21 error corpus, containing error type annotations allowing us to select only non-word errors for evaluation. Specifically, PlEWi supplied 550,755 [error, correction] pairs, from which 298,715 were unique. The corpus contains data extracted from histories of page versions of Polish Wikipedia. An algorithm designed by the corpus author determined where the changes were correcting spelling errors, as opposed to expanding content and disagreements among Wikipedia editors.The corpus features texts that are descriptive rather than conversational, contain relatively many proper names and are more likely to have been at least skimmed by the authors before submitting for online publication. Error cases provided by PlEWi are, therefore, not a balanced representation of spelling errors in written Polish language. PlEWi does have the advantage of scale in comparison to existing literature, such as BIBREF4 operating on a set of only 740 annotated errors in tweets.All methods were tested on a test subset of 25% of cases, with 75% left for training (where needed) and 5% for development.The methods that required training – namely recurrent neural networks – had their loss measured as cross-entropy loss measure between correct character labels and predictions. This value was minimized with Adam algorithm BIBREF22 . The networks were trained for 35 epochs.ResultsThe experimental results are presented in Table TABREF4 . Diacritic swapping showed a remarkably poor performance, despite promising mentions in existing literature. This might be explained by the already mentioned feature of Wikipedia edits, which can be expected to be to some degree self-reviewed before submission. This can very well limit the number of most trivial mistakes.On the other hand, the vector distance method was able to bring a discernible improvement over pure Levenshtein distance, comparable even with the most basic LSTM. It is possible that assigning more fine-tuned weights to edit distance and semantic distance would make the quality of predictions even higher. The idea of using vector space measurements explicitly can be also expanded if we were to consider the problem of contextualizing corrections. For example, the semantic distance of proposed corrections to the nearest words is likely to carry much information about their appropriateness. Looking from another angle, searching for words that seem semantically off in context may be a good heuristic for detecting errors that are not nonword (that is, they lead to wrong forms appearing in text which are nevertheless in-vocabulary).The good performance of recurrent network methods is hardly a surprise, given observed effectiveness of neural networks in many NLP tasks in the recent decade. It seems that bidirectional LSTM augmented with ELMo may already hit the limit for correcting Polish spelling errors without contextual information. While it improves accuracy in comparison to LSTM initialized withrandom noise, it makes the test cross-entropy slightly worse, which hints at overfitting. The perplexity measures actually increase sharply for more sophisticated architectures. Perplexity should show how little probability is assigned by the model to true answers. We measure it as INLINEFORM0 where INLINEFORM0 is a sequence of INLINEFORM1 characters, forming the correct version of the word, and INLINEFORM2 is the estimated probability of the INLINEFORM3 th character, given previous predicted characters and the incorrect form. The observed increase of perplexity for increasingly accurate models is most likely due to more refined predicted probability distributions, which go beyond just assigning the bulk of probability to the best answer.Interesting insights can be gained from weights assigned by optimization to layers of ELMo network, which are taken as the word form embedding (Table TABREF5 ). The first layer, and the one that is nearest to input of the network, is given relatively the least importance, while the middle one dominates both others taken together. This suggests that in error correction, at least for Polish, the middle level of morphemes and other characteristic character chunks is more important than phenomena that are low-level or tied to some specific words. This observation should be taken into account in further research on practical solutions for spelling correction.ConclusionAmong the methods tested the bidirectional LSTM, especially initialized by ELMo embeddings, offers the best accuracy and raw performance. Adding ELMo to a straightforward PyTorch implementation of LSTM may be easier now than at the time of performing our tests, as since then the authors of ELMoForManyLangs package BIBREF19 improved their programmatic interface. However, if a more interpretable and explainable output is required, some version of vector distance combined with edit distance may be the best direction. It should be noted that this method produces multiple candidate corrections with their similarity scores, as opposed to only one “best guess“ correction that can be obtained from a character-based LSTM. This is important in applications where it is up to humans to the make the final decision, and they are only to be aided by a machine.It is desirable for further reasearch to expand the corpus material into a wider and more representative set of texts. Nevertheless, the solution for any practical case has to be tailored to its characteristic error patterns. Works on language correction for English show that available corpora can be ”boosted” BIBREF1 , i.e. expanded by generating new errors consistent with a generative model inferred from the data. This may greatly aid in developing models that are dependent on learning from error corpora.A deliberate omission in this paper are the elements accompanying most real-word error correction solutions. Some fairly obvious approaches to integrating evidence from context include n-grams and Markov chains, although the possibility of using measurements in spaces of semantic vectors was already mentioned in this article. Similarly, non-word errors can be easily detected with comparing tokens against reference vocabulary, but in practice one should have ways of detecting mistakes masquerading as real words and fixing bad segmentation (tokens that are glued together or improperly separated). Testing how performant are various methods for dealing with these problems in Polish language is left for future research.Table 1: Test results for all the methods used. The loss measure is cross-entropy.Table 2: Discovered optimal weights for summing layers of ELMo embedding for initializing an error-correcting LSTM. The layers are numbered from the one that directly processes character and word input to the most abstract one.Question: How is PIEWi annotated?","answer":"{\\"answer\\": [\\"[error, correction] pairs\\"], \\"evidence\\": [\\"PlEWi BIBREF20 is an early version of WikEd BIBREF21 error corpus, containing error type annotations allowing us to select only non-word errors for evaluation. Specifically, PlEWi supplied 550,755 [error, correction] pairs, from which 298,715 were unique. The corpus contains data extracted from histories of page versions of Polish Wikipedia. An algorithm designed by the corpus author determined where the changes were correcting spelling errors, as opposed to expanding content and disagreements among Wikipedia editors.\\"]}"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Cardiac sars-cov-2 infection is associated with distinct transcriptomic changes within the liver.Abstract:COronaVIrus Disease 19 (COVID-19) is caused by the infection of the Severe Acute Respiratory Syndrome CoronaVirus 2 (SARS-CoV-2).Although the main clinical manifestations of COVID-19 are respiratory, many patients also display acute myocardial injury and chronic damage to the cardiovascular system.Understanding both direct and indirect damage caused to the heart and the vascular system by SARS-CoV-2 infection is necessary to identify optimal clinical care strategies.The homeostasis of the cardiovascular system requires a tight regulation of the gene expression, which is controlled by multiple types of RNA molecules, including RNA encoding proteins (messenger RNAs) (mRNAs) and those lacking protein-coding potential, the noncoding-RNAs.In the last few years, dysregulation of noncoding-RNAs has emerged as a crucial component in the pathophysiology of virtually all cardiovascular diseases.Here we will discuss the potential role of noncoding RNAs in COVID-19 disease mechanisms and their possible use as biomarkers of clinical use.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Understanding both direct and indirect damage caused to the heart and the vascular system by SARS-CoV-2 infection is necessary to identify optimal clinical care strategies.\\"]}"},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Sars-cov-2 in-vitro neutralization assay reveals inhibition of virus entry by iota-carrageenanAbstract:In the absence of a vaccine and other effective prophylactic or therapeutic countermeasures the severe acute respiratory syndrome-related coronavirus 2 (SARS-CoV-2) remains a significant public health threat.Attachment and entry of coronaviruses including SARS-CoV-2 is mediated by the spike glycoprotein (SGP).Recently, a SARS-CoV-2 Spike Pseudotyped Lentivirus (SSPL) was developed that allows studying spike-mediated cell entry via luciferase reporter activity in a BSL2 environment.Here, we show that iota-carrageenan can inhibit the cell entry of SSPL in a dose dependent manner.SSPL particles were efficiently neutralized with an IC50 value of 2.6 µg/ml iota-carrageenan.In vitro data on iota-carrageenan against various Rhino-and Coronaviruses showed similar IC50 values and translated readily into clinical effectiveness when a nasal spray containing iota-carrageenan demonstrated a reduction in severity and duration of symptoms of common cold caused by various respiratory viruses.Accordingly, our in vitro data on SSPL suggest that administration of iota-carrageenan may be an effective and safe prophylaxis or treatment for SARS-CoV-2 infections.","answer":"{\\"verdict\\": \\"SUPPORT\\", \\"evidence\\": [\\"In vitro data on iota-carrageenan against various Rhino-and Coronaviruses showed similar IC50 values and translated readily into clinical effectiveness when a nasal spray containing iota-carrageenan demonstrated a reduction in severity and duration of symptoms of common cold caused by various respiratory viruses.\\", \\"Accordingly, our in vitro data on SSPL suggest that administration of iota-carrageenan may be an effective and safe prophylaxis or treatment for SARS-CoV-2 infections.\\"]}"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:The recent breakthroughs in Artificial Intelligence (AI) have allowed individuals to rely on automated systems for a variety of reasons. Some of these systems are the currently popular voice-enabled systems like Echo by Amazon and Home by Google that are also called as Intelligent Personal Assistants (IPAs). Though there are raising concerns about privacy and ethical implications, users of these IPAs seem to continue using these systems. We aim to investigate why users are concerned about privacy and how they are handling these concerns while using the IPAs. By utilizing the reviews posted online along with the responses to a survey, this paper provides a set of insights about the detected markers related to user interests and privacy challenges. The insights suggest that users of these systems irrespective of their concerns about privacy, are generally positive in terms of utilizing IPAs in their everyday lives. However, there is a significant percentage of users who are concerned about privacy and took further actions to address the related concerns. Some percentage of users expressed that they do not have any privacy concerns but when they learned about the \\"always listening\\" feature of these devices, their concern about privacy increased.Cited Abstract(s):[1]: As the complexity of software for Cyber-Physical Systems (CPS) rapidly increases, multi-core processors and parallel programming models such as OpenMP become appealing to CPS developers for guaranteeing timeliness. Hence, a parallel task on multi-core processors is expected to become a vital component in CPS such as a self-driving car, where tasks must be scheduled in real-time. In this paper, we extend the fork-join parallel task model to be scheduled in real-time, where the number of parallel threads can vary depending on the physical attributes of the system. To efficiently schedule the proposed task model, we develop the task stretch transform. Using this transform for global Deadline Monotonic scheduling for fork-join real-time tasks, we achieve a resource augmentation bound of 3.73. In other words, any task set that is feasible on m unit-speed processors can be scheduled by the proposed algorithm on m processors that are 3.73 times faster. The proposed scheme is implemented on Linux RK as a proof of concept, and ported to Boss, the self-driving vehicle that won the 2007 DARPA Urban Challenge. We evaluate our scheme on Boss by showing its driving quality, i.e., curvature and velocity profiles of the vehicle.[2]: We are in the midst of a technological revolution whereby, for the first time, researchers can link daily word use to a broad array of real-world behaviors. This article reviews several computerized text analysis methods and describes how Linguistic Inquiry and Word Count (LIWC) was created and validated. LIWC is a transparent text analysis program that counts words in psychologically meaningful categories. Empirical results using LIWC demonstrate its ability to detect meaning in a wide variety of experimental settings, including to show attentional focus, emotionality, social relationships, thinking styles, and individual differences.[3]: Personal software assistants that help users with tasks like finding information, scheduling calendars, or managing work-flow will require significant customization to each individual user. For example, an assistant that helps schedule a particular user’s calendar will have to know that user’s scheduling preferences. This paper explores the potential of machine learning methods to automatically create and maintain such customized knowledge for personal software assistants. We describe the design of one particular learning assistant: a calendar manager, called CAP (Calendar APprentice), that learns user scheduling preferences from experience. Results are summarized from approximately five user-years of experience, during which CAP has learned an evolving set of several thousand rules that characterize the scheduling preferences of its users. Based on this experience, we suggest that machine learning methods may play an important role in future personal software assistants.[4]: Most information retrieval technologies are designed to facilitate information discovery. However, much knowledge work involves finding and re-using previously seen information. We describe the design and evaluation of a system, called Stuff I've Seen (SIS), that facilitates information re-use. This is accomplished in two ways. First, the system provides a unified index of information that a person has seen, whether it was seen as email, web page, document, appointment, etc. Second, because the information has been seen before, rich contextual cues can be used in the search interface. The system has been used internally by more than 230 employees. We report on both qualitative and quantitative aspects of system use. Initial findings show that time and people are important retrieval cues. Users find information more easily using SIS, and use other search tools less frequently after installation.[5]: With the recent advancements in Artificial Intelligence (AI), various organizations and individuals started debating about the progress of AI as a blessing or a curse for the future of the society. This paper conducts an investigation on how the public perceives the progress of AI by utilizing the data shared on Twitter. Specifically, this paper performs a comparative analysis on the understanding of users from two categories -- general AI-Tweeters (AIT) and the expert AI-Tweeters (EAIT) who share posts about AI on Twitter. Our analysis revealed that users from both the categories express distinct emotions and interests towards AI. Users from both the categories regard AI as positive and are optimistic about the progress of AI but the experts are more negative than the general AI-Tweeters. Characterization of users manifested that London' is the popular location of users from where they tweet about AI. Tweets posted by AIT are highly retweeted than posts made by EAIT that reveals greater diffusion of information from AIT.[6]: Creating a good schedule for a large conference such as CHI requires taking into account the preferences and constraints of organizers, authors, and attendees. Traditionally, the onus of planning is placed entirely on the organizers and involves only a few individuals. Cobi presents an alternative approach to conference scheduling that engages the entire community to take active roles in the planning process. The Cobi system consists of a collection of crowdsourcing applications that elicit preferences and constraints from the community, and software that enable organizers and other community members to take informed actions toward improving the schedule based on collected information. We are currently piloting Cobi as part of the CHI 2013 planning process.[7]: In this paper we explore the power of surface text patterns for open-domain question answering systems. In order to obtain an optimal set of patterns, we have developed a method for learning such patterns automatically. A tagged corpus is built from the Internet in a bootstrapping process by providing a few hand-crafted examples of each question type to Altavista. Patterns are then automatically extracted from the returned documents and standardized. We calculate the precision of each pattern, and the average precision for each question type. These patterns are then applied to find answers to new questions. Using the TREC-10 question set, we report results for two cases: answers determined from the TREC-10 corpus and from the web.[8]: One subclass of human computation applications are those directed at tasks that involve planning (e.g. tour planning) and scheduling (e.g. conference scheduling). Interestingly, work on these systems shows that even primitive forms of automated oversight on the human contributors helps in significantly improving the effectiveness of the humans crowd. In this paper, we argue that the automated oversight used in these systems can be viewed as a primitive automated planner, and that there are several opportunities for more sophisticated automated planning in effectively steering the crowd. Straightforward adaptation of current planning technology is however hampered by the mismatch between the capabilities of human workers and automated planners. We identify and partially address two important challenges that need to be overcome before such adaptation of planning technology can occur: (i) interpreting inputs of the human workers (and the requester) and (ii) steering or critiquing plans produced by the human workers, armed only with incomplete domain and preference models. To these ends, we describe the implementation of AI-MIX, a tour plan generation system that uses automated checks and alerts to improve the quality of plans created by human workers; and present a preliminary evaluation of the effectiveness of steering provided by automated planning.[9]: We discuss what constitutes an integrated system in AI, and why AI researchers should be interested in building and studying them. Taking integrated systems to be ones that integrate a variety of components in order to perform some task from start to finish, we believe that such systems (a) allow us to better ground our theoretical work in actual tasks, and (b) provide an opportunity for much-needed evaluation based on task performance. We describe one particular integrated system we have developed that supports spoken-language dialogue to collaboratively solve planning problems. We discuss how the integrated system provides key advantages for helping both our work in natural language dialogue processing and in interactive planning and problem solving, and consider the opportunities such an approach affords for the future.[10]: We describe an intelligent personal assistant that has been developed to aid a busy knowledge worker in managing time commitments and performing tasks. The design of the system was motivated by the complementary objectives of (1) relieving the user of routine tasks, thus allowing her to focus on tasks that critically require human problem-solving skills, and (2) intervening in situations where cognitive overload leads to oversights or mistakes by the user. The system draws on a diverse set of AI technologies that are linked within a Belief-Desire-Intention (BDI) agent system. Although the system provides a number of automated functions, the overall framework is highly user centric in its support for human needs, responsiveness to human inputs, and adaptivity to user working style and preferences.[11]: Assisting users in performing their tasks is an important issue in Human Computer Interaction research. A solution to deal with this challenge is to build a personal assistant agent capable to discover the user's habits, abilities, preferences, and goals, ever more accurately anticipating the user's intentions. In order to solve in an intelligent manner this problem, the assistant agent has to continuously improve its behavior based on previous experiences. By endowing the agent with the learning capability, it will become able to adapt himself to the user's behavior. This paper proposes an intelligent personal assistant agent that learns by supervision to assist users in performing specific tasks. For evaluating the performance of the agent a case study is considered, and a neural network is used by the agent to learn by supervision from its experience. We also provide a comparison of our approach with other similar existing work.","answer":"Intelligent systems are becoming part of our lives as more and more individuals are relying on them for driving [1] , work management [4]3 [4]2 , time scheduling [6] [4]6 , information and email organization [3] [4] , and responding to factual questions [2] [4]5 . These systems leverage AI to learn and reduce the mistakes made by users due to cognitive overload [4]2 . In this context, there are multiple debates about whether AI that is primarily used by these intelligent systems is a blessing or curse to the society. One of our previous works [5] investigated the public perceptions of individuals about AI. These individuals comprise both AI experts and common users on Twitter (a popular micro-blogging platform) who are sharing their personal opinions and information about AI. However, we believe that researching the interactions of individuals with the intelligent systems has greater potential to understand the impact of AI on the society to a certain level especially the privacy concerns that come along with that [4]1 ."},{"question":"You will be presented with a collection of medical randomized controlled trial (RCT) reports addressing a shared clinical question -- for instance, the efficacy of a medical intervention on a disease or condition. Given the titles and abstracts of these reports, your task is to generate the conclusion of the systematic review article synthesizing the key findings. Your conclusion should be a few sentences long. In your response, include only the conclusion and no other text. The RCT reports are below.Title 1:The visibility of clear and opaque fissure sealantsAbstract 1:Results are reported of a double-blind trial to assess the accuracy with which three examiners identified an  opaque and a clear fissure sealant .  The combined identification error rate for opaque resin was only 1.4 % , whilst for clear resin it was 22.8 % . The difference was highly significant ( P less than 0.0001 ) . Significant differences were also found in the accuracy with which the three dentists identified each type of resin . The most common error was to identify the presence of clear resin on an untreatedTitle 2:2-year clinical performance of a fluoride-containing fissure sealant in young schoolchildren at caries risk.Abstract 2:PURPOSE To evaluate the clinical performance of Helioseal-F , a fluoride-containing fissure sealant , in school children at caries risk . MATERIAL S AND METHODS A caries risk assessment based on past caries experience , saliva microbial tests , buffer capacity and frequency of sugar intake was carried out in 204 healthy children , 6 - 7 years of age . Children exhibiting one or more risk factors were considered at caries risk ( n = 121 ) and their permanent molars were sealed with a fluoride-containing fissure sealant , thus forming a fissure sealant group ( FSG ) . The remaining 83 children with low caries risk received no fissure sealants and constituted a reference group ( RG ) . Both groups were followed for 2 years . From 15 children of both groups , unstimulated whole saliva was collected 1 month after sealant placement in order to determine fluoride levels . In another 20 children , a split-mouth study design was utilized to compare the colonization of mutans streptococci adjacent to and on F-containing sealants and conventional controls . The sealants were placed by dental hygienists according to the manufacturers ' instructions . RESULTS A total of 431 fissure sealants were placed at baseline . Complete retention was found in 76.6 % during the study period while 22.0 % were partially lost . Six sealants ( 1.4 % ) were completely lost . The enamel caries incidence was 45 % lower ( P < 0.05 ) in the permanent molars of the caries risk FSG compared with the low risk RG . There was no significant increase in saliva fluoride concentration following placement of the sealants and the proportion of mutans streptococci in relation to total viable counts was unaffected by type of material . The levels of salivary mutans streptococci were mainly unchanged in both groups during the study period , while the levels of salivary lactobacilli decreased in the FSGTitle 3:Continuous effect of pit and fissure sealing on S. mutans presence in situ.Abstract 3:PURPOSE The effect of sealants on S. mutans presence in situ was investigated . METHODS Four intact , fully erupted first permanent molars in each of 74 children , aged 6 - 8 years were required for inclusion in the study . Baseline examination included deft and plaque index . S. mutans presence on occlusal surfaces of the molars was evaluated , using a microbial replica method . Immediately after sealing the first permanent molars on one side , S. mutans presence in situ was re-evaluated , as well as three and six months thereafter . Three months after the initiation of the study , S. mutans presence was evaluated on the molars of the unsealed side , which were consequently sealed and re-evaluated immediately , and three months later . RESULTS Positive correlation was found between deft scores , plaque indices and microbial replica values , at baseline . Sealing caused a significant reduction in S. mutans levels on the treated occlusal surfaces , in vivo ( P < 0.001 ) , which lasted , in most cases , up to six months . CONCLUSIONS The data suggest that sealants enable a prolonged reduction of S. mutans presence in situ , indicating an additional prevention effect , by reducing one source of disseminationTitle 4:Evaluation of a school-based sealant program in New York State.Abstract 4:This study evaluated the outcome of a targeted dental sealant program by comparing the survival probabilities of sealed high-risk first molar tooth sites to unsealed low-risk tooth sites in 1,122 children enrolled in a school-based sealant program .  A comparison of the survival probabilities between low-risk first molar teeth that did not receive sealants and the sealed high-risk first molar teeth did not show significant differences . The results suggest that the protocol used by the program provides a satisfactory method for identification of children who could best benefit from  sealants  in a school-based situationTitle 5:Improved Sealant Retention with Bonding Agents: A Clinical Study of Two-bottle and Single-bottle SystemsAbstract 5:Recent in vitro work and a short clinical study suggest that adding a bonding agent layer between sealant and saliva-contaminated enamel allows for adequate bond strength and retention of resin sealants and may improve success of all sealant applications . This five-year clinical study scored 617 occlusal and 441 buccal/lingual molar sealants , with use of a split-mouth design , with half receiving sealant alone and half bonding agent plus sealant . Treatment effects and potential risk factors for sealant failure were tested by means of a Cox regression model . Three bonding agent groups were analyzed for treatment effect : Tenure primer , Scotchbond Multi- Purpose , and 3 single-bottle dentin bonding agents as a third group . The single-bottle group was successful in reducing risk of sealant failure , with a hazard ratio ( HR ) of 0.53 ( p = 0.014 ) for occlusal and 0.35 ( p = 0.006 ) for buccal/lingual sealants . Scotchbond was detrimental to occlusal sealant success , with a HR of 2.96 ( p = 0.0003 ) . Tenure primer was neutral , showing HRs close to 1.0 . Variables that affected success differed between occlusal and buccal/lingual sealants , suggesting that failures on these two surfaces may be dependent upon differing factors . Early eruption stage was a significant risk factor for both surfaces ( HR = 2.91 , p = 0.00001 , occlusal ; and HR = 1.52 , p = 0.015 , buccal/lingual ) . Behavior ( HR = 1.96 , p = 0.0007 ) , salivary problems ( HR = 1.73 , p = 0.002 ) , and visually apparent variations in enamel ( HR = 1.51 , p = 0.018 ) were significant risk factors for occlusal sealants only . In addition to completing detailed analyses of risk factors for sealant survival , this study shows that single-bottle bonding agents protect sealant survival , yielding half the usual risk of failure for occlusal sealants and one-third the risk of failure for buccal/lingual sealantsTitle 6:Retention and effectiveness of a chemically polymerized pit and fissure sealant after 2 years.Abstract 6:Following a single application of a chemically polymerized fissure sealant ( Concise Enamel Bond System ) 60 % of the sealants were present after 2 years of examination . The effectiveness of the treatment was highly significant and the caries reduction , irrespective of the sealant status , was found to be about 50 % . The caries reduction was 98 % in sealed pairs where the material was fully retainedTitle 7:Pit and fissure sealants: one-year results from a study in Kalispell, Montana.Abstract 7:The half-mouth technique was used to determine the treatment effect of an application of an ultraviolet-light-polymerized sealant . The side of the mouth to be treated with the sealant was r and omly selected . At the one-year examination , a statistically significant reduction in occlusal caries was found for teeth coated with the sealant . Practically no color change or marginal discoloration was evident and retention of the sealant was excellent","answer":"There is good evidence that  sealants can be used efficaciously and effectively in high-risk  children as long as the sealant is retained .Sealants are more effective in preventing further caries and providing cost savings in a shorter time span if placed in children who have high rather than low caries risk"},{"question":"You are presented with a paragraph from a COVID-19 literature. Classify the topics of this piece of text by choosing from the following categories:- Epidemic Forecasting: The content relates to predictions about the spread of COVID-19.- Treatment: The paragraph discusses therapeutic methods or medication for COVID-19.- Prevention: The content covers measures to prevent the spread of COVID-19.- Mechanism: The paragraph explains the biological mechanisms of the virus.- Case Report: The content is a report of a COVID-19 case.- Transmission: The paragraph discusses how COVID-19 is transmitted.- Diagnosis: The content is about diagnosing COVID-19 in individuals.Your classification should be provided as an element within a JSON array. The array should be formatted with topics enclosed in double quotes and separated by commas, following the JSON format, for example: [\\"Topic1\\", \\"Topic2\\", ...]. Include all applicable topics within the array. Your output should be a valid JSON array, and no additional text should be included in your response.Article:The aim of this study was to assess the analytical performances, sensitivity and specificity, of two rapid tests (Covid- Presto(R) test rapid Covid-19 IgG/IgM and NG-Test(R) IgM-IgG COVID-19) and one automated immunoassay (Abbott SARS-CoV-2 IgG) for detecting anti- SARS-CoV-2 antibodies. This study was performed with: (i) a positive panel constituted of 88 SARS-CoV-2 specimens collected from patients with a positive SARS-CoV-2 RT-PCR, and (ii) a negative panel of 120 serum samples, all collected before November 2019, including 64 samples with a cross-reactivity panel. Sensitivity of Covid-Presto(R) test for IgM and IgG was 78.4% and 92.0%, respectively. Sensitivity of NG-Test(R) for IgM and IgG was 96.6% and 94.9%, respectively. Sensitivity of Abbott IgG assay was 96.5% showing an excellent agreement with the two rapid tests (kappa = 0.947 and kappa = 0.936 for NGTest (R) and Covid-Presto(R) test, respectively). An excellent agreement was also observed between the two rapid tests (kappa = 0.937). Specificity for IgM was 100% and 86.5% for Covid-Presto(R) test and NG-Test(R), respectively. Specificity for IgG was 92.0%, 94.9% and 96.5% for Covid-Presto(R), NGTest (R), and Abbott, respectively. Most of the false positive results observed with NG-Test(R) resulted from samples containing malarial antibodies. In conclusion, performances of these 2 rapid tests are very good and comparable to those obtained with automated immunoassay, except for IgM specificity with the NG-Test(R). Thus, isolated IgM should be cautiously interpreted due to the possible false-positive reactions with this test. Finally, before their large use, the rapid tests must be reliably evaluated with adequate and large panel including early seroconversion and possible cross-reactive samples.","answer":"[\\"Diagnosis\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:The nature and importance of changes in toe-brachial pressure indices following percutaneous transluminal angioplasty for leg ischaemia . OBJECTIVES To document changes in toe-brachial pressure indices ( TBPI ) during the 6 months following percutaneous transluminal angioplasty ( PTA ) and relate these changes to restenosis . Furthermore , to ascertain the effect of administering a vasodilator , glyceryl trinitrate ( GTN ) , immediately following PTA . DESIGN Eighty-three technically successful PTA procedures were studied . Fifty-six were for intermittent claudication , 14 for ischaemic rest pain , and 13 for non-healing ulcers . Immediately following balloon dilatation an intra-arterial bolus of either 150 micrograms GTN , with or without a 10 mg GTN patch for 24 h , or a saline placebo was administered . TBPI were measured before and for 6 h after PTA and then at 24 h , 1 week , 1 month and 6 months . At this time , patency at the PTA site was determined by arteriography . RESULTS There was continuing TBPI improvement over 1 month in patients given saline following PTA . In patients given GTN , peak TBPI was achieved by 1 week , and corresponded with the TBPI observed immediately following GTN administration . Restenosis occurred in 27 ( 33 % ) patients , and was significantly more frequent following the procedures for rest pain or ulceration , or where a TBPI increase of more than 0.15 by 1 week was observed . CONCLUSIONS Haemodynamic changes following PTA continue for at least 1 month , can be modified by GTN administration , and are predictive of subsequent restenosis . Measuring the TBPI increase during the first week following PTA underestimates total improvement , and may give false reassurance with respect to recurrent disease .","answer":"{\\"Intervention\\": [\\"percutaneous transluminal angioplasty\\", \\"GTN\\", \\"balloon dilatation an intra-arterial bolus\\", \\"saline\\", \\"percutaneous transluminal angioplasty ( PTA )\\", \\"PTA\\", \\"saline placebo\\", \\"GTN patch\\", \\"150 micrograms GTN\\", \\"glyceryl trinitrate ( GTN )\\"], \\"Outcome\\": [\\"effect\\", \\"toe-brachial pressure indices ( TBPI )\\", \\"TBPI\\", \\"Restenosis\\", \\"peak TBPI\\"], \\"Participant\\": [\\"ischaemic rest pain\\", \\"PTA procedures\\", \\"non-healing ulcers\\"]}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: A Survey on Deep Learning for Named Entity Recognition Chapter Title:  Rule-based Approaches 1. Abstract of Cited Paper (BIB001):  In the rest of this paper, we first give some background on the context in which the system used in the MUC-7 NE task was developed. We then outline its internal structure, concentrating on the rule notation which is its most salient feature. An evaluation of its performance in the task then follows, before concluding with some speculation on the extent to which the approach adopted is susceptible to further improvement. 2. Abstract of Cited Paper (BIB002):  It is often claimed that Named Entity recognition systems need extensive gazetteers---lists of names of people, organisations, locations, and other named entities. Indeed, the compilation of such gazetteers is sometimes mentioned as a bottleneck in the design of Named Entity recognition systems.We report on a Named Entity recognition system which combines rule-based grammars with statistical (maximum entropy) models. We report on the system's performance with gazetteers of different types and different sizes, using test material from the MUC-7 competition. We show that, for the text type and task of this competition, it is sufficient to use relatively small gazetteers of well-known names, rather than large gazetteers of low-frequency names. We conclude with observations about the domain independence of the competition and of our experiments. 3. Abstract of Cited Paper (BIB003):  The tagging of Named Entities, the names of particular things or classes, is regarded as an important component technology for many NLP applications. The first Named Entity set had 7 types, organization, location, person, date, time, money and percent expressions. Later, in the IREX project artifact was added and ACE added two, GPE and facility, to pursue the generalization of the technology. However, 7 or 8 kinds of NE are not broad enough to cover general applications. We proposed about 150 categories of NE (Sekine et al. 2002) and now we have extended it again to 200 categories. Also we have developed dictionaries and an automatic tagger for NEs in Japanese. 4. Abstract of Cited Paper (BIB004):  The KnowItAll system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an unsupervised, domain-independent, and scalable manner. The paper presents an overview of KnowItAll's novel architecture and design principles, emphasizing its distinctive ability to extract information without any hand-labeled training examples. In its first major run, KnowItAll extracted over 50,000 class instances, but suggested a challenge: How can we improve KnowItAll's recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Pattern Learning learns domain-specific extraction rules, which enable additional extractions. Subclass Extraction automatically identifies sub-classes in order to boost recall (e.g., ''chemist'' and ''biologist'' are identified as sub-classes of ''scientist''). List Extraction locates lists of class instances, learns a ''wrapper'' for each list, and extracts elements of each list. Since each method bootstraps from KnowItAll's domain-independent methods, the methods also obviate hand-labeled training examples. The paper reports on experiments, focused on building lists of named entities, that measure the relative efficacy of each method and demonstrate their synergy. In concert, our methods gave KnowItAll a 4-fold to 8-fold increase in recall at precision of 0.90, and discovered over 10,000 cities missing from the Tipster Gazetteer. 5. Abstract of Cited Paper (BIB005):  BackgroundIdentification of gene and protein names in biomedical text is a challenging task as the corresponding nomenclature has evolved over time. This has led to multiple synonyms for individual genes and proteins, as well as names that may be ambiguous with other gene names or with general English words. The Gene List Task of the BioCreAtIvE challenge evaluation enables comparison of systems addressing the problem of protein and gene name identification on common benchmark data.MethodsThe ProMiner system uses a pre-processed synonym dictionary to identify potential name occurrences in the biomedical text and associate protein and gene database identifiers with the detected matches. It follows a rule-based approach and its search algorithm is geared towards recognition of multi-word names [1]. To account for the large number of ambiguous synonyms in the considered organisms, the system has been extended to use specific variants of the detection procedure for highly ambiguous and case-sensitive synonyms. Based on all detected synonyms for one abstract, the most plausible database identifiers are associated with the text. Organism specificity is addressed by a simple procedure based on additionally detected organism names in an abstract.ResultsThe extended ProMiner system has been applied to the test cases of the BioCreAtIvE competition with highly encouraging results. In blind predictions, the system achieved an F-measure of approximately 0.8 for the organisms mouse and fly and about 0.9 for the organism yeast. 6. Abstract of Cited Paper (BIB006):  Abstract In health care information systems, electronic health records are an important part of the knowledge concerning individual health histories. Extracting valuable knowledge from these records represents a challenging task because they are composed of data of different kind: images, test results, narrative texts that include both highly codified and a variety of notes which are diverse in language and detail, as well as ad hoc terminology, including acronyms and jargon, far from being highly codified. This paper proposes a combined approach for the recognition of named entities in such narrative texts. This approach is a composition of three different methods. The possible combinations are evaluated and the resulting composition shows an improvement of the recall and a limited impact on precision for the named entity recognition process.Literature Review:","answer":"Rule-based NER systems rely on hand-crafted rules. Rules can be designed based on domain-specific gazetteers BIB005 , BIB004 and syntactic-lexical patterns  . Kim  proposed to use Brill rule inference approach for speech input. This system generates rules automatically based on Brill's partof-speech tagger. In biomedical domain, Hanisch et al. BIB006 proposed ProMiner, which leverages a pre-processed synonym dictionary to identify protein mentions and potential gene in biomedical text. Quimbaya et al. BIB007 proposed a dictionary-based approach for NER in electronic health records. Experimental results show the approach improves recall while having limited impact on precision. Some other well-known rule-based NER systems include LaSIE-II  , NetOwl  , Facile BIB002 , SAR  , FASTUS BIB001 , and LTG BIB003 systems. These systems are mainly based on hand-crafted semantic and syntactic rules to recognize entities. Rule-based systems work very well when lexicon is exhaustive. Due to domain-specific rules and incomplete dictionaries, high precision and low recall are often observed from such systems, and the systems cannot be transferred to other domains."},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:Treatment of hyperphosphatemia based on specific interactions between phosphorus and Zr(<scp>iv</scp>) active centers of nano-MOFsPaper sections:Introduction<p>Chronic kidney disease, especially renal failure, has dramatically increased over the past few years as a serious global public problem which threatens humans. 1 Currently, hemodialysis as an effective renal failure therapy still experiences limitations in the removal of toxins that leads to the presence of metabolites in the body. [2][3][4] Moreover, hyperphosphatemia, considered to be a common metabolic complication in hemodialysis patients, was found to be key for raising serum phosphorus levels in chronic kidney disease-mineral and bone disorder (CKD-MB), thereby further increasing the occurrence and development of CKD-MB. 5,6 The main clinical manifestations of CKD-MB are hyperparathyroidism, abnormal mineral and bone metabolism, and calcication of blood vessels and other so tissues. Such a disease not only increases the patients' morbidity and seriously inuences their quality of life, but also increases the incidence of cardiovascular diseases and eventually death. [7][8][9] Hence, curing hyperphosphatemia has become quite crucial for the prevention and control of complications in hemodialysis patients, and urgently needs to be solved.</p><p>The phosphorus binders currently used for hyperphosphatemia treatment are aluminum, calcium and iron based binders, as well as La 2 (CO 3 ) 3 etc. 10,11 However, these binders' side effects and their impact on the patient's prognosis remain a serious concern. 12,13 Take aluminum-based phosphorus binders for example: their toxicity for the central nervous system, blood system, and bones signicantly limits their clinical applications. On the other hand, La accumulates in many organs such as the liver and kidneys, which causes adverse reactions like encephalopathy. 14,15 Therefore, the development of new types of phosphorus-reducing drug with fewer side effects faces severe challenges.</p><p>In order to improve the materials' therapeutic effects, metal organic frameworks (MOFs) as a new kind of porous complex, [16][17][18][19][20][21][22] which have been widely used in the elds of biosensing, catalysis, and photodynamic therapy due to their controllable synthesis, structural diversity and high specic surface area, [23][24][25][26][27][28][29][30][31][32] have raised our interest. Recently, our group designed nano-MOFs with Cu(II) as the active center to reduce glutathione levels and increase the concentration of ROS, thus strengthening the photodynamic efficiency and achieving a synergistic antitumor effect. 33 In this regard, we hypothesized that a Zr(IV)-based nano-MOF with an active center prone to specic phosphorus reactions would have the advantages of a large surface area and enhanced chemisorption abilities, as well as selective uorescence sensing of phosphate to monitor the process. Zr(IV) as the active center of the nano-MOF can specically bind and absorb in vivo phosphate, thus directly decreasing the blood phosphorus levels and leading to a remission of hyperphosphatemia (Scheme 1). Notably, compared to commercially available phosphorus binders, the nano-MOF exhibits a greatly enhanced decrement in phosphorus levels. Finally, the hyperphosphatemia mice model with the MOF treatment further proved there was less in vivo toxicity and a better curing effect. This work provides strong evidence for MOFs as promising drugs for the treatment of hyperphosphatemia by directly adsorbing phosphorus in the blood, which will further optimize the clinical applications in the future.</p>Results and discussion<p>Characterization Typically, porphyrin-inlaid Zr(IV)-based nano-MOF UiO-66 materials were prepared and characterized. The mechanical stability of the nano-MOFs was rst investigated (Fig. 1a), where the PXRD patterns of the nano-MOF treated with PBS were consistent with those of the as-prepared MOFs, which proves decent crystalline stability in biological environments. By comparison with the FTIR absorptions of UiO-TCPP and UiO-66-NH 2 , identical results were obtained (Fig. S1 †) which suggests that porphyrin does not affect the crystal structure of the MOFs. The morphology and particle size of the MOFs were acquired through dynamic light scattering (DLS), SEM and TEM (Fig. 1b-d), which demonstrated the ne size control of the particles, which had a uniform distribution of 120 nm.</p>Fluorescence response<p>The uorescence response of the MOFs to phosphate was studied via the two largest uorescence emission peaks at 440 nm (2-aminoterephthalic acid) and 650 nm (porphyrin) (Fig. S2 †). By interacting with phosphate, the uorescence intensities of MOFs were signicantly enhanced due to the charge transfer interruption between the ligand molecule and the metal junction of the MOFs, and thus the ligand molecule's uorescence was restored. To further explore the mechanism of the uorescence intensity change caused by MOFs and phosphate, the uorescence response of the MOFs to phosphate in the presence/absence of Zr(IV) ions was examined (Fig. S3 †). Interestingly, no signicant uorescence change was observed when adding different concentrations of phosphate, which was attributed to Zr(IV) ions' preferential interactions with the phosphate. The Zr(IV) of the MOFs does not interact with phosphate, so there are no obvious changes in uorescence   intensity, which further demonstrated the important role of Zr(IV) of MOFs for identication and uorescence sensing of phosphate.</p><p>To thoroughly investigate the interactions between the MOFs and phosphate, the pH, concentration and response time were optimized (Fig. S4 †). The uorescence responses of the MOFs towards phosphate rst increased greatly until 60 min, and then slowed down with the time extension, whilst a plateau was reached by 120 min. Under optimal conditions, the MOFs' phosphate absorption specicity was investigated using their uorescence response (Fig. S5 †). The phosphate was found to enhance the uorescence intensities of MOFs (435 nm and 650 nm) with linear relationship ranges of 0.5-105 mM and 0.5-7 mM and correlation coefficients of 0.9987 and 0.9997, respectively. Based on the uorescence response of the MOFs to phosphate, the material is used for uorescence monitoring of the levels of phosphate in samples.</p>Selectivity<p>The MOFs' phosphate absorption selectivity was studied with the interference of common in vivo small molecular species. Fig. 2a shows that the uorescence responses are signicantly weaker for the ions even with higher concentrations than phosphate, representing a high selectivity of the MOFs towards phosphate. By further verication of the relationship between Zr(IV)-based MOFs and phosphate, UV-vis spectroscopy was carried out and an enhanced absorption at 420 nm was obtained aer 1 h of incubation (Fig. S6 †). This is most probably because phosphate, when binding to the MOFs' network architecture, inuences the coordination between the metal center and the ligands, thus enhancing the absorption intensity of the porphyrin. UV-vis spectroscopy was performed to conrm the hypothesis by measuring the concentration of phosphate aer incubating with MOFs (Fig. S7 †), and 92.4 mg mg À1 was achieved, demonstrating a signicant decrease from the phosphate solution, which means that the MOFs exhibit a signicant adsorption capacity for phosphate.</p>Adsorption capacity<p>To improve the biocompatibility of the MOFs, the BSA protein was used to modify the MOFs' surface. The surface charge  34 The phosphorus levels was measured using an ICP emission spectrometer. The cystatin C and creatinine levels were evaluated using an automatic biochemical analyzer from Qilu Medical Research Institute.  changes of MOFs before and aer modication with BSA were measured using the zeta potential. The potential increase from À13.7 mV to À3.5 mV (Fig. S8 †) indicated that the BSA protein was successfully attached onto the surface of the MOFs (BSA-MOFs). Then, the hyperphosphatemia serum model was used to test if BSA-MOFs can reduce the levels of phosphate using UVvis spectroscopy and an ICP emission spectrometer (Fig. S9 †), and good efficacy was obtained in both characterizations. Subsequently, other commercially available phosphorus binders were compared with MOFs (Fig. 2b), but the MOFs exhibit obviously better adsorption capacities than all of the others. In addition, the MTT test showed the excellent biocompatibility of the MOFs in vivo (Fig. S10 †). These results demonstrated that the MOFs directly adsorb phosphate, which remarkably reduces the phosphate levels.</p>Treatment of hyperphosphatemia in a mouse model<p>Then, a mouse model for chronic renal failure was established using adenine chemical induction. By measuring physiological indicators such as renal function, blood phosphorus levels, kidney tissue sections, body weight changes, and imaging of the mouse kidney tissue in normal and model mice, these results showed that all physiological indicators of the model mice were clearly distinguished from the normal mice, indicating successful establishment of a renal failure mouse model (Table 1 and Fig. 3 and 4). Therefore, the phosphate reducing efficacy by MOFs using the hyperphosphatemia mouse model was rationally tested. Next, we tested the efficacy of the MOFs for lowering the phosphate levels using the hyperphosphatemia mouse model. Aer 10 days of treatment with MOFs in the stomachs of the mice, the physiological indicators were measured through different means. The serum phosphorus values and other indicators in the treated group are identical to those of the control group, indicating that the kidney metabolism of the treated group has mainly recovered to normal (Table 1). To verify whether the MOFs can relieve the symptoms of renal failure in mice, weight changes in mice in both groups were studied, and the treatment group has a slightly faster increase than the model group, which correlates with the hypothesis. As shown in Fig. 4a, the uorescence images of kidney tissue (model group and therapy group) showed signicant differences, suggesting the phosphorus levels in the kidneys have been signicantly reduced. By comparing the kidney tissue slides (Fig. 4b), the renal tissue images of the treated group no longer exhibited dilation of the renal tubules compared with the model group, and more importantly, the treatment group had no pathological abnormalities of the renal tissues.</p><p>Finally, the levels of phosphate in the kidneys of the therapy group were measured based on the uorescence of the nano-MOFs (Fig. 4c and d). It can be seen that there was no signicant difference in uorescence intensity, suggesting the phosphate levels between the treated group and the normal group had no signicant difference. More importantly, the results measured using the uorescence method were basically identical to those of other methods. These results conrmed that the phosphate levels in the treated group were remarkably reduced, and the physiological indicators of the mouse models were basically consistent with the normal mice, indicating that the hyperphosphatemia mouse model was effectively treated using the MOFs. In addition, the in vivo toxicity for the organs was tested to prove the biosafety of the MOF material as a phosphorus binding agent (Fig. S11 †). Experiments on tissue slides (heart, liver, spleen and lung, respectively) were performed. Although the nano-MOFs enter the bloodstream via stomach feeding, the images showed the MOF material has less effect on other organs, which indicated that the nano-MOF has less in vivo toxicity.</p>Conclusions<p>In summary, as chronic kidney disease retains high levels of phosphorus in the blood, we have developed a nano-MOF with Zr(IV) as the active center to reduce the blood phosphorus levels and cure hyperphosphatemia by the direct adsorption of phosphorus. The highly porous MOFs offer signicant numbers of Zr(IV) surface active centers for interactions, which dramatically reduce the phosphorus concentrations in vivo. By further comparisons with common in vivo small molecules and other phosphate binders, the MOFs possess high specicity and selectivity for reducing levels of phosphorus. Finally, the hyperphosphatemia mouse model with treatment using MOFs shows identical physiological parameters with the control group, representing promising biocompatibility for future applications. The present work provides not only a uorescence nanosensor for monitoring blood phosphorus levels, but a new approach for effective hyperphosphatemia treatment in clinical therapies.</p>Conflicts of interest<p>There are no conicts to declare.</p>","answer":"Hyperphosphatemia is closely associated with the occurrence of multiple organ dysfunctions in patients with end-stage renal disease (ESRD). The application of phosphorus binders as an effective clinical approach for such diseases still suffers from serious side effects. Therefore, development of new phosphorus binders for the treatment of hyperphosphatemia remains a great challenge. Herein, we describe a kind of zirconium (Zr(IV))-based nano-MOF that is well suited for specific adsorption and selective fluorescence sensing of phosphate, and is based on the particular interactions between Zr(IV) and phosphate. The reduced levels of phosphate were quantitatively monitored using the MOF-based fluorescence nanosensor. Notably, the MOFs exhibit a greater reduction in phosphorus levels than commercially available phosphorus binders, and comparable therapeutic effects in the treatment of hyperphosphatemia of a mice model. Hence, the MOF acts as a promising medication for hyperphosphatemia by directly adsorbing phosphorus in the blood, which offers new perspectives in future applications of MOFs."},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:Adversarial training is one of the main defenses against adversarial attacks.In this paper, we provide the first rigorous study on diagnosing elements of large-scale adversarial training on ImageNet, which reveals two intriguing properties. First, we study the role of normalization.Batch normalization (BN) is a crucial element for achieving state-of-the-art performance on many vision tasks, but we show it may prevent networks from obtaining strong robustness in adversarial training.One unexpected observation is that, for models trained with BN, simply removing clean images from training data largely boosts adversarial robustness, i.e., 18.3%.We relate this phenomenon to the hypothesis that clean images and adversarial images are drawn from two different domains.This two-domain hypothesis may explain the issue of BN when training with a mixture of clean and adversarial images, as estimating normalization statistics of this mixture distribution is challenging.Guided by this two-domain hypothesis, we show disentangling the mixture distribution for normalization, i.e., applying separate BNs to clean and adversarial images for statistics estimation, achieves much stronger robustness.Additionally, we find that enforcing BNs to behave consistently at training and testing can further enhance robustness.Second, we study the role of network capacity.We find our so-called \\"deep\\" networks are still shallow for the task of adversarial learning.Unlike traditional classification tasks where accuracy is only marginally improved by adding more layers to \\"deep\\" networks (e.g., ResNet-152), adversarial training exhibits a much stronger demand on deeper networks to achieve higher adversarial robustness.This robustness improvement can be observed substantially and consistently even by pushing the network capacity to an unprecedented scale, i.e., ResNet-638.  Adversarial attacks (Szegedy et al., 2014) can mislead neural networks to make wrong predictions by adding human imperceptible perturbations to input data.Adversarial training (Goodfellow et al., 2015) is shown to be an effective method to defend against such attacks, which trains neural networks on adversarial images that are generated on-the-fly during training.Later works further improve robustness of adversarially trained models by mitigating gradient masking (Tramèr et al., 2018) , imposing logits pairing (Kannan et al., 2018) , denoising at feature space (Xie et al., 2019b) , etc.However, these works mainly focus on justifying the effectiveness of proposed strategies and apply inconsistent pipelines for adversarial training, which leaves revealing important elements for training robust models still a missing piece in current adversarial research.In this paper, we provide the first rigorous diagnosis of different adversarial learning strategies, under a unified training and testing framework, on the large-scale ImageNet dataset (Russakovsky et al., 2015) .We discover two intriguing properties of adversarial training, which are essential for training models with stronger robustness.First, though Batch Normalization (BN) (Ioffe & Szegedy, 2015) is known as a crucial component for achieving state-of-the-arts on many vision tasks, it may become a major obstacle for securing robustness against strong attacks in the context of adversarial training.By training such networks adversarially with different strategies, e.g., imposing logits pairing (Kannan et al., 2018) , we observe an unexpected phenomenon -removing clean images from training data is the most effective way for boosting model robustness.We relate this phenomenon to the conjecture that clean images and adversarial images are drawn from two different domains.This two-domain hypothesis may explain the limitation of BN when training with a mixture of clean and adversarial images, as estimating normalization statistics on this mixture distribution is challenging.We further show that adversarial training without removing clean images can also obtain strong robustness, if the mixture distribution is well disentangled at BN by constructing different mini-batches for clean images and adversarial images to estimate normalization statistics, i.e., one set of BNs exclusively for adversarial images and another set of BNs exclusively for clean images.An alternative solution to avoiding mixture distribution for normalization is to simply replace all BNs with batch-unrelated normalization layers, e.g., group normalization (Wu & He, 2018) , where normalization statistics are estimated on each image independently.These facts indicate that model robustness is highly related to normalization in adversarial training.Furthermore, additional performance gain is observed via enforcing consistent behavior of BN during training and testing.Second, we find that our so-called \\"deep\\" networks (e.g., are still shallow for the task of adversarial learning, and simply going deeper can effectively boost model robustness.Experiments show that directly adding more layers to \\"deep\\" networks only marginally improves accuracy for traditional image classification tasks.In contrast, substantial and consistent robustness improvement is witnessed even by pushing the network capacity to an unprecedented scale, i.e., ResNet-638.This phenomenon suggests that larger networks are encouraged for the task of adversarial learning, as the learning target, i.e., adversarial images, is a more complex distribution than clean images to fit.In summary, our paper reveals two intriguing properties of adversarial training: (1) properly handling normalization is essential for obtaining models with strong robustness; and (2) our so-called \\"deep\\" networks are still shallow for the task of adversarial learning.We hope these findings can benefit future research on understanding adversarial training and improving adversarial robustness.In this paper, we reveal two intriguing properties of adversarial training at scale: (1) conducting normalization in the right manner is essential for training robust models on large-scale datasets like ImageNet; and (2) our so-called \\"deep\\" networks are still shallow for the task of adversarial learning.Our discoveries may also be inherently related to our two-domain hypothesis -clean images and adversarial images are drawn from different distributions.We hope these findings can facilitate fellow researchers for better understanding of adversarial training as well as further improvement of adversarial robustness.","answer":"The first rigor diagnose of large-scale adversarial training on ImageNet"},{"question":"Given a short query with keyphrases about a research idea in 2014 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: I want to train a supervised model for image classification on [DATASET] 2012.Keyphrases: image classification imagesDataset description:ImageCLEF-DA: The ImageCLEF-DA dataset is a benchmark dataset for ImageCLEF 2014 domain adaptation challenge, which contains three domains: Caltech-256 (C), ImageNet ILSVRC 2012 (I) and Pascal VOC 2012 (P). For each domain, there are 12 categories and 50 images in each category.ImageNet: The ImageNet dataset contains 14,197,122 annotated images according to the WordNet hierarchy. Since 2010 the dataset is used in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC), a benchmark in image classification and object detection.WebVision: The WebVision dataset is designed to facilitate the research on learning visual representation from noisy web data. It is a large scale web images dataset that contains more than 2.4 million of images crawled from the Flickr website and Google Images search.SNIPS: The SNIPS Natural Language Understanding benchmark is a dataset of over 16,000 crowdsourced queries distributed among 7 user intents of various complexity:   SearchCreativeWork (e.g. Find me the I, Robot television show), GetWeather (e.g.Options:- A: ImageCLEF-DA  B: ImageNet  C: WebVision  D: SNIPS","answer":"ImageNet"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: This model can estimate vehicle poses from surveillance videos and is robust to the variationsKeyphrases: 6-dof pose estimation videoDataset description:KITTI: KITTI (Karlsruhe Institute of Technology and Toyota Technological Institute) is one of the most popular datasets for use in mobile robotics and autonomous driving. It consists of hours of traffic scenarios recorded with a variety of sensor modalities, including high-resolution RGB, grayscale stereo cameras, and a 3D laser scanner.ShapeNet: ShapeNet is a large scale repository for 3D CAD models developed by researchers from Stanford University, Princeton University and the Toyota Technological Institute at Chicago, USA. The repository contains over 300M models with 220,000 classified into 3,135 classes arranged using WordNet hypernym-hyponym relationships.NYU-VP: NYU-VP is a new dataset for multi-model fitting, vanishing point (VP) estimation in this case. Each image is annotated with up to eight vanishing points, and pre-extracted line segments are provided which act as data points for a robust estimator.EYEDIAP: The EYEDIAP dataset is a dataset for gaze estimation from remote RGB, and RGB-D (standard vision and depth), cameras. The recording methodology was designed by systematically including, and isolating, most of the variables which affect the remote gaze estimation algorithms:   Head pose variations.DAWN: DAWN emphasizes a diverse traffic environment (urban, highway and freeway) as well as a rich variety of traffic flow. The DAWN dataset comprises a collection of 1000 images from real-traffic environments, which are divided into four sets of weather conditions: fog, snow, rain and sandstorms.PoseTrack: The PoseTrack dataset is a large-scale benchmark for multi-person pose estimation and tracking in videos. It requires not only pose estimation in single frames, but also temporal tracking across frames.Options:- A: KITTI  B: ShapeNet  C: NYU-VP  D: EYEDIAP  E: DAWN  F: PoseTrack","answer":"[\\"KITTI\\", \\"ShapeNet\\"]"},{"question":"You will be presented with the full text of a science research paper. Please write an abstract for this paper. Your response should include the abstract and no additional text.Paper text:novae near maximum light are so luminous - ranging from m@xmath4 to @xmath5 @xcite - that they can be detected with the _ hubble space telescope _ ( hst ) out to cosmologically interesting distances , beyond the useful ranges of rr lyrae stars , cepheids and planetary nebulae . after the announcement of their discovery in the andromeda galaxy @xcite, @xcite claimed that novae behave as standard candles , with light curves that can be interpreted to yield the distances to their host galaxies .zwicky s initial correlation between the maximum magnitude of a nova and its rate of decline ( now known as the mmrd relation ) , was improved upon by @xcite and @xcite .if the mmrd relation did indeed calibrate novae as standard candles , then they could be used to independently measure distances to galaxies with cepheids .more important , they could determine distances to e.g. elliptical galaxies with no cepheids , to low luminosity dwarf galaxies @xcite , and even to intergalactic tramp novae @xcite which act as tracers of stars unbound to any galaxy .    because it is _not _ just wd mass , but also total accreted envelope mass that control nova tnrs , and because different accretion rates can produce a vast range of accreted envelope masses @xcite , the scatter in the mmrd was predicted to be significant @xcite .the many observed mmrd relations in the literature are summarised in @xcite .it is clear from their figure 17 that the observational scatter in an mmrd plot is far from negligible . with the discovery of faint , fast novae \\" in m31 @xcite and in m87 @xcite , increasing the observed scatter in mmrd plots to 3 magnitudes , it is now evident from observations that the above - noted predictions from theory were correct : the mmrd has no value as a distance indicator @xcite .@xcite reached the same conclusion , based on a smaller and less densely sampled group of nine novae in the virgo cluster elliptical galaxy m49 .fortunately , there is another methodology that has been proposed to use novae as distance indicators .@xcite suggested that all novae reach roughly the same absolute magnitude , @xmath6 , about 15 days after maximum light .the goal of this paper is to use our recently - reported _ hubble space telescope _ ( hst )survey of novae in m87 , and their light curves , to provide the most robust determination of the epochs of minimum scatter , and the values of nova absolute magnitudes at those epochs in two of the most frequently - used hst filters .    in section 2we summarise our observations of well - observed novae in m87 . in section 3we plot the light curves of all m87 novae with well - observed maxima , and the daily standard deviations of those light curves , to demonstrate that the buscombe - de vaucouleurs relation _ is _ a very useful standard candle , and to determine the time and amplitude of its minimum scatter .we compare those results with previous determinations in section 4 , and offer guidelines for optimal use of novae as distance indicators .our results and conclusions are summarised in section 5 .we carried out daily _ hubble space telescope _advanced camera for surveys ( hst / acs ) imaging of the giant elliptical galaxy m87 in the f606w ( @xmath7 band ) and f814w ( @xmath8 band ) filters taken for hst cycle-14 program 10543 ( pi - e. baltz ) over the 72 day interval 24 december 2005 through 5 march 2006 , with a few 5-day gaps at the end of the run .full details of the observations , data reductions , detections and characterisations of 41 variables - 32 certain and 9 likely novae - and their images , and light and color curves , are given in @xcite ( hereafter paper i ) .this survey for extragalactic novae is unprecedented , because hst observations rule out gaps due to weather , and there are no variations in limiting magnitude due to variable seeing or lunar phase .24 of the above noted 41 m87 novae were detected both before and after maximum light , and their brightnesses were measured within 12 hours of maximum light .the numbering of these novae below follows the nomenclature of paper i. our daily sampling over a 10 week span was deep enough to be almost impervious to m87 s background light , revealing novae to within 10 \\" of the galaxy s nucleus .in addition , novae were detected over a nearly 6 magnitude range of brightness , so that even the faintest and fastest of novae were easily detected .the apparent hst f606w and f814w magnitudes of the novae presented in paper i were converted to absolute magnitudes using the distance modulus to m87 derived by @xcite , i.e. ( m - m)@xmath9 .the hst f606w and f814w light curves of 24 novae in m87 with well - defined maxima are shown in figures 1 and 2 respectively .the daily means of those light curves are shown in figure 3 , and the daily standard deviations of the light curves of those same 24 novae are presented in figure 4 .the largest sample of novae studied to measure the absolute magnitudes of novae 15 days after maximum light is due to @xcite . for 46 well - observed novae in m31 , the galaxy , and the magellanic clouds he determined @xmath10 = @xmath11 . @xcite and @xcite used their ground based samples of 11 and 6 galactic novae to determine values of @xmath12 = @xmath13 and @xmath14 , respectively .@xcite used 15 galactic novae to determine @xmath12 = @xmath15 . finally , hst observations of 5 novae in m49 allowed @xcite to measure @xmath16 = @xmath17 .all of the above studies of galactic novae were plagued by ( relatively ) uncertain distances and reddenings , while the sample size of @xcite was only 5 novae .in addition , none of the above studies had cadences dense enough to definitively determine the epoch of minimum scatter of the absolute magnitudes of novae after maximum light .figure 4 yields the most robust determination ever of the epochs of minimum standard deviation of nova light curves . forthe f606w filter the first significant minimum deviation occurs on day 17 ; for the f814w filter the minimum deviation occurs on day 20 .( minor local minima afterwards are ignored ) .this is in very good agreement with the @xcite empirical , photographic determination of minimum deviation at 15 days after maximum light , but our sample is larger , of higher cadence and based on hst ccd magnitudes.we use the m87 distance modulus noted in section 2 , and assume absorptions to m87 of a(v ) = 0.07 and a(i ) = 0.04 .the absolute f606w and f814w magnitudes on those dates , from figure 3 , are then @xmath18 = @xmath1 and @xmath19 = @xmath3 .these values are the key result of this paper . in light of our relatively large sample of m87 novae ,all at the same distance , our dense sampling with no gaps , invariant seeing and immunity to lunar phase , we suggest that our derived values of @xmath18 and @xmath19 are now the most reliable values when using novae as standard candles .using a sample of 24 novae in m87 observed daily with hst , we have determined that the optimal epochs for using novae as distance indicators are at 17 and 20 days after maximum light , when using the hst f606w and f814 filters , respectively .the absolute f606w and f814w magnitudes on those dates are @xmath18 = @xmath1 and @xmath19 = @xmath3 .we gratefully acknowledge the support of the stsci team responsible for ensuring timely and accurate implementation of our m87 program .support for program # 10543 was provided by nasa through a grant from the space telescope science institute , which is operated by the association of universities for research in astronomy , inc ., under nasa contract nas 5 - 26555 . this research has been partly supported by the polish ncn grant dec-2013/10/m / st9/00086 .mms gratefully acknowledges the support of ethel lipsitz and the late hilary lipsitz , longtime friends of the amnh astrophysics department .ap , ag and tm gratefully acknowledge the support of the richard guilder graduate school of the american museum of natural history .jtg thanks the science research and mentoring program of the american museum of natural history for the opportunity to participate in the research described in this paper .arp , h.c .1956 , , 61 , 15 bird , s. , harris , w.  e. , blakeslee , j.  p. , & flynn , c.  2010 , , 524 , a71 buscombe , w. , & de vaucouleurs , g.  1955 , the observatory , 75 , 170 cohen , j.  g.  1985 , , 292 , 90 conroy , c. , & bullock , j.  s.  2015 , , 805 , l2 darnley , m.  j. , henze , m. , bode , m.  f. , et al .2016 , , 833 , 149 downes , r.  a. , & duerbeck , h.  w.  2000 , , 120 , 2007 faulkner , j. , flannery , b.  p. , & warner , b.  1972 , , 175 , l79 ferrarese , l. , ct , p. , & jordn , a.  2003 , , 599 , 1302 hubble , e. 1929 , , 69 , 103 kasliwal , m.  m. , cenko , s.  b. , kulkarni , s.  r. , et al .2011 , , 735 , 94 kovetz , a. , & prialnik , d.  1985 , , 291 , 812 mclaughlin , d.  b.  1945 , , 57 , 69 neill , j.  d. , & shara , m.  m.  2004 , , 127 , 816 pfau , w.  1976 , , 50 , 113 prialnik , d. , & kovetz , a. 1995 , , 445 , 789 schlegel , d.  j. , finkbeiner , d.  p. , & davis , m.  1998 , , 500 , 525 shara , m.  m. , prialnik , d. , & shaviv , g.  1980 , , 239 , 586 shara , m.  m.  2006 , , 131 , 2980 shara , m.  m. , doyle , t.  f. , lauer , t.  r. , et al .2016 , , 227 , 1 ( paper i ) .shara , m.  m. , doyle , t. , lauer , t.  r. , et al .  2017 , arxiv:1702.05788 teyssier , m. , johnston , k.  v. , & shara , m.  m.  2009 , , 707 , l22 van den bergh , s. , & younger , p.  f.  1987 , , 70 , 125 warner , b. 1995 , cataclysmic variable stars , cambridge univ .press , cambridge yaron , o. , prialnik , d. , shara , m.  m. , & kovetz , a.  2005 , , 623 , 398 zwicky , f.  1936 , , 48 , 191","answer":"ten weeks daily imaging of the giant elliptical galaxy m87 with the _ hubble space telescope _ has yielded 41 nova light curves of unprecedented quality for extragalactic cataclysmic variables .  we have recently used these light curves to demonstrate that the observational scatter in the so - called maximum - magnitude rate of decline ( mmrd ) relation for classical novae is so large as to render the nova - mmrd useless as a standard candle . here  we demonstrate that the buscombe - de vaucouleurs hypothesis , that all novae converge to nearly the same absolute magnitude about two weeks after maximum light , is strongly supported by our m87 nova data . for 24 novae in v - band ( f606w filter ) and i - band ( f814w filter ) light with daily - sampled light curves and well determined maxima , we find that the times of minimum scatter of nova absolute magnitude are , respectively , 17 and 20 days after maximum light . at those epochs novae display @xmath0 = @xmath1 and @xmath2 = @xmath3 .  the distances of single novae in the milky way , sparse or elliptical galaxies , or free - floating in intergalactic space can be reasonably well - determined with the above calibrations .     # 1#2#3#4#5#6#7    to#2    ' '' ''"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Drug-drug interactions with Mefloquine have not been explored in detail. There is one report of cardiopulmonary arrest, with full recovery, in a patient who was taking a beta blocker (propranolol). The effects of Mefloquineuine on the compromised cardiovascular system have not been evaluated. The benefits of Mefloquine therapy should be weighed against the possibility of adverse effects in patients with cardiac disease. Because of the danger of a potentially fatal prolongation of the QTc interval, halofantrine must not be given simultaneously with or subsequent to Mefloquine. Concomitant administration of Mefloquine and other related compounds (eg, quinine, quinidine and chloroquine) may produce electrocardiographic abnormalities and increase the risk of convulsions. If these drugs are to be used in the initial treatment of severe malaria, Mefloquine administration should be delayed at least 12 hours after the last dose. There is evidence that the use of halofantrine after Mefloquineuine causes a significant lengthening of the QTc interval. Clinically significant QTc prolongation has not been found with Mefloquineuine alone. This appears to be the only clinically relevant interaction of this kind with Mefloquine, although theoretically, coadministration of other drugs known to alter cardiac conduction (eg, anti-arrhythmic or beta-adrenergic blocking agents, calcium channel blockers, antihistamines or H1-blocking agents, tricyclic antidepressants and phenothiazines) might also contribute to a prolongation of the QTc interval. There are no data that conclusively establish whether the concomitant administration of Mefloquineuine and the above listed agents has an effect on cardiac function. In patients taking an anticonvulsant (eg, valproic acid, carbamazepine, phenobarbital or phenytoin), the concomitant use of Mefloquine may reduce seizure control by lowering the plasma levels of the anticonvulsant. Therefore, patients concurrently taking antiseizure medication and Mefloquine should have the blood level of their antiseizure medication monitored and the dosage adjusted appropriately. When Mefloquine is taken concurrently with oral live typhoid vaccines, attenuation of immunization cannot be excluded. Vaccinations with attenuated live bacteria should therefore be completed at least 3 days before the first dose of Mefloquine. No other drug interactions are known. Nevertheless, the effects of Mefloquine on travelers receiving comedication, particularly diabetics or patients using anticoagulants, should be checked before departure. In clinical trials, the concomitant administration of sulfadoxine and pyrimethamine did not alter the adverse reaction profile.","answer":"{\\"Brand\\": [], \\"Drug\\": [\\"anti-arrhythmic\\", \\"carbamazepine\\", \\"phenobarbital\\", \\"phenytoin\\", \\"sulfadoxine\\", \\"pyrimethamine\\", \\"chloroquine\\", \\"valproic acid\\", \\"quinidine\\", \\"Mefloquine\\", \\"propranolol\\", \\"quinine\\", \\"halofantrine\\"], \\"DrugGroup\\": [\\"anticonvulsant\\", \\"beta blocker\\", \\"tricyclic antidepressants\\", \\"anticoagulants\\", \\"calcium channel blockers\\", \\"phenothiazines\\", \\"antihistamines\\", \\"H1-blocking agents\\", \\"beta-adrenergic blocking agents\\", \\"live typhoid vaccines\\"], \\"UnapprovedDrug\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Naloxone\\", ...], \\"Disease\\" : [\\"Hypotensive\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Flurbiprofen in the treatment of juvenile rheumatoid arthritis. Thirty-four patients with juvenile rheumatoid arthritis, who were treated with flurbiprofen at a maximum dose of 4 mg/kg/day, had statistically significant decreases from baseline in 6 arthritis indices after 12 weeks of treatment. Improvements were seen in the number of tender joints, the severity of swelling and tenderness, the time of walk 50 feet, the duration of morning stiffness and the circumference of the left knee. The most frequently observed side effect was fecal occult blood (25% of patients); however, there was no other evidence of gastrointestinal (GI) bleeding in these patients. One patient was prematurely discontinued from the study for severe headache and abdominal pain. Most side effects were mild and related to the GI tract.","answer":"{\\"Chemical\\": [\\"Flurbiprofen\\", \\"flurbiprofen\\"], \\"Disease\\": [\\"tenderness\\", \\"gastrointestinal (GI) bleeding\\", \\"morning stiffness\\", \\"arthritis\\", \\"abdominal pain\\", \\"juvenile rheumatoid arthritis\\", \\"fecal occult blood\\", \\"headache\\", \\"tender joints\\", \\"swelling\\"]}"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: Disentangling the geometry and appearance representations in the face recognition task.Keyphrases: face recognition imagesDataset description:PASCAL Face: The PASCAL FACE dataset is a dataset for face detection and face recognition. It has a total of 851 images which are a subset of the PASCAL VOC and has a total of 1,341 annotations.MAFL: The MAFL dataset contains manually annotated facial landmark locations for 19,000 training and 1,000 test images.irc-disentanglement: This is a dataset for disentangling conversations on IRC, which is the task of identifying separate conversations in a single stream of messages. It contains disentanglement information for 77,563 messages or IRC.CASIA-WebFace: The CASIA-WebFace dataset is used for face verification and face identification tasks. The dataset contains 494,414 face images of 10,575 real identities collected from the web.Color FERET: The color FERET database is a dataset for face recognition. It contains 11,338 color images of size 512×768 pixels captured in a semi-controlled environment with 13 different poses from 994 subjects.CelebA: CelebFaces Attributes dataset contains 202,599 face images of the size 178×218 from 10,177 celebrities, each annotated with 40 binary labels indicating facial attributes like hair color, gender and age.SentEval: SentEval is a toolkit for evaluating the quality of universal sentence representations. SentEval encompasses a variety of tasks, including binary and multi-class classification, natural language inference and sentence similarity.Options:- A: PASCAL Face  B: MAFL  C: irc-disentanglement  D: CASIA-WebFace  E: Color FERET  F: CelebA  G: SentEval","answer":"[\\"CASIA-WebFace\\", \\"CelebA\\"]"},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: Early Symptoms Of COVID-19 Initial reports stated that COVID-19 symptoms usually take two to 10 days to appear after contracting the virus.Abstract:The outbreak of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) from Wuhan, China in December 2019 leads to the present coronavirus disease 2019 (COVID-19) pandemic.The various symptoms identified for COVID-19 are fever, dry cough, sore throat, dyspnea, fatigue, myalgia, and headache.Olfactory and gustatory dysfunctions are emerging as a new symptom more in the European patients.Taste disturbances are common in various oral and systemic diseases.Varying severity and onset of taste disturbances are reported in COVID-19 positive patients in this pandemic.But a sudden onset of taste disturbances without an established and recognized cause should raise suspicion of COVID-19.This article will analyze the various studies focusing on taste disturbances as a reliable early symptom for COVID-19 screening.","answer":"{\\"verdict\\": \\"NEI\\", \\"evidence\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Protein\\", \\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\" : [\\"Dexamethasone\\", ...], \\"Protein\\" : [\\"BRCA-1\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Impaired function of prejunctional adenosine A1 receptors expressed by perivascular sympathetic nerves in DOCA-salt hypertensive rats.Increased sympathetic nervous system activity contributes to deoxycorticosterone acetate (DOCA)-salt hypertension in rats. ATP and norepinephrine (NE) are coreleased from perivascular sympathetic nerves. NE acts at prejunctional α2-adrenergic receptors (α2ARs) to inhibit NE release, and α2AR function is impaired in DOCA-salt rats. Adenosine, an enzymatic ATP degradation product, acts at prejunctional A1 adenosine receptors (A1Rs) to inhibit NE release. We tested the hypothesis that prejunctional A1R function is impaired in sympathetic nerves supplying mesenteric arteries (MAs) and veins (MVs) of DOCA-salt rats. Electrically evoked NE release and constrictions of blood vessels were studied in vitro with use of amperometry to measure NE oxidation currents and video microscopy, respectively. Immunohistochemical methods were used to localize tyrosine hydroxylase (TH) and A1Rs in perivascular sympathetic nerves. TH and A1Rs colocalized to perivascular sympathetic nerves. Adenosine and N(6)-cyclopentyl-adenosine (CPA, A1R agonist) constricted MVs but not MAs. Adenosine and CPA (0.001-10 µM) inhibited neurogenic constrictions and NE release in MAs and MVs. DOCA-salt arteries were resistant to adenosine and CPA-mediated inhibition of NE release and constriction. The A2A adenosine receptor agonist CGS21680 (C23H29N7O6.HCl.xH2O) (0.001-0.1 μM) did not alter NE oxidation currents. We conclude that there are prejunctional A1Rs in arteries and both pre- and postjunctional A1Rs in veins; thus, adenosine selectively constricts the veins. Prejunctional A1R function is impaired in arteries, but not veins, from DOCA-salt rats. Sympathetic autoreceptor dysfunction is not specific to α2ARs, but there is a more general disruption of prejunctional mechanisms controlling sympathetic neurotransmitter release in DOCA-salt hypertension.","answer":"{\\"Chemical\\": [\\"C23H29N7O6.HCl.xH2O\\", \\"DOCA\\", \\"N(6)-cyclopentyl-adenosine\\", \\"CPA\\", \\"Adenosine\\", \\"ATP\\", \\"tyrosine\\", \\"norepinephrine\\", \\"deoxycorticosterone acetate\\", \\"adenosine\\", \\"CGS21680\\"], \\"Protein\\": [\\"A1R\\", \\"tyrosine hydroxylase\\", \\"A1Rs\\", \\"TH\\", \\"A2A adenosine receptor\\", \\"adenosine A1 receptors\\", \\"u03b12ARs\\", \\"A1 adenosine receptors\\", \\"u03b12-adrenergic receptors\\", \\"u03b12AR\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Home based management in multiple sclerosis : results of a randomised controlled trial . BACKGROUND Home based medical care is a popular alternative to standard hospital care but there is uncertainty about its cost-effectiveness . OBJECTIVES To compare the effectiveness and the costs of multidisciplinary home based care in multiple sclerosis with hospital care in a prospective randomised controlled trial with a one year follow up . METHODS 201 patients with clinically definite multiple sclerosis were studied . They were randomised in a ratio 2:1 to an intervention group ( 133 ) or a control group ( 68 ) . They were assessed at baseline and one year after randomisation with validated measures of physical and psychological impairment and quality of life ( SF-36 health survey ) . The costs to the National Health Service over the one year follow up were calculated by a cost minimisation analysis . RESULTS There were no differences in functional status between the home based care group and the hospital group . There was a significant difference between the two groups favouring home based management in four SF-36 health dimensions-general health , bodily pain , role-emotional , and social functioning ( all p < or = 0.001 ) . The cost of home based care was slightly less ( 822 euros/patient/year ) than hospital care , mainly as a result of a reduction in hospital admissions . CONCLUSIONS Comprehensive planning of home based intervention implemented by an interdisciplinary team and designed specifically for people with multiple sclerosis may provide a cost-effective approach to management and improve the quality of life .","answer":"{\\"Intervention\\": [\\"Comprehensive planning of home based intervention\\", \\"Home based management\\", \\"multidisciplinary home based care\\", \\"Home based medical care\\"], \\"Outcome\\": [\\"cost-effectiveness .\\", \\"cost-effective\\", \\"functional status\\", \\"costs to the National Health Service over the one year follow up\\", \\"cost\\", \\"effectiveness and the costs\\", \\"quality of life\\", \\"four SF-36 health dimensions-general health , bodily pain , role-emotional , and social functioning\\", \\"validated measures of physical and psychological impairment and quality of life ( SF-36 health survey ) .\\"], \\"Participant\\": [\\"multiple sclerosis\\", \\"201\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Arsenic\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Two Dimensional Window Exchange Umbrella Sampling for Transmembrane Helix Assembly. The method of window exchange umbrella sampling molecular dynamics (WEUSMD) with a pre-optimized parameter set was recently used to obtain the most probable conformations and the energetics of transmembrane (TM) helix assembly of a generic TM sequence. When applied to glycophorin A TM domain (GpA-TM) using the restraint potentials along the helix-helix distance, however, tight interfacial packing of GpA-TM resulted in insufficient conformational sampling at short helix-helix separation. This sampling issue is addressed by extending the WEUSMD into two dimensions with the restraint potentials along the helix-helix distance and crossing angle. The two-dimensional WEUSMD results demonstrate that the incomplete sampling in the one-dimensional WEUSMD arises from high barriers along the crossing angle between the GpA-TM helices. Together with the faster convergence in both the assembled conformations and the potential of mean force, the 2D-WEUSMD can be a general and efficient approach in computational studies of TM helix assembly.","answer":"{\\"Chemical\\": []}"},{"question":"You will be shown the title of a chemistry paper, together with sections excerpted from the body of the paper. The paper sections may include HTML tags like \`<p>\` and \`</p>\`; please ignore these. Your task is to write an abstract for the paper. Your response should include the abstract and no other text.Title:MDockPeP: An ab-initio protein-peptide docking serverPaper sections:Introduction<p>Protein-peptide interactions are crucial to a variety of cellular processes including transcription regulation, signal transductions and immune response [1]. An increasing number of peptides have been designed and approved as drugs [2]. The structure of the protein-peptide complex is a key to understand the underlying mechanism of the protein-peptide interaction, and is therefore critical for peptide therapeutic development. Yet, the number of the resolved protein-peptide complex structures deposited in the Protein Data Bank (PDB) [3] is only a fraction of the whole protein-peptide interaction universe, due to the difficulty and cost for determining complex structures by experimental techniques such as X-ray crystallography and NMR.</p><p>Facing this challenge, several in silico methods have recently been developed for predicting protein-peptide complex structures and can be categorized into three classes: template-based modeling, molecular docking, and molecular dynamics (MD) simulation. The template-based methods are computationally efficient, but suffer from limited available protein-peptide templates [4–5]. On the other hand, regarding MD simulations, impractically expensive computational cost is the major stumbling block to their large-scale applications [6–7]. Molecular docking is a compromising strategy, which aims to account for both accuracy and computational efficiency. Among the recently developed docking methods, Rosetta FlexPepDock [8] and HADDOCK [9] focus on local docking with known binding sites. pepATTRACT [10] and AnchorDock [11] start with crudely sampling the whole protein surface, followed by extremely time-consuming MD refinement. The CABS-dock server [12] has the ability to dock a fully flexible peptide onto the whole protein surface within reasonable computational time. It uses a coarse-grained model for both the protein and the peptide; the peptide secondary structure either is provided by the user or is generated by PSI-PRED, a protein secondary structure prediction tool. PIPER-FlexPepDock [13] is another approach that performs the global blind docking. Briefly, a number of pre-generated peptide conformers are docked to a whole protein surface using a rigid sampling algorithm, and then the selected models are refined by considering the peptide flexibility and the protein sidechain flexibility. A thorough summary of state-of-the-art in the field can be found in a very recent review [14].</p><p>We recently developed a novel, ab initio protein-peptide docking method, referred to as MDockPeP [15]. The method starts with a given peptide sequence and a protein structure, and globally docks the all-atom, flexible peptide to the protein (Fig. 1). MDockPeP was systematically validated and achieved good performance based on the peptiDB benchmarking database [9,16]. Here, we present the MDockPeP Server, which is free and open to all users without registration. The server can be used for both protein-peptide complex structure prediction and initial-stage sampling of the protein-peptide binding modes for other docking or simulation methods.</p>Overview of MDockPeP<p>Here, we briefly introduce the MDockPeP method; the details are available in our recently published paper [15]. MDockPeP includes three primary stages (Fig. 1):</p><p>Model the peptide conformers based on the given peptide sequence;</p><p>Sample putative peptide binding modes on the whole protein surface;</p><p>Rank the sampled binding modes according to their energy scores with our newly derived scoring function for protein-peptide docking.</p>Overview of MDockPeP<p>For a given peptide sequence, first, MDockPeP models up to 3 non-redundant conformers based on the similar-sequence fragments from monomeric proteins with lengths longer than 50 amino acids. This strategy is based on the argument that binding of a peptide on a protein is similar to the protein folding process and that protein-peptide binding interfaces share remarkable similarities with the interior of proteins [17]. Our systematic assessment showed that the modeled peptide conformer was within 5.3 Å of the backbone RMSD (bRMSD) in comparison with the bound peptide structure when the best conformer among the top 3 peptide models was considered [15], for the 103 non-redundant peptides in the peptiDB benchmarking database [9,16].</p><p>Next, the modeled peptide conformers are independently docked to the whole protein using a method modified from AutoDockVina [18]. The grid box was defined by extending 20 Å to both the minimum and the maximum of the coordinates of the protein structure in three dimensions. First, the peptide conformer is rigidly docked to the whole protein by randomly generating 105 translational and rotational configurations within the grid box. The generated models are ranked by the built-in Vina scoring function. Then, flexible sampling is performed for the model that has the lowest score. All rotatable bonds in the peptide are treated as flexible during sampling, by using the iterated local search (ILS) global optimizer approach in AutoDock Vina. If the peptide conformation of a Vina-accepted mode strays too far from the initial peptide conformer (e.g., with bRMSD > 5.5 Å), the rigid global sampling process will be repeated for the initial peptide conformer, followed by flexible sampling. The procedure stops when the maximum step number for ILS, N, is reached. N is dependent on both the number of torsional angles and the number of the movable atoms. The exhaustiveness value in Vina is set to 100 for the MDockPeP server, which means 100 independent runs are performed for each docking. Finally, up to 2×104 binding modes are generated for each initial peptide conformer.</p><p>These binding modes generated from different initial peptide conformers are combined and ranked according to their energy scores calculated by our recently developed scoring function ITScorePeP [15]. ITScorePeP is a statistical potential-based scoring function that is developed for protein-peptide dockings. Contributions from both interactions between the protein and the peptide (inter-score) and interactions among non-neighbored residues within the peptide (intra-score) are considered in the scoring function. For any two modes with ligand RMSD (Lrms) less than a cutoff, only the one with the lower score is kept. Lrms is calculated based on the backbone atoms of the peptide between the predicted binding mode and the native binding mode after the optimal superimposition of the protein structures. The cutoff is set to 4.0 Å for the prediction of top 10 models. For the enrichment of high-quality models (Lrms ≤ 3.0 Å) in top 500 models that are provided to the user as the sampling results, the cutoff is set to 2.0 Å.</p>The peptiDB benchmarking database<p>The non-redundant protein-peptide database peptiDB was employed to validate the MDockPeP Server. After the examination of the 103 bound protein-peptide complex structures and 69 unbound protein receptor structures, 3 bound complexes and 5 unbound protein receptors were discarded from the database [15]. The remaining entries, 100 bound cases and 64 unbound cases (see Table S1) were used to evaluate the sampling performance of the MDockPeP Server. The results in this study are slightly different from our original paper (Fig. 5 in ref. 14), in which the binding modes were sampled more exhaustively at a cost of longer computational time.</p>Inputs<p>As shown in Fig. 2A, two inputs, a peptide sequence and a protein structure, are required for job submission on the MDockPeP Server. The email address is optional but recommended. If the email address is provided, the user will receive an email notification after the job is completed.</p>Advanced options<p>The MDockPeP Server provides several advanced options for the user to improve prediction results (as shown in Fig. 2B).</p><p>First, the server allows the user to upload one initial peptide 3D structure. The server will generate up to two other initial peptide conformers. As the peptide conformation during sampling is restricted to be relatively close to the initial peptide conformation, a reliable initial peptide structure would significantly reduce the search space and improve the prediction. Furthermore, the user is also allowed to control the degree of restriction of the peptide conformations in the sampling process by changing the cutoff value (default = 5.5 Å) of the backbone RMSD (bRMSD).</p><p>Another option is the exhaustiveness value. By increasing the exhaustiveness value, a larger conformational space can be reached during the sampling process at the cost of the increase in computational time. The default exhaustiveness value is set to 100, namely, each docking calculation (docking one initial peptide conformer onto the protein) contains 100 independent runs.</p><p>In addition, the user is allowed to define a binding location by providing the XYZ coordinates of the center of the grid box. The box (cubic) size will be automatically determined according to the peptide length. Specifically, the side of the cubic box equals (3.8×peptide_sequence_length+40) Å. The value 3.8 is the distance between two CA atoms in adjacent residues. This option is recommended for a large protein receptor with known binding location.</p>Outputs<p>Once a job is submitted successfully, the job status is monitored on the \\"Queue\\" page. If the email address is given, the user will receive an email notification with a link of the results after the job is completed. As shown in Fig. 2C, the top 10 predicted protein-peptide complex structures are displayed via 3Dmol.js [19] on the result page. In addition, top 500 predicted protein-peptide binding modes are provided as the initial sampling results.</p>Computational resources and run time<p>Jobs being submitted are performed on a computing node containing 24 Intel Xeon cores [Intel(R) Xeon(R) CPU E5–2650 v3 @ 2.30GHz]. For our test on the peptiDB database, the MDockPeP server normally takes less than 10 hours for a job depending on the length of the peptide and the size of the protein.</p>Performance<p>The MDockPeP Server was assessed with a non-redundant protein-peptide benchmarking database peptiDB (Table S1). As shown in Fig. 3A, the MDockPeP server successfully predicted at least one near-native (Lrms ≤ 5.5 Å) mode among the top 10 models for 59% of the bound docking cases (high quality model with Lrms ≤ 3.0 Å: 36%; medium quality model with 3.0 Å < Lrms ≤ 5.5 Å: 23%), and for 40.6% of the more challenging unbound docking cases (high quality: 3.1%; medium quality: 37.5%). Here, Lrms is the ligand RMSD, which is calculated based on the backbone atoms of the peptide between the predicted binding mode and the native binding mode after optimal superimposition of the protein structures.</p><p>Fig. 3B shows the rates for successfully ranking at least one near-native mode among the top N models. Impressively, bound docking achieved a high success rate of 77% when top 100 models were considered. The success rate decreased to 60.9% for the challenging unbound docking cases. For enrichment studies (see Fig. 3C), when considering the top 500 models that are provided for the user in the sampling results, the successful rate is 85% for bound docking cases (high quality: 65%; medium quality: 20%), and 71.9% for the unbound docking cases (high quality: 36%; medium quality: 36.9%).</p>Discussion<p>In our previous MDockPeP method paper [15], we analyzed the relationship between the best sampled binding mode (the mode with the lowest Lrms) and bRMSD of the best modeled peptide conformer. Because a smaller exhaustiveness value (100) was used for the web server than the exhaustive value for the method paper (500), we re-calculated the correlations. Fig. 4A and 4B show the results for the bound docking cases and the unbound docking cases, respectively. Similar to those observed in the method paper, Lrms and bRMSD show very weak correlations, with Pearson correlation coefficients of 0.19 (for bpro-upep) and 0.14 (for upro-upep), respectively. Encouragingly, our sampling method successfully generated medium-quality or even high-quality models for several cases in which no high-quality peptide conformers were modeled (using bRMSD = 4.0 Å as the threshold).</p><p>Fig. 4C and 4D show the dependence of the sampling performance on the peptide size for the bound docking cases and the unbound docking cases, respectively. The peptide lengths in the peptiDB benchmark range from 5 to 15. MDockPeP was able to generate high-quality models (Lrms ≤ 3Å) for most cases with short- or medium-size peptides (less than 12 residues). For a number of cases with peptide length ≥ 12, our method failed to generate high-quality models or even medium-quality models. This is reasonable, because long peptides typically contain more rotatable bonds than short peptides and therefore require larger conformational spaces for sampling. Another concern is the use of the same Lrms threshold for different peptide lengths. It is well known that the RMSD value is dependent of the size of a ligand [20]. How to normalize the RMSD value based on the ligand size remains an open question.</p><p>It is further noted that to optimize the performance of the MDockPeP server for users, the whole peptiDB database were used for the training of the scoring function. Overfitting is not expected to be an issue, because in our method paper [15] 3-fold cross-validation was used to assess the scoring function to avoid overlap between the training set and the test set; no significant difference was found between the two scoring performances. In both scoring studies, the success rate of unbound docking is significantly lower than the success rate of bound docking. A possible reason is that the decoys used in the training process were generated using bound protein structures and the protein structures were treated as rigid bodies in the sampling process. The scoring function needs to be improved in future studies.</p>Conclusion<p>The MDockPeP Server provides a useful and efficient means to produce models of protein-peptide complexes via a user-friendly web interface. The server can be used for both protein-peptide complex structure prediction and initial-stage sampling of the protein-peptide binding modes for other docking or simulation methods.</p>","answer":"Protein-peptide interactions play a crucial role in a variety of cellular processes. The protein-peptide complex structure is a key to understand the mechanisms underlying protein-peptide interactions and is critical for peptide therapeutic development. We present a user-friendly protein-peptide docking server, MDockPeP. Starting from a peptide sequence and a protein receptor structure, the MDockPeP Server globally docks the all-atom, flexible peptide to the protein receptor. The produced modes are then evaluated with a statistical potential-based scoring function, ITScorePeP. This method was systematically validated using the peptiDB benchmarking database. At least one near-native peptide binding mode was ranked among top 10 (or top 500) in 59% (85%) of the bound cases, and in 40.6% (71.9%) of the challenging unbound cases. The server can be used for both protein-peptide complex structure prediction and initial-stage sampling of the protein-peptide binding modes for other docking or simulation methods. MDockPeP Server is freely available at http://zougrouptoolkit.missouri.edu/mdockpep."},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: I want to build an open-domain QA system that performs better than the state of theKeyphrases: open-domain question answering textDataset description:ARC: The AI2’s Reasoning Challenge (ARC) dataset is a multiple-choice question-answering dataset, containing questions from science exams from grade 3 to grade 9. The dataset is split in two partitions: Easy and Challenge, where the latter partition contains the more difficult questions that require reasoning.TechQA: TECHQA is a domain-adaptation question answering dataset for the technical support domain. The TECHQA corpus highlights two real-world issues from the automated customer support domain.SQuAD: The Stanford Question Answering Dataset (SQuAD) is a collection of question-answer pairs derived from Wikipedia articles. In SQuAD, the correct answers of questions can be any sequence of tokens in the given text.LogiQA: LogiQA consists of 8,678 QA instances, covering multiple types of deductive reasoning. Results show that state-of-the-art neural models perform by far worse than human ceiling.RiSAWOZ: RiSAWOZ is a large-scale multi-domain Chinese Wizard-of-Oz dataset with Rich Semantic Annotations. RiSAWOZ contains 11.2K human-to-human (H2H) multi-turn semantically annotated dialogues, with more than 150K utterances spanning over 12 domains, which is larger than all previous annotated H2H conversational datasets.HotpotQA: HotpotQA is a question answering dataset collected on the English Wikipedia, containing about 113K crowd-sourced questions that are constructed to require the introduction paragraphs of two Wikipedia articles to answer. Each question in the dataset comes with the two gold paragraphs, as well as a list of sentences in these paragraphs that crowdworkers identify as supporting facts necessary to answer the question.Options:- A: ARC  B: TechQA  C: SQuAD  D: LogiQA  E: RiSAWOZ  F: HotpotQA","answer":"[\\"ARC\\", \\"SQuAD\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Arsenic\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Influence of gas phase equilibria on the chemical vapor deposition of graphene. We have investigated the influence of gas phase chemistry on the chemical vapor deposition of graphene in a hot wall reactor. A new extended parameter space for graphene growth was defined through literature review and experimentation at low pressures (≥0.001 mbar). The deposited films were characterized by scanning electron microscopy, Raman spectroscopy, and dark field optical microscopy, with the latter showing promise as a rapid and nondestructive characterization technique for graphene films. The equilibrium gas compositions have been calculated across this parameter space. Correlations between the graphene films grown and prevalent species in the equilibrium gas phase revealed that deposition conditions associated with a high acetylene equilibrium concentration lead to good quality graphene deposition, and conditions that stabilize large hydrocarbon molecules in the gas phase result in films with multiple defects. The transition between lobed and hexagonal graphene islands was found to be linked to the concentration of the monatomic hydrogen radical, with low concentrations associated with hexagonal islands.","answer":"{\\"Chemical\\": [\\"graphene\\", \\"hydrogen\\", \\"hydrocarbon\\", \\"acetylene\\"]}"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:experimentsContext before the citation:To address this inconsistency in the correspondence between inflectional features and morphemes, and inspired by SmrÅ¾ (2007), we distinguish between two types of inflectional features: formbased (a.k.a. surface, or illusory) features and functional features.6 Most available Arabic NLP tools and resources model morphology using formbased (âsurfaceâ) inflectional features, and do not mark rationality; this includes the Penn Arabic Treebank (PATB) (Maamouri et al. 2004), the Buckwalter morphological analyzer (Buckwalter 2004), and tools using them such as the Morphological Analysis and Disambiguation for Arabic (MADA) toolkit (Habash and Rambow 2005; Habash, Rambow, and Roth 2012). A similar inconsistency appears in feminine nominals that are not inflected using sound gender suffixes, for example, the feminine form of the masculine singular adjective S,  ï¿½ï¿½l Ãzraq+Ï (âblueâ) is Abj zarqAâ+Ï not U, j ï¿½l* *Ãzraq+ah. This irregular inflection, known as broken plural, is similar to the English mouse/mice, but is much more common in Arabic (over 50% of plurals in our training data).Citation Sentence:To address this inconsistency in the correspondence between inflectional features and morphemes , and inspired by SmrÅ¾ ( 2007 ) , we distinguish between two types of inflectional features : formbased ( a.k.a. surface , or illusory ) features and functional features .6 Most available Arabic NLP tools and resources model morphology using formbased ( \`\` surface '' ) inflectional features , and do not mark rationality ; this includes the Penn Arabic Treebank ( PATB ) ( Maamouri et al. 2004 ) , the Buckwalter morphological analyzer ( Buckwalter 2004 ) , and tools using them such as the Morphological Analysis and Disambiguation for Arabic ( MADA ) toolkit ( Habash and Rambow 2005 ; Habash , Rambow , and Roth 2012 ) .Context after the citation:The Elixir-FM analyzer (SmrÅ¾ 2007) readily provides the \\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000\\u0000 4 PATB-tokenized words; see Section 2.5. 5 We ignore duals, which are regular in Arabic, and case/state variations in this discussion for simplicity. 6 Note that the functional and form-based feature values for verbs always coincide.","answer":"CompareOrContrast"},{"question":"You will be shown biomedical passages and your task is to the answer the provided question. Provide a concise and accurate response and do not include any additional text in the response other than the answer.Question: What is the function of the HSJ1 proteins?Context: HSJ1 (DNAJB2), a member of the DNAJ family of molecular chaperones, is a key player in neuronal proteostasis maintenance.HSJ1 is a neuronal enriched member of the HSP40/DNAJ co-chaperone family. Previous studies have shown that HSP40 proteins play a crucial role in protein aggregation and neurodegeneration in several neuronal types, in animal models and human diseases.Homo sapiens J domain protein (HSJ1) is a J-domain containing co-chaperone that is known to stimulate ATPase activity of HSP70 chaperone, while it also harbors two ubiquitin (Ub)-interacting motifs (UIMs) that may bind with ubiquitinated substrates and potentially function in protein degradation.","answer":"HSJ1 are chaperones."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Intravenous ranitidine was shown to double the bioavailability of oral alendronate. The clinical significance of this increased bioavailability and whether similar increases will occur in patients given oral H2-antagonists is unknown; no other specific drug interaction studies were performed. Products containing calcium and other multivalent cations likely will interfere with absorption of alendronate.","answer":"{\\"Brand\\": [], \\"Drug\\": [\\"multivalent cations\\", \\"calcium\\", \\"alendronate\\", \\"ranitidine\\"], \\"DrugGroup\\": [\\"H2-antagonists\\"], \\"UnapprovedDrug\\": []}"},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(PURPOSE) Minority patients with cancer experience worse control of their pain than do their white counterparts. This disparity may, in part, reflect more miscommunication between minority patients and their physicians. Therefore, we examined whether patient coaching could reduce disparities in pain control in a secondary analysis of a randomized controlled trial.(METHODS) Sixty-seven English-speaking adult cancer outpatients, including 15 minorities, with moderate pain over the prior 2 weeks were randomly assigned to the experimental (N = 34) or control group (N = 33). Experimental patients received a 20-minute individualized education and coaching session to increase knowledge of pain self-management, to redress personal misconceptions about pain treatment, and to rehearse an individually scripted patient-physician dialog about pain control. The control group received standardized information on controlling pain. Data on average pain (0-10 scale) were collected at enrollment and 2-week follow-up.(RESULTS) At enrollment, minority patients had significantly more pain than their white counterparts (6.0 vs 5.0, P = 0.05). At follow-up, minorities in the control group continued to have more pain (6.4 vs 4.7, P = 0.01), whereas in the experimental group, disparities were eliminated (4.0 vs 4.3, P = 0.71). The effect of the intervention on reducing disparities was significant (P = 0.04).Question:Can patient coaching reduce racial/ethnic disparities in cancer pain control?Answer:","answer":"YES"},{"question":"You will be presented a sentence from biomedical research text. Extract all terms that correspond to chemical entities of biological interest (ChEBI).Return your identified terms in a JSON array, formatted like this: [\\"Entity1\\", \\"Entity2\\", ...].If no such entities are detected, respond by providing an empty JSON array [].Biomedical context:Thegraphsdepictbloodglucoselevels+/-SEMinPGC-1alpha-/-miceduringGTT(leftgraph)andITT(rightgraph)studies.","answer":"[\\"glucose\\"]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"HealthCareActivity\\", \\"InjuryOrPoisoning\\", \\"BodySubstance\\", \\"IntellectualProduct\\", \\"AnatomicalStructure\\", \\"SpatialConcept\\", \\"Chemical\\", \\"Bacterium\\", \\"MedicalDevice\\", \\"Organization\\", \\"BiomedicalOccupationOrDiscipline\\", \\"Finding\\", \\"BiologicFunction\\", \\"Virus\\", \\"ResearchActivity\\", \\"ClinicalAttribute\\", \\"PopulationGroup\\", \\"Eukaryote\\", \\"BodySystem\\", \\"Food\\", \\"ProfessionalOrOccupationalGroup\\"].Please return the output as a JSON object of the format: {\\"Virus\\": [\\"HIV\\", ...], \\"Bacterium\\": [\\"MRSA\\", ...], \\"AnatomicalStructure\\": [\\"Lung\\", ...], \\"BodySystem\\": [\\"CNS\\", ...], \\"BodySubstance\\": [\\"Serum\\", ...], \\"Finding\\": [\\"Headache\\", ...], \\"InjuryOrPoisoning\\": [\\"Fracture\\", ...], \\"BiologicFunction\\": [\\"Death\\", ...], \\"HealthCareActivity\\": [\\"Biopsy\\", ...], \\"ResearchActivity\\": [\\"Clinical trial\\", ...], \\"MedicalDevice\\": [\\"Lenses\\", ...], \\"SpatialConcept\\": [\\"Camps\\", ...], \\"BiomedicalOccupationOrDiscipline\\": [\\"Forensic medicine\\", ...], \\"Organization\\": [\\"WHO\\", ...], \\"ProfessionalOrOccupationalGroup\\": [\\"Provider\\", ...], \\"PopulationGroup\\": [\\"Swimmers\\", ...], \\"Chemical\\": [\\"Gold\\", ...], \\"Food\\": [\\"Rice\\", ...], \\"IntellectualProduct\\": [\\"RPAM\\", ...], \\"ClinicalAttribute\\": [\\"Biomarker\\", ...], \\"Eukaryote\\": [\\"Dogs\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:A sequential approach with imatinib, chemotherapy and transplant for adult Ph+ acute lymphoblastic leukemia. Final results of the GIMEMA LAL 0904 study In the GIMEMA LAL 0904 protocol, adult Ph+ acute lymphoblastic leukemia patients were treated with chemotherapy for induction and consolidation, followed by maintenance with imatinib. The protocol was subsequently amended and imatinib was incorporated in the induction and post - remission phase together with chemotherapy. Due to the toxicity of this combined approach, the protocol was further amended to a sequential scheme based on imatinib plus steroids as induction, followed by consolidation with chemotherapy plus imatinib and, when applicable, by a hematopoietic stem cell transplant. Fifty-one patients (median age: 45.9 years) were enrolled in the final sequential protocol, hereby reported. At the end of induction (day +50), 96% of evaluable patients (n=49) achieved a complete hematologic remission; after consolidation, all were in complete hematologic remission. No deaths in induction were recorded. Overall survival and disease-free survival at 60 months are 48.8% and 45.8%, respectively. At day +50 (end of the imatinib induction), a log - reduction of BCR-ABL1 levels >1.3 was associated with a significantly more prolonged disease-free survival (55.6%, C.I. 95%: 39.0-79.3 vs 20%, C.I. 95%: 5.8-69.1; p =0.03), overall survival (59.1%, C.I. 95%: 42.3-82.6 vs 20%, C.I. 95%: 5.8-69.1, p =0.02) and lower relapse incidence (20.5%, C.I. 95%: 7.2-38.6 vs 60.0%, C.I. 95%: 21.6-84.3, p =0.01). Mean BCR-ABL1 levels remained significantly higher in patients who subsequently relapsed. Finally, BCR-ABL1p190 patients showed a significantly faster molecular response than BCR-ABL1p210 patients (p =0.023). Thought the study was not powered to evaluate the role of allogeneic stem cell transplant, allografting positively impacted on overall survival and disease-free survival. A sequential approach with imatinib alone in induction, consolidated by chemotherapy plus imatinib followed by a stem cell transplant is a feasible, well-tolerated and effective strategy for adult Ph+ acute lymphoblastic leukemia, leading to the best long-term survival rates so far reported. Trial ID: NCT00458848.","answer":"{\\"AnatomicalStructure\\": [], \\"Bacterium\\": [], \\"BiologicFunction\\": [\\"Ph+ acute lymphoblastic leukemia\\"], \\"BiomedicalOccupationOrDiscipline\\": [], \\"BodySubstance\\": [], \\"BodySystem\\": [], \\"Chemical\\": [\\"imatinib\\", \\"BCR-ABL1p190\\", \\"steroids\\", \\"BCR-ABL1p210\\", \\"BCR-ABL1\\"], \\"ClinicalAttribute\\": [], \\"Eukaryote\\": [], \\"Finding\\": [\\"deaths\\", \\"results\\", \\"remission phase\\", \\"hematologic remission\\", \\"molecular response\\", \\"transplant\\"], \\"Food\\": [], \\"HealthCareActivity\\": [\\"reported\\", \\"stem cell transplant\\", \\"consolidation\\", \\"allogeneic stem cell transplant\\", \\"hematopoietic stem cell transplant\\", \\"chemotherapy\\", \\"allografting\\", \\"induction\\", \\"consolidated\\", \\"GIMEMA LAL 0904 study\\", \\"evaluate\\"], \\"InjuryOrPoisoning\\": [\\"toxicity\\"], \\"IntellectualProduct\\": [\\"GIMEMA LAL 0904 protocol\\", \\"protocol\\"], \\"MedicalDevice\\": [], \\"Organization\\": [], \\"PopulationGroup\\": [], \\"ProfessionalOrOccupationalGroup\\": [], \\"ResearchActivity\\": [\\"study\\"], \\"SpatialConcept\\": [\\"approach\\"], \\"Virus\\": []}"},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: This paper addresses the ReID problem with illumination variations and names it as {emKeyphrases: person re-identification imagesDataset description:Market-1501: Market-1501 is a large-scale public benchmark dataset for person re-identification. It contains 1501 identities which are captured by six different cameras, and 32,668 pedestrian image bounding-boxes obtained using the Deformable Part Models pedestrian detector.AVA-LAEO: Dataset to address the problem of detecting people Looking At Each Other (LAEO) in video sequences.ParCorFull: ParCorFull is a parallel corpus annotated with full coreference chains that has been created to address an important problem that machine translation and other multilingual natural language processing (NLP) technologies face -- translation of coreference across languages. This corpus contains parallel texts for the language pair English-German, two major European languages.COG: A configurable visual question and answer dataset (COG) to parallel experiments in humans and animals. COG is much simpler than the general problem of video analysis, yet it addresses many of the problems relating to visual and logical reasoning and memory -- problems that remain challenging for modern deep learning architectures.Options:- A: Market-1501  B: AVA-LAEO  C: ParCorFull  D: COG","answer":"Market-1501"},{"question":"Below is an abstract from a computer science research paper. Given this abstract, your task is to extract all unique relationships between entities of the following types:- \\"USED-FOR\\": For instance, \\"Our method models user proficiency\\" -> [\\"method\\", \\"user proficiency\\", \\"USED-FOR\\"].- \\"EVALUATE-FOR\\": For instance, \\"We evaluate our method using F1-measure\\" -> [\\"F1-measure\\", \\"method\\", \\"EVALUATE-FOR\\"].- \\"FEATURE-OF\\": For instance, \\"prior knowledge of the model\\" -> [\\"prior knowledge\\", \\"model\\", \\"FEATURE-OF\\"].- \\"HYPONYM-OF\\": For instance, \\"TUIT is a software library\\" -> [\\"TUIT\\", \\"software library\\", \\"HYPONYM-OF\\"].- \\"PART-OF\\": For instance, \\"We incorporate NLU module into the system.\\" -> [\\"NLU module\\", \\"system\\", \\"PART-OF\\"].- \\"COMPARE\\": For instance, \\"Unlike the quantitative prior, the qualitative prior is often ignored\\" -> [\\"quantitative prior\\", \\"qualitative prior\\", \\"COMPARE\\"].- \\"CONJUNCTION\\": For instance: \\"obtained from human expert or knowledge base\\" -> [\\"human expert\\", \\"knowledge base\\", \\"CONJUNCTION\\"].Format your output as a json array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<Entity_B>\\", \\"<RELATION_A_B>\\"]. An example output might look like:[[\\"neural networks\\", \\"classification\\", \\"USED-FOR\\"], [\\"neuron\\", \\"neural network\\", \\"PART-OF\\"]].If no relations are found, please return an empty array [].Abstract:The paper proposes and empirically motivates an integration of supervised learning with unsupervised learning to deal with human biases in summarization. In particular, we explore the use of probabilistic decision tree within the clustering framework to account for the variation as well as regularity in human created summaries. The corpus of human created extracts is created from a newspaper corpus and used as a test set. We build probabilistic decision trees of different flavors and integrate each of them with the clustering framework. Experiments with the corpus demonstrate that the mixture of the two paradigms generally gives a significant boost in performance compared to cases where either ofthe two is considered alone.","answer":"[[\\"supervised learning\\", \\"human biases in summarization\\", \\"USED-FOR\\"], [\\"unsupervised learning\\", \\"supervised learning\\", \\"CONJUNCTION\\"], [\\"unsupervised learning\\", \\"human biases in summarization\\", \\"USED-FOR\\"], [\\"newspaper corpus\\", \\"corpus of human created extracts\\", \\"USED-FOR\\"], [\\"clustering framework\\", \\"probabilistic decision trees\\", \\"CONJUNCTION\\"], [\\"clustering framework\\", \\"probabilistic decision tree\\", \\"FEATURE-OF\\"]]"},{"question":"Below are the abstract, introduction, and conclusion of a computer science research paper. Please summarize the main contribution of the work in a single sentence. Your response should include the summary and no additional text.Paper text:We describe techniques for training high-quality image denoising models that require only single instances of corrupted images as training data.Inspired by a recent technique that removes the need for supervision through image pairs by employing networks with a \\"blind spot\\" in the receptive field, we address two of its  shortcomings: inefficient training and poor final denoising performance.This is achieved through a novel blind-spot convolutional network architecture that allows efficient self-supervised training, as well as application of Bayesian distribution prediction on output colors.Together, they bring the self-supervised model on par with fully supervised deep learning techniques in terms of both quality and training speed in the case of i.i.d. Gaussian noise.Denoising, the removal of noise from images, is a major application of deep learning.Several architectures have been proposed for general-purpose image restoration tasks, e.g., U-Nets BID13 , hierarchical residual networks BID11 , and residual dense networks BID17 .Traditionally, the models are trained in a supervised fashion with corrupted images as inputs and clean images as targets, so that the network learns to remove the corruption.BID9 introduced NOISE2NOISE training, where pairs of corrupted images are used as training data.They observe that when certain statistical conditions are met, a network faced with the impossible task of mapping corrupted images to corrupted images learns, loosely speaking, to output the \\"average\\" image.For a large class of image corruptions, the clean image is a simple per-pixel statistic -such as mean, median, or mode -over the stochastic corruption process, and hence the restoration model can be supervised using corrupted data by choosing the appropriate loss function to recover the statistic of interest.While removing the need for clean training images, NOISE2NOISE training still requires at least two independent realizations of the corruption for each training image.While this eases data collection significantly compared to noisy-clean pairs, large collections of (single) poor images are still much more widespread.This motivates investigation of self-supervised training: how much can we learn from just looking at bad data?While foregoing supervision would lead to the expectation of some regression in performance, can we make up for it by making stronger assumptions about the corruption process?In this paper, we show that under the assumption of additive Gaussian noise that is i.i.d. between pixels, no concessions in denoising performance are necessary.We draw inspiration from the recent NOISE2VOID (N2V) training technique of BID7 .The algorithm needs no image pairs, and uses just individual noisy images as training data, assuming that the corruption is zero-mean and independent between pixels.The method is based on blind-spot networks where the receptive field of the network does not include the center pixel.This allows using the same noisy image as both training input and training target -because the network cannot see the correct answer, using the same image as target is equivalent to using a different noisy realization.This approach is self-supervised in the sense that the surrounding context is used to predict the value of the output pixel without a separate reference image BID3 .Thenetworks used by BID7 do not have a blind spot by design, but are trained to ignore the center pixel using a masking scheme where only a few output pixels can contribute to the loss function, reducing training efficiency considerably. Weremedy this with a novel architecture that allows efficient training without masking. Furthermore, the existence of the blind spot leads to poor denoising quality. We derivea scheme for combining the network output with data in the blind spot, bringing the denoising quality on par with conventionally trained networks. In our blind-spotnetwork architecture, we effectively construct four denoiser network branches, each having its receptive field restricted to a different direction. A single-pixel offsetat the end of each branch separates the receptive field from the center pixel. The results are thencombined by 1×1 convolutions. In practice, we runfour rotated versions of each input image through a single receptive field -restricted branch, yielding a simpler architecture that performs the same function. This also implicitlyshares the convolution kernels between the branches and thus avoids the four-fold increase in the number of trainable weights.For the baseline experiments, as well as for the backbone of our blind-spot networks, we use the same U-Net BID13 architecture as BID9 , see their appendix for details.The only differences are that we have layers DEC CONV1A and DEC CONV1B output 96 feature maps like the other convolution layers at the decoder stage, and layer DEC CONV1C is removed.After combining the four receptive field restricted branches, we thus have 384 feature maps.These are fed into three successive 1×1 convolutions with 384, 96, and n output channels, respectively, where n is the number of output components for the network.All convolution layers except the last 1×1 convolution use leaky ReLU with α = 0.1 (Maas et al., 2013).All networks were trained using Adam with default parameters BID6 , learning rate λ = 0.0003, and minibatch size of 4.As training data, we used random 256×256 crops from the 50K images in the ILSVRC2012 (Imagenet) validation set.The training continued until 1.2M images were shown to the network.All training and test images were corrupted with Gaussian noise, σ = 25.Table 1 shows the denoising quality in dB for the four test datasets used.From the BSD300 dataset we use the 100 validation images only.Similar to BID7 , we use the grayscale version of the BSD68 dataset -for this case we train a single-channel (c = 1) denoiser using only the luminance channel of the training images.All our blind-spot noise-to-noise networks use the convolutional architecture (Section2) and are trained without masking.In BSD68 our simplified L2 variant closely matches the original NOISE2VOID training, suggesting that our network with an architecturally enforced blind spot is approximately as capable as the masking-based network trained by BID7 .We see that the denoising quality of our Full setup (Section3) is on par with baseline results of N2N and N2C, and clearly surpasses standard blind-spot denoising (L2) that does not exploit the information in the blind spot.Doing the estimation separately for each color BID9 and BID7 .Full is our blind-spot training and denoising method as described in Section 3.Per-comp.is an ablated setup where each color component is treated as an independent univariate Gaussian, highlighting the importance of expressing color outputs as multivariate distributions.L2 refers to training using the standard L2 loss function and ignoring the center pixel when denoising.Columns N2N and N2C refer to NOISE2NOISE training of BID9 and traditional supervised training with clean targets (i.e., noise-to-clean), respectively.Results within 0.05 dB of the best result for each dataset are shown in boldface.channel (Per-comp.) performs significantly worse, except in the grayscale BSD68 dataset where it is equivalent to the Full method.FIG1 shows example denoising results.Our Full setup produces images that are virtually identical to the N2N baseline both visually and in terms of PSNR.The ablated Per-comp.setup tends to produce color artifacts, demonstrating the shortcomings of the simpler per-component univariate model.Finally, the L2 variant that ignores the center pixel during denoising produces visible checkerboard patterns, some of which can also be seen in the result images of BID7 .We have shown that self-supervised training -looking at noisy images only, without the benefit of seeing the same image under different noise realizations -is sufficient for learning deep denoising models on par with those that make use of another realization as a training target, be it clean or corrupted.Currently this comes at the cost of assuming pixel-wise independent noise with a known analytic likelihood model.","answer":"We learn high-quality denoising using only single instances of corrupted images as training data."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: A Predictive Model of the Oxygen and Heme Regulatory Network in Yeast}Article:Abstract:Deciphering gene regulatory mechanisms through the analysis of high-throughput expression data is a challenging computational problem. Previous computational studies have used large expression datasets in order to resolve fine patterns of coexpression, producing clusters or modules of potentially coregulated genes. These methods typically examine promoter sequence information, such as DNA motifs or transcription factor occupancy data, in a separate step after clustering. We needed an alternative and more integrative approach to study the oxygen regulatory network in Saccharomyces cerevisiae using a small dataset of perturbation experiments. Mechanisms of oxygen sensing and regulation underlie many physiological and pathological processes, and only a handful of oxygen regulators have been identified in previous studies. We used a new machine learning algorithm called MEDUSA to uncover detailed information about the oxygen regulatory network using genome-wide expression changes in response to perturbations in the levels of oxygen, heme, Hap1, and Co2+. MEDUSA integrates mRNA expression, promoter sequence, and ChIP-chip occupancy data to learn a model that accurately predicts the differential expression of target genes in held-out data. We used a novel margin-based score to extract significant condition-specific regulators and assemble a global map of the oxygen sensing and regulatory network. This network includes both known oxygen and heme regulators, such as Hap1, Mga2, Hap4, and Upc2, as well as many new candidate regulators. MEDUSA also identified many DNA motifs that are consistent with previous experimentally identified transcription factor binding sites. Because MEDUSA's regulatory program associates regulators to target genes through their promoter sequences, we directly tested the predicted regulators for OLE1, a gene specifically induced under hypoxia, by experimental analysis of the activity of its promoter. In each case, deletion of the candidate regulator resulted in the predicted effect on promoter activity, confirming that several novel regulators identified by MEDUSA are indeed involved in oxygen regulation. MEDUSA can reveal important information from a small dataset and generate testable hypotheses for further experimental analysis. Supplemental data are included.Introduction:Oxygen is critical for the survival and development of virtually all living organisms. As such, living organisms ranging from yeast to humans have developed sophisticated mechanisms to respond to changes of oxygen level in the environment[1]. Several microarray gene expression studies have been performed in the yeast model eukaryote Saccharomyces cerevisiae to understand oxygen sensing and regulation at a genome-wide level[2]–[6]. However, most of these studies mainly identified genes responding to low levels of oxygen[2]–[6] or determined the DNA-binding sites for several known oxygen regulators, such as Rox1[3]. Recently, there has also been a cluster analysis of expression profiles under hypoxia and reoxygenation in glucose versus galactose media[6],[7], where the authors looked for enrichment of functional annotations and known transcription factor binding sites within gene clusters and also applied existing motif discovery algorithms to the clusters. These previous microarray studies have provided further evidence of the role of known regulators such as Hap1, Rox1, and Upc2, but they have had limited success in identifying novel components of the oxygen and heme regulatory network. In this study, we apply an integrative computational approach to analyze genome-wide changes in expression in response to perturbations of the oxygen regulatory network. Our approach is based on a new machine learning algorithm called MEDUSA that combines information from promoter sequences and gene expression profiling to learn a quantitative and statistically robust global model for the oxygen regulatory system.( A mathematical description of MEDUSA has appeared as an extended abstract in a conference proceedings[8]). Numerous computational approaches for inferring gene regulatory networks from gene expression data have been developed to date[9]–[20]. We were motivated by two recent computational approaches in particular: one algorithm aimed at predicting a gene's cluster membership based on the motifs in its promoter[21], and another for partitioning genes into regulatory modules, i. e., clusters of genes with shared regulatory logic[22]. Both these previous methods depend on clustering genes and describing regulatory logic at the level of clusters. However, genes with similar expression patterns are not necessarily regulated by the same regulators and mechanisms. Thus, in our work, we do not assume that clusters reflect the full complexity and condition-specific nature of gene regulation. Indeed, given that virtually all yeast RNA polymerase II promoters are distinct, it remains to be demonstrated that any two promoters are regulated identically by the same regulators across all possible experimental conditions. In contrast to these previous approaches, the MEDUSA algorithm aims to predict the condition-specific differential expression of individual genes, not clusters of genes, by using a single global model. It integrates promoter sequence, promoter occupancy data from ChIP-chip experiments, and the expression levels of potential regulators, including those that do not bind to DNA, to learn a regulatory program controlling target genes. Notably, MEDUSA identifies motifs directly from promoter sequences; no prior knowledge of any DNA-binding motifs is used. MEDUSA trains on differentially expressed target genes from multiple experiments to discover both the motifs in promoters and the condition-specific regulators that together define a global regulatory control program. This regulatory program predicts whether a gene will be up- or downregulated, given its promoter sequence and the condition-specific expression level of the regulators. MEDUSA uses a modern statistical learning technique called boosting[23] to avoid over-fitting as it searches through the large space of possible regulators and sequence motifs[24]. As a result, it achieved high prediction accuracy in cross-validation results using held out gene-experiment examples for the oxygen regulation dataset, where we compare up/down prediction to experimentally measured differential expression, despite the fact that the number of gene expression experiments( 6 conditions with 3 replicates) was much smaller than in previous computational approaches for learning regulatory networks. We then used a novel margin-based score to extract the condition-specific regulators and putative DNA binding site motifs that are most significant for predicting the expression of particular sets of target genes. We summarized this information with a global map of the oxygen regulatory network, which includes both known and novel regulators. Since MEDUSA associates regulators to target genes via motifs in the promoter sequence, we directly tested the predicted regulators for the OLE1 gene by experimental analysis of its promoter activity under deletion of each of these regulators. In each case, the change in OLE1's promoter activity under hypoxia was consistent with MEDUSA's predictions. These results confirm that several novel regulators are indeed involved in oxygen regulation. Finally, we performed a comprehensive comparison of the motif discovery results of MEDUSA with a conventional cluster-first motif discovery algorithm, and we found that MEDUSA identified many DNA binding site motifs that are relevant to hypoxia and missed by the traditional approach.Discussion:In this study, we applied a novel machine learning algorithm to learn regulatory programs underlying oxygen regulation and heme regulation. This algorithm uses experimental data, including microarray gene expression data, promoter sequence, and ChIP-chip data, without introducing prior assumptions such as presuming a cluster structure in gene expression data. The results from our analysis show that the MEDUSA algorithm can provide important, unbiased information about global regulatory programs. MEDUSA identifies many DNA sequence motifs important for oxygen and heme regulation( Figure 8). Further, experimental data from measuring OLE1 promoter activity confirms the specific predictions made by MEDUSA( Figure 7). Finally, a comprehensive comparison with a traditional “cluster-first” motif discovery approach demonstrated that MEDUSA is more successful at identifying binding site motifs relevant to oxygen regulation( Figure 8). MEDUSA identifies many regulators previously known to be involved in this system. For example, MEDUSA identifies Upc2, Mga2, and Hap1[2],[32],[33],[37],[46],[48],[65] as important regulators in oxygen regulation( Figure 5). Further, MEDUSA predicts many new regulators of oxygen and heme regulation, such as Pph3, Bem2, and Pcl1. In support of the regulatory network identified by MEDUSA, several identified regulators are known to interact with each other. For example, Mbp1 and Ure2 are known to coexist in one complex, and the MAP kinase kinase kinase Ssk22 acts upstream of Mbp1. Pph3 and Bem2 are known to coexist in one complex, and both likely mediate the regulation of both hypoxically induced genes and oxygen-induced genes in Δhap1 cells( Figures 4A, 5A, and 6). Wtm1 and Afr1, which are known to coexist in one complex, act in concert to promote oxygen regulation in wild type HAP1 cells( Figures 4A and 6). Likewise, Ire1, which acts upstream of Rgs2, may act with Rgs2 to mediate the regulation of heme-suppressed genes( Figures 5A and 6). The purpose of achieving high prediction accuracy on the test data is to confirm that the identified regulators are statistically important predictors for the regulation of target genes. The number of significant regulators identified by MEDUSA is much smaller than the number of regulators whose expression is changed in a specific experiment. For example, in cells bearing the Hap1 expression plasmid( HAP1), we identified 18 significant regulators that may mediate the regulation of the oxygen-induced genes( Figure 4A), out of 98 regulators whose mRNA levels were significantly altered in the experiment. This dramatic filtering is achieved by three aspects of our computational approach. First, we require that regulators control their putative targets through shared motifs in the promoter sequences. Second, we train on examples from multiple experimental conditions. If a regulator cannot be associated with a binding site motif through which it contributes to target gene regulation in a consistent way across multiple conditions, it will not be selected by the algorithm. Finally, we use a novel margin-based score to identify the most significant regulators for specific conditional and gene sets. This filtering represents an important improvement over simply correlating expression levels of regulators with those of target genes. It is important to note that the MEDUSA analysis did not identify the regulators that mediate stress responses, such as Msn2, Msn4, Tpk1, Usv1, Yap1, and Hsf1[22],[52]–[55],[66],[67], although motifs for some of these regulators are identified in the promoters of target genes. In some aspects, anaerobic and heme-deficient conditions exhibit certain characteristics of stress responses. As such, certain genes induced by stress, such as genes involved in ribosome synthesis, were induced by anaerobic and heme-deficient conditions( see Figure S8). However, the regulatory network mediating oxygen and heme regulation is clearly different from the general stress response network. The most significant regulators in the oxygen and heme regulatory network are not those involved in general stress responses. Interestingly, however, this oxygen and heme regulatory network shares many regulators with other signaling pathways, such as pheromone signaling and osmotic responses. Our analyses suggest a remarkable flexibility of the oxygen and heme regulatory network. For example, in the absence of Hap1, certain new regulators, such as Glc8 and Mbp1 and Ure2, along with some of the regulators acting in wild type HAP1 cells, appear to be recruited to mediate oxygen regulation to substitute Hap1( Figure 6). Another feature of the oxygen and heme regulation network is its complexity. Although several previously known oxygen and heme regulators, including Hap1 and Mga2[32],[46], are confirmed to be important in oxygen and heme regulation by our analysis, many other regulators appear to play important roles in global oxygen and heme regulation. Through biochemical validation of the predicted regulators for the OLE1 promoter, we have taken the first step in confirming the novel components of the oxygen regulatory network as predicted by MEDUSA. While much experimental work remains to be done, we are encouraged by MEDUSA's success in generating condition- and target-specific hypotheses that we were able to validate experimentally. MEDUSA's “cluster-free” approach has the advantage that it can still be effective for small expression datasets, where clustering may only generate large and functionally heterogeneous gene sets. Moreover, clustering and most “module” learning approaches rely on the static assignment of genes to clusters across all experiments in a dataset, which may oversimplify coregulation relationships between genes. MEDUSA models condition-specific regulation in a more flexible way that avoids the cluster assumption. However, methods that produce sets of clusters or modules are more familiar and easier to visualize than MEDUSA's gene regulatory programs, and MEDUSA analysis requires an interpretation step to reveal detailed information for specific conditions or sets of genes. In the present work, we used margin scoring to extract significant regulators for the set of induced/suppressed target genes in each condition and significant motifs associated with genes belonging to expression signatures. This analysis gave a convenient summarization of our results, but more general kinds of statistical post-processing are possible and could be more informative. MEDUSA is well suited to a perturbation dataset, where the set of regulators exhibit diverse expression signatures across conditions. In a dataset where many of the regulators are highly correlated, such as in a short time series, there may not be enough information in the discretized regulator expression profiles for MEDUSA to resolve condition-specific regulators. More generally, MEDUSA incurs some loss of information by discretizing gene expression data prior to training. Extending MEDUSA to handle real-valued regulator and target gene expression levels, for example through a regression formulation, might address this limitation, but it could also introduce too much noise and lead to over-fitting. Further investigation is needed to determine whether such extensions to the MEDUSA algorithm will lead to greater biological insight.","answer":"The cell uses complex regulatory networks to modulate the expression of genes in response to changes in cellular and environmental conditions . The transcript level of a gene is directly affected by the binding of transcriptional regulators to DNA motifs in its promoter sequence . Therefore , both expression levels of transcription factors and other regulatory proteins as well as sequence information in the promoters contribute to transcriptional gene regulation . In this study , we describe a new computational strategy for learning gene regulatory programs from gene expression data based on the MEDUSA algorithm . We learn a model that predicts differential expression of target genes from the expression levels of regulators , the presence of DNA motifs in promoter sequences , and binding data for transcription factors . Unlike many previous approaches , we do not assume that genes are regulated in clusters , and we learn DNA motifs de novo from promoter sequences as an integrated part of our algorithm . We use MEDUSA to produce a global map of the yeast oxygen and heme regulatory network . To demonstrate that MEDUSA can reveal detailed information about regulatory mechanisms , we perform biochemical experiments to confirm the predicted regulators for an important hypoxia gene ."},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: The novel coronavirus is a zoonotic disease, meaning an infection that can jump between different speciesAbstract:A novel coronavirus (severe acute respiratory syndrome-CoV-2) that initially originated from Wuhan, China, in December 2019 has already caused a pandemic.While this novel coronavirus disease (covid-19) frequently induces mild diseases, it has also generated severe diseases among certain populations, including older-aged individuals with underlying diseases, such as cardiovascular disease and diabetes.As of 31 March 2020, a total of 9786 confirmed cases with covid-19 have been reported in South Korea.South Korea has the highest diagnostic rate for covid-19, which has been the major contributor in overcoming this outbreak.We are trying to reduce the reproduction number of covid-19 to less than one and eventually succeed in controlling this outbreak using methods such as contact tracing, quarantine, testing, isolation, social distancing and school closure.This report aimed to describe the current situation of covid-19 in South Korea and our response to this outbreak.","answer":"{\\"verdict\\": \\"NEI\\", \\"evidence\\": []}"},{"question":"You will be shown an abstract from a research paper, and a corresponding research question. Determine the answer to the research question based on the context provided. Your answer should be one of: \\"YES\\", \\"NO\\", or \\"MAYBE\\".Context:(BACKGROUND) Epidemiologic findings support a positive association between asthma and obesity.(OBJECTIVE) Determine whether obesity or increasing level of body mass index (BMI) are associated with worse asthma control in an ethnically diverse urban population.(METHODS) Cross-sectional assessment of asthma control was performed in patients with asthma recruited from primary care offices by using 4 different validated asthma control questionnaires: the Asthma Control and Communication Instrument (ACCI), the Asthma Control Test (ACT), the Asthma Control Questionnaire (ACQ), and the Asthma Therapy Assessment Questionnaire (ATAQ). Multiple linear regression analysis was performed to evaluate the association between obesity and increasing BMI level and asthma control.(RESULTS) Of 292 subjects with a mean age of 47 years, the majority were women (82%) and African American (67%). There was a high prevalence of obesity with 63%, with only 15% normal weight. The mean score from all 4 questionnaires showed an average suboptimal asthma control (mean score/maximum possible score): ACCI (8.3/19), ACT (15.4/25), ACQ (2.1/6), and ATAQ (1.3/4). Regression analysis showed no association between obesity or increasing BMI level and asthma control using all 4 questionnaires. This finding persisted even after adjusting for FEV(1), smoking status, race, sex, selected comorbid illnesses, and long-term asthma controller use.Question:Does higher body mass index contribute to worse asthma control in an urban population?Answer:","answer":"NO"},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: A system for self-supervised optical flow estimation from images and top-downKeyphrases: semantic segmentation images top-view grid map sequences autonomous drivingDataset description:MVSEC: The Multi Vehicle Stereo Event Camera (MVSEC) dataset is a collection of data designed for the development of novel 3D perception algorithms for event based cameras. Stereo event data is collected from car, motorbike, hexacopter and handheld data, and fused with lidar, IMU, motion capture and GPS to provide ground truth pose and depth images.Creative Flow+ Dataset: Includes 3000 animated sequences rendered using styles randomly selected from 40 textured line styles and 38 shading styles, spanning the range between flat cartoon fill and wildly sketchy shading. The dataset includes 124K+ train set frames and 10K test set frames rendered at 1500x1500 resolution, far surpassing the largest available optical flow datasets in size.MPI Sintel: MPI (Max Planck Institute) Sintel is a dataset for optical flow evaluation that has 1064 synthesized stereo images and ground truth data for disparity. Sintel is derived from open-source 3D animated short film Sintel.COCO: The MS COCO (Microsoft Common Objects in Context) dataset is a large-scale object detection, segmentation, key-point detection, and captioning dataset. The dataset consists of 328K images.Options:- A: MVSEC  B: Creative Flow+ Dataset  C: MPI Sintel  D: COCO","answer":"COCO"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Prior Myocardial Infarction andSustained monomorphic VT documented on 12-lead ECG or rhythm strip terminated by pharmacologic means or DC cardioversion=3 episodes of VT treated with antitachycardia pacing (ATP), at least one of which was symptomatic= 5 episodes of VT treated with antitachycardia pacing (ATP) regardless of symptoms=1 appropriate ICD shocks,=3 VT episodes within 24 hours","answer":"{\\"Condition\\": [\\"Myocardial Infarction\\", \\"monomorphic VT\\", \\"VT\\"], \\"Device\\": [], \\"Drug\\": [], \\"Measurement\\": [], \\"Mood\\": [], \\"Multiplier\\": [\\"e des with\\", \\"at least one\\", \\"3 episodes\\", \\"=1\\", \\"5 episodes\\"], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [], \\"Procedure\\": [\\"12-lead ECG\\", \\"DC cardioversion\\", \\"antitachycardia pacing\\", \\"pharmacologic means\\", \\"ATP\\", \\"rhythm strip\\", \\"ICD shocks\\"], \\"Qualifier\\": [\\"symptomatic\\", \\"Sustained\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"pharmacologic means or DC cardioversion\\", \\"12-lead ECG or rhythm strip\\"], \\"Temporal\\": [\\"within 24 hours\\"], \\"Value\\": [], \\"Visit\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Constitutive and inducible protein / DNA interactions of the interferon-gamma promoter in vivo in [ corrected ] CD45RA and CD45R0 T helper subsets [ published erratum appears in Eur J Immunol 1997 Jul; 27 (7): 1830 ] Interferon-gamma (IFN-gamma) is a key cytokine of T lymphocytes with major regulatory functions in the immune system. To determine and compare protein / DNA interactions at the native IFN-gamma locus in T cells, we analyzed the human IFN-gamma promoter by ligation-mediated polymerase chain reaction (LM-PCR) techniques. Accordingly, Jurkat T cells and primary CD45RA and CD45R0 CD4 + T cell subsets isolated from peripheral blood using immunomagnetic beads were cultured and analyzed by LM-PCR. Constitutive and inducible protein / DNA interactions of the IFN-gamma promoter in vivo were detected in all T cells tested. Interestingly, an inducible footprint between-183 and-196 was consistently observed in Jurkat T cells and CD45RA and CD45R0 T helper subsets upon stimulation with phorbol 12-myristate 13-acetate + phytohemagglutinin (PMA + PHA) that was highly sensitive to treatment with corticosteroids. This novel target site, denoted the C-site, was shown by several criteria, including cell distribution studies, stimulation experiments, supershift assays, and cross-competition electrophoretic mobility shift assays to bind the transcription factor AP-1. Mutation of the C-site that prevented AP-1 binding to this site was sufficient strikingly to reduce inducible promoter activity in primary CD45R0 T cells. In summary, the data demonstrate that IFN-gamma gene transcription in primary T cells is regulated in vivo at the level of constitutive and inducible protein / DNA interactions. We propose a model where basal transcription is maintained by binding of various transcription factors to the IFN-gamma promoter, whereas PMA + PHA-inducible IFN-gamma transcription in CD45R0 T cells is associated with binding of AP-1 to the C-site.","answer":"{\\"CellLine\\": [\\"Jurkat T cells\\"], \\"CellType\\": [\\"primary T cells\\", \\"CD45R0 T cells\\", \\"primary CD45RA and CD45R0 CD4 + T cell subsets\\", \\"CD45RA and CD45R0 T helper subsets\\", \\"primary CD45R0 T cells\\", \\"T cells\\", \\"T lymphocytes\\"], \\"DNA\\": [\\"human IFN - gamma promoter\\", \\"C - site\\", \\"IFN - gamma promoter\\", \\"interferon - gamma promoter\\", \\"novel target site\\", \\"- 183 and - 196\\"], \\"Protein\\": [\\"PHA\\", \\"phytohemagglutinin\\", \\"IFN - gamma\\", \\"transcription factor AP - 1\\", \\"AP - 1\\", \\"transcription factors\\"], \\"RNA\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Spontaneous reversion of novel Lesch-Nyhan mutation by HPRT gene rearrangement. Molecular analysis of an unusual patient with the Lesch-Nyhan syndrome has suggested that the mutation is due to a partial HPRT gene duplication. We now report the cloning and sequencing of the mutant HPRT cDNA which shows the precise duplication of exons 2 and 3. This mutation is the result of an internal duplication of 16-20 kilobases of the gene. The structure of the mutant gene suggests that the duplication was not generated by a single unequal crossing-over event between two normal HPRT alleles. Growth of Epstein-Barr virus-transformed lymphoblasts from this patient in selective medium has permitted isolation of spontaneous HPRT + revertants of this mutation. The reversion event involves a second major HPRT gene rearrangement where most or all of the duplicated portion of the mutant gene is deleted. The original mutation therefore has the potential for spontaneous somatic reversion. This may explain the relatively mild symptoms of the Lesch-Nyhan syndrome exhibited by this patient..","answer":"{\\"Disease\\": [\\"Lesch-Nyhan\\", \\"Lesch-Nyhan syndrome\\", \\"Epstein-Barr\\"]}"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:methodContext before the citation:This method allows the efficient retrieval of arbitrary length n-grams (Nagao and Mori, 94; Haruno et al., 96; Ikehaxa et al., 96; Shimohata et al., 1997; Russell, 1998). For sake of efficiency, we used the suffix array technique to get a compact representation of our training corpus. Our approach relies on distributional and frequency statistics computed on each sequence of words found in a training corpus.Citation Sentence:This method allows the efficient retrieval of arbitrary length n-grams ( Nagao and Mori , 94 ; Haruno et al. , 96 ; Ikehaxa et al. , 96 ; Shimohata et al. , 1997 ; Russell , 1998 ) .Context after the citation:The literature abounds in measures that can help to decide whether words that co-occur are linguistically significant or not. In this work, the strength of association of a sequence of words wr = w1, wn is computed by two measures: a likelihood-based one p(wr) (where is the likelihood ratio given in (Dunning, 93)) and an entropy-based one e(w) (Shimohata et al., 1997). Letting T stand for the training text and m a token: Intuitively, the first measurement accounts for the fact that parts of a sequence of words that should be considered as a whole should not appear often by themselves.","answer":"Background"},{"question":"Below is an abstract from a computer science research paper. Given this abstract, your task is to extract all unique relationships between entities of the following types:- \\"USED-FOR\\": For instance, \\"Our method models user proficiency\\" -> [\\"method\\", \\"user proficiency\\", \\"USED-FOR\\"].- \\"EVALUATE-FOR\\": For instance, \\"We evaluate our method using F1-measure\\" -> [\\"F1-measure\\", \\"method\\", \\"EVALUATE-FOR\\"].- \\"FEATURE-OF\\": For instance, \\"prior knowledge of the model\\" -> [\\"prior knowledge\\", \\"model\\", \\"FEATURE-OF\\"].- \\"HYPONYM-OF\\": For instance, \\"TUIT is a software library\\" -> [\\"TUIT\\", \\"software library\\", \\"HYPONYM-OF\\"].- \\"PART-OF\\": For instance, \\"We incorporate NLU module into the system.\\" -> [\\"NLU module\\", \\"system\\", \\"PART-OF\\"].- \\"COMPARE\\": For instance, \\"Unlike the quantitative prior, the qualitative prior is often ignored\\" -> [\\"quantitative prior\\", \\"qualitative prior\\", \\"COMPARE\\"].- \\"CONJUNCTION\\": For instance: \\"obtained from human expert or knowledge base\\" -> [\\"human expert\\", \\"knowledge base\\", \\"CONJUNCTION\\"].Format your output as a json array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<Entity_B>\\", \\"<RELATION_A_B>\\"]. An example output might look like:[[\\"neural networks\\", \\"classification\\", \\"USED-FOR\\"], [\\"neuron\\", \\"neural network\\", \\"PART-OF\\"]].If no relations are found, please return an empty array [].Abstract:Spelling-checkers have become an integral part of most text processing software. From different reasons among which the speed of processing prevails they are usually based on dictionaries of word forms instead of words. This approach is sufficient for languages with little inflection such as English, but fails for highly inflective languages such as Czech, Russian, Slovak or other Slavonic languages. We have developed a special method for describing inflection for the purpose of building spelling-checkers for such languages. The speed of the resulting program lies somewhere in the middle of the scale of existing spelling-checkers for English and the main dictionary fits into the standard 360K floppy, whereas the number of recognized word forms exceeds 6 million (for Czech). Further, a special method has been developed for easy word classification.","answer":"[[\\"Slavonic languages\\", \\"highly inflective languages\\", \\"HYPONYM-OF\\"], [\\"Russian\\", \\"highly inflective languages\\", \\"HYPONYM-OF\\"], [\\"Spelling-checkers\\", \\"highly inflective languages\\", \\"USED-FOR\\"], [\\"Spelling-checkers\\", \\"text processing software\\", \\"PART-OF\\"], [\\"method\\", \\"Spelling-checkers\\", \\"USED-FOR\\"], [\\"method\\", \\"word classification\\", \\"USED-FOR\\"], [\\"Slovak\\", \\"Slavonic languages\\", \\"CONJUNCTION\\"], [\\"Czech\\", \\"Russian\\", \\"CONJUNCTION\\"], [\\"Czech\\", \\"highly inflective languages\\", \\"HYPONYM-OF\\"], [\\"method\\", \\"inflection\\", \\"USED-FOR\\"], [\\"highly inflective languages\\", \\"dictionaries of word forms\\", \\"USED-FOR\\"], [\\"English\\", \\"Spelling-checkers\\", \\"USED-FOR\\"], [\\"English\\", \\"highly inflective languages\\", \\"HYPONYM-OF\\"], [\\"Slovak\\", \\"highly inflective languages\\", \\"HYPONYM-OF\\"], [\\"dictionaries of word forms\\", \\"Spelling-checkers\\", \\"USED-FOR\\"], [\\"Russian\\", \\"Slovak\\", \\"CONJUNCTION\\"], [\\"inflection\\", \\"highly inflective languages\\", \\"FEATURE-OF\\"]]"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:Recent years have witnessed a rapid growth of deep-network based services and applications. A practical and critical problem thus has emerged: how to effectively deploy the deep neural network models such that they can be executed efficiently. Conventional cloud-based approaches usually run the deep models in data center servers, causing large latency because a significant amount of data has to be transferred from the edge of network to the data center. In this paper, we propose JALAD, a joint accuracy- and latency-aware execution framework, which decouples a deep neural network so that a part of it will run at edge devices and the other part inside the conventional cloud, while only a minimum amount of data has to be transferred between them. Though the idea seems straightforward, we are facing challenges including i) how to find the best partition of a deep structure; ii) how to deploy the component at an edge device that only has limited computation power; and iii) how to minimize the overall execution latency. Our answers to these questions are a set of strategies in JALAD, including 1) A normalization based in-layer data compression strategy by jointly considering compression rate and model accuracy; 2) A latency-aware deep decoupling strategy to minimize the overall execution latency; and 3) An edge-cloud structure adaptation strategy that dynamically changes the decoupling for different network conditions. Experiments demonstrate that our solution can significantly reduce the execution latency: it speeds up the overall inference execution with a guaranteed model accuracy loss.Cited Abstract(s):[1]: The proliferation of Internet of Things (IoT) and the success of rich cloud services have pushed the horizon of a new computing paradigm, edge computing, which calls for processing the data at the edge of the network. Edge computing has the potential to address the concerns of response time requirement, battery life constraint, bandwidth cost saving, as well as data safety and privacy. In this paper, we introduce the definition of edge computing, followed by several case studies, ranging from cloud offloading to smart home and city, as well as collaborative edge to materialize the concept of edge computing. Finally, we present several challenges and opportunities in the field of edge computing, and hope this paper will gain attention from the community and inspire more research in this direction.[2]: [3]: Despite the increasing usage of cloud computing, there are still issues unsolved due to inherent problems of cloud computing such as unreliable latency, lack of mobility support and location-awareness. Fog computing can address those problems by providing elastic resources and services to end users at the edge of network, while cloud computing are more about providing resources distributed in the core network. This survey discusses the definition of fog computing and similar concepts, introduces representative application scenarios, and identifies various aspects of issues we may encounter when designing and implementing fog computing systems. It also highlights some opportunities and challenges, as direction of potential future work, in related techniques that need to be considered in the context of fog computing.[4]: The paper considers the conceptual approach for organization of the vertical hierarchical links between the scalable distributed computing paradigms: Cloud Computing, Fog Computing and Dew Computing. In this paper, the Dew Computing is described and recognized as a new structural layer in the existing distributed computing hierarchy. In the existing computing hierarchy, the Dew computing is positioned as the ground level for the Cloud and Fog computing paradigms. Vertical, complementary, hierarchical division from Cloud to Dew Computing satisfies the needs of high- and low-end computing demands in everyday life and work. These new computing paradigms lower the cost and improve the performance, particularly for concepts and applications such as the Internet of Things (IoT) and the Internet of Everything (IoE). In addition, the Dew computing paradigm will require new programming models that will efficiently reduce the complexity and improve the productivity and usability of scalable distributed computing, following the principles of High-Productivity computing.[5]: With the increasing commoditization of computer vision, speech recognition and machine translation systems and the widespread deployment of learning-based back-end technologies such as digital advertising and intelligent infrastructures, AI (Artificial Intelligence) has moved from research labs to production. These changes have been made possible by unprecedented levels of data and computation, by methodological advances in machine learning, by innovations in systems software and architectures, and by the broad accessibility of these technologies. The next generation of AI systems promises to accelerate these developments and increasingly impact our lives via frequent interactions and making (often mission-critical) decisions on our behalf, often in highly personalized contexts. Realizing this promise, however, raises daunting challenges. In particular, we need AI systems that make timely and safe decisions in unpredictable environments, that are robust against sophisticated adversaries, and that can process ever increasing amounts of data across organizations and individuals without compromising confidentiality. These challenges will be exacerbated by the end of the Moore's Law, which will constrain the amount of data these technologies can store and process. In this paper, we propose several open research directions in systems, architectures, and security that can address these challenges and help unlock AI's potential to improve lives and society.","answer":"Attracted by the elasticity in computing power and flexible collaboration, hierarchically distributed computing structures(e.g., cloud computing, fog computing, edge computing) naturally becomes the choice for supporting deep-structure-based services and applications [3] [1] [2] [4] [5] . Considering the deployment location for model, the-state-of-art approaches could be divided into the three classes."},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Phase II trial of induction chemotherapy with carboplatin and paclitaxel plus bevacizumab in patients with stage IIIA to IV nonsquamous non-small cell lung cancer. Surgery remains the best curative treatment option for non-small cell lung cancer (NSCLC), but is of benefit only to patients with localized disease. A meta-analysis showed a significant beneficial effect of induction chemotherapy on survival, but there is still no clear evidence. This phase II study was conducted to establish whether induction chemotherapy with carboplatin ( CBDCA ) and paclitaxel ( PTX ) plus bevacizumab prior to surgery reduces the risk of progression .  methods The subjects of this study were 29 patients with treatment-naive nonsquamous NSCLC (clinical stages IIIA to IV). Patients received PTX (200 mg/m  results The overall response rate was 72.4%. Of the 29 patients, ten underwent surgery after the induction chemotherapy and complete resection was achieved in 7 (70%). The median progression-free-survival (PFS) time and the 3-year PFS rate were 0.92 years and 16.2%, respectively. The median overall survival (OS) time and the 3-year OS rate were 1.96 years and 44.9%, respectively.  conclusion Combined modality therapy with surgery after induction chemotherapy with CBDCA and PTX plus bevacizumab is clinically feasible and tolerable for patients with unknown or negative molecular profiles.sentence: This phase II study was conducted to establish whether induction chemotherapy with carboplatin ( CBDCA ) and paclitaxel ( PTX ) plus bevacizumab prior to surgery reduces the risk of progression .","answer":"[[\\"carboplatin\\", \\"paclitaxel\\", \\"bevacizumab\\", \\"POS\\"]]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Identification of latency-associated transcripts that map antisense to the ICP4 homolog gene of Marek's disease virus. Two small RNAs (0.9 and 0.75 kb), named Marek's disease virus (MDV) small RNAs (MSRs) and a 10-kb RNA, all of which map antisense to the MDV ICP4 homolog gene, have been readily detected in MDCC-MSB1 MDV-transformed T-lymphoblastoid cells. These RNAs were not detectable in reticuloendotheliosis virus-transformed T cells. When MDV was reactivated by treatment of lymphoblastoid cells with 25 micrograms of iododeoxyuridine per ml, the relative levels of the transcripts decreased. These RNAs were not detected by Northern (RNA) hybridization in productively infected chicken embryo fibroblasts 48 h postinfection; however, they were apparent 140 h postinfection. By using Northern hybridization, RNase protection assays, and primer extension analysis, the MSRs were determined to map antisense to the predicted translational start site of the ICP4 homolog gene. The conclusion most consistent with the data is that the two MSRs are overlapping, spliced RNAs. Both small RNAs contain a latency promoter binding factor consensus recognition sequence located toward their 5' ends as well as two potential ICP4 recognition consensus sequences, one in each orientation. The region contains a number of small open reading frames on each side and within the MSRs. Although the exact endpoints are unknown, the large 10-kb species spans the entire ICP4 homolog region. We believe that this group of RNAs, which map antisense to the ICP4 homolog gene, are latency-associated transcripts of MDV.","answer":"{\\"AnatomicalEntity\\": [\\"MDCC-MSB1\\", \\"T-lymphoblastoid cells\\", \\"T cells\\", \\"embryo fibroblasts\\", \\"lymphoblastoid cells\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Cortisol and interferon tau regulation of endometrial function and conceptus development in female sheep. During early pregnancy in sheep, the elongating conceptus secretes interferon-τ (IFNT) and the conceptus as well as endometrial epithelia produce prostaglandins (PG) via PG synthase 2 (PTGS2) and cortisol via hydroxysteroid (11-β) dehydrogenase 1 (HSD11B1). Ovarian progesterone induces and PG and IFNT stimulates endometrial HSD11B1 expression and keto-reductase activity as well as many epithelial genes that govern trophectoderm proliferation, migration, and attachment during elongation. The primary aim of these studies was to test the hypothesis that HSD11B1-derived cortisol has a biological role in endometrial function and conceptus development during early pregnancy in sheep. In study 1, cyclic ewes received vehicle, cortisol, PF 915275 (PF; a selective inhibitor of HSD11B1), cortisol and PF, meloxicam (a selective inhibitor of PTGS2), cortisol and meloxicam, recombinant ovine IFNT, or IFNT and PF into the uterus from day 10 to day14 after estrus. Cortisol and IFNT stimulated endometrial HSD11B1 expression and activity, increased endometrial PTGS2 activity and the amount of PG in the uterine lumen, and up-regulated many conceptus elongation-related genes in the endometrium. Some effects of cortisol and IFNT were mediated by PTGS2-derived PG. In study 2, bred ewes received PF 915275 or recombinant ovine IFNT and into the uterus from day 10 to day 14 after mating. Inhibition of HSD11B1 activity in utero prevented conceptus elongation, whereas IFNT rescued conceptus elongation in PF-infused ewes. These results suggest that HSD11B1-derived cortisol mediates, in part, actions of ovarian progesterone and the conceptus on endometrial function and support the hypothesis that IFNT, PG, and cortisol coordinately regulate endometrial functions important for conceptus elongation and implantation during early pregnancy in sheep.","answer":"[[\\"cortisol\\", \\"PRODUCT-OF\\", \\"hydroxysteroid (11-u03b2) dehydrogenase 1\\"], [\\"Cortisol\\", \\"ACTIVATOR\\", \\"PTGS2\\"], [\\"prostaglandins\\", \\"PRODUCT-OF\\", \\"PTGS2\\"], [\\"PF 915275\\", \\"INHIBITOR\\", \\"HSD11B1\\"], [\\"meloxicam\\", \\"INHIBITOR\\", \\"PTGS2\\"], [\\"prostaglandins\\", \\"PRODUCT-OF\\", \\"PG synthase 2\\"], [\\"cortisol\\", \\"PRODUCT-OF\\", \\"HSD11B1\\"], [\\"Cortisol\\", \\"INDIRECT-UPREGULATOR\\", \\"HSD11B1\\"]]"},{"question":"You will be presented with a citation segment from the section of an NLP research paper, as well as the context surrounding that citation. Classify the intent behind this citation by choosing from one of the following categories:- Background: provides context or foundational information related to the topic.- Extends: builds upon the cited work.- Uses: applies the methods or findings of the cited work.- Motivation: cites the work as inspiration or rationale for the research.- CompareOrContrast: compares or contrasts the cited work with others.- FutureWork: cites the work as a direction for future research.Your answer should be a single word from the following list of options: [\\"Background\\", \\"Extends\\", \\"Uses\\", \\"Motivation\\", \\"CompareOrContrast\\", \\"FutureWork\\"]. Do not include any other text in your response.Section Title:introductionContext before the citation:Cross-lingual Textual Entailment (CLTE) has been proposed by (Mehdad et al., 2010) as an extension of Textual Entailment (Dagan and Glickman, 2004) that consists in deciding, given two texts T and H in different languages, if the meaning of H can be inferred from the meaning of T.Citation Sentence:Cross-lingual Textual Entailment ( CLTE ) has been proposed by ( Mehdad et al. , 2010 ) as an extension of Textual Entailment ( Dagan and Glickman , 2004 ) that consists in deciding , given two texts T and H in different languages , if the meaning of H can be inferred from the meaning of T .Context after the citation:The task is inherently difficult, as it adds issues related to the multilingual dimension to the complexity of semantic inference at the textual level. For instance, the reliance of current monolingual TE systems on lexical resources (e.g. WordNet, VerbOcean, FrameNet) and deep processing components (e.g. syntactic and semantic parsers, co-reference resolution tools, temporal expressions recognizers and normalizers) has to confront, at the cross-lingual level, with the limited availability of lexical/semantic resources covering multiple languages, the limited coverage of the existing ones, and the burden of integrating languagespecific components into the same cross-lingual architecture. As a first step to overcome these problems, (Mehdad et al., 2010) proposes a âbasic solutionâ, that brings CLTE back to the monolingual scenario by translating H into the language of T. Despite the advantages in terms of modularity and portability of the architecture, and the promising experimental results, this approach suffers from one main limitation which motivates the investigation on alternative solutions. Decoupling machine translation (MT) and TE, in fact, ties CLTE performance to the availability of MT components, and to the quality of the translations.","answer":"Background"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:A 3-base pair in-frame deletion of the phenylalanine hydroxylase gene results in a kinetic variant of phenylketonuria. Phenylketonuria (PKU) is an autosomal recessive disease due to deficiency of a hepatic enzyme, phenylalanine hydroxylase (PAH). The absence of PAH activity results in typical PKU while persistence of a residual enzyme activity gives rise to variant forms of the disease. We report here a 3-base pair in-frame deletion of the PAH gene (delta 194) in a mild variant, with markedly reduced affinity of the enzyme for phenylalanine (Km = 160 nM), and we provide functional evidence for responsibility of the deletion in the mutant phenotype. Since the deletion was located in the third exon of the gene, which presents no homology with other hydroxylases, we suggest that exon 3 is involved in the specificity of the enzyme for phenylalanine. Finally, since none of the 98 PKU patients tested were found to carry this particular deletion, our study suggests that this molecular event probably occurred recently on the background of a haplotype 2 gene in Portugal..","answer":"{\\"Disease\\": [\\"Phenylketonuria\\", \\"phenylketonuria\\", \\"deficiency of a hepatic enzyme, phenylalanine hydroxylase\\", \\"autosomal recessive disease\\", \\"PKU\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Heterogeneous expression and polymorphic genotype of glutathione S-transferases in human lung. BACKGROUND: Glutathione S-transferases (GSTs) are involved in the detoxification of xenobiotics by conjugation with glutathione. One of the mu class genes of this superfamily of enzymes, GSTM1, is polymorphic because of a partial gene deletion. This results in a failure to express GSTM1 in approximately 50% of individuals. Several studies have linked GSTM1 null status to an increased risk of lung carcinoma. This study investigated the expression and distribution of GST isoenzymes in human lung, and developed a polymerase chain reaction (PCR) assay which would allow genotyping of archival, paraffin embedded lung tissue. METHODS: Distribution was examined using a panel of polyclonal anti-GST antibodies for immunohistochemistry in normal tissue of 21 tumour-bearing lungs. DNA for PCR was extracted from paraffin blocks and a control group of 350 blood lysates. As a positive control each assay amplified part of GSTM4, a mu class gene which is not polymorphic but which shows strong sequence homology to GSTM1. The presence of GST in bronchoalveolar lavage fluid was sought by Western analysis. RESULTS: Proximal airways contained pi class GST, alpha class GST, and mu class GST with expression concentrated in the brush border. In distal airspaces no alpha GST was expressed but pi GST and mu GST were present in alveolar cells and also alveolar macrophages. Pi class GST was present in bronchoalveolar lavage fluid. The PCR assay enabled genotypic determination using DNA extracted from archival material. Of the control group 56% were null at the GSTM1 locus. CONCLUSIONS: The distribution of GST isoenzymes in the lung is heterogeneous with an apparent decrease in GST in distal lung. Since GSTM1 status has already been associated with susceptibility to disease, the PCR assay developed will allow further studies of the relation between genotype and structural disorders in the lung using archival pathological material.","answer":"[]"},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: For instance, Ae. aegypti, responsible for epidemics in Kenya, Comoros, and Seychelles, carried CHIKV with an alanine in the 226 position of the E1 gene (E1-A226) [4, 18] . However, when the virus struck La Reunion Islands, a decline in population of Ae. aegypti, due to massive dichlorodiphenyltrichloroethane usage and dearth of Ae. albopictus species' www.plosntds.org population, resulted in an ecological pressure, favoring replacement of alanine at position 226 with valine (E1-A226V) [5] . This mutation allowed CHIKV's secondary vector species, Ae. albopictus, to supplement Ae. aegypti as its primary vector [5] . Within a year, the E1-A226V mutation was present in La Reunion Island, and Ae. albopictus apparently vectored the large epidemic infecting 34% of La Reunion Island's population [5] . All of the CHIKV strains isolated from Mayotte carried the E1-A226V mutation, and the mutation was also found in Madagascar in 2007 [ 5] . The E1-A226V mutation was not present at the beginning of the Indian Ocean Islands outbreak (before September 2005). However, more than 90% of later viral strains found there had incorporated the mutation (December-March 2006), indicating a genotype switch during the winter season [5, 18, 20] . The E1-A226V mutation also enabled an increase in infectivity of Ae. albopictus when compared to its infectivity of Ae. aegypti [4, 11, 18, 30] , and with several factors taken together, Ae. albopictus has become the new preferred and more lethal vector for CHIKV [4, 5, 11] . In fact, Tsetsarkin et al. found that a Green Fluorescent Protein tagged E1-A226V virus was 100 times more infective to Ae. albopictus than it was to Ae. aegypti [4] . In all the Indian Ocean Islands, Ae. albopictus became the main vector for CHIKV within 1-2 y after CHIKV was introduced to the region [31] . Of note is that Ae. aegypti has most likely been established in North America for over 300 y, while Ae. albopictus has been in many areas of the US, since 1985, primarily in Florida [32] and since then has expanded its range in the country. Reiskind et al. set out to determine if Ae. aegypti and Ae. albopictus mosquitoes captured in Florida were susceptible to CHIKV infection by a La Reunion isolate [32] . Each mosquito tested was highly susceptible to infection by a full-length infectious clone of the La Réunion Island isolate, CHIKV LR2006 OPY1 strain. Even though the Ae. albopictus strains were more susceptible to infection, overall ecology and differences in human biting patterns need to be studied further Characteristically, there are two rounds of translation: (+) sense genomic RNA (49S9 = 11.7 kb) acts directly as mRNA and is partially translated (59 end) to produce non-structural proteins (nsp's). These proteins are responsible for replication and formation of a complementary (2) strand, the template for further (+) strand synthesis. Subgenomic mRNA (26 S = 4.1 kb) replication occurs through the synthesis of full-length (2) intermediate RNA, which is regulated by nsp4 and p123 precursor in early infection and later by mature nsp's. Translation of the newly synthesized sub-genomic RNA results in production of structural proteins such as Capsid and protein E2-6k-E1 (from 39 end of genome). Assembly occurs at the cell surface, and the envelope is acquired as the virus buds from the cell and release and maturation almost simultaneous occurred. Replication occurs in the cytoplasm and is very rapid (,4 h) [28, 29] . doi:10.1371/journal.pntd.0000623.g002 www.plosntds.org to gain a more accurate understanding of a potential CHIKV epidemic in the US [32] . During the 7 d preceding birth, no human mother has been reported to transmit the disease vertically. However, about 50% of newborns delivered while the mother was infected with CHIKV contracted the disease from their mother, despite the method of delivery. Furthermore, there have been instances of CHIKV transmission from mother to fetus causing congenital illness and fetal death [33] . During the 2005-2006 La Reunion Island outbreaks, Ramful et al. discovered that mothers could transmit CHIKV to their progeny during the perinatal period (Day 24 to Day +1) [33, 34] , and it is associated with a high degree of morbidity. By mean Day 4 of life, all of the neonates were symptomatic for CHIKV, exhibiting common CHIKF symptoms. Six neonates were confirmed to have contracted CHIKV and developed mengoencephalitis. Of those mothers who, during the La Reunion Island epidemic, were infected long before delivery, only three fetal deaths were reported [12, 33] . Ramful et al. theorized that motherto-child transmission most likely happens transplacentally shortly before delivery [33] . A similar study by Gerardin et al. reported nineteen cases of neonatal infection associated with intrapartum maternal viremia that progressed to develop encephalitis owing to vertical transmission from infected mothers [34] . Clinical and epidemiological similarities with dengue fever make CHIKV diagnosis difficult, which may lead physicians to misdiagnose CHIKV as dengue fever; therefore, the incidence of CHIKV may actually be higher than currently believed (Table 1 ) [6, 12, 35] . The amount of time elapsed since disease onset is the most critical parameter when choosing a diagnostic test. CHIKV can be detected and isolated by culturing with mosquito cells (C6/36), Vero cells (mammalian), or in mice [26] . However, this method can take at least a week and only achieves a high sensitivity during the viremic phase, which usually only lasts up to 48 h after the bite. Five days post-infection, the viral isolation approach has a low sensitivity but is still the preferred method for detecting the CHIKV strain [12, 26, 31, 35] . RT-PCR on the other hand is a faster and more sensitive method that can be used within the first week of disease onset [26] , and it is currently the most sensitive method for detecting and quantifying viral mRNA [4, 36] . Classic serological detection, by assays such as ELISA [37] , immunofluorescence [5, 38] , complement binding, and haemagglutination inhibition [39] , constitutes the second diagnostic tool used for biological diagnosis of CHIKV infection. These proven techniques are useful for detection of Antigen in mosquitoes during epidemiological studies. These assays detect virus-specific IgM and IgG, however the sensitivity and specificity of these assays has been poorly characterized. Viral competence, or the potential of viral infection and transmission, is an important parameter that can be quantified by ELISA, viral culture, and PCR. A study by Ng et al. showed biomarkers indicative of severe CHIKV infection [40] . They found decreased levels of RANTES and increased levels of Interleukin-6 (IL-6) and Interleukin-1b (IL-1b) that could be sued for CHIKV detection in patients as indicators of CHIKV-driven cytokine storm. Couderc et al. demonstrate another cytokine, type-I IFN, as a key player in the progression to CHIKV infection [26] . Using an IFN-a/b null mouse model, they demonstrated evidence of muscles, joints, and skin as privileged CHIKV targets, which is consistent with human pathology. Although Ng et al. concluded that RANTES levels were significantly suppressed in severe CHIKF patients [40] , interestingly, an increase in levels of RANTES has been observed in dengue infection [41] . Since the symptoms of CHIKF mimic those of dengue fever, results obtained from this study strongly suggest that RANTES could be a potential distinctive biomarker that differentiates between these two clinically similar diseases. There are no approved antiviral treatments currently available for CHIKV [1, 3, 12, 42] . Currently, CHIKF is treated symptomatically, usually with non-steroidal anti-inflammatory drugs or steroids, bed rest, and fluids. Movement and mild exercise are thought to decrease stiffness and morning arthralgia, but heavy exercise may exacerbate rheumatic symptoms. Corticosteroids may be used in cases of debilitating chronic CHIKV infection. There is a debate about the appropriateness of chloroquine as treatment for unresolved, non-steroidal anti-inflammatory drugresistant arthritis [43] . A study showed that viral production was www.plosntds.org drastically reduced at 16 h post-infection after treatment with 100 mM dec-RVKR-cmk (Decanoyl-Arg-Val-Lys-Arg-chloromethylketone), a furine inhibitor [42, 44] . Chloroquine acted by raising the pH, blocking low pH-dependent entry of virus into the cell. It is important to note that dec-RVKR-cmk or chloroquine only inhibited viral spreading from cell to cell, not CHIKV replication once it had entered the cell [43] . However, most would agree that the best weapon against CHIKV is prevention. A live CHIKV vaccine developed by the United States reached phase II clinical trial encompassing 59 healthy volunteers [45] . Eight percent of the volunteers experienced transient arthralgia, while 98% of the volunteers had seroconversion [45] . However, live CHIKV vaccines are still questionable. One cannot discount the risk of a live vaccine possibly inducing chronic rheumatism. Also, there is the question as to whether widespread use among the public could trigger mosquito transmission or lead to chronic infection or viral reversion [1] . An alternative approach would be to produce a chimeric vaccine against CHIKV. Wang et al. developed a chimeric alphavirus vaccine that is uniformly attenuated and does not cause reactogenicity in mice [3] . Three different versions of this vaccine were made using three different backbone vectors: Venezuelan equine encephalitis virus (VEEV) attenuated vaccine strain T-83, naturally attenuated eastern equine encephalitis virus (EEEV), and attenuated Sindbis virus (SINV). In short, CHIKV structural proteins were engineered into the backbones of the aforementioned vaccines to produce the chimeras [3] . These chimeras were found to stimulate a strong humoral immunity, and even at doses of 5.3-5.8 log 10 PFU, they did not trigger reactogenicity. When vaccinated mice were challenged with CHIKV, neither adult nor neonatal mice gained weight, had fever, or displayed signs of neurological illness. Upon comparison of the chimeras with the Army181/25 vaccine, the Army vaccine resulted in higher levels of viremia and replication in the joints of neonatal mice. Because the joints are known targets of CHIKV, Wang et al. noted their vaccine might avoid the negative reactogenic side effects of the Army vaccine. After being subcutaneously vaccinated with 5.3-5.8 log 10 PFU of the chimeric vaccines, mice produced strong neutralizing antibody titers. The VEEV and EEEV chimeras yielded higher neutralizing antibody titers than the SINV chimera without being more virulent. On top of this, the VEEV and EEEV CHIKV chimeras seemed to be more immunogenic than the Army vaccine despite the chimeras' lower viremia and replication in the joints of neonatal mice [3] . Tiwari et al. [46] adopted a different strategy using formalin inactivated CHIKV in combination with alhydrogel (Aluminum Hydroxide) as an adjuvant. This study clearly suggests that this vaccine elicits both humoral and cell-mediated immune responses in mice, providing its immunogenic potential. A recent study by Couderc et al. [47] showed passive immunization as a potential treatment for CHIKV infection. Using purified immunoglobulin extracted from convalescent CHIKV patients, they demonstrated effective neutralizing activity against CHIKV infection both in vitro and in vivo. This thereby establishes a potential preventive and therapeutic approach to combat CHIKV infection. Pathogenesis studies conducted with related alpha virus, like RRV, have shown the role of macrophages in persistence on infection [48] . They also demonstrated the role of RRV-specific CD8 T cells in clearing viral load in infected patients, thereby warranting similar investigations with CHIKV and the importance of investigating a cell-mediated immune response-based vaccine against CHIKV [49] . There are always certain risks associated with live attenuated or inactivated viral vaccines [50] . One way to avoid these potential problems is to construct a consensus-based DNA vaccine. DNA based vaccines have an improved safety profile as compared to live or attenuated vaccines [51, 52] . A consequence of CHIKV's rapid evolution is difficulty in constructing a vaccine that will be able to Figure 3 . Levels of CHIKV-specific IgG in mice immunized with CHIKV vaccines. Each group of C57BL/6 mice (n = 5) was immunized with 12.5 mg of pVax1 control vector or CHIKV vaccine plasmids as indicated at 0 and 2 wk. Mice were bled 2 wk after each immunization, and each group's serum pool was diluted to 1:100 and 1:500 for reaction with specific vaccine constructs. Serum was incubated for 1 h at 37uC on 96-well plates coated with 2 mg/ml of respective CHIKV peptides, and antibody was detected using anti-mouse IgG-HRP and OD was measured at 405 nm. doi:10.1371/journal.pntd.0000623.g003 www.plosntds.org effectively protect large populations from multiple strains of the virus. One of the strengths of DNA consensus vaccines is its ability to induce cross-reactive immune responses against the three distinct phylogenetic groups of CHIKV. Also DNA-based vaccines can be produced more rapidly than protein-based vaccines.Question: Where were  the CHIKV strain found?","answer":"All of the CHIKV strains isolated from Mayotte carried the E1-A226V mutation, and the mutation was also found in Madagascar in 2007 ["},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Disease\\"].Please return the output as a JSON object of the format: {\\"Disease\\" : [\\"COVID-19\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Multiple origins for phenylketonuria in Europe. Phenylketonuria (PKU), a disorder of amino acid metabolism prevalent among Caucasians and other ethnic groups, is caused primarily by a deficiency of the hepatic enzyme phenylalanine hydroxylase (PAH). PKU is a highly heterogeneous disorder, with more than 60 molecular lesions identified in the PAH gene. The haplotype associations, relative frequencies, and distributions of five prevalent PAH mutations (R158Q, R261Q, IVS10nt546, R408W, and IVS12n1) were established in a comprehensive European sample population and subsequently were examined to determine the potential roles of several genetic mechanisms in explaining the present distribution of the major PKU alleles. Each of these five mutations was strongly associated with only one of the more than 70 chromosomal haplotypes defined by eight RFLPs in or near the PAH gene. These findings suggest that each of these mutations arose through a single founding event that occurred within time periods ranging from several hundred to several thousand years ago. From the significant differences observed in the relative frequencies and distributions of these five alleles throughout Europe, four of these putative founding events could be localized to specific ethnic subgroups. Together, these data suggest that there were multiple, geographically and ethnically distinct origins for PKU within the European population..","answer":"{\\"Disease\\": [\\"Phenylketonuria\\", \\"disorder of amino acid metabolism\\", \\"phenylketonuria\\", \\"deficiency of the hepatic enzyme phenylalanine hydroxylase\\", \\"PKU\\"]}"},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Integrated Multiregional Analysis Proposing a New Model of Colorectal Cancer Evolution}Article:Abstract:Understanding intratumor heterogeneity is clinically important because it could cause therapeutic failure by fostering evolutionary adaptation. To this end, we profiled the genome and epigenome in multiple regions within each of nine colorectal tumors. Extensive intertumor heterogeneity is observed, from which we inferred the evolutionary history of the tumors. First, clonally shared alterations appeared, in which C>T transitions at CpG site and CpG island hypermethylation were relatively enriched. Correlation between mutation counts and patients’ ages suggests that the early-acquired alterations resulted from aging. In the late phase, a parental clone was branched into numerous subclones. Known driver alterations were observed frequently in the early-acquired alterations, but rarely in the late-acquired alterations. Consistently, our computational simulation of the branching evolution suggests that extensive intratumor heterogeneity could be generated by neutral evolution. Collectively, we propose a new model of colorectal cancer evolution, which is useful for understanding and confronting this heterogeneous disease.Introduction:Cancer is a heterogeneous disease. Recent cancer genomics studies have revealed extensive genetic diversity among patients. Moreover, even a clonal tumor in one patient often harbors multiple subclones. This phenomenon is called intratumor heterogeneity( ITH) and is presumably generated by branching clonal evolution of cancer cells. Understanding of ITH is clinically important, since the existence of multiple subclones presumably boosts the evolutionary adaptation of tumors against therapies, constituting a source of resistant clones[1]. Recently, a multiregional sequencing approach, which sequences DNA sampled from geographically separated regions of a single tumor, has revealed branched evolution and ITH. Yachida et al.[2] investigated the genomic evolution of pancreatic cancer, establishing two categories of mutations: “founder” and “progressor” mutations are present in all regions and a subset of regions, respectively. Founder mutations are assumed to appear in the early phase of clonal evolution. We refer to the clone that has accumulated all the founder mutations as the parental clone( or the most recent common ancestor). The parental clone then branches into subclones by accumulating progressor mutations, which shape ITH. Several studies employing multiregional exome sequencing have revealed the occurrence of branched evolution and ITH in several other types of cancers, including clear cell renal cell carcinomas and non-small cell lung cancers. ITH of clear cell renal cell carcinomas is characterized by parallel evolution, in which the same driver gene is independently mutated in different branches of evolutionary trees[3]. In contrast, no evidence of parallel evolution has been reported for non-small cell lung cancer[4, 5]. In addition to genetic aberrations, epigenetic aberrations are also a hallmark of cancer; as for DNA methylation, a few groups have also performed multiregional epigenomic analyses[6, 7]. However, the types of cancers that have been subjected to multiregional analyses remain limited, and ITH of genomes and epigenomes has been poorly studied in an integrated way. In this study, we present genetic and epigenetic analysis of ITH in a series of nine colorectal cancers. Following multiregional sampling, we performed exome sequencing and copy number( CN), methylation, and mRNA expression array profiling. Our integrated analysis revealed not only extensive ITH, but also the evolutionary histories of the nine tumors. Finally, we also performed computational simulation of cancer evolution, which suggested a possible evolutionary principle underlying the extensive ITH.Discussion:In this study, our integrated multiregional analysis revealed the ITH and evolutionary history of a series of nine colorectal tumors. In particular, by focusing on founder and progressor mutations, we identified clues for decoding the life history of the tumors. For example, we found that founder mutations included established driver mutations such as APC, KRAS, and FBWX7, and their counts correlated with the ages of patients, suggesting that accumulation of alterations in the early phase results from aging. It is a well-accepted dogma that cancer results from aging[17]. Moreover, associations between somatic mutations and aging have been studied recently. Welch et al.[18] found that acute myeloid leukemia( AML) genomes accumulate mutations as a function of age; furthermore, they also confirmed age-dependent mutation accumulation in hematopoietic stem/progenitor cells. Other recent studies report that somatic mosaicism in blood increases in an age-dependent way, and it also has a positive association with cancer risk[19, 20]. Although the association between somatic mutations and aging has been poorly studied in the context of solid tumors, our findings indicate that an association between somatic mutations and patients’ ages exists in colorectal cancer. During aging, a colorectal stem/progenitor cell presumably accumulates somatic mutations, some of which could unfortunately be driver mutations that transform the normal cell to a parental clone. This view is also consistent with a recent report that a high division rate of colorectal stem/progenitor cells well explains a high lifetime risk of colorectal cancer[21]. Through mutational signature analysis, we also found that CpG transitions at CpG sites more frequently occur in founder mutations than in progressor mutations. This mutational signature is related to spontaneous deamination of 5-methyl-cytosine at CpG dinucleotides and is most predominantly observed in various cancer types. A recent pan-cancer analysis[11] and our TCGA data analysis showed that this mutational signature is positively correlated with patients’ ages, which is consistent with our finding that founder mutations marked by this signature increased with patients’ ages. As for DNA methylation, hypermethylation in CpG islands was more prominent in founder methylation than in progressor methylation. We also found that the number of hypermethylated probes is correlated with patients’ ages in TGCA samples. Taken together, we speculate that CpG island hypermethylation incurred by aging also predisposes a colorectal stem/progenitor cell to tumorigenesis in collaboration with somatic mutations. Thus, genetic and epigenetic alterations are accumulated during aging, and some of them act as driver alterations that transform the normal cell to a parental clone. Once the parental clone is established, it undergoes branched evolution in a geographically consistent way. In addition to ITH of mutations and CN alterations, we found that epigenetic ITH marked by global hypomethylations is prevalent. Our integrated analysis also showed that the genetic and epigenetic ITH are correlated with each other. In contrast to founder alterations, progressor alterations appeared not to have any known driver alterations, with the exception of a few examples such as PIK3CA mutation and MYC amplification. There also existed no parallel evolution, which is conspicuous in clear cell renal cell carcinomas[3]. Namely, we found little evidence that positive natural selection shaped the extensive ITH, similar to the findings of recent non-small cell lung cancer studies[4, 5]. Moreover, our clonality analysis of mutations suggested that subclones existed even in each of the multiregional samples. It should be noted that such local ITH is consistent with a recent breast cancer study in which single-cell sequencing identified subclonal mutations occurring at low frequencies[22]. In pursuit of the unknown principles generating such extensive ITH, we performed the BEP simulation. Intriguingly, our simulation suggests that neutral evolution can shape extensive ITH as observed in our multiregional mutation profiles. Notably, our simulation also well explained the local ITH within each of the multiregional samples. Although a single-cell mutation profile showed that a simulated tumor actually harbored numerous subclones, snapshots of the simulated evolution suggested that “macroscopic” subclones, which can be captured by the resolution of multiregional sequencing, were generated by genetic drift in the course of the neutral evolution( S20 Fig). A possible mechanism that boosts the neutral mutations is a high mutation rate, as assumed in our simulation. We speculate that genetic instability is incurred and the mutation rate increases before the branched evolution, which is also indicated by the temporal change of mutational signatures. Our computational analysis also suggests that a cancer stem cell hierarchy can boost the neutral evolution[16]. Most importantly, our view that a tumor harbors numerous neutral mutations can explain the robustness and evolvability of cancer. A therapeutic action induces an environmental change, which would convert some of the numerous neutral mutations to driver genes that confer therapeutic resistance. Consistent with this idea, it has recently been reported that resistance to some targeted cancer drugs may result from the outgrowth of preexisting low-frequency subclones[23]. Collectively, this work presents a new model of colorectal cancer evolution; aging leads to the accumulation of genetic and epigenetic alterations in the early phase, while neutral evolution shapes extensive ITH in the late phase( Fig 6). Colorectal cancer has been an attractive subject for studying cancer evolution and its evolution have been addressed from various viewpoints[24–28]. Recently, Sottoriva et al. have also proposed that ITH is mainly shaped by neutral evolution, based on uniformly high ITH, subclonal mixing in distant sites and a power-law distribution of VAFs[10, 29]. Along with these works, this study is unique in that it not only unveiled the extensive ITH, but also explained the underlying principle. We believe that our model not only provides insights into colorectal cancer pathogenesis, but also constitute a new basis for designing therapeutic strategies.","answer":"Cancer is heterogeneous disease; each tumor in different patients has different cancer genomes . Furthermore , another level of heterogeneity exists: even a single tumor harbors multiple genetically distinct subclones . This intratumor heterogeneity is presumably one of causes of therapeutic difficulty , and its understanding is clinically necessary . In this study , we investigated intratumor heterogeneity in colorectal cancer by analyzing sample obtained from geographically separated regions of 9 colorectal tumors . Our integrated data analyses combined with computational simulation strongly suggest that , after clonally shared alterations were accumulated by aging , numerous subclones were generated by neutral evolution . Importantly , this view can explain the robustness and evolvability of cancer: therapeutic action inducing an environmental change would convert some of the numerous neutral mutations to driver genes that confer therapeutic resistance . We believe that this study not only provides insights into colorectal cancer pathogenesis , but also constitutes a new basis for designing therapeutic strategies ."},{"question":"You will be presented with the abstract, introduction, and discussion section from a biomedical research article. Your task is to create a summary that a layperson can understand, capturing the essence of the research article. Keep essential scientific terms, but ensure that the language remains clear and the concepts are explained in an uncomplicated manner.Title: Mesolimbic confidence signals guide perceptual learning in the absence of external feedback}Article:Abstract:It is well established that learning can occur without external feedback, yet normative reinforcement learning theories have difficulties explaining such instances of learning. Here, we propose that human observers are capable of generating their own feedback signals by monitoring internal decision variables. We investigated this hypothesis in a visual perceptual learning task using fMRI and confidence reports as a measure for this monitoring process. Employing a novel computational model in which learning is guided by confidence-based reinforcement signals, we found that mesolimbic brain areas encoded both anticipation and prediction error of confidence—in remarkable similarity to previous findings for external reward-based feedback. We demonstrate that the model accounts for choice and confidence reports and show that the mesolimbic confidence prediction error modulation derived through the model predicts individual learning success. These results provide a mechanistic neurobiological explanation for learning without external feedback by augmenting reinforcement models with confidence-based feedback.Introduction:Learning is an integral part of our everyday life and necessary for survival in a dynamic environment. The behavioral changes arising from learning have quite successfully been described by the reinforcement learning principle( Sutton and Barto, 1998), according to which biological agents continuously adapt their behavior based on the consequences of their actions. Thus, reinforcement learning models and most other learning models depend on feedback from the environment. Yet, there are important instances of learning where no such external feedback is provided, challenging the generality of these learning models in shaping our behavior. A well-studied case of learning is the improvement of performance in perceptually demanding tasks through training or repeated exposure( Gibson, 1963). Such perceptual learning has repeatedly been demonstrated to occur without feedback( Herzog and Fahle, 1997; Gibson and Gibson, 1955; McKee and Westheimer, 1978; Karni and Sagi, 1991) and is therefore ideally suited as a test case to study learning in the absence of external feedback. Previous work has emphasized the role of reinforcement learning in perceptual learning( Kahnt et al., 2011; Law and Gold, 2009). However, these accounts were based on perceptual learning with external feedback and therefore cannot account for instances in which learning occurs without external feedback. Here, we pursued the idea that, in the absence of external feedback, learning is guided by internal feedback processes that evaluate current perceptual information in relation to prior knowledge about the sensory world. We reasoned that introspective reports of perceptual confidence could serve as a window into such internal feedback processes. In this scenario, low or high confidence would correspond to a negative or positive self-evaluation of one’s own perceptual performance, respectively. Accordingly, confidence could act as a teaching signal in the same way as external feedback in normative theories of reinforcement learning( Daniel and Pollmann, 2012; Hebart et al., 2014). Applied to the case of perceptual learning, a confidence-based reinforcement signal could serve to strengthen neural circuitry that gave rise to high-confidence percepts and weaken circuitry that led to low-confidence percepts, thereby enhancing the quality of future percepts. We tested this idea in a challenging perceptual learning task, in which participants continuously reported their confidence in perceptual choices while undergoing functional magnetic resonance imaging( fMRI). No external feedback was provided; instead, confidence ratings were used as a proxy of internal monitoring processes. To account for perceptual learning in the absence of feedback, we devised a confidence-based associative reinforcement learning model. In the model, confidence prediction errors( Daniel and Pollmann, 2012) serve as teaching signals that indicate the mismatch between the current level of confidence and a running average of previous confidence experiences( expected confidence). Based on recent evidence of confidence signals in the mesolimbic dopamine system( Daniel and Pollmann, 2012; Hebart et al., 2014; Schwarze et al., 2013), we hypothesized to find neural correlates of confidence prediction errors in mesolimbic brain areas such as the ventral striatum and the ventral tegmental area. Since confidence prediction errors act as a teaching signal in our model, we hypothesized that the strength of these mesolimbic confidence signals should be linked to individual perceptual learning success.Discussion:In this study, we used perceptual learning to address the question of how humans can improve performance in the absence of external feedback. Previous reinforcement learning accounts of perceptual learning were based on external cognitive and rewarding feedback( Law and Gold, 2009; Kahnt et al., 2011) and could not explain the established phenomenon of perceptual learning without such feedback( Herzog and Fahle, 1997; Gibson and Gibson, 1955; McKee and Westheimer, 1978; Karni and Sagi, 1991). Here, we suggest that observers are capable of generating internal feedback by utilizing confidence signals that provide a graded evaluation of the correctness of a perceptual decision. In this way, confidence may serve as a reinforcement signal similar to reward and guide perceptual learning in cases where no external feedback is provided. In support of this view, our model-free fMRI analyses revealed that mesolimbic confidence signals mirror those typically found for reward, both in the anticipation period( Preuschoff et al., 2006; Delgado et al., 2000; Knutson et al., 2001) and for prediction errors( Schultz et al., 1997; O’Doherty et al., 2004; Berns et al., 2001). To establish a mechanistic ground for this suggested parallel, we devised an associate reinforcement learning model, which links behavior to computational variables that each account for a different aspect of the learning process. CPEs served as feedback in the model, defined as the difference between the current level of confidence and a long-term estimate of expected confidence. The model successfully described the learning process as a continuous adjustment of a perceptual filter linking sensory and decision units. Our model-based fMRI analyses confirmed and extended the results of the model-free analyses by demonstrating a parametric modulation in mesolimbic brain areas both by expected confidence and confidence prediction. Importantly, the strength of the striatal modulation by CPEs predicted participants’ perceptual improvements, further corroborating the behavioral relevance of these internally-generated feedback signals. The observed pattern of confidence-related activity in the mesolimbic system, including the co-modulation of the ventral tegmental area, fit well with the prediction error hypothesis of dopamine, which posits that dopaminergic midbrain neurons and their targets respond at two time points during a learning trial( Schultz et al., 1997). In this framework, the first response is triggered by an outcome-predictive cue and reflects an anticipatory signal. In the case of classical reinforcement learning, such a cue may be probabilistically coupled with rewards of possibly varying magnitudes. The anticipated value of the cue is then assumed to be computed as the average reward magnitude—contingent on the cue—in previous trials( Schultz, 2006). Here, we argue that the same principle could hold for confidence: participants learn to anticipate a certain level of confidence for the upcoming trial based on past confidence experiences, and this anticipatory state is activated when the beginning of a new trial is indicated( equivalent to a cue). In congruence with this postulation, we indeed found a modulation of striatal activity by expected confidence at trial onsets—as previously reported for expected reward( Preuschoff et al., 2006; Delgado et al., 2000; Knutson et al., 2001). The second response is triggered by the actual outcome and corresponds to a prediction error signal. In classical reinforcement learning, the reward prediction error represents the difference between expected value and actual outcome. In the confidence domain, the outcome would correspond to the level of confidence calculated from the stimulus and the prediction error would be computed as the difference between expected confidence and actual confidence. Overall, our results may therefore indicate that self-generated confidence assumes the role of external reward in dopaminergic prediction-error-based reinforcement learning when no external feedback is available. A number of previous studies have used reinforcement learning models to capture the neural underpinnings of perceptual learning( Law and Gold, 2009; Kahnt et al., 2011) and category learning( Daniel and Pollmann, 2012). In particular, an fMRI study by Kahnt and colleagues( Kahnt et al., 2011) investigated perceptual learning with external reward and found that behavioral improvements were well explained by a reinforcement learning model. Their results exhibit a notable parallel to the present findings: the authors reported stimulus information encoded in visual cortex and model-derived decision value in frontal cortices, in agreement with the findings of the present study. In addition, this previous study identified a perceptual learning-related reward prediction error in the ventral striatum, dovetailing with our finding of a perceptual learning-related confidence prediction error in the same brain region. Importantly, our combined Hebbian and reinforcement learning model extends and improves previous models in several ways. First and foremost, by implementing confidence prediction errors in replacement of reward prediction errors, it extends previous reward reinforcement learning models of perceptual learning( Law and Gold, 2009; Kahnt et al., 2011) to cases without feedback. Second, these previous models were based on the assumption that perceptual performance is determined by a single 'readout weight', representing the amplification of stimulus information in sensory areas. While the simplicity of these models is appealing, they are limited in the sense that negative prediction errors have an unreasonable influence on behavior: according to these models, worse-than-expected feedback reduces the readout weight, which leads to an additional reduction in performance. This property runs counter to the idea that reinforcement learning agents improve their behavior through both positive and negative prediction errors. By contrast, the associative reinforcement learning rule of the present model entails a behaviorally advantageous and plausible function of negative prediction errors: inhibition of sensory noise. Third, a conceptually related reinforcement learning model for perceptual categorization( Daniel and Pollmann, 2012) implies that stimuli exclusively activate the correct stimulus category, an assumption that disregards the fact that the ambiguity of incoming stimulus information is an essential property of perceptually demanding tasks. In contrast, the present model utilizes a dedicated representational subsystem( Petrov et al., 2005) to estimate the activation of all implemented input units, and it is their differential activity that determines perceptual choices. The present model and results are biologically plausible and fit well with theoretical accounts of the neural basis of learning. The associative reinforcement learning rule in the model was inspired by the three-factor learning rule( Schultz, 2002; Reynolds et al., 2001), which has been proposed to underlie the potentiation of synapses in the striatum. It proposes that changes in neural transmission in cortico-striatal synapses not only depend on coincident presynaptic and postsynaptic activity( Hebbian learning), but also on the presence of dopamine error signals. Indeed, Ashby and colleagues( Ashby et al., 2007; Hélie et al., 2015) have previously suggested that the basal ganglia, which represent the predominant site of dopaminergic synaptic plasticity, are themselves a key region for learning in perceptual tasks. They proposed that( i) the basal ganglia serve to activate the appropriate target regions in executive frontal cortices shortly after sensory cortex activation; and( ii) such basal ganglia learning is superseded by cortico-cortical Hebbian learning, once the correct cortico-cortical synapses are built. This account fits well with the present model, in which perceptual learning corresponds to the process of reweighting connections between sensory and decisional units. These considerations in combination with the present results thus lend support to the hypothesis that the optimization of perceptual read-out( as implicated by our model) could be mediated via reinforcement learning in the basal ganglia. While our study represents a first but important step towards understanding the role of confidence signals in perceptual learning, future studies are needed to investigate in more detail the characteristics of these signals which were not addressed in the current study. First, are these signals triggered independent of whether participants have to report their level of confidence after the percept or independent of whether they receive external feedback? Investigating these questions could clarify whether the observed activity in the reward network is an automatic response or depends on the task of the observer. Second, are these learning signals independent of making a perceptual decision? In other words, are they triggered only when participants have to engage in a subsequent perceptual choice? Similarly, can these confidence signals be disentangled from choice accuracy, for instance by manipulating stimulus luminance( Busey et al., 2000)? An answer to this latter question would shed light on the nature of the confidence signals, i. e. whether they can also be affected by metacognitive biases. In summary, our study devised and tested a novel model of perceptual learning in the absence of external feedback, utilizing confidence prediction errors to guide the learning process. Our analyses revealed a compelling analogy between confidence-based and reward-based feedback, suggesting a similar neural mechanism for learning with and without external feedback. Future work could investigate whether a learning mechanism based on such self-generated feedback is also applicable outside the realm of perception, where learning without feedback has likewise been a long-standing puzzle( Köhler, 1925).","answer":"Much of our behavior is shaped by feedback from the environment . We repeat behaviors that previously led to rewards and avoid those with negative outcomes . At the same time , we can learn in many situations without such feedback . Our ability to perceive sensory stimuli , for example , improves with training even in the absence of external feedback . Guggenmos et al . hypothesized that this form of perceptual learning may be guided by self-generated feedback that is based on the confidence in our performance . The general idea is that the brain reinforces behaviors associated with states of high confidence , and weakens behaviors that lead to low confidence . To test this idea , Guggenmos et al . used a technique called functional magnetic resonance imaging to record the brain activity of healthy volunteers as they performed a visual learning task . In this task , the participants had to judge the orientation of barely visible line gratings and then state how confident they were in their decisions . Feedback signals derived from the participants’ confidence reports activated the same brain areas typically engaged for external feedback or reward . Moreover , just as these regions were previously found to signal the difference between actual and expected rewards , so did they signal the difference between actual confidence levels and those expected on the basis of previous confidence levels . This parallel suggests that confidence may take over the role of external feedback in cases where no such feedback is available . Finally , the extent to which an individual exhibited these signals predicted overall learning success . Future studies could investigate whether these confidence signals are automatically generated , or whether they only emerge when participants are required to report their confidence levels . Another open question is whether such self-generated feedback applies in non-perceptual forms of learning , where learning without feedback has likewise been a long-standing puzzle ."},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Interaction with central nervous system depressants other than benzodiazepines has not been specifically studied; however, no deleterious interactions were seen when ROMAZICON was administered after narcotics, inhalational anesthetics, muscle relaxants and muscle relaxant antagonists administered in conjunction with sedation or anesthesia. Particular caution is necessary when using ROMAZICON in cases of mixed drug overdosage since the toxic effects (such as convulsions and cardiac dysrhythmias) of other drugs taken in overdose (especially cyclic antidepressants) may emerge with the reversal of the benzodiazepine effect by flumazenil. The use of ROMAZICON is not recommended in epileptic patients who have been receiving benzodiazepine treatment for a prolonged period. Although ROMAZICON exerts a slight intrinsic anticonvulsant effect, its abrupt suppression of the protective effect of a benzodiazepine agonist can give rise to convulsions in epileptic patients. ROMAZICON blocks the central effects of benzodiazepines by competitive interaction at the receptor level. The effects of nonbenzodiazepine agonists at benzodiazepine receptors, such as zopiclone, triazolopyridazines and others, are also blocked by ROMAZICON. The pharmacokinetics of benzodiazepines are unaltered in the presence of flumazenil and vice versa. There is no pharmacokinetic interaction between ethanol and flumazenil. Use in Ambulatory Patients The effects of ROMAZICON may wear off before a long-acting benzodiazepine is completely cleared from the body. In general, if a patient shows no signs of sedation within 2 hours after a 1-mg dose of flumazenil, serious resedation at a later time is unlikely. An adequate period of observation must be provided for any patient in whom either long-acting benzodiazepines (such as diazepam) or large doses of short-acting benzodiazepines (such as  10 mg of midazolam) have been used. Because of the increased risk of adverse reactions in patients who have been taking benzodiazepines on a regular basis, it is particularly important that physicians query patients or their guardians carefully about benzodiazepine, alcohol and sedative use as part of the history prior to any procedure in which the use of ROMAZICON is planned.","answer":"{\\"Brand\\": [\\"ROMAZICON\\"], \\"Drug\\": [\\"flumazenil\\", \\"zopiclone\\", \\"alcohol\\", \\"diazepam\\", \\"ethanol\\", \\"midazolam\\"], \\"DrugGroup\\": [\\"benzodiazepines\\", \\"muscle relaxants\\", \\"sedative\\", \\"short-acting benzodiazepines\\", \\"long-acting benzodiazepine\\", \\"anesthetics\\", \\"central nervous system depressants\\", \\"long-acting benzodiazepines\\", \\"narcotics\\", \\"cyclic antidepressants\\", \\"benzodiazepine\\"], \\"UnapprovedDrug\\": []}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: Computer-Vision Based Diagnosis of Parkinson’s Disease via Gait: A Survey Chapter Title:  c: MB AND ML FUSION 1. Abstract of Cited Paper (BIB001):  Abstract Gait patterns differ between healthy elders and those with Parkinson's disease (PD). A simple, low-cost clinical tool that can evaluate kinematic differences between these populations would be invaluable diagnostically; since gait analysis in a clinical setting is impractical due to cost and technical expertise. This study investigated the between group differences between the Kinect and a 3D movement analysis system (BTS) and reported validity and reliability of the Kinect v2 sensor for gait analysis. Nineteen subjects participated, eleven without (C) and eight with PD (PD). Outcome measures included spatiotemporal parameters and kinematics. Ankle range of motion for C was significantly less during ankle swing compared to PD ( p = 0.04) for the Kinect. Both systems showed significant differences for stride length (BTS (C 1.24 ± 0.16, PD= 1.01 ± 0.17, p = 0.009), Kinect (C= 1.24 ± 0.17, PD= 1.00 ± 0.18, p = 0.009)), gait velocity (BTS (C= 1.06 ± 0.14, PD= 0.83 ± 0.15, p = 0.01), Kinect (C= 1.06 ± 0.15, PD= 0.83 ± 0.16, p = 0.01)), and swing velocity (BTS (C= 2.50 ± 0.27, PD= 2.12 ± 0.36, p = 0.02), Kinect (C= 2.32 ± 0.25, PD= 1.95 ± 0.31, p = 0.01)) between groups. Agreement (Range ICC = 0.93–0.99) and consistency (Range ICC = 0.94–0.99) were excellent between systems for stride length, stance duration, swing duration, gait velocity, and swing velocity. The Kinect v2 can was sensitive enough to detect between group differences and consistently produced results similar to the BTS system.Literature Review:","answer":"However, both the vision-based modalities i.e. MB and ML offered high reliability for PD investigation, some of the research studies used the fusion of them (e.g. 3D Mocap system+ reflective markers and MS Kinect). In this category, Mocap systems in combination with markers were used as a 'gold standard' to compare the simultaneously captured results using Kinect, to check its efficacy in PD assessment. Eltoukhy et al. BIB002 presented a study to scrutinize and compare the gait variables of older adults suffering from PD and having no such disease. The gait data was gathered using Kinect v2, a Mocap system (BTS) and reflective markers concurrently. The study results demonstrated the correlation among both the systems, reflecting the potential of Kinect v2. Another work reported by Galna et al. BIB001 tried to explore the capability of Kinect in diagnosing the movement of 9 PD and 10 healthy subjects. The experiment was conducted by initially collecting the gait data using 3D Vicon system along with markers as a benchmark and a Kinect system. Comparison among computed gait variables via both modalities manifested high correlation (r>0.8) proving the reliability of the Kinect sensor for PD inspection."},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Acute critical limb ischemiaSevere critical limb ischemia (Rutherford category 6)Major bleeding history within prior 2 monthsKnown hypersensitivity or contraindication to any of the following medications: heparin, aspirin, clopidogrel or contrast agentsAge > 85 yearsSevere hepatic dysfunction (> 3 times normal reference values)Significant renal dysfunction (Serum creatinine > 2.0 mg/dlSignificant leucopenia, neutropenia, thrombocytopenia, anemia, or known bleeding diathesisLVEF <40% or clinically overt congestive heart failurePregnant women or women with potential childbearingLife expectancy <1 year due to comorbidityPrevious bypass surgery or stenting of the superficial femoral arteryUntreated inflow disease of the ipsilateral pelvic arteries (more than 50%stenosis or or occlusionPopliteal artery stenosis >50% at P2 or P3 segment","answer":"{\\"Condition\\": [\\"comorbidity\\", \\"hepatic dysfunction\\", \\"hypersensitivity\\", \\"stenosis\\", \\"Popliteal artery stenosis\\", \\"inflow disease\\", \\"Major bleeding history\\", \\"renal dysfunction\\", \\"limb ischemia\\", \\"contraindication\\", \\"leucopenia\\", \\"thrombocytopenia\\", \\"potential childbearing\\", \\"congestive heart failure\\", \\"anemia\\", \\"Pregnant\\", \\"bleeding diathesis\\", \\"neutropenia\\"], \\"Device\\": [\\"stenting of the superficial femoral artery\\"], \\"Drug\\": [\\"aspirin\\", \\"contrast agents\\", \\"clopidogrel\\", \\"heparin\\"], \\"Measurement\\": [\\"LVEF\\", \\"Serum creatinine\\", \\"Rutherford category\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [\\"Life expectancy\\"], \\"Person\\": [\\"women\\", \\"Age\\"], \\"Procedure\\": [\\"bypass surgery\\"], \\"Qualifier\\": [\\"Significant\\", \\"clinically overt\\", \\"critical\\", \\"Untreated\\", \\"Severe\\", \\"P2 or P3 segment\\", \\"ipsilateral pelvic arteries\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"heparin, aspirin, clopidogrel or contrast agents\\", \\"hypersensitivity or contraindication\\", \\"leucopenia, neutropenia, thrombocytopenia, anemia, or known bleeding diathesis\\", \\"%stenosis or nPopliteal \\", \\"Severe critical\\"], \\"Temporal\\": [\\"Previous\\", \\"Acute\\", \\"within prior 2 months\\"], \\"Value\\": [\\"u003e50%\\", \\"more than 50%\\", \\"u003e 2.0 mg/dl\\", \\"u003c1 year\\", \\"u003e 85 years\\", \\"occlusion\\", \\"6\\", \\"u003c40%\\"], \\"Visit\\": []}"},{"question":"You will be shown a paragraph from a biomedical research paper, followed by a question about the paper. Please extract text from the paragraph to answer the question. Do not include any text in your repsonse other than the answer.Paragraph: Country % of total population infected (mean [95% credible intervall)Austria 1.1% [0.36%-3.1%]Belgium 3.7% [1.3%-9.7%] Denmark 1.1% [0.40%-3.1%]France 3.0% [1.1%-7.4%]Germany 0.72% [0.28%-1.8%]Italy 9.8% [3.2%-26%]Norway 0.41% [0.09%-1.2%]Spain 15% [3.7%-41%]Sweden 3.1% [0.85%-8.4%]Switzerland 3.2% [1.3%-7.6%]United Kingdom 2.7% [1.2%-5.4%]2.2 Reproduction numbers and impact of interventionsAveraged across all countries, we estimate initial reproduction numbers of around 3.87 [3.01-4.66],which is in line with other estimates.1'8 These estimates are informed by our choice of serial intervaldistribution and the initial growth rate of observed deaths. A shorter assumed serial interval results inlower starting reproduction numbers (Appendix 8.4.2, Appendix 8.4.6). The initial reproductionnumbers are also uncertain due to (a) importation being the dominant source of new infections earlyin the epidemic, rather than local transmission (b) possible under-ascertainment in deaths particularlybefore testing became widespread. We estimate large changes in Rt in response to the combined non-pharmaceutical interventions. Ourresults, which are driven largely by countries with advanced epidemics and larger numbers of deaths(e.g. Italy, Spain), suggest that these interventions have together had a substantial impact ontransmission, as measured by changes in the estimated reproduction number Rt. Across all countrieswe find current estimates of Rt to range from a posterior mean of 0.97 [0.14-2.14] for Norway to aposterior mean of2.64 [1.40-4.18] for Sweden, with an average of 1.43 across the 11 country posteriormeans, a 64% reduction compared to the pre-intervention values. We note that these estimates arecontingent on intervention impact being the same in different countries and at different times. In allcountries but Sweden, under the same assumptions, we estimate that the current reproductionnumber includes 1 in the uncertainty range. The estimated reproduction number for Sweden is higher,not because the mortality trends are significantly different from any other country, but as an artefactof our model, which assumes a smaller reduction in Rt because no full lockdown has been ordered sofar. Overall, we cannot yet conclude whether current interventions are sufficient to drive Rt below 1(posterior probability of being less than 1.0 is 44% on average across the countries). We are alsounable to conclude whether interventions may be different between countries or over time. There remains a high level of uncertainty in these estimates. It is too early to detect substantialintervention impact in many countries at earlier stages of their epidemic (e.g. Germany, UK, Norway). Many interventions have occurred only recently, and their effects have not yet been fully observeddue to the time lag between infection and death. This uncertainty will reduce as more data becomeavailable. For all countries, our model fits observed deaths data well (Bayesian goodness of fit tests). We also found that our model can reliably forecast daily deaths 3 days into the future, by withholdingthe latest 3 days of data and comparing model predictions to observed deaths (Appendix 8.3). The close spacing of interventions in time made it statistically impossible to determine which had thegreatest effect (Figure 1, Figure 4). However, when doing a sensitivity analysis (Appendix 8.4.3) withuninformative prior distributions (where interventions can increase deaths) we find similar impact ofImperial College COVID-19 Response Teaminterventions, which shows that our choice of prior distribution is not driving the effects we see in themain analysis. Figure 2: Country-level estimates of infections, deaths and Rt. Left: daily number of infections, brownbars are reported infections, blue bands are predicted infections, dark blue 50% credible interval (CI),light blue 95% CI. The number of daily infections estimated by our model drops immediately after anintervention, as we assume that all infected people become immediately less infectious through theintervention. Afterwards, if the Rt is above 1, the number of infections will starts growing again. Middle: daily number of deaths, brown bars are reported deaths, blue bands are predicted deaths, CIas in left plot. Right: time-varying reproduction number Rt, dark green 50% CI, light green 95% CI. Icons are interventions shown at the time they occurred. Imperial College COVID-19 Response TeamTable 2: Totalforecasted deaths since the beginning of the epidemic up to 31 March in our modeland in a counterfactual model (assuming no intervention had taken place). Estimated averted deathsover this time period as a result of the interventions. Numbers in brackets are 95% credible intervals. 2.3 Estimated impact of interventions on deathsTable 2 shows total forecasted deaths since the beginning of the epidemic up to and including 31March under ourfitted model and under the counterfactual model, which predicts what would havehappened if no interventions were implemented (and R, = R0 i.e. the initial reproduction numberestimated before interventions). Again, the assumption in these predictions is that interventionimpact is the same across countries and time. The model without interventions was unable to capturerecent trends in deaths in several countries, where the rate of increase had clearly slowed (Figure 3). Trends were confirmed statistically by Bayesian leave-one-out cross-validation and the widelyapplicable information criterion assessments —WA|C). By comparing the deaths predicted under the model with no interventions to the deaths predicted inour intervention model, we calculated the total deaths averted up to the end of March. We find that,across 11 countries, since the beginning of the epidemic, 59,000 [21,000-120,000] deaths have beenaverted due to interventions. In Italy and Spain, where the epidemic is advanced, 38,000 [13,000-84,000] and 16,000 [5,400-35,000] deaths have been averted, respectively. Even in the UK, which ismuch earlier in its epidemic, we predict 370 [73-1,000] deaths have been averted. These numbers give only the deaths averted that would have occurred up to 31 March. lfwe were toinclude the deaths of currently infected individuals in both models, which might happen after 31March, then the deaths averted would be substantially higher. Figure 3: Daily number of confirmed deaths, predictions (up to 28 March) and forecasts (after) for (a)Italy and (b) Spain from our model with interventions (blue) and from the no interventionscounterfactual model (pink); credible intervals are shown one week into the future. Other countriesare shown in Appendix 8.6. 03/0 25% 50% 753% 100%(no effect on transmissibility) (ends transmissibilityRelative % reduction in R.Figure 4: Our model includes five covariates for governmental interventions, adjusting for whetherthe intervention was the first one undertaken by the government in response to COVID-19 (red) orwas subsequent to other interventions (green). Mean relative percentage reduction in Rt is shownwith 95% posterior credible intervals. If 100% reduction is achieved, Rt = 0 and there is no moretransmission of COVID-19. No effects are significantly different from any others, probably due to thefact that many interventions occurred on the same day or within days of each other as shown inFigure l.3 DiscussionDuring this early phase of control measures against the novel coronavirus in Europe, we analyze trendsin numbers of deaths to assess the extent to which transmission is being reduced. Representing theCOVlD-19 infection process using a semi-mechanistic, joint, Bayesian hierarchical model, we canreproduce trends observed in the data on deaths and can forecast accurately over short time horizons. We estimate that there have been many more infections than are currently reported. The high levelof under-ascertainment of infections that we estimate here is likely due to the focus on testing inhospital settings rather than in the community. Despite this, only a small minority of individuals ineach country have been infected, with an attack rate on average of 4.9% [l.9%-ll%] with considerablevariation between countries (Table 1). Our estimates imply that the populations in Europe are notclose to herd immunity (\\"50-75% if R0 is 2-4). Further, with Rt values dropping substantially, the rateof acquisition of herd immunity will slow down rapidly. This implies that the virus will be able to spreadrapidly should interventions be lifted. Such estimates of the attack rate to date urgently need to bevalidated by newly developed antibody tests in representative population surveys, once these becomeavailable. We estimate that major non-pharmaceutical interventions have had a substantial impact on the time-varying reproduction numbers in countries where there has been time to observe intervention effectson trends in deaths (Italy, Spain). lfadherence in those countries has changed since that initial period,then our forecast of future deaths will be affected accordingly: increasing adherence over time willhave resulted in fewer deaths and decreasing adherence in more deaths. Similarly, our estimates ofthe impact ofinterventions in other countries should be viewed with caution if the same interventionshave achieved different levels of adherence than was initially the case in Italy and Spain. Due to the implementation of interventions in rapid succession in many countries, there are notenough data to estimate the individual effect size of each intervention, and we discourage attributingassociations to individual intervention. In some cases, such as Norway, where all interventions wereimplemented at once, these individual effects are by definition unidentifiable. Despite this, whileindividual impacts cannot be determined, their estimated joint impact is strongly empirically justified(see Appendix 8.4 for sensitivity analysis). While the growth in daily deaths has decreased, due to thelag between infections and deaths, continued rises in daily deaths are to be expected for some time. To understand the impact of interventions, we fit a counterfactual model without the interventionsand compare this to the actual model. Consider Italy and the UK - two countries at very different stagesin their epidemics. For the UK, where interventions are very recent, much of the intervention strengthis borrowed from countries with older epidemics. The results suggest that interventions will have alarge impact on infections and deaths despite counts of both rising. For Italy, where far more time haspassed since the interventions have been implemented, it is clear that the model withoutinterventions does not fit well to the data, and cannot explain the sub-linear (on the logarithmic scale)reduction in deaths (see Figure 10). The counterfactual model for Italy suggests that despite mounting pressure on health systems,interventions have averted a health care catastrophe where the number of new deaths would havebeen 3.7 times higher (38,000 deaths averted) than currently observed. Even in the UK, much earlierin its epidemic, the recent interventions are forecasted to avert 370 total deaths up to 31 of March. 4 Conclusion and LimitationsModern understanding of infectious disease with a global publicized response has meant thatnationwide interventions could be implemented with widespread adherence and support. Givenobserved infection fatality ratios and the epidemiology of COVlD-19, major non-pharmaceuticalinterventions have had a substantial impact in reducing transmission in countries with more advancedepidemics. It is too early to be sure whether similar reductions will be seen in countries at earlierstages of their epidemic. While we cannot determine which set of interventions have been mostsuccessful, taken together, we can already see changes in the trends of new deaths. When forecasting3 days and looking over the whole epidemic the number of deaths averted is substantial. We note thatsubstantial innovation is taking place, and new more effective interventions or refinements of currentinterventions, alongside behavioral changes will further contribute to reductions in infections. Wecannot say for certain that the current measures have controlled the epidemic in Europe; however, ifcurrent trends continue, there is reason for optimism. Our approach is semi-mechanistic. We propose a plausible structure for the infection process and thenestimate parameters empirically. However, many parameters had to be given strong priordistributions or had to be fixed. For these assumptions, we have provided relevant citations toprevious studies. As more data become available and better estimates arise, we will update these inweekly reports. Our choice of serial interval distribution strongly influences the prior distribution forstarting R0. Our infection fatality ratio, and infection-to-onset-to-death distributions stronglyinfluence the rate of death and hence the estimated number of true underlying cases. We also assume that the effect of interventions is the same in all countries, which may not be fullyrealistic. This assumption implies that countries with early interventions and more deaths since theseinterventions (e.g. Italy, Spain) strongly influence estimates of intervention impact in countries atearlier stages of their epidemic with fewer deaths (e.g. Germany, UK). We have tried to create consistent definitions of all interventions and document details of this inAppendix 8.6. However, invariably there will be differences from country to country in the strength oftheir intervention — for example, most countries have banned gatherings of more than 2 people whenimplementing a lockdown, whereas in Sweden the government only banned gatherings of more than10 people. These differences can skew impacts in countries with very little data. We believe that ouruncertainty to some degree can cover these differences, and as more data become available,coefficients should become more reliable. However, despite these strong assumptions, there is sufficient signal in the data to estimate changesin R, (see the sensitivity analysis reported in Appendix 8.4.3) and this signal will stand to increase withtime. In our Bayesian hierarchical framework, we robustly quantify the uncertainty in our parameterestimates and posterior predictions. This can be seen in the very wide credible intervals in more recentdays, where little or no death data are available to inform the estimates. Furthermore, we predictintervention impact at country-level, but different trends may be in place in different parts of eachcountry. For example, the epidemic in northern Italy was subject to controls earlier than the rest ofthe country.Question: What is Belgium's estimated mean percentage [95% credible interval] of total population infected as of 28th March?","answer":"3.7% [1.3%-9.7%]"},{"question":"You are provided with a research question, keyphrases about the question, a description of candidate datasets and dataset options. Read the description of popular datasets provided below and select the ones that can be used to validate the following research question. Use your knowledge of machine learning datasets to make the best judgement.Your response should be formatted as a \`json\` array. For instance, for the query \\"Semi supervised image classification\\", a sample response might be: [\\"CIFAR-10\\", \\"CIFAR-100\\"]. Do not include any extra text in the response other than the answer array.Query: I have a large ReID dataset.Keyphrases: person re-identification imagesDataset description:PKU-Reid: This dataset contains 114 individuals including 1824 images captured from two disjoint camera views. For each person, eight images are captured from eight different orientations under one camera view and are normalized to 128x48 pixels.COCO-Tasks: Comprises about 40,000 images where the most suitable objects for 14 tasks have been annotated.Market-1501: Market-1501 is a large-scale public benchmark dataset for person re-identification. It contains 1501 identities which are captured by six different cameras, and 32,668 pedestrian image bounding-boxes obtained using the Deformable Part Models pedestrian detector.Partial-REID: Partial REID is a specially designed partial person reidentification dataset that includes 600 images from 60 people, with 5 full-body images and 5 occluded images per person. These images were collected on a university campus by 6 cameras from different viewpoints, backgrounds and different types of occlusion.VRAI: VRAI is a large-scale vehicle ReID dataset for UAV-based intelligent applications. The dataset consists of 137, 613 images of 13, 022 vehicle instances.CUHK03: The CUHK03 consists of 14,097 images of 1,467 different identities, where 6 campus cameras were deployed for image collection and each identity is captured by 2 campus cameras. This dataset provides two types of annotations, one by manually labelled bounding boxes and the other by bounding boxes produced by an automatic detector.Options:- A: PKU-Reid  B: COCO-Tasks  C: Market-1501  D: Partial-REID  E: VRAI  F: CUHK03","answer":"[\\"Market-1501\\", \\"CUHK03\\"]"},{"question":"You are provided with the abstract of a scientific paper and the abstracts of the papers it references. Your task is to write a Related Work section for the main paper. This section should concisely summarize and integrate the key points from the cited abstracts, reflecting how they relate to the main paper's contributions and context. In your summary, use numerical citation markers like [1], [2], etc., to refer to the corresponding papers.Main Abstract:This paper reexamines univariate reduction from a toric geometric point of view. We begin by constructing a binomial variant of the @math -resultant and then retailor the generalized characteristic polynomial to fully exploit sparsity in the monomial structure of any given polynomial system. We thus obtain a fast new algorithm for univariate reduction and a better understanding of the underlying projections. As a corollary, we show that a refinement of Hilbert's Tenth Problem is decidable within single-exponential time. We also show how certain multisymmetric functions of the roots of polynomial systems can be calculated with sparse resultants.Cited Abstract(s):[1]: Multipolynomial resultants provide the most efficient methods known (in terms as asymptoticcomplexity) for solving certain systems of polynomial equations or eliminating variables (, 1988). The resultant of f\\"1, ..., f\\"n in K[x\\"1,...,x\\"m] will be a polynomial in m-n+1 variables which is zero when the system f\\"1=0 has a solution in ^m ( the algebraic closure of K). Thus the resultant defines a projection operator from ^m to ^(^m^-^n^+^1^). However, resultants are only exact conditions for homogeneous systems, and in the affine case just mentioned, the resultant may be zero even if the system has no affine solution. This is most serious when the solution set of the system of polynomials has ''excess components'' (components of dimension >m-n), which may not even be affine, since these cause the resultant to vanish identically. In this paper we describe a projection operator which is not identically zero, but which is guaranteed to vanish on all the proper (dimension=m-n) components of the system f\\"i=0. Thus it fills the role of a general affine projection operator or variable elimination ''black box'' which can be used for arbitrary polynomial systems. The construction is based on a generalisation of the characteristic polynomial of a linear system to polynomial systems. As a corollary, we give a single-exponential time method for finding all the isolated solution points of a system of polynomials, even in the presence of infinitely many solutions, at infinity or elsewhere.[2]: Abstract We propose a new and efficient algorithm for computing the sparse resultant of a system of n + 1 polynomial equations in n unknowns. This algorithm produces a matrix whose entries are coefficients of the given polynomials and is typically smaller than the matrices obtained by previous approaches. The matrix determinant is a non-trivial multiple of the sparse resultant from which the sparse resultant itself can be recovered. The algorithm is incremental in the sense that successively larger matrices are constructed until one is found with the above properties. For multigraded systems, the new algorithm produces optimal matrices, i.e. expresses the sparse resultant as a single determinant. An implementation of the algorithm is described and experimental results are presented. In addition, we propose an efficient algorithm for computing the mixed volume of n polynomials in n variables. This computation provides an upper bound on the number of common isolated roots. A publicly available implementation of the algorithm is presented and empirical results are reported which suggest that it is the fastest mixed volume code to date.","answer":"From an applied angle, our observations on degeneracies and handling polynomial systems with infinitely many roots nicely complement the work of Emiris and Canny [2] . In particular, their sparse resultant based algorithms for polynomial system solving can now be made to work even when problem B occurs. Also, an added benefit of working torically (as opposed to the classical approach of working in projective space) is the increased efficiency of the sparse resultant: the resulting matrix calculations (for polynomial system solving) are much smaller and faster. In particular, whereas it was remarked in [1] that Gr \\"obner basis methods are likely to be faster than the GCP for sparse polynomial systems, the toric GCP appears to be far more competitive in such a comparison."},{"question":"You will be shown a claim related to the COVID-19 pandemic, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\".- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract.For instance, if the model were given the claim \\"the COVID vaccine is safe for healthy adults\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that the risks of severe COVID vaccine side effects are low for healthy adults.\\"]}Claim: Measuring sars-cov-2 neutralizing antibody activity using pseudotyped and chimeric virusesAbstract:The emergence of SARS-CoV-2 and the ensuing explosive epidemic of COVID-19 disease has generated a need for assays to rapidly and conveniently measure the antiviral activity of SARS-CoV-2-specific antibodies.Here, we describe a collection of approaches based on SARS-CoV-2 spike-pseudotyped, single-cycle, replication-defective human immunodeficiency virus type-1 (HIV-1), and vesicular stomatitis virus (VSV), as well as a replication-competent VSV/SARS-CoV-2 chimeric virus.While each surrogate virus exhibited subtle differences in the sensitivity with which neutralizing activity was detected, the neutralizing activity of both convalescent plasma and human monoclonal antibodies measured using each virus correlated quantitatively with neutralizing activity measured using an authentic SARS-CoV-2 neutralization assay.The assays described herein are adaptable to high throughput and are useful tools in the evaluation of serologic immunity conferred by vaccination or prior SARS-CoV-2 infection, as well as the potency of convalescent plasma or human monoclonal antibodies.","answer":"{\\"verdict\\": \\"SUPPORT\\", \\"evidence\\": [\\"While each surrogate virus exhibited subtle differences in the sensitivity with which neutralizing activity was detected, the neutralizing activity of both convalescent plasma and human monoclonal antibodies measured using each virus correlated quantitatively with neutralizing activity measured using an authentic SARS-CoV-2 neutralization assay.\\"]}"},{"question":"Given a short query with keyphrases about a research idea in 2019 in the domain of artificial intelligence, recommend the relevant datasets to validate the research idea from options provided. A short description of the datasets is also provided to help you.Query: We propose a generative model for images with Convolutional Sum-Product Networks (ConvSPNs).Keyphrases: generative image modeling imagesDataset description:CIFAR-10: The CIFAR-10 dataset (Canadian Institute for Advanced Research, 10 classes) is a subset of the Tiny Images dataset and consists of 60000 32x32 color images. The images are labelled with one of 10 mutually exclusive classes: airplane, automobile (but not truck or pickup truck), bird, cat, deer, dog, frog, horse, ship, and truck (but not pickup truck).COCO-Text: The COCO-Text dataset is a dataset for text detection and recognition. It is based on the MS COCO dataset, which contains images of complex everyday scenes.Stanford Cars: The Stanford Cars dataset consists of 196 classes of cars with a total of 16,185 images, taken from the rear. The data is divided into almost a 50-50 train/test split with 8,144 training images and 8,041 testing images.MPII Human Pose: MPII Human Pose Dataset is a dataset for human pose estimation. It consists of around 25k images extracted from online videos.Options:- A: CIFAR-10  B: COCO-Text  C: Stanford Cars  D: MPII Human Pose","answer":"CIFAR-10"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"RNA\\", \\"CellLine\\", \\"Protein\\", \\"DNA\\", \\"CellType\\"].Please return the output as a JSON object of the format: {\\"DNA\\" : [\\"TAL1\\", ...], \\"RNA\\": [\\"mRNAs\\", ...], \\"CellLine\\": [\\"T cells\\", ...], \\"CellType\\": [\\"monocytes\\", ...], \\"Protein\\": [\\"IL-2\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Activation of nuclear factor-kappaB via T cell receptor requires a Raf kinase and Ca2 + influx. Functional synergy between Raf and calcineurin. Signals transduced via the TCR activate the transcription factor nuclear factor-kappaB (NF-kappaB), which, in turn, is critical to the transcriptional induction of many genes important for the proliferation and expression of a differentiated phenotype. Treatment of T cells with the protein kinase C activator PMA in combination with Ca2 + ionophores mimics this process, and the two agents are often substituted for TCR stimulation, bypassing the TCR. Here we identify intracellular signaling components involved in activation of NF-kappaB following TCR stimulation. TCR signaling was triggered by treating Jurkat T cells with PHA or anti-CD3 Abs, and NF-kappaB activation was monitored by electrophoretic mobility shift assays and / or by kappaB-dependent reporter assays. Contrary to the idea that protein kinase C is involved in TCR-mediated activation of NF-kappaB, high doses of staurosporine did not interfere with activation of NF-kappaB by PHA, while the same dose of staurosporine completely blocked activation by PMA. PHA-induced kappaB-dependent reporter activity was, however, effectively blocked by a dominant negative form of Raf-1, suggesting a critical role for a Raf kinase. The TCR-mediated activation of NF-kappaB was also dependent on a Ca2 + influx, because the Ca2 + channel blocker, SK&F 96365, as well as other agents that prevented the Ca2 + influx, inhibited NF-kappaB activation. Cotransfection of a constitutively active form of calcineurin largely substituted for the Ca2 + requirement and reversed the blockade by SK&F 96365. Consistent with these observations, coexpression of constitutively active forms of Raf-1 and calcineurin synergistically induced kappaB-dependent reporter activity, suggesting a physiologically relevant functional interaction between the kinase and the phosphatase.","answer":"{\\"CellLine\\": [\\"Jurkat T cells\\"], \\"CellType\\": [\\"T cells\\"], \\"DNA\\": [], \\"Protein\\": [\\"PHA\\", \\"Raf kinase\\", \\"PHA - induced\\", \\"TCR\\", \\"TCR - mediated\\", \\"kinase\\", \\"calcineurin\\", \\"the TCR\\", \\"protein kinase C\\", \\"Raf\\", \\"kappaB\\", \\"phosphatase\\", \\"nuclear factor - kappaB\\", \\"the transcription factor nuclear factor - kappaB (NF - kappaB)\\", \\"anti - CD3 Abs\\", \\"Raf - 1\\", \\"T cell receptor\\", \\"NF - kappaB\\", \\"transcription factor\\"], \\"RNA\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Chemical\\"].Please return the output as a JSON object of the format: {\\"Chemical\\": [\\"Arsenic\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Understanding Morphology-Controlled Synthesis of Zinc Nanoparticles and Their Characteristics of Hydrolysis Reaction. Two-step thermochemical water-splitting cycle based on a Zn/ZnO redox pair is considered as a potential route for carbon-free production of hydrogen because the first hydrolysis step of the cycle highly depends on the method of preparation and the resultant particle characteristics, such as size, morphology, surface state, and initial oxide content. Here, employing a conventional evaporation and condensation method, we successfully produce three types of Zn nanoparticles ranging from nanorods, mesoporous nanorods with nanospheres on their surfaces, and fully sintered nanocrystals. The achievement in morphology control is realized simply by changing the injection position of the quenching gas. We found that the resultant hydrolysis kinetics is highly dependent on the morphology and porosity of the Zn nanoparticles. Finally, a series of simple mathematical modeling is made in an effort to understand the formation mechanism of Zn nanoparticles.","answer":"{\\"Chemical\\": [\\"Zn\\", \\"carbon\\", \\"oxide\\", \\"Zinc\\", \\"hydrogen\\", \\"ZnO\\"]}"},{"question":"You are presented with multiple paper abstracts, alongside the associated literature review and chapter titles. Given the provided information, you are going to do a literature review. Please generate a coherent literature review that synthesizes the content, draws connections between different works, highlights major findings, and identifies any gaps in the existing research.Literature Review Title: Methods and techniques of complex systems science: An overview Chapter Title:  D. The Nonlinear Dynamics Approach 1. Abstract of Cited Paper (BIB001):  Part I. Basic Concepts: 1. Introduction: why nonlinear methods? 2. Linear tools and general considerations 3. Phase space methods 4. Determinism and predictability 5. Instability: Lyapunov exponents 6. Self-similarity: dimensions 7. Using nonlinear methods when determinism is weak 8. Selected nonlinear phenomena Part II. Advanced Topics: 9. Advanced embedding methods 10. Chaotic data and noise 11. More about invariant quantities 12. Modeling and forecasting 13. Chaos control 14. Other selected topics Appendix 1. Efficient neighbour searching Appendix 2. Program listings Appendix 3. Description of the experimental data sets. 2. Abstract of Cited Paper (BIB002):  When a dynamical system is investigated from a time series, one of the most challenging problems is to obtain a model that reproduces the underlying dynamics. Many papers have been devoted to this problem but very few have considered the influence of symmetries in the original system and the choice of the observable. Indeed, it is well known that there are usually some variables that provide a better representation of the underlying dynamics and, consequently, a global model can be obtained with less difficulties starting from such variables. This is connected to the problem of observing the dynamical system from a single time series. The roots of the nonequivalence between the dynamical variables will be investigated in a more systematic way using previously defined observability indices. It turns out that there are two important ingredients which are the complexity of the coupling between the dynamical variables and the symmetry properties of the original system. As will be mentioned, symmetries and the choice of observables also has important consequences in other problems such as synchronization of nonlinear oscillators. (c) 2002 American Institute of Physics.Literature Review:","answer":"The younger approach to the analysis of time series comes from nonlinear dynamics, and is intimately bound up with the state-space approach described in §III.A above. The idea is that the dynamics on the state space can be determined directly from observations, at least if certain conditions are met. The central result here is the Takens Embedding Theorem  ; a simplified, slightly inaccurate version is as follows. Suppose the k-dimensional state vector x t evolves according to an unknown but continuous and (crucially) deterministic dynamic. Suppose, too, that the one-dimensional observable y is a smooth function of x, and \\"coupled\\" to all the components of x. Now at any time we can look not just at the present measurement y(t), but also at observations made at times removed from us by multiples of some lag τ : y t−τ , y t−2τ , etc. If we use k lags, we have a k-dimensional vector. One might expect that, as the number of lags is increased, the motion in the lagged space will become more and more predictable, and perhaps in the limit k → ∞ would become deterministic. In fact, the dynamics of the lagged vectors become deterministic at a finite dimension; not only that, but the deterministic dynamics are completely equivalent to those of the original state space! (More exactly, they are related by a smooth, invertible change of coordinates, or diffeomorphism.) The magic embedding dimension k is at most 2d + 1, and often less. Given an appropriate reconstruction via embedding, one can investigate many aspects of the dynamics. Because the reconstructed space is related to the original state space by a smooth change of coordinates, any geometric property which survives such treatment is the same for both spaces. These include the dimension of the attractor, the Lyapunov exponents (which measure the degree of sensitivity to initial conditions) and certain qualitative properties of the autocorrelation function and power spectrum (\\"correlation dimension\\"). Also preserved is the relation of \\"closeness\\" among trajectories -two trajectories which are close in the state space will be close in the embedding space, and vice versa. This leads to a popular and robust scheme for nonlinear prediction, the method of analogs: when one wants to predict the next step of the series, take the current point in the embedding space, find a similar one with a known successor, and predict that the current point will do the analogous thing. Many refinements are possible, such as taking a weighted average of nearest neighbors, or selecting an analog at random, with a probability decreasing rapidly with distance. Alternately, one can simply fit non-parametric predictors on the embedding space. (See BIB002 for a review.) Closely related is the idea of noise reduction, using the structure of the embedding-space to filter out some of the effects of measurement noise. This can work even when the statistical character of the noise is unknown (see Kantz and Schreiber again) . Determining the number of lags, and the lag itself, is a problem of model selection, just as in §II, and can be approached in that spirit. An obvious approach is to minimize the in-sample forecasting error, as with ARMA models. A more common procedure for determining the embedding dimension, however, is the false nearest neighbor method  . The idea is that if the current embedding dimension k is sufficient to resolve the dynamics, k + 1 would be too, and the reconstructed state space will not change very much. In particular, points which were close together in the dimension-k embedding should remain close in the dimension-k + 1 embedding. Conversely, if the embedding dimension is too small, points which are really far apart will be brought artificially close together (just as projecting a sphere on to a disk brings together points on the opposite side of a sphere). The particular algorithm of Kennel et al., which has proved very practical, is to take each point in the k-dimensional embedding, find its nearest neighbor in that embedding, and then calculate the distance between them. One then calculates how much further apart they would be if one used a k + 1-dimensional embedding. If this extra distance is more than a certain fixed multiple of the original distance, they are said to be \\"false nearest neighbors\\". (Ratios of 2 to 15 are common, but the precise value does not seem to matter very much.) One then repeats the process at dimension k + 1, stopping when the proportion of false nearest neighbors becomes zero, or at any rate sufficiently small. Here, the loss function used to guide model selection is the number of false nearest neighbors, and the standard prescriptions amount to empirical risk minimization. One reason simple ERM works well here is that the problem is intrinsically finite-dimensional (via the Takens result). Unfortunately, the data required for calculations of quantities like dimensions and exponents to be reliable can be quite voluminous. Approximately 10 2+0.4D data-points are necessary to adequately reconstruct an attractor of dimension D (Sprott, 2003, pp. 317-319) . (Even this is more optimistic than the widely-quoted, if apparently pessimistic, calculation of BIB001 , that attractor reconstruction with an embedding dimension of k needs 42 k data-points!) In the early days of the application of embedding methods to experimental data, these limitations were not well appreciated, leading to many calculations of low-dimensional deterministic chaos in EEG and EKG series, economic time series, etc., which did not stand up to further scrutiny. This in turn brought some discredit on the methods themselves, which was not really fair. More positively, it also led to the development of ideas such as surrogate-data methods. Suppose you have found what seems like a good embedding, and it appears that your series was produced by an underlying deterministic attractor of dimension D. One way to test this hypothesis would be to see what kind of results your embedding method would give if applied to similar but non-deterministic data. Concretely, you find a stochastic model with similar statistical properties (e.g., an ARMA model with the same power spectrum), and simulate many time-series from this model. You apply your embedding method to each of these surrogate data series, getting the approximate distribution of apparent \\"attractor\\" dimensions when there really is no attractor. If the dimension measured from the original data is not significantly different from what one would expect under this null hypothesis, the evidence for an attractor (at least from this source) is weak. To apply surrogate data tests well, one must be very careful in constructing the null model, as it is easy to use over-simple null models, biasing the test towards apparent determinism. A few further cautions on embedding methods are in order. While in principle any lag τ is suitable, in practice very long or very short lags both lead to pathologies. A common practice is to set the lag to the autocorrelation time (see above), or the first minimum of the mutual information function (see §VII below), the notion being that this most nearly achieves a genuinely \\"new\\" measurement  . There is some evidence that the mutual information method works better  . Again, while in principle almost any smooth observation function will do, given enough data, in practice some make it much easier to reconstruct the dynamics; several indices of observability try to quantify this BIB003 . Finally, it strictly applies only to deterministic observations of deterministic systems. Embedding approaches are reasonably robust to a degree of noise in the observations. They do not cope at all well, however, to noise in the dynamics itself. To anthropomorphize a little, when confronted by apparent non-determinism, they respond by adding more dimensions, and so distinguishing apparently similar cases. Thus, when confronted with data which really are stochastic, they will infer an infinite number of dimensions, which is correct in a way, but definitely not helpful. These remarks should not be taken to belittle the very real power of nonlinear dynamics methods. Applied skillfully, they are powerful tools for understanding the behavior of complex systems, especially for probing aspects of their structure which are not directly accessible."},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Does the majority of the mitochondrial genomes abide to the second parity rule (PR2)?Context: a large number of mitochondrial genomes significantly deviate from the 2nd parity rule in contrast to the eubacterial onesmitochondria may be divided into three distinct sub-groups according to their overall deviation from the aforementioned parity rule.The behaviour of the large majority of the mitochondrial genomes may be attributed to their distinct mode of replication, which is fundamentally different from the one of the eubacteria.We tested all available organellar genomes and found that a large number of mitochondrial genomes significantly deviate from the 2nd parity rule in contrast to the eubacterial ones, although mitochondria are believed to have evolved from proteobacteria.The behaviour of the large majority of the mitochondrial genomes may be attributed to their distinct mode of replication, which is fundamentally different from the one of the eubacteria.We tested all available organellar genomes and found that a large number of mitochondrial genomes significantly deviate from the 2nd parity rule in contrast to the eubacterial ones, although mitochondria are believed to have evolved from proteobacteria.The behaviour of the large majority of the mitochondrial genomes may be attributed to their distinct mode of replication, which is fundamentally different from the one of the eubacteriaWe tested all available organellar genomes and found that a large number of mitochondrial genomes significantly deviate from the 2nd parity rule in contrast to the eubacterial ones, although mitochondria are believed to have evolved from proteobacteria","answer":"no"},{"question":"You will be shown inclusion or exclusion criteria for a clinical trial. Given these criteria, your task is to extract all unique entities of the following types: [\\"Observation\\", \\"Condition\\", \\"Procedure\\", \\"Drug\\", \\"Temporal\\", \\"Multiplier\\", \\"Qualifier\\", \\"Negation\\", \\"ReferencePoint\\", \\"Scope\\", \\"Value\\", \\"Mood\\", \\"Device\\", \\"Visit\\", \\"Measurement\\", \\"Person\\"].Please return the output as a JSON object of the format: {\\"Condition\\" : [\\"breast cancer\\", ...], \\"Device\\" : [\\"ports\\", ...], \\"Drug\\" : [\\"Atenolol\\", ...], \\"Measurement\\" : [\\"blood pressure\\", ...], \\"Mood\\" : [\\"suspected\\", ...], \\"Multiplier\\" : [\\"more than two\\", ...], \\"Negation\\" : [\\"no\\", ...], \\"Observation\\" : [\\"history\\", ...], \\"Person\\" : [\\"male\\", ...], \\"Procedure\\" : [\\"surgery\\", ...], \\"Qualifier\\" : [\\"severe\\", ...], \\"ReferencePoint\\" : [\\"enrollment\\", ...], \\"Scope\\" : [\\"infection\\", ...], \\"Temporal\\" : [\\"one day\\", ...], \\"Value\\" : [\\"50%\\", ...], \\"Visit\\" : [\\"ICU\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Patient refusalAllergy to local anaesthesiaSevere coagulopathyContralateral phrenic nerve palsyLocal infectionModerate to severe pulmonary dysfunction (GOLD II, II, IV)","answer":"{\\"Condition\\": [\\"Local infection\\", \\"coagulopathy\\", \\"phrenic nerve palsy\\", \\"Allergy\\", \\"pulmonary dysfunction\\"], \\"Device\\": [], \\"Drug\\": [\\"local anaesthesia\\"], \\"Measurement\\": [\\"GOLD\\"], \\"Mood\\": [], \\"Multiplier\\": [], \\"Negation\\": [], \\"Observation\\": [], \\"Person\\": [], \\"Procedure\\": [], \\"Qualifier\\": [\\"severe\\", \\"Moderate\\", \\"Severe\\", \\"Contralateral\\"], \\"ReferencePoint\\": [], \\"Scope\\": [\\"GOLD II, II, IV\\", \\"Moderate to severe\\"], \\"Temporal\\": [], \\"Value\\": [\\"II, II, IV\\"], \\"Visit\\": []}"},{"question":"You will be presented with a citation segment from the section of a research paper. Classify the intent behind this citation by choosing from one of the following categories:- Method: Cites the paper for its methodology or procedure.- Background: Cites the paper to provide background information.- Result: Cites the paper for its findings or results.Your answer should be a single word from the following list of options: [\\"Method\\", \\"Background\\", \\"Result\\"]. Do not include any other text in your response.Citation sentence:Moreover, the publications suggest that the approach makes it possible to foster a ‘shared responsibility between students and instructors’ (McLaughlin et al., 2014, p. 242), and overall, optimising classroom time is often specifically emphasised (Gannod et al., 2008; Mason et al., 2013; McLaughlin…","answer":"Background"},{"question":"You have to answer a biomedical question in binary format, i.e. only yes and no are the only acceptable answer formats. A list of paragraphs is provided as context to help you answer the question.Question: Are there ultraconserved regions in the budding yeast (Saccharomyces cerevisiae)?Context: The systematic analysis of ultraconserved genomic regions in the budding yeast.In the evolution of species, a kind of special sequences, termed ultraconserved sequences (UCSs), have been inherited without any change, which strongly suggests those sequences should be crucial for the species to survive or adapt to the environment. However, the UCSs are still regarded as mysterious genetic sequences so far. Here, we present a systematic study of ultraconserved genomic regions in the budding yeast based on the publicly available genome sequences, in order to reveal their relationship with the adaptability or fitness advantages of the budding yeast.Results: Our results indicate that, in addition to some fundamental biological functions, the UCSs play an important role in the adaptation of Saccharomyces cerevisiae to the acidic environment, which is backed up by the previous observation. Besides that, we also find the highly unchanged genes are enriched in some other pathways, such as the nutrient-sensitive signaling pathway. To facilitate the investigation of unique UCSs, the UCSC Genome Browser was utilized to visualize the chromosomal position and related annotations of UCSs in S.cerevisiae genome.Here, we present a systematic study of ultraconserved genomic regions in the budding yeast based on the publicly available genome sequences, in order to reveal their relationship with the adaptability or fitness advantages of the budding yeast.Motivation In the evolution of species, a kind of special sequences, termed ultraconserved sequences (UCSs), have been inherited without any change, which strongly suggests those sequences should be crucial for the species to survive or adapt to the environment.The systematic analysis of ultraconserved genomic regions in the budding yeast.<AbstractText Label=\\"Motivation\\">In the evolution of species, a kind of special sequences, termed ultraconserved sequences (UCSs), have been inherited without any change, which strongly suggests those sequences should be crucial for the species to survive or adapt to the environment.Here, we present a systematic study of ultraconserved genomic regions in the budding yeast based on the publicly available genome sequences, in order to reveal their relationship with the adaptability or fitness advantages of the budding yeast.Here, we present a systematic study of ultraconserved genomic regions in the budding yeast based on the publicly available genome sequences, in order to reveal their relationship with the adaptability or fitness advantages of the budding yeast.<br><b>Results</b>: Our results indicate that, in addition to some fundamental biological functions, the UCSs play an important role in the adaptation of Saccharomyces cerevisiae to the acidic environment, which is backed up by the previous observation.","answer":"yes"},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: The coronavirus may have been leaked from the Wuhan Institute of VirologyAbstract:Origin of the COVID-19 virus has been intensely debated in the scientific community since the first infected cases were detected in December 2019.The disease has caused a global pandemic, leading to deaths of thousands of people across the world and thus finding origin of this novel coronavirus is important in responding and controlling the pandemic.Recent research results suggest that bats or pangolins might be the original hosts for the virus based on comparative studies using its genomic sequences.This paper investigates the COVID-19 virus origin by using artificial intelligence (AI) and raw genomic sequences of the virus.More than 300 genome sequences of COVID-19 infected cases collected from different countries are explored and analysed using unsupervised clustering methods.The results obtained from various AI-enabled experiments using clustering algorithms demonstrate that all examined COVID-19 virus genomes belong to a cluster that also contains bat and pangolin coronavirus genomes.This provides evidences strongly supporting scientific hypotheses that bats and pangolins are probable hosts for the COVID-19 virus.At the whole genome analysis level, our findings also indicate that bats are more likely the hosts for the COVID-19 virus than pangolins.","answer":"{\\"verdict\\": \\"CONTRADICT\\", \\"evidence\\": [\\"Recent research results suggest that bats or pangolins might be the original hosts for the virus based on comparative studies using its genomic sequences.\\", \\"The results obtained from various AI-enabled experiments using clustering algorithms demonstrate that all examined COVID-19 virus genomes belong to a cluster that also contains bat and pangolin coronavirus genomes.\\", \\"This provides evidences strongly supporting scientific hypotheses that bats and pangolins are probable hosts for the COVID-19 virus.\\", \\"At the whole genome analysis level, our findings also indicate that bats are more likely the hosts for the COVID-19 virus than pangolins.\\"]}"},{"question":"Given an abstract from a research paper, your task is to identify and label relationships between chemical compounds and genes mentioned in the abstract.The relationship type must be one of ['DOWNREGULATOR', 'SUBSTRATE', 'INDIRECT-REGULATOR', 'PART-OF', 'MODULATOR-ACTIVATOR', 'REGULATOR', 'INHIBITOR', 'COFACTOR', 'UPREGULATOR', 'ACTIVATOR', 'ANTAGONIST', 'NOT', 'INDIRECT-DOWNREGULATOR', 'SUBSTRATE_PRODUCT-OF', 'INDIRECT-UPREGULATOR', 'AGONIST', 'PRODUCT-OF', 'MODULATOR', 'DIRECT-REGULATOR', 'UNDEFINED', 'AGONIST-INHIBITOR', 'AGONIST-ACTIVATOR', 'MODULATOR-INHIBITOR'].Please format your output as a JSON array. Each entry in the array should express a single relation, formatted as [\\"<Entity_A>\\", \\"<RELATION_A_B>\\", \\"<Entity_B>\\"]. If no relations can be found, please output an empty JSON array [].Abstract:Degradation of MAC13243 and studies of the interaction of resulting thiourea compounds with the lipoprotein targeting chaperone LolA. The discovery of novel small molecules that function as antibacterial agents or cellular probes of biology is hindered by our limited understanding of bacterial physiology and our ability to assign mechanism of action. We previously employed a chemical genomic strategy to identify a novel small molecule, MAC13243, as a likely inhibitor of the bacterial lipoprotein targeting chaperone, LolA. Here, we report on the degradation of MAC13243 into the active species, S- (4-chlorobenzyl) isothiourea. Analogs of this compound (e.g., A22) have previously been characterized as inhibitors of the bacterial actin-like protein, MreB. Herein, we demonstrate that the antibacterial activity of MAC13243 and the thiourea compounds are similar; these activities are suppressed or sensitized in response to increases or decreases of LolA copy number, respectively. We provide STD NMR data which confirms a physical interaction between LolA and the thiourea degradation product of MAC13243, with a Kd of ~150 μM. Taken together, we conclude that the thiourea series of compounds share a similar cellular mechanism that includes interaction with LolA in addition to the well-characterized target MreB.","answer":"[[\\"thiourea\\", \\"DIRECT-REGULATOR\\", \\"LolA\\"], [\\"MAC13243\\", \\"INHIBITOR\\", \\"chaperone\\"], [\\"MAC13243\\", \\"DIRECT-REGULATOR\\", \\"LolA\\"], [\\"thiourea\\", \\"REGULATOR\\", \\"lipoprotein\\"], [\\"thiourea\\", \\"REGULATOR\\", \\"chaperone\\"], [\\"MAC13243\\", \\"INHIBITOR\\", \\"bacterial lipoprotein\\"]]"},{"question":"You will be shown a question, followed by excerpts from biomedical research papers. Please answer the question based on the provided context. Do not include any text in your response other than the answer.Question: What is known about the effect of acupuncture in smoking cessation ?Context: Ear acupressure (EAP) and ear acupuncture have been used for smoking cessation, and some positive results have been reportedAuricular (ear) acupressure has been purported to be beneficial in achieving smoking cessation in some studies, while in others has been deemed insignificantAcupuncture combined with auricular point sticking and pressing has reliable therapeutic effect for smoking cessationAcupuncture has been promoted as a treatment modality for smoking cessation. However, its efficacy still remains controversialOur results showed that auricular acupuncture did not have a better efficacy in smoking cessation compared to sham acupuncture. Combined acupuncture with behavior counseling or with nicotine replacement therapy should be used in further smoking cessation trials to enhance the success rate of smoking cessation.Combining ten studies showed auricular acupuncture at 'correct' points to be more effective than control interventions, odds ratio 2.24 (95% CI 1.61, 3.10),Auricular acupuncture appears to be effective for smoking cessation, but the effect may not depend on point location.The combination of auricular acupressure and Internet-assisted smoking cessation program was more efficacious than auricular acupressure alone in terms of quit rate.auricular acupuncture in smoking cessation has some effect.With a one-year success rate of 41.1% ear acupuncture is a competitive alternative to orthodox medicine withdrawal methods. Acupuncture treatment can be applied and adapted individually, furthermore it is economical and without side effects.Auriculotherapy is an useful aid for giving up smoking. It is easy and painless, has no secondary effects and it is economic.the combined acupuncture-education group showing the greatest effect from treatment.Acupuncture and education, alone and in combination, significantly reduce smoking; however, combined they show a significantly greater effect, as seen in subjects with a greater pack-year history.A double blind, randomized, placebo-controlled clinical study was conducted to evaluate the efficacy of laser acupuncture treatment in adolescent smokers.Thus, there was no significant difference in the rates of smoking cessation in the treatment and control groups.This simple ear electroacupuncture treatment was significantly more effective in helping volunteers to quit smoking than placebo treatment.","answer":"Ear acupressure (EAP) and ear acupuncture have been used for smoking cessation, and some positive results have been reported.Auricular (ear) acupressure has been purported to be beneficial in achieving smoking cessation in some studies, while in others has been deemed insignificant.The combined acupuncture-education group showing the greatest effect from treatment."},{"question":"You will be shown a paragraph from a biomedical research article. Your task is to extract all drug combinations appearing in a specific sentence within in the paragraph. Each drug combination should be assigned to one of the following three categories:- POS: Indicates a positive interaction between the drugs in the combination; for instance, drugs that have an additive or synergistic effect.- NEG: Indicates a negative interaction between the drugs in the combination; for instance, combining these drugs might result in adverse side effects, or might reduce their efficacy.- COMB: Indicates that the drugs are given in combination, but the type of interaction between the drugs cannot be determined based on the provided context.Please format your answer as a json array. Each entry in the array should itself be an array formatted as [<drug_1>, <drug_2>, ..., <drug_n>, <category>] where <category> is one of the three categories listed above and <drug_1>, ..., <drug_n> are drug names copied verbatim from the input sentence. Different combinations may involve different numbers of drugs; in other words, the \`n\` in <drug_n> may vary.As an example, the following output describes two extracted drug combinations; one between two drugs, and one between three drugs:[[\\"artesunate\\", \\"artemether\\", \\"COMB\\"], [\\"Nifedipine\\", \\"Labetalol\\", \\"Prazosin\\", \\"POS\\"]]The paragraph and specific sentence are below. You should only extract relationships expressed in the specific sentence; the paragraph is provided for context.In your output, return only the json array and no other text. If no drug combinations appear, return an empty array \`[]\`.paragraph: Specific downregulation of bcl-2 and xIAP by RNAi enhances the effects of chemotherapeutic agents in MCF-7 human breast cancer cells. Antiapoptotic genes such as bcl-2 or xIAP may be responsible for resistance to apoptosis induced by cytotoxic drugs. The aim of this study was to investigate if downregulation of bcl-2 or xIAP by RNA interference (RNAi) would sensitize MCF-7 cells to etoposide and doxorubicin. FITC-siRNAs uptake was verified by fluorescence microscopy and downregulation of Bcl-2 or XIAP was confirmed by Western Blotting. Both siRNAs reduced the number of viable cells and increased cellular apoptosis. Treatment with siRNAs followed by treatment with etoposide or doxorubicin further reduced the number of viable cells, when compared to either of the treatments alone. Therefore , downregulation of bcl-2 or xIAP by RNAi enhances the effects of etoposide and doxorubicin .sentence: Therefore , downregulation of bcl-2 or xIAP by RNAi enhances the effects of etoposide and doxorubicin .","answer":"[]"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Brand\\", \\"UnapprovedDrug\\", \\"Drug\\", \\"DrugGroup\\"].Please return the output as a JSON object of the format: {\\"Brand\\" : [\\"Aspirin\\", ...], \\"DrugGroup\\": [\\"Salicyclate\\", ...], \\"Drug\\": [\\"Phenobarbital\\", ...], \\"UnapprovedDrug\\": [\\"Heroin\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Potentially fatal drug interactions may occur when coadministered with digoxin, as this may enhance cardiovascular depression and bradyarrhythmias may occur. Anticholinesterases (neostgmine, physostigmine), lignocaine, quinine, procainamide can enhance toxicity and cause cardio respiratory depression. In addition, neuromuscular blocking action is enhanced by general anesthetics, local anesthetics like lidocaine, procaine, beta-blockers, metaclopramide, lithium carbonate, and terbutaline.","answer":"{\\"Brand\\": [], \\"Drug\\": [\\"lidocaine\\", \\"physostigmine\\", \\"lithium carbonate\\", \\"digoxin\\", \\"procaine\\", \\"procainamide\\", \\"terbutaline\\", \\"lignocaine\\", \\"metaclopramide\\", \\"quinine\\"], \\"DrugGroup\\": [\\"anesthetics\\", \\"beta-blockers\\", \\"Anticholinesterases\\"], \\"UnapprovedDrug\\": []}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"AnatomicalEntity\\"].Please return the output as a JSON object of the format: {\\"AnatomicalEntity\\": [\\"tumor cells\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Mitochondria in Cardiac Myocyte ApoptosisIt has been suggested that activation of the mitochondrial apoptotic pathway leading to executioner casp activation is relevant in heart injury.1 The notion of participation of casp activation in adult cardiac myocyte apoptosis emerged from studies using immunofluorescence microscopy16 and casp inhibitors.37 Bahi et al.38 demonstrated that cardiomyocyte levels of all casps decrease with age, and they are very low in adult cardiac cells. Recently, Bae et al.39 reported that apoptosis can be induced in the heart lacking casp activation via casp-independent pathways, probably through apoptosis-inducing factor (AIF). Both the intrinsic and extrinsic pathways can be inhibited by the cytoprotective protein apoptosis repressor with caspase recruitment domain (ARC). ARC inhibits the extrinsic pathway by interacting with casp 8 and components of the death-inducing signaling complex, such as FADD, whereas inhibition of the intrinsic pathway is mediated by blocking BAX activation and mitochondria translocation.40AIF is anchored by its N terminus to the mitochondrial inner membrane, with its C terminus oriented toward the intermembrane space. AIF is required for oxidative phosphorylation and for the assembly and/or stabilization of respiratory complex I.41 Upon induction of apoptosis, AIF is cleaved and released into the cytosol, where it translocates to the nucleus and mediates chromatin condensation and large-scale DNA fragmentation.41 However, this well-known pro-apoptotic action of AIF is in conflict with the observation that AIF is essential for the maintenance of normal heart function and its inactivation results in dilated C.42 Moreover, cardiac myocytes isolated from a mouse model with 80% reduction in AIF levels manifested increased cell death induced by oxidative stress, and the hearts of these mice displayed enhanced ischemic damage after in vivo I/R.43 Although it has been described that AIF is released from cardiac myocyte mitochondria during I/R, its contribution to I/R-induced apoptosis was discounted.38 However, AIF has been implicated in cardiac myocyte death induced by oxidative stress and HF.44Endonuclease G (Endo G) is a nuclear-encoded endonuclease localized to the intermembrane space of mitochondria. In cardiac myocyte apoptosis, Endo G translocates to the nucleus, where it cleaves DNA. In heart and cultured cardiac myocytes, Endo G has a role in I/R-mediated cell death.38 Activation of the intrinsic pathway by the extrinsic apoptotic pathway can take place through casp-8-dependent cleavage of BCL2-interacting protein (BID) to truncated BID (t-BID). The C-terminal fragment of t-BID subsequently translocates to the mitochondrial outer membrane, where it presumably activates the intrinsic pathway. This pathway is operative in the heart.1","answer":"{\\"AnatomicalEntity\\": [\\"mitochondrial outer membrane\\", \\"adult cardiac cells\\", \\"cardiac myocyte mitochondria\\", \\"cytosol\\", \\"Mitochondria\\", \\"nucleus\\", \\"Cardiac Myocyte\\", \\"cell\\", \\"cardiac myocytes\\", \\"adult cardiac myocyte\\", \\"cardiomyocyte\\", \\"mitochondria\\", \\"heart\\", \\"chromatin\\", \\"mitochondrial\\", \\"hearts\\", \\"nuclear\\", \\"mitochondrial inner membrane\\", \\"intermembrane space\\", \\"cardiac myocyte\\"]}"},{"question":"You will be shown an abstract from a biomedical research paper. Given this abstract, your task is to extract all unique entities of the following types: [\\"Outcome\\", \\"Participant\\", \\"Intervention\\"].Please return the output as a JSON object of the format: {\\"Participant\\" : [\\"patients with COPD\\", ...], \\"Intervention\\" : [\\"Atenolol\\", ...], \\"Outcome\\" : [\\"blood pressure\\", ...]}. The keys should be entity types and values should be lists of extracted entities belonging to the corresponding type. If you cannot find entities belonging to a specific type, the value should be [].Only output the JSON object and do not include any additional text.Abstract:Safety of nifedipine in patients with hypertension : a meta-analysis . Our objective was to compare cardiovascular event rates in patients with mild or moderate hypertension who received nifedipine with active drug controls . We performed a MEDLARS search using the MeSH heading \\" hypertension \\" and the text word \\" nifedipine \\" to identify all articles that were published between 1966 and August 1995 in English , French , German , Italian , and Spanish languages and that involved human subjects . The computerized search was supplemented by a manual search of article bibliographies . Review of 1880 citations revealed 98 randomized controlled clinical trials that met protocol criteria . Articles were extracted independently by two doctors who were blinded for author , institution , and treatment regimen , using a structured , pretested extraction form . Differences of opinion were resolved by consensus . Fourteen events occurred in 5198 exposures ( 0.27 % ) to nifedipine and 24 events in 5402 exposures ( 0.44 % ) to other active drug controls . Unadjusted odds ratios for nifedipine versus controls were 0.49 ( 95 % confidence interval [ CI ] , 0.22-1.09 ) for definitive events ( death , nonfatal myocardial infarction or stroke , revascularization procedure ) and 0.61 ( 95 % CI , 0.31-1.17 ) for all events ( definitive plus increased angina ) . The odds ratio for nifedipine monotherapy ( sustained- or extended-release in 91 % of exposures ) was nonsignificantly higher for definitive and all events ( odds ratio , 1.40 ; 95 % CI , 0.49-4.03 and odds ratio , 1.39 ; 95 % CI , 0.59-3.32 , respectively ) . The odds ratio for nifedipine in combination with another drug was significantly lower for definitive and all events ( odds ratio , 0.09 ; 95 % CI , 0.01-0.66 and odds ratio , 0.15 ; 95 % CI , 0.03-0.65 , respectively ) . Differences in odds ratio for nifedipine monotherapy and combined therapy were statistically significant ( P=.02 for definitive events and P=.001 for all events ) . Results support the safety of sustained- and extended-release nifedipine in the treatment of mild or moderate hypertension when it is used in combination with other drugs .","answer":"{\\"Intervention\\": [\\"active drug controls\\", \\"nifedipine\\"], \\"Outcome\\": [\\"death\\", \\"Safety\\", \\"cardiovascular event rates\\", \\"Unadjusted odds ratios\\", \\"odds ratio for nifedipine monotherapy\\", \\"safety of sustained- and extended-release nifedipine\\", \\"odds ratio for nifedipine in combination with another drug\\", \\"Differences in odds ratio for nifedipine monotherapy and combined therapy\\", \\"nonfatal myocardial infarction or stroke , revascularization procedure\\", \\"all events ( definitive plus increased angina ) .\\"], \\"Participant\\": [\\"mild or moderate hypertension\\", \\"hypertension\\"]}"},{"question":"You will be shown a claim about public health, and the abstract of a biomedical research paper. Each sentence from the abstract will be on a separate line. Your task is to return a JSON object with two fields:- \\"verdict\\": The fact-checking verdict. If the information in the abstract supports the claim, write \\"SUPPORT\\". If the abstract contradicts the claim, write \\"CONTRADICT\\". If the abstract does not provide enough information to arrive at a verdict, write \\"NEI\\" (for \\"not enough information\\").- \\"evidence\\": An array of sentences providing evidence for the verdict. Please copy all relevant sentences verbatim from the abstract. If the verdict was \\"NEI\\", then return an empty array.For instance, if the model were given the claim \\"wearing masks can prevent the spread of COVID\\", the output might be{  \\"verdict\\": \\"SUPPORT\\",  \\"evidence\\": [\\"Our findings indicate that mass mask-wearing reduces the transmission rate for COVID-19.\\"]}Claim: There is Potential Role of Social Distancing in Mitigating Spread of Coronavirus DiseaseAbstract:OBJECTIVE.To analyze the effectiveness of social distancing in the United States (U.S.).METHODS.A novel cell-phone ping data was used to quantify the measures of social distancing by all U.S. counties.RESULTS.Using a difference-in-difference approach results show that social distancing has been effective in slowing the spread of COVID-19.CONCLUSIONS.As policymakers face the very difficult question of the necessity and effectiveness of social distancing across the U.S., counties where the policies have been imposed have effectively increased social distancing and have seen slowing the spread of COVID-19.These results might help policymakers to make the public understand the risks and benefits of the lockdown.","answer":"{\\"verdict\\": \\"SUPPORT\\", \\"evidence\\": [\\"As policymakers face the very difficult question of the necessity and effectiveness of social distancing across the U.S., counties where the policies have been imposed have effectively increased social distancing and have seen slowing the spread of COVID-19.\\"]}"}]`),D={name:"App",components:{PoemCard:R},data(){return{searchQuery:"",visibleCount:6,poemsData:O,isLoading:!1}},computed:{filteredPoems(){return this.searchQuery.trim()?this.poemsData.filter(i=>{const e=this.searchQuery.toLowerCase();return i.question.toLowerCase().includes(e)||i.answer.toLowerCase().includes(e)}).slice(0,this.visibleCount):this.poemsData.slice(0,this.visibleCount)},hasMorePoems(){return this.visibleCount<this.poemsData.length}},methods:{async loadMore(){this.isLoading=!0,await new Promise(i=>setTimeout(i,1e3)),this.visibleCount+=6,this.isLoading=!1}}},N={class:"search-container"},M={class:"card-container"},E=["disabled"],B={key:0},q={key:1};function F(i,e,l,u,o,s){const m=f("PoemCard");return a(),n("section",null,[e[3]||(e[3]=t("div",{class:"top-banner"},[t("div",{class:"top-banner-title"},[t("div",{class:"top-banner-title-text"},"🤔 AI effective tips collection 🧠")])],-1)),t("div",N,[e[2]||(e[2]=t("span",{class:"search-icon"},null,-1)),g(t("input",{type:"text",class:"search-input","onUpdate:modelValue":e[0]||(e[0]=r=>o.searchQuery=r),placeholder:"Search..."},null,512),[[y,o.searchQuery]])]),t("div",M,[(a(!0),n(b,null,w(s.filteredPoems,(r,p)=>(a(),v(m,{key:p,poem:r},null,8,["poem"]))),128))]),s.hasMorePoems?(a(),n("button",{key:0,class:"load-more-button",disabled:o.isLoading,onClick:e[1]||(e[1]=(...r)=>s.loadMore&&s.loadMore(...r))},[o.isLoading?(a(),n("span",q,"Loading...")):(a(),n("span",B,"See more"))],8,E)):x("",!0)])}const z=h(D,[["render",F],["__scopeId","data-v-3f33025e"]]),G=JSON.parse('{"title":"","description":"","frontmatter":{"page":true},"headers":[],"relativePath":"library/46.md","filePath":"library/46.md"}'),L={name:"library/46.md"},W=Object.assign(L,{setup(i){return(e,l)=>(a(),n("div",null,[T(z)]))}});export{G as __pageData,W as default};
